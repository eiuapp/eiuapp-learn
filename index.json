[
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/",
	"title": "前言",
	"tags": [],
	"description": "blog",
	"content": " 内容介绍 这是个人博客, 主要包括一些学习笔记\n访问方式 请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-docker-break-ufw-rules-state-1.html",
	"title": "docker break ufw&#39;s rules in ubuntu - env1",
	"tags": [],
	"description": "docker break ufw&#39;s rules in ubuntu - env1",
	"content": " docker break ufw\u0026rsquo;s rules in ubuntu - env1\nenv 当运行docker后\nsudo docker run --detach \\ --restart always \\ --hostname 192.168.168.137 \\ --publish 192.168.168.137:12443:443 --publish 192.168.168.137:80:80 --publish 192.168.168.137:22:22 \\ --name gitlab-ce-11.9.1-2 \\ --volume /srv/gitlab9.1/config:/etc/gitlab \\ --volume /srv/gitlab9.1/logs:/var/log/gitlab \\ --volume /srv/gitlab9.1/data:/var/opt/gitlab \\ gitlab/gitlab-ce:11.9.1-ce.0  也会导致 整个局域网能访问到 80\nsudo docker run --detach \\ --restart always \\ --hostname 192.168.168.137 \\ --publish 127.0.0.1:12443:443 --publish 127.0.0.1:80:80 --publish 127.0.0.1:22:22 \\ --name gitlab-ce-11.9.1-2 \\ --volume /srv/gitlab9.1/config:/etc/gitlab \\ --volume /srv/gitlab9.1/logs:/var/log/gitlab \\ --volume /srv/gitlab9.1/data:/var/opt/gitlab \\ gitlab/gitlab-ce:11.9.1-ce.0  会导致 无法通过IP 192.168.168.137 来访问 80\nubuntu@utuntu:~$ telnet 127.0.0.1 80 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is '^]'. ^] telnet\u0026gt; ^CConnection closed by foreign host. ubuntu@utuntu:~$ telnet 192.168.168.137 80 Trying 192.168.168.137... telnet: Unable to connect to remote host: Connection refused ubuntu@utuntu:~$  step 这时, 参考\nhttps://chaifeng.com/to-fix-ufw-and-docker-security-flaw-without-disabling-iptables/\n发现没用.\n再参考\nhttps://my.oschina.net/abcfy2/blog/539485 和 https://blog.36web.rocks/2016/07/08/docker-behind-ufw.html\n正确.\n注意  无需重启host ubuntu下还需要配置 /lib/systemd/system/docker.service 的 ExecStart 加上--iptables=false, 然后, systemctl daemon-reload`  docker 编辑/etc/default/docker文件，修改DOCKER_OPTS=\u0026ldquo;\u0026ndash;iptables=false\u0026rdquo;，等同于给docker启动参数添加\u0026ndash;iptables=false选项，此选项会禁用docker添加iptables规则。\nubuntu@utuntu:~/lcnx/local/lvchuang-admin-server$ sudo cat /etc/default/docker | grep DOCKER_OPTS # Use DOCKER_OPTS to modify the daemon startup options. #DOCKER_OPTS=\u0026quot;--dns 8.8.8.8 --dns 8.8.4.4\u0026quot; DOCKER_OPTS=\u0026quot;--iptables=false\u0026quot; ubuntu@utuntu:~/lcnx/local/lvchuang-admin-server$  同时,还要修改一下 docker.service 文件\nubuntu@utuntu:~/lcnx/local/lvchuang-admin-server$ sudo vi /lib/systemd/system/docker.service ubuntu@utuntu:~/lcnx/local/lvchuang-admin-server$ sudo cat /lib/systemd/system/docker.service | grep ExecStart ExecStart=/usr/bin/dockerd --iptables=false --containerd=/run/containerd/containerd.sock ubuntu@utuntu:~/lcnx/local/lvchuang-admin-server$  重启docker\nsudo systemctl daemon-reload sudo systemctl restart docker  ufw 编辑/etc/ufw/before.rules这个文件，在文件末尾追加以下内容:\n*nat :POSTROUTING ACCEPT [0:0] -A POSTROUTING ! -o docker0 -s 172.17.0.0/16 -j MASQUERADE COMMIT  之后重启一下ufw规则即可:\nsudo ufw disable sudo ufw enable  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/_index.zh.html",
	"title": "前言",
	"tags": [],
	"description": "介绍Hugo学习笔记的基本资料和访问方式",
	"content": " 内容介绍 Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\nHugo以速度快著称，号称是世界上最快的网站生成框架。\nThe world’s fastest framework for building websites\n访问方式 这是个人学习Hugo的笔记，请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。托管于腾讯云香港节点，速度快，偶尔抽风 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/babun/babun-quick-start.html",
	"title": "最快入门 babun",
	"tags": ["babun"],
	"description": "最快入门 babun",
	"content": " https://www.hi-linux.com/posts/57246.html\n最快入门 babun\n什么是babun babun是windows上的一个第三方shell，在这个shell上面你可以使用几乎所有linux，unix上面的命令，他几乎可以取代windows的shell。用官方的题目说就是A Windows shell you will love!\nbabun的几个特点\n使用babun无需管理员权限 先进的安装包管理器(类似于linux上面的apt-get或yum) 预先配置了Cygwin和很多插件 拥有256色的兼容控制台 HTTP(S)的代理支持 面向插件的体系结构 可以使用它来配置你的git 集成了oh-my-zsh 自动升级 支持shell编程，内置VIM等 Cygwin babun的核心包括一个预配置的Cygwin。cygwin是一个非常好的工具，但有很多使用技巧，使你能够节省大量的时间。babun解决了很多问题，它里面包含了很多重要的软件包，是你能够第一时间能够使用它们。 包的管理： babun的包管理在shell输入：pact，这类似于：apt-get或yum，来非常方便的管理软件包，安装、升级、搜索和删除，让你省区很多麻烦，shell输入pact --help能够获得帮助信息。 shell babun的shell通过调整，已达到最佳的用户体验，babun有两个配置之后马上使用的shell(默认使用zsh)，babun的shell具有以下的特点 语法高亮 具有unix的工具 软件开发工具 git-语义提示 自定义脚本和别名 等等… Console babun支持HTTP代理，只需添加地址和HTTP代理服务器的凭据。babunrc文件所在文件夹执行源babunrc启用HTTP代理。目前还不支持SOCKS代理。 开发者工具 babun提供多种方便的工具和脚本，是你的开发工作更轻松，具有的功能如下 编程语言(python,Perl, etc等) git(各种各样的别名调整) UNIX工具((grep, wget, curl, etc) vcs (svn, git) oh-my-zsh 自定义脚本(pbcopy, pbpaste, babun, etc)  babun官网链接：http://babun.github.io/\n什么是cmder cmder是window下的多标签命令行工具，可以方便的新建cmd、cmd admin、powershell、powershell admin多种命令行，设置很多，功能强大。\n安装 cmder安装 下载：http://cmder.net/\ncmder是开箱即用的软件就不在详述了，具体使用可参考官网说明。\nbabun安装 下载：http://babun.github.io/\n默认安装 下载完成之后解压babun，直接双击目录中install.bat脚本(需管理员权限)进行安装。几分钟之后自动安装完成，默认会被安装在%userprofile%\\.babun目录下。\n自定义安装位置 通过cmd命令行在执行install.bat时指定参数/t或/target指定安装的目录。\n执行：babun.bat /t c:\\babun\n安装好之后会在c:\\babun目录下生成一个.babun的目录，babun所有文件都在这个目录中。注意安装目录最好不要有空格，这是cygwin要求的。\n测试安装成功 安装完毕后，一般需要以下两个命令检查\nbabun check(用于判断环境是否正确) babun update(用于判断是否有新的更新包)  Babun配置 默认根目录\n%userprofile%\\.babun\\cygwin\\home\\Mike  windows cmd内置命令显示中文 babun默认编码是UTF-8的，而windows的cmd命令输出是GBK编码的，所以在Babun里面运行ipconfig等windows命令时，中文会是一大堆乱码。最好在Babun环境中使用UTF-8编码，ipconfig等windows指令用cmder或默认cmd执行就行了。\n一个不推荐的方案：在babun自带的shell(mintty)右上角右键options-text,在character set选择default或者GBK,之后执行ipconfig等cmd内置的命令时就正常显示中文了。\n如果把Babun的编码改成GBK的话，命令的中文输出倒是正常了，PS1却会出现一个乱码字符，如图\n去掉命令提示符乱码\nbabun内置两个shell，默认是zsh,另一个是bash,设置成中文后命令提示符最后会有一个乱码字符，看着很不爽，要修改PS1变量去掉。把乱码字符替换为：\u0026gt;\u0026gt;\nbash\nvi /usr/local/etc/babun.bash PS1=\u0026quot;\\[\\033[00;34m\\]{ \\[\\033[01;34m\\]\\W \\[\\033[00;34m\\]}\\[\\033[01;32m\\] \\$( git rev-parse --abbrev-ref HEAD 2\u0026gt; /dev/null || echo \u0026quot;\u0026quot; ) \\[\\033[01;31m\\]\u0026gt;\u0026gt;\\[\\033[00m\\]\u0026quot;  zsh\nvi ~/.oh-my-zsh/custom/babun.zsh-theme PROMPT='%{$fg[blue]%}{ %c } \\ %{$fg[green]%}$( git rev-parse --abbrev-ref HEAD 2\u0026gt; /dev/null || echo \u0026quot;\u0026quot; )%{$reset_color%} \\ %{$fg[red]%}%(!.#.\u0026gt;\u0026gt;)%{$reset_color%} '  这样改好后命令提示符就变成： { ~ } \u0026gt;\u0026gt;\n注：将编码修改成GBK后，ls命令中文文件名的会出现乱码。\n将Babun整合到ConEmu/cmder 在cmder窗口右上角右键Settings\u0026gt;Startup\u0026gt;Tasks,点+号添加一个新task，命名为babun。\n在Task parameters中填入\n/icon \u0026quot;%userprofile%\\.babun\\cygwin\\bin\\mintty.exe\u0026quot; /dir \u0026quot;%userprofile%\u0026quot;  在Commands中填入以下任意一种都可以\n#默认使用ZSH %userprofile%\\.babun\\cygwin\\bin\\mintty.exe /bin/env CHERE_INVOKING=1 /bin/zsh.exe #使用自定义mintty配置 %userprofile%\\.babun\\cygwin\\bin\\mintty.exe -t \u0026quot;%userprofile%\\.babun\\cygwin\\etc\\minttyrc\u0026quot;  保存后,建立一个新终端时选Babun就可用了。\n配置个性化的mintty vim ~/.minttyrc CursorType=block Term=xterm-256color Font=Source Code Pro Semibold FontHeight=10  开发环境配置 pip\nBabun内置了Python、Perl等解释器。cygwin自带的python没有pip,需手动安装。\n直接执行下面这个命令就好了。\nwget https://bootstrap.pypa.io/get-pip.py -O - | python  有了pip就可以自由的安装诸如ipython之类的东西，还有包罗万象的类库。\n常用插件 Babun默认是安装了Oh My ZSH的，这里可以根据自身情况安装一些插件。具体可参考利用Oh-My-Zsh打造你的超级终端一文\n包管理器使用 babun提供一个叫pact包管理工具，类似于linux上面的apt-get或yum的包管理工具。\npact使用语法\npact: Installs and removes Cygwin packages. Usage: \u0026quot;pact install \u0026lt;package names\u0026gt;\u0026quot; to install given packages \u0026quot;pact remove \u0026lt;package names\u0026gt;\u0026quot; to remove given packages \u0026quot;pact update \u0026lt;package names\u0026gt;\u0026quot; to update given packages \u0026quot;pact show\u0026quot; to show installed packages \u0026quot;pact find \u0026lt;patterns\u0026gt;\u0026quot; to find packages matching patterns \u0026quot;pact describe \u0026lt;patterns\u0026gt;\u0026quot; to describe packages matching patterns \u0026quot;pact packageof \u0026lt;commands or files\u0026gt;\u0026quot; to locate parent packages \u0026quot;pact invalidate\u0026quot; to invalidate pact caches (setup.ini, etc.) Options: --mirror, -m \u0026lt;url\u0026gt; : set mirror --invalidate, -i : invalidates pact caches (setup.ini, etc.) --force, -f : force the execution --help --version  pact使用比较简单，不在详述了！\n常用软件安装\n#安装tmux pact install tmux #安装screen pact install screen #安装zip pact install zip #安装svn pact install subversion #安装lftp命令 pact install lftp #安装p7zip命令 pact install p7zip #基于openssh的socks https代理 pact install connect-proxy #安装linux基础命令行工具more/col/whereis等命令 pact install util-linux #安装dig命令 pact install bind-utils #安装Telnet等常用网络命令 pact install inetutils #安装python环境 pact install python pact install python-crypto  总结 Babun虽然没有多少技术创新，但是它博采众长，追求极致的体验，把其他同类软件狠狠的甩在了后面。Babun是近年来最好的在Windows下使用Linux Shell的一站式解决方案。\n无论是被迫使用Windows的Linuxer，还是离不开Windows却又羡慕Linux下强大的命令行工具的PC用户，Babun都是一个不容错过的好东西，相信你们会爱上它的。\nref  让 Windows 用上 OMZ 的神器 Babun 如何搭建优雅的windows开发环境 Babun 配置  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-docker-break-ufw-rules-state-2.html",
	"title": "docker break ufw&#39;s rules in ubuntu - env2",
	"tags": [],
	"description": "docker break ufw&#39;s rules in ubuntu - env2",
	"content": " docker break ufw\u0026rsquo;s rules in ubuntu - env2\nufw 阻止了从docker容器到外部的网络连接\n对我来说这是一个非常标准的设置，我有一台运行docker和ufw的ubuntu机器作为我的防火墙。 如果启用防火墙，则docker实例无法连接到外部\nhttps://blog.36web.rocks/2016/07/08/docker-behind-ufw.html https://oomake.com/question/4955599\nenv 当运行docker后\ndocker 配置 ubuntu@utuntu:~/lcnx/local/lvchuang-server$ sudo cat /etc/docker/daemon.json { \u0026quot;hosts\u0026quot;: [\u0026quot;tcp://0.0.0.0:2376\u0026quot;,\u0026quot;unix:///var/run/docker.sock\u0026quot;], \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://0d6wdn2y.mirror.aliyuncs.com\u0026quot;], \u0026quot;dns\u0026quot; : [\u0026quot;192.168.168.222\u0026quot;] } ubuntu@utuntu:~/lcnx/local/lvchuang-server$ sudo cat /etc/default/docker # Docker Upstart and SysVinit configuration file # # THIS FILE DOES NOT APPLY TO SYSTEMD # # Please see the documentation for \u0026quot;systemd drop-ins\u0026quot;: # https://docs.docker.com/engine/admin/systemd/ # # Customize location of Docker binary (especially for development testing). #DOCKERD=\u0026quot;/usr/local/bin/dockerd\u0026quot; # Use DOCKER_OPTS to modify the daemon startup options. #DOCKER_OPTS=\u0026quot;--dns 8.8.8.8 --dns 8.8.4.4\u0026quot; DOCKER_OPTS=\u0026quot;--iptables=false\u0026quot; # If you need Docker to use an HTTP proxy, it can also be specified here. #export http_proxy=\u0026quot;http://127.0.0.1:3128/\u0026quot; # This is also a handy place to tweak where Docker's temporary files go. #export DOCKER_TMPDIR=\u0026quot;/mnt/bigdrive/docker-tmp\u0026quot; ubuntu@utuntu:~/lcnx/local/lvchuang-server$ sudo cat /etc/default/docker | grep DOCKER_OPTS # Use DOCKER_OPTS to modify the daemon startup options. #DOCKER_OPTS=\u0026quot;--dns 8.8.8.8 --dns 8.8.4.4\u0026quot; DOCKER_OPTS=\u0026quot;--iptables=false\u0026quot; ubuntu@utuntu:~/lcnx/local/lvchuang-server$  docker container 现象 ubuntu@utuntu:~/docker/images/ubuntu$ docker run -it -d --dns 192.168.168.222 --name ubuntu-tools ubuntu-tools:v1.0 b4b3f7cd3d03c09f48eae8b0979678af57a07b2fcf118f80de653f8ef45c4e4e ubuntu@utuntu:~/docker/images/ubuntu$ docker exec -it ubuntu-tools bash root@b4b3f7cd3d03:/# cat /etc/resolv.conf nameserver 192.168.168.222 root@b4b3f7cd3d03:/# ping qq.com ^C  当ufw disable后, 则 container 可以连接外网\nroot@b4b3f7cd3d03:/# ping qq.com PING qq.com (59.37.96.63) 56(84) bytes of data. 64 bytes from 59.37.96.63: icmp_seq=1 ttl=54 time=4.77 ms 64 bytes from 59.37.96.63: icmp_seq=2 ttl=54 time=4.69 ms ^C --- qq.com ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1001ms rtt min/avg/max/mdev = 4.691/4.730/4.770/0.079 ms root@b4b3f7cd3d03:/# route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default 172.17.0.1 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 * 255.255.0.0 U 0 0 0 eth0 root@b4b3f7cd3d03:/# traceroute qq.com traceroute to qq.com (59.37.96.63), 30 hops max, 60 byte packets 1 172.17.0.1 (172.17.0.1) 0.095 ms 0.036 ms 0.035 ms 2 * * * 3 218.17.137.1 (218.17.137.1) 4.515 ms 5.474 ms 5.535 ms 4 202.105.103.117 (202.105.103.117) 3.896 ms 202.105.159.205 (202.105.159.205) 3.651 ms 202.105.159.213 (202.105.159.213) 3.763 ms 5 117.176.37.59.broad.dg.gd.dynamic.163data.com.cn (59.37.176.117) 4.348 ms * * 6 119.147.223.178 (119.147.223.178) 3.624 ms 119.147.223.254 (119.147.223.254) 3.451 ms 121.34.242.134 (121.34.242.134) 3.370 ms 7 * * * 8 14.17.2.250 (14.17.2.250) 6.196 ms 14.17.2.242 (14.17.2.242) 6.363 ms 6.457 ms 9 * * * 10 * * * 11 * * * 12 * * * 13 * * * 14 * * * 15 * * * 16 * * *^C root@b4b3f7cd3d03:/#  ufw 日志 显示来自docker的阻塞连接\n$ sudo tail /var/log/ufw.log Jun 11 11:46:08 utuntu kernel: [68180.673178] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:3c:d0:1e:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:46:08 utuntu kernel: [68180.673448] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:3c:d0:1e:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:46:09 utuntu kernel: [68181.175761] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:17:16:de:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:46:09 utuntu kernel: [68181.176021] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:17:16:de:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:48:14 utuntu kernel: [68306.114435] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:3c:d0:1e:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:48:14 utuntu kernel: [68306.114666] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:3c:d0:1e:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:48:14 utuntu kernel: [68306.617583] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:17:16:de:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:48:14 utuntu kernel: [68306.617832] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:17:16:de:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2 Jun 11 11:50:19 utuntu kernel: [68431.555632] [UFW BLOCK] IN=enp2s0 OUT= MAC=01:00:5e:00:00:01:78:11:dc:3c:d0:1e:08:00 SRC=0.0.0.0 DST=224.0.0.1 LEN=32 TOS=0x00 PREC=0xC0 TTL=1 ID=0 DF PROTO=2  step (可跳过)失敗尝试 使用ip添加规则。 $ sudo ufw allow in from 172.16.42.2 $ sudo ufw allow out from 172.16.42.2  ip sudo ufw allow from 172.17.0.0/16\ndocker0 sudo ufw allow in on docker0  /etc/ufw/before.rules sudo vi /etc/ufw/before.rules  编辑/etc/ufw/before.rules如下： 在* filter部分中，在第一个必需行块之后，添加：\n# docker rules to enable external network access from the container # forward traffic accross the bridge -A ufw-before-forward -i docker0 -j ACCEPT -A ufw-before-forward -i testbr0 -j ACCEPT -A ufw-before-forward -m state --state RELATED,ESTABLISHED -j ACCEPT  在文件末尾，在显示COMMIT的行之后，添加以下部分：\n*nat :POSTROUTING ACCEPT [0:0] -A POSTROUTING -s 172.16.42.0/8 -o eth0 -j MASQUERADE # don't delete the 'COMMIT' line or these rules won't be processed COMMIT  保存文件后，使用sudo ufw disable \u0026amp;\u0026amp; sudo ufw enable重新启动ufw\n并没有改变仍然被阻止。\n如果您熟悉iptables sudo ufw show raw  但是,我不熟悉,这个就尴尬了.\n/etc/default/ufw以将DEFAULT_FORWARD_POLICY的值更改为\u0026rdquo;ACCEPT\u0026rdquo; 这时, 参考\nhttps://oomake.com/question/4955599\n也许这是由于当前版本，但目前的答案不适用于我的系统(Docker 0.7.2与基础Ubuntu映像)。 解决方案解释为here in the official Docker documentation。 对于懒惰的人： 编辑/etc/default/ufw以将DEFAULT_FORWARD_POLICY的值更改为\u0026quot;ACCEPT\u0026quot;， 使用[sudo] ufw reload重新加载。 这可以确保您将流量转发到Docker的桥接网络(就我目前对这些事情的理解而言......)。  发现有用.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/babun/babun-faq.html",
	"title": "babun 中 zsh tab 失效",
	"tags": ["babun"],
	"description": "babun 中 zsh tab 失效",
	"content": " babun 中 zsh tab 失效 https://github.com/babun/babun/issues/281\nTry running rm -f ~/.zcompdump*; compinit and see if that fixes it.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/django/temp.html",
	"title": "Post",
	"tags": [],
	"description": "blog",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/temp.html",
	"title": "Post",
	"tags": [],
	"description": "blog",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/react/temp.html",
	"title": "Post",
	"tags": [],
	"description": "blog",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/interview.html",
	"title": "interview",
	"tags": [],
	"description": "interview",
	"content": "interview\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/",
	"title": "ubuntu",
	"tags": [],
	"description": "介绍ubuntu",
	"content": "linux ubuntu\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/introduction.html",
	"title": "介绍",
	"tags": [],
	"description": "介绍Hugo，以及为什么要使用hugo",
	"content": " Hugo是什么？ Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\n为什么用Hugo？ Hugo以速度快著称，号称是世界上最快的网站生成框架。\nThe world’s fastest framework for building websites\n1Password 这里有一段来自1Password的对hugo的评价，很有代表性。\n 内容翻译自 https://gohugo.io/showcase/1password-support/\n 在1Password，我们过去每个月都会经历一个不同的文档平台：博客引擎，电子书，维基，用Ruby和JavaScript编写的网站生成器。 每个方式都有自己的不足。然后我们找到了hugo。我们做了最后一次切换，我们很高兴我们做到了。\n并非所有静态站点生成器都是相同的\n找到一个能让您的客户，作者，设计师和DevOps团队满意的工具并非易事，但我们通过Hugo进行了管理：\n Hugo是静态的。我们是一家安全公司，所以我们坚持静态网站并尽可能地使用它们。我们觉得客户在HTML文件上比在需要强化的复杂服务器上更安全。\n Hugo是基于Go的。在1Password我们喜欢Go编程语言，我们很高兴得知Hugo使用了我们的设计师和前端开发人员已经掌握的相同的Go模板语法。\n Hugo很快。我们以前的静态站点生成器花费将近一分钟来编译我们的（那时还小得多）站点。开发人员可能已经习惯了这一点，但对于希望看到工作实时预览的作家来说，这并不合适。Hugo在几毫秒内完成了同样的工作，到现在，转瞬之间就可以编译五种语言编写的400多个页面。\n Hugo很灵活。感谢Hugo的内容和布局系统，我们能够保留现有的文件和文件夹结构，并在几天内移植整个生产站点。然后我们可以创建以前不可能的新内容类型，比如这些时髦的陈列柜。\n Hugo非常适合作家。我们的文档团队已经对Markdown和Git感到满意，并且可以开始为Hugo创建内容而无需停顿。一旦我们添加了短代码，我们的作者就可以通过少量的新语法来使用类似平台盒(platform boxes)的功能来装饰文章。\n Hugo有一个惊人的开发者社区。Hugo更新频繁，充满了功能和修复。在我们开发网站的多语言版本时，我们提交了所需功能的PR，并通过@bep和其他人的流程得到了帮助。\n Hugo易于部署。 Hugo拥有适量的配置选项，可以适应我们的构建系统而不会太复杂。\n  我的个人感受 我的个人博客网站，十几年来经历过很多变更，从csdn，blogjava，javaeye，hexo+github page，gitbook一路走来，在2018年2月，开始转换到hugo，迄今半年多。\n这些年博客的历程，有兴趣了解的同学可以看看我当时写的文章：十年一觉扬州梦，赢得青楼薄幸名\n目前的博客网站使用了自行修改订制之后的 academic 主题，非常满意，点击 这里 可以看到实际效果。而现在这份Hugo学习笔记和另一份cilium学习笔记，则采用的是Hugo+material-docs主题，后续会将目前大大小小的四五十份学习笔记逐步迁移到hugo上来。\n对于hugo，个人非常喜爱，上面1Password列出的几点都感同身受。仅从个人感受上说，我觉得hugo优势主要体现在以下方面：\n 静态文件生成：生成纯静态文件，可以任意找地方托管，无任何特殊依赖。免费的github pages，廉价的虚拟主机，廉价的VPS，都可以轻松完成网站托管。 markdown编写：这是至关重要的一点，在习惯了markdown高效而专注的写作体验之后，markdown的支持成为硬性要求。 使用方便：无论是偏公共性质的技术博客，还是偏私人性质的学习笔记，从内容创作或者学习心得记录的角度，都是“内容为王”！因此，一个样式简单大方的网站，在一次性的安装调试完成之后，后续就应该可以轻松快捷的进行内容创作。 速度！：仅以上述三点而言，hexo和gitbook都表现的很好，两者的功能和主题都非常的丰富。但是，hugo在渲染速度上明显高出太多，尤其是对比gitbook，几乎有几十上百倍的性能差距。当站点内容比较多，比如积攒了几年的博客，或者大量细节展开的学习笔记，gitbook的渲染速度就开始从秒级到十几秒再到分钟级，而变得越来越不可接受。Hugo的速度，是我最终放弃hexo和gitbook的最关键的原因。 Go语言：这是讨人喜欢的一点，当然这会因人而异，nodejs的同学可能更愿意用gitbook。仅从个人感受上说，我对基于go的hugo好感更多。 喜欢的主题：对于hexo、gitbook、hugo，都拥有数以千计的各式主题。而要在众多主题中找到自己的心头好，有时需要一点运气。我自我感觉比较幸运的是：我找到了两个很喜欢的主题，academic 和 material-docs，分别用于我的技术博客网站和学习笔记。特点是简单大气，简洁大方，不花俏，不土气，精致而内敛。有喜欢的主题，是一个关键的决策依据。  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/introduction/information.html",
	"title": "资料",
	"tags": [],
	"description": "收集Hugo的各种资料",
	"content": " 官方资料  Hugo官网 官方文档 官方主题 官方展示案例  社区资料  Hugo中文网站： 貌似有段时间没有更新了？  学习资料  Hogo handbook: 宋净超(Jimmy Song)同学整理的hugo使用资料 Hugo❤️ China User Group: 宋净超(Jimmy Song)同学组织，有个微信群可以申请加入  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command.html",
	"title": "command",
	"tags": [],
	"description": "blog",
	"content": " 内容介绍 这是个人博客, 主要包括一些学习笔记\n访问方式 请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/",
	"title": "ssh",
	"tags": [],
	"description": "介绍linux的ssh",
	"content": "linux ssh\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/installation/_index.zh.html",
	"title": "_index.zh安装",
	"tags": [],
	"description": "详细介绍Hugo的安装",
	"content": " 准备工作 安装golang 安装hugo之前，先安装好golang。\n目前新版本的hugo如0.54版本，需要golang最新的1.11版本支持。安装hugo前最好检查一下hugo对golang的版本要求。\n安装 在Hugo Releases页面下载对应操作系统版本的安装包。\nLinux安装 找到linux的安装包，对于 ubuntu 可以直接用 deb 文件：\n hugo_0.54_Linux-64bit.deb  deb文件直接安装即可。\nsudo dpkg -i hugo_0.54_Linux-64bit.deb  Mac安装 mac 下安装最简单的方式是用brew命令\nbrew install hugo  也可以从下载页面下载到macos的安装包，解压后，将 hugo 可执行文件放在path路径下即可。\n安装后设置 验证安装：\n$ hugo version Hugo Static Site Generator v0.54.0-B1A82C61 linux/amd64 BuildDate: 2019-02-01T09:40:34Z  为了方便使用，增加hugo server 命令的 alias：\nalias h=\u0026quot;hugo server --disableFastRender\u0026quot;  自动发布 以下是jenkins自动生成并发布到nginx的简单脚本：\nsh update_academic.sh # clean cd /var/www/skyao/ # 删除所有文件和文件夹，但排除以\u0026quot;learning-\u0026quot;前缀开头的 rm -rf `ls | grep -v \u0026quot;learning-\u0026quot;` cd /var/lib/jenkins/workspace/skyao.io/ # 需要明确指定baseUrl hugo --baseUrl=\u0026quot;https://skyao.io/\u0026quot; -d \u0026quot;/var/www/skyao/\u0026quot;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/installation.html",
	"title": "安装",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/installation/",
	"title": "index安装",
	"tags": [],
	"description": "详细介绍Hugo的安装",
	"content": " 准备工作 安装golang 安装hugo之前，先安装好golang。\n目前新版本的hugo如0.54版本，需要golang最新的1.11版本支持。安装hugo前最好检查一下hugo对golang的版本要求。\n安装 在Hugo Releases页面下载对应操作系统版本的安装包。\nLinux安装 找到linux的安装包，对于 ubuntu 可以直接用 deb 文件：\n hugo_0.54_Linux-64bit.deb  deb文件直接安装即可。\nsudo dpkg -i hugo_0.54_Linux-64bit.deb  Mac安装 mac 下安装最简单的方式是用brew命令\nbrew install hugo  也可以从下载页面下载到macos的安装包，解压后，将 hugo 可执行文件放在path路径下即可。\n安装后设置 验证安装：\n$ hugo version Hugo Static Site Generator v0.54.0-B1A82C61 linux/amd64 BuildDate: 2019-02-01T09:40:34Z  为了方便使用，增加hugo server 命令的 alias：\nalias h=\u0026quot;hugo server --disableFastRender\u0026quot;  自动发布 以下是jenkins自动生成并发布到nginx的简单脚本：\nsh update_academic.sh # clean cd /var/www/skyao/ # 删除所有文件和文件夹，但排除以\u0026quot;learning-\u0026quot;前缀开头的 rm -rf `ls | grep -v \u0026quot;learning-\u0026quot;` cd /var/lib/jenkins/workspace/skyao.io/ # 需要明确指定baseUrl hugo --baseUrl=\u0026quot;https://skyao.io/\u0026quot; -d \u0026quot;/var/www/skyao/\u0026quot;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/installation/quickstart.html",
	"title": "快速开始",
	"tags": [],
	"description": "详细介绍通过Hugo快速开始搭建一个站点",
	"content": " 新建站点 hugo new side /path/tp/your/site  提示如下：\n$ hugo new site learning-cilium Congratulations! Your new Hugo site is created in /home/sky/work/code/learning/learning-cilium. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/, or create your own with the \u0026quot;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026quot; command. 2. Perhaps you want to add some content. You can add single files with \u0026quot;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026quot;. 3. Start the built-in live server via \u0026quot;hugo server\u0026quot;. Visit https://gohugo.io/ for quickstart guide and full documentation.  下载模板 选择喜欢的模板，一般下载方式如下：\ncd learning-cilium git clone git@github.com:digitalcraftsman/hugo-material-docs.git themes/hugo-material-docs  为了快速开始使用，一般模板都会提供一个exampleSite，通常将该目录下的内容都复制到站点跟目录下：\ncp -av themes/hugo-material-docs/exampleSite/* .  运行 直接执行server命令就可以启动：\nhugo server  通过浏览器访问 http://localhost:1313/ 就可以看内容，由于上面我们采用的是直接复制exampleSite的内容，所以一般此时看到的就是这个模板的example内容。\n之后再进行具体的网站设定，模板修改，添加内容等。\n提交到github echo \u0026quot;# learning-cilium\u0026quot; \u0026gt;\u0026gt; README.md git init git add -A git commit -m \u0026quot;first commit\u0026quot; git remote add origin git@github.com:skyao/learning-cilium.git git push -u origin master  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/installation/https.html",
	"title": "开启HTTPS",
	"tags": [],
	"description": "详细介绍如何为Hugo增加HTTPS支持",
	"content": " 参考文章：\n 给博客加上HTTPS 在Ubuntu上获取Let’s Encrypt免费证书  由于我用的博客服务器是ubuntu 16.04，因此部分命令稍有不同。\n生成证书 先安装工具：\nsudo apt-get install letsencrypt  生成证书：\nsudo letsencrypt certonly --webroot -w /var/www/skyao -d skyao.io  配置nginx 在/etc/nginx/sites-available下增加一个skyao.io.https站点文件，内容如下：\nserver { listen 443 ssl; server_name skyao.io www.skyao.io; root /var/www/skyao; index index.html; ssl on; ssl_certificate /etc/letsencrypt/live/skyao.io/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/skyao.io/privkey.pem; }  然后将http请求都自动转为https，修改原来的skyao.io配置文件：\nserver { listen 80; server_name skyao.io www.skyao.io; rewrite ^(.*)$ https://$host$1 permanent; }  重启nginx：\nsudo service nginx restart  设置自动更新证书 由于Let\u0026rsquo;s Encrypt证书的有效期为90天，所有我们需要定期更新以避免证书过期，通常Let\u0026rsquo;s Encrypt会发邮件提醒的。\n更新操作如下：\n# 更新证书 sudo letsencrypt renew # 重新启动nginx sudo systemctl restart nginx  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/installation/seo.html",
	"title": "搜索引擎优化",
	"tags": [],
	"description": "为了让Hugo网站更好的被搜索引擎收录，需要进行搜索引擎优化（SEO）",
	"content": " 为了让Hugo网站更好的被搜索引擎收录，需要进行搜索引擎优化（SEO）。\n站点内容优化 修改配置 修改 hugo/config/_default 目录下的 params.toml 文件：\ndescription = \u0026quot;敖小剑的个人技术博客网站，主要关注服务网格,serverless,kubernetes,微服务等云原生技术。\u0026quot;  修改模板 0.54 版本下基本做的很好了，不再修改。\n添加页面信息 首先确保每个页面一定都要设置有 title，description，最好还有 keywords：\ntitle: 前言 keywords: - hugo - 学习笔记 - hugo学习笔记 description : \u0026quot;介绍Hugo学习笔记的基本资料和访问方式。\u0026quot;  google搜索优化 提交给Google网站站长 打开 Google网站站长，点击 \u0026ldquo;SEARCH CONSOLE \u0026rdquo; 进入，然后添加资源，如https://skyao.io/learning-hugo/。会要求下载一个html文件如google571325××××.html做验证，将这个文件保存到hugo站点根目录下的static子目录，更新站点内容让google search console可以访问到进行验证即可。\n进入资源页面，点\u0026rdquo;索引\u0026rdquo;下的\u0026rdquo;站点地图\u0026rdquo;，在\u0026rdquo;添加新的站点地图\u0026rdquo;处输入当前hugo站点的sitemap，这个文件hugo会默认生成，就在根路径下，如https://skyao.io/learning-hugo/sitemap.xml。\n百度搜索优化 打开 百度搜索资源平台 ，点击 链接提交，然后点\u0026rdquo;添加站点\u0026rdquo;。同样可以用文件验证的方式来进行网站验证。\n进入\u0026rdquo;数据引入\u0026rdquo;下的\u0026rdquo;链接提交\u0026rdquo;，再点 \u0026ldquo;自动提交\u0026rdquo; 下的 \u0026ldquo;sitemap\u0026rdquo;，在这里可以提交hugo网站的sitemap文件。注意百度不容许以子目录的方式提交子站点，和google不一样，我们的学习笔记 https://skyao.io/learning-hugo/ 就不能直接提交了，只能在提交sitemap文件时，提交多个sitemap文件。这样也能勉强让百度收录。\n参考资料 有参考以下资料，特此鸣谢：\n 搜索引擎优化（SEO）: 来自宋静超的hugo handbook Front-End-Checklist - Github SEO 查询 - 站长之家 SEO Meta Tags Meta Description 从Hexo迁移到Hugo-送漂亮的Hugo Theme主题 Hugo website SEO Hugo SEO Markup  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ai.html",
	"title": "ai",
	"tags": [],
	"description": "AI",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/ssh-command-env-not-found-command.html",
	"title": "SSH远程命令找不到环境变量",
	"tags": [],
	"description": "解决SSH远程执行命令找不到环境变量的问题",
	"content": " 解决SSH远程执行命令找不到环境变量的问题\nenv  ssh  原理 https://blog.csdn.net/whitehack/article/details/51705889 (这个写得最好) https://www.jianshu.com/p/77ebeb27a2dc (简单) https://www.cnblogs.com/zhenyuyaodidiao/p/9287497.html\n实践 在 ssh 服务端 找到 # If not running interactively, don't do anything , (在这一行下面,一般会有一句return之类的), 在这一行下面, 加入我们需要的环境变量. 但是, 也不能加多了, 加多了, scp 会失效.\n如下面,就是加多了, 如果报错, 则导致 远程scp不了文件.\n$ vi /home/lcnx/.bashrc # If not running interactively, don't do anything export NVM_DIR=\u0026quot;$HOME/.nvm\u0026quot; [ -s \u0026quot;$NVM_DIR/nvm.sh\u0026quot; ] \u0026amp;\u0026amp; \\. \u0026quot;$NVM_DIR/nvm.sh\u0026quot; # This loads nvm [ -s \u0026quot;$NVM_DIR/bash_completion\u0026quot; ] \u0026amp;\u0026amp; \\. \u0026quot;$NVM_DIR/bash_completion\u0026quot; # This loads nvm bash_completion nvm use v11.14.0 export PATH=$PATH:/home/lcnx/.nvm/versions/node/v11.14.0/bin [ -z \u0026quot;$PS1\u0026quot; ] \u0026amp;\u0026amp; return  应该修改成\n$ vi /home/lcnx/.bashrc # If not running interactively, don't do anything export PATH=$PATH:/home/lcnx/.nvm/versions/node/v11.14.0/bin [ -z \u0026quot;$PS1\u0026quot; ] \u0026amp;\u0026amp; return  ssh 客户端 查看所使用的 ssh服务端环境 ssh lcnx@120.77.39.189 \u0026quot;. /home/lcnx/.bashrc; env\u0026quot; ssh lcnx@120.77.39.189 \u0026quot;env\u0026quot;  但是下面的 %HOME 取的是 ssh 客户端 的用户,所以无效.\nssh lcnx@120.77.39.189 \u0026quot;. $HOME/.bashrc; env\u0026quot;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/theme.html",
	"title": "主题",
	"tags": [],
	"description": "介绍hugo主题的使用方式",
	"content": "Hugo有非常丰富的主题。\n后面会列出一些个人觉得不错的Hugo主题，然后重点推荐两个我自己在用的主题：\n academic主题：用于我的个人博客网站 material-docs主题：用于我的学习笔记  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/tar/",
	"title": "tar",
	"tags": [],
	"description": "介绍linux的tar",
	"content": "linux tar\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/tar/linux-tar-z-unknown-function-modifie.html",
	"title": "linux tar: z: unknown function modifie 错误",
	"tags": [],
	"description": "linux tar: z: unknown function modifie 错误",
	"content": "linux tar: z: unknown function modifie 错误\n转载 https://blog.csdn.net/syc001/article/details/72841916\n某些linux版本的机器上使用 tar -zxvf *.tar.gz 命令解压.tar.gz时会出现\ntar: z: unknown function modifier\n错误。\n而使用 tar -x *.tar.gz 会出现“tar: /dev/rmt/0: No such file or directory”错误。\n这是因为该linux下的tar不支持z参数造成的。在这种情况下，可以把解压过程分为两步：\ngzip -d yourfile.tar.gz。生成一个.tar文件。\ntar -xvf yourfile.tar。解压文件。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/blockchain.html",
	"title": "blockchain",
	"tags": [],
	"description": "blockchain",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/theme/academic.html",
	"title": "academic主题",
	"tags": [],
	"description": "介绍hugo的academic主题，使用方式和订制化",
	"content": " 主题介绍 academic是一个特别适合搭建内容相对比较丰富的网站的主题，如果我们hugo网站的内容不仅仅是博客，还有其他好几种样式的内容，那么academic会是一个很不错的选择。此外，academic主题简洁大方，也适合作为一个稍有规模的正式网站。\n 官网介绍：https://themes.gohugo.io/academic/ 我用academic主题搭建的个人技术博客网站: https://skyao.io  准备工作 git仓库准备 以建立skyao.io这个网站为例，fork github项目：\n https://github.com/gcushen/hugo-academic: 修改仓库名为hugo-academic，这是自行订制的主题仓库，加cn后缀名以示区别。 https://github.com/sourcethemes/academic-kickstart: 修改仓库名为skyao.io，这是存放站点内容的仓库，为了方便起见，从官方的kickstart仓库开始改起，也方便未来保持更新。   备注：实际证明，academic的版本变化非常大，fork出来之后，再修改，到升级版本时到处是冲突，极易出错，很难正确处理。最后还是不得不从头来过：取到最新版本，然后手工将原有的改动重新再做一遍。\n kickstart 项目就没有必要再fork了，hugo-academic 还是需要 fork 的。\n本地仓库准备 clone下来 kickstart 的仓库到本地：\n# 本地准备好academic主题仓库 git clone https://github.com/skyao/hugo-academic.git # 直接获取kickstart的内容作为建站的基础 git clone https://github.com/sourcethemes/academic-kickstart.git skyao.io cd skyao.io/ rm -rf .git .gitmodules rm -r themes/academic/  修改.gitignore文件内容如下：\n.* !.gitignore public/ themes/  修改update_academic.sh文件内容如下：\n#!/bin/bash if [ ! -d \u0026quot;themes\u0026quot; ];then echo \u0026quot;No themes directory, create it\u0026quot; mkdir themes fi if [ -d \u0026quot;themes/academic\u0026quot; ];then echo 'Find directoy \u0026quot;themes/academic\u0026quot;, update by \u0026quot;git pull\u0026quot;' cd themes/academic git pull cd ../../ else echo 'Directoy \u0026quot;themes/academic\u0026quot; not found, do \u0026quot;ln -s\u0026quot;' cd themes ln -s ../../hugo-academic academic cd ../ fi  执行命令 sh update_academic.sh 获取 academic 主题文件(实际是一个ln过程)。此时themes/academic是我们订制的主题内容，此时两个git仓库都可以分别提交内容，而且实时生效，非常方便本地修改。\n创建网站 使用 exampleSite 初始化 删除｀skyao.io｀目录下的config.toml文件和content/static目录，然后从｀themes/academic/exampleSite｀下的这三个文件和目录复制到｀skyao.io｀目录下。执行hugo server命令，就可以通过浏览器访问 http://localhost:1313/ 看到示例站点。\n我们从这个基础开始进行修改和订制。\n修改配置 注意新版本的hugo将原来的单个config.toml配置文件拆分为多个配置文件，这些配置文件在 config/_default 目录下。\n修改config.toml文件 title = \u0026quot;敖小剑的博客\u0026quot; copyright = \u0026quot;skyao.io \u0026amp;copy; 2019\u0026quot; googleAnalytics = \u0026quot;17048c9d4209e5d08a9ae5b0b4160808\u0026quot; # 修改默认语言，需要对应的在languages.toml添加中文 defaultContentLanguage = \u0026quot;zh\u0026quot; hasCJKLanguage = true paginate = 20  修改languages.toml 先只替换默认语言为中文，暂时不启用多语言版本。\n# 注释掉en #[en] # languageCode = \u0026quot;en-us\u0026quot; # 添加中文 [zh] languageCode = \u0026quot;zh-Hans\u0026quot;  如果要调整页面上的字眼，需要修改主题文件中的 i18n 文件，如themes/academic/i18n/zh.yaml。\n如果要修改 publication_types 的显示，需要参考 themes/academic/layouts/partials 下 pub_types.html 的内容，在 themes/academic/i18n/zh.yaml 文件中加入对应的内容：\n- id: pub_uncat translation: 未分组 - id: pub_conf translation: 会议记录 - id: pub_journal translation: 期刊文章 - id: pub_manuscript translation: 手稿 - id: pub_report translation: 技术报告 - id: pub_book translation: 书籍 - id: pub_book_section translation: 书籍摘抄  修改params.toml color_theme = \u0026quot;1950s\u0026quot; description = \u0026quot;敖小剑的个人技术博客网站，主要关注服务网格,serverless,kubernetes,微服务等云原生技术。\u0026quot; # 这个还不知道该如何设置 sharing_image = \u0026quot;\u0026quot; twitter = \u0026quot;SkyAoXiaojian\u0026quot; date_format = \u0026quot;2006-01-02\u0026quot; time_format = \u0026quot;15:04\u0026quot; email = \u0026quot;aoxiaojian@hotmail.com\u0026quot; phone = \u0026quot;\u0026quot; address = \u0026quot;广州市天河区广电平云广场B塔15楼\u0026quot; office_hours = \u0026quot;\u0026quot; contact_links = [ {icon = \u0026quot;twitter\u0026quot;, icon_pack = \u0026quot;fab\u0026quot;, name = \u0026quot;DM Me\u0026quot;, link = \u0026quot;https://twitter.com/SkyAoXiaojian\u0026quot;}, # {icon = \u0026quot;skype\u0026quot;, icon_pack = \u0026quot;fab\u0026quot;, name = \u0026quot;Skype Me\u0026quot;, link = \u0026quot;skype:echo123?call\u0026quot;}, # {icon = \u0026quot;keybase\u0026quot;, icon_pack = \u0026quot;fab\u0026quot;, name = \u0026quot;Chat on Keybase\u0026quot;, link = \u0026quot;https://keybase.io/\u0026quot;}, # {icon = \u0026quot;comments\u0026quot;, icon_pack = \u0026quot;fas\u0026quot;, name = \u0026quot;Discuss on Forum\u0026quot;, link = \u0026quot;https://discourse.gohugo.io\u0026quot;}, # {icon = \u0026quot;telegram\u0026quot;, icon_pack = \u0026quot;fab\u0026quot;, name = \u0026quot;Telegram Me\u0026quot;, link = \u0026quot;https://telegram.me/@Telegram\u0026quot;}, ] reading_time = false comment_count = false [publications] date_format = \u0026quot;2006-01-02\u0026quot;  修改menus.toml [[main]] name = \u0026quot;首页\u0026quot; url = \u0026quot;#about\u0026quot; weight = 1 [[main]] name = \u0026quot;演讲分享\u0026quot; url = \u0026quot;/talk/\u0026quot; weight = 2 [[main]] name = \u0026quot;出版作品\u0026quot; url = \u0026quot;/publication/\u0026quot; weight = 3 [[main]] name = \u0026quot;技术博客\u0026quot; url = \u0026quot;/post/\u0026quot; weight = 4 [[main]] name = \u0026quot;开源项目\u0026quot; url = \u0026quot;#projects\u0026quot; weight = 5 [[main]] name = \u0026quot;学习笔记\u0026quot; url = \u0026quot;/learning/\u0026quot; weight = 6 [[main]] name = \u0026quot;内容标签\u0026quot; url = \u0026quot;#tags\u0026quot; weight = 7 [[main]] name = \u0026quot;和我联系\u0026quot; url = \u0026quot;#contact\u0026quot; weight = 8  订制首页 需要修改的文件在 content/home 目录下。\n关闭部分不需要的内容（设置active = false）：\n accomplishments.md experience.md skills.md teaching.md  about.md title = \u0026quot;简介\u0026quot;  然后修改 author/admin 下的文件，如替换头像，修改_index.md:\nname = \u0026quot;敖小剑\u0026quot; role = \u0026quot;中年码农\u0026quot; organizations = [ { name = \u0026quot;Dreamfly.io\u0026quot;, url = \u0026quot;https://dreamfly.io\u0026quot; } ] bio = \u0026quot;我目前研究的方向主要在微服务/Microservice、服务网格/Servicemesh、无服务器架构/Serverless等和云原生/Cloud Native相关的领域，欢迎交流和指导\u0026quot; email = \u0026quot;aoxiaojian@hotmail.com\u0026quot; interests = [ \u0026quot;微服务/Micro Service\u0026quot;, \u0026quot;服务网格/Service Mesh\u0026quot;, \u0026quot;无服务器架构/Serverless\u0026quot;, \u0026quot;云原生/Cloud Native\u0026quot;, \u0026quot;敏捷/DevOps\u0026quot; ] [[education.courses]] # 删除 ## 图标的代码需要在 https://fontawesome.com 网站上查找 [[social]] icon = \u0026quot;envelope\u0026quot; icon_pack = \u0026quot;fas\u0026quot; link = \u0026quot;mailto:aoxiaojian@hotmail.com\u0026quot; # For a direct email link, use \u0026quot;mailto:test@example.org\u0026quot;. [[social]] icon = \u0026quot;twitter\u0026quot; icon_pack = \u0026quot;fab\u0026quot; link = \u0026quot;https://twitter.com/SkyAoXiaojian\u0026quot; [[social]] icon = \u0026quot;github\u0026quot; icon_pack = \u0026quot;fab\u0026quot; link = \u0026quot;https://github.com/skyao\u0026quot; [[social]] icon = \u0026quot;git\u0026quot; icon_pack = \u0026quot;fab\u0026quot; link = \u0026quot;//legacy.gitbook.com/@skyao\u0026quot; [[social]] icon = \u0026quot;weibo\u0026quot; icon_pack = \u0026quot;fab\u0026quot; link = \u0026quot;//weibo.com/aoxiaojian\u0026quot; [[social]] icon = \u0026quot;youtube\u0026quot; icon_pack = \u0026quot;fab\u0026quot; link = \u0026quot;//www.youtube.com/channel/UCKeIYzzIeOtVR1iSfAdRBqQ\u0026quot; 增加个人简介  hero.md 暂时 禁用，后面再来设置\ntitle = \u0026quot;SOFAMesh\u0026quot; overlay_img = \u0026quot;projects/sofamesh-wide.jpg\u0026quot; # 记得把图片放到static/img/下 # 其他内容酌情修改  hero_carousel.md 是另一个版本的hero，横屏，可以多个话题滑动，效果更好的感觉。后面再整理。\nposts.md title = \u0026quot;技术博客\u0026quot; count = 10 view = 2  修改 content/posts/_index.md 文件：\ntitle = \u0026quot;技术博客\u0026quot; view = 3  publications.md title = \u0026quot;出版作品\u0026quot; count = 5 weight = 30 view = 3 exclude_featured = true  修改 content/publications/_index.md 文件：\ntitle = \u0026quot;出版作品\u0026quot; view = 3  publications_featured.md title = \u0026quot;特别推荐\u0026quot;  tags.md title = \u0026quot;内容标签\u0026quot;  projects.md title = \u0026quot;开源项目\u0026quot;  contact.md title = \u0026quot;和我联系\u0026quot;  talks.md title = \u0026quot;演讲分享\u0026quot; count = 5 weight = 20  修改talks_selected.md:\ntitle = \u0026quot;下一站\u0026quot; subtitle = \u0026quot;近期活动，欢迎关注\u0026quot;  修改post 修改 content/posts/_index.md\ntitle = \u0026quot;技术博客\u0026quot; # 在页面 http://localhost:1313/post/ 显示一张图片 [header] image = \u0026quot;\u0026quot; caption = \u0026quot;\u0026quot;  修改project project没有要修改的内容。\n修改publications 修改 content/publication/_index.md\ntitle = \u0026quot;最近发表\u0026quot; [header] image = \u0026quot;\u0026quot; caption = \u0026quot;\u0026quot;  增加 learning 新版本提供了 content/tutorials 的实例，不过没有挂在首页，不容易发现。\n官方说明是适合用于：\n 项目或者软件文档 在线课程 教程  我这次用它来记录我的学习笔记，因为数量繁多不好整理，一直都没有放在个人网站上。\n具体修改内容如下：\n 重命名 content/tutorials 为 content/learning，通过 http://localhost:1313/learning/ 可以访问\n 由于目录被改名，所以左边的菜单报错，修改修改example.md中\n[menu.learning] # 将menu.tutorial修改为menu.learning parent = \u0026quot;Example Topic\u0026quot; weight = 1  修改_index.md:\n[menu.learning] # 将menu.tutorial修改为menu.learning name = \u0026quot;Overview\u0026quot; weight = 1  菜单恢复正常\n 在顶部的导航条中增加链接\n修改config.toml，增加菜单：\n[[menu.main]] name = \u0026quot;学习笔记\u0026quot; url = \u0026quot;/learning/\u0026quot; weight = 5  修改themes/academic/layouts/partials/docs_layout.html，注释掉一下内容：\n\u0026lt;!-- \u0026lt;div class=\u0026quot;body-footer\u0026quot;\u0026gt; {{ i18n \u0026quot;last_updated\u0026quot; }} {{ $.Lastmod.Format $.Site.Params.date_format }} \u0026lt;/div\u0026gt; --\u0026gt;  不直接显示最后修改时间在页面上，这样界面清爽一些。\n  slides功能 在content/slides下发现一个 example-slides.md 文件，用浏览器打开下面的地址：\nhttp://localhost:1313/slides/example-slides/\n发现原来是一个用markdown书写slides的功能，很有意思，稍后研究。\n图标和其他文件设置 复制 icon.png / icon-192.png 到 static/img 目录下。\n复制 baidu_verify_××××.html 和 google××××.html 到 static 目录下。\n优化 关闭google地图 首页的google地图现实，太影响页面打开速度。最后选择关闭。修改config.toml:\nmap = 0 # 最后还是决定关闭地图现实，太影响页面打开速度  去掉github项目的star显示 在hero页面上，默认设置会去取github项目的star数量，同样非常的拖累整体速度。还是去掉吧，修改文件content/home，删除以下内容：\n\u0026lt;a id=\u0026quot;academic-release\u0026quot; href=\u0026quot;https://github.com/alipay/sofa-mesh/releases\u0026quot; data-repo=\u0026quot;alipay/sofa-mesh\u0026quot;\u0026gt; Latest release \u0026lt;!-- V --\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;div class=\u0026quot;mt-3\u0026quot;\u0026gt; Star \u0026lt;/div\u0026gt; \u0026lt;script async defer src=\u0026quot;/local/buttons.github.io/buttons.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  改google analytics为百度统计 修改 academic/layouts/partials/header.html，将下面原来用于google analytics的内容：\n{{ if not .Site.IsServer }} {{ if .Site.GoogleAnalytics }} \u0026lt;script\u0026gt; window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', '{{ .Site.GoogleAnalytics }}', 'auto'); {{ if .Site.Params.privacy_pack }}ga('set', 'anonymizeIp', true);{{ end }} ga('require', 'eventTracker'); ga('require', 'outboundLinkTracker'); ga('require', 'urlChangeTracker'); ga('send', 'pageview'); \u0026lt;/script\u0026gt; \u0026lt;script async src=\u0026quot;//www.google-analytics.com/analytics.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; {{ if ($scr.Get \u0026quot;use_cdn\u0026quot;) }} {{ printf \u0026quot;\u0026lt;script async src=\\\u0026quot;%s\\\u0026quot; integrity=\\\u0026quot;%s\\\u0026quot; crossorigin=\\\u0026quot;anonymous\\\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\u0026quot; (printf $js.autotrack.url $js.autotrack.version) $js.autotrack.sri | safeHTML }} {{ end }} {{ end }} {{ end }}  修改为百度统计的内容：\n{{ if not .Site.IsServer }} {{ if .Site.GoogleAnalytics }} \u0026lt;script\u0026gt; var _hmt = _hmt || []; (function() { var hm = document.createElement(\u0026quot;script\u0026quot;); hm.src = \u0026quot;https://hm.baidu.com/hm.js?{{ .Site.GoogleAnalytics }}\u0026quot;; var s = document.getElementsByTagName(\u0026quot;script\u0026quot;)[0]; s.parentNode.insertBefore(hm, s); })(); \u0026lt;/script\u0026gt; {{ end }} {{ end }}  本地文件加速 使用中，发现网页装载速度不是很好，而且有时无法访问。检查后发现问题出现在页面上的一些静态文件下载上，使用的路径居然是https://cdnjs.cloudflare.com/××。\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css\u0026quot; integrity=\u0026quot;sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==\u0026quot; crossorigin=\u0026quot;anonymous\u0026quot;\u0026gt;  cloudflare网站是在国外，访问速度慢，而且非常不稳定：经常被墙。导致页面加载的速度慢，有时还会出现无法打开页面的问题（被墙）。解决的方式就是将这些文件放在网站本地，从而避开这个问题。\n具体做法：\n 修改 themes/academic/data/assets.toml，将类似https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js 的地址修改为 /local/cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js 修改 fonts.googleapis.com/css.css 文件，用 /local/fonts 替换 https://fonts ，将原来访问https://fonts.gstatic.com的地址指到本地。 修改 themes/academic/ 下的文件，将类似 //cdnjs.cloudflare.com 的地址替换为 /local/cdnjs.cloudflare.com  layouts/partials/header.html layouts/partials/footer.html layouts/partials/cookie_consent.html layouts/slides/baseof.html  然后将上述这些地址所指向的文件存放在static/img/local目录下，最大的工作量在这里。  最终的目标是实现下面第一个地址修改为第二个地址。\n https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js https://127.0.0.1:1313/local/cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js  小技巧：\n 用chrome浏览器的开发工具，看network，就知道有哪些文件是走remote访问了 find -type f -exec grep -H \u0026quot;//cdn\u0026quot; {} \\; 这样的命令可以方便的查找存在问题的文件  主题模板调整 0.54 版本的 academic 主题，在 post、publication、talk 等几个列表显示时，都不再提供图片显示，效果和之前版本差别好大，因此考虑修改模板。\nacademic/layouts/partials/widgets\ntalk 修改 themes/academic/layouts/partials/talk_li_card.html 文件。\n下面的内容，只显示日期，不显示具体时间。然后显示publication信息\n\u0026lt;div class=\u0026quot;talk-metadata\u0026quot; itemprop=\u0026quot;startDate\u0026quot;\u0026gt; {{ $date := .Params.time_start | default .Date }} {{ (time $date).Format $.Site.Params.date_format }} @ {{ .Params.publication }} \u0026lt;/div\u0026gt;  原有的这段内容删除，非常难看：\n{{ (time $date).Format $.Site.Params.date_format }} {{ if not .Params.all_day }} {{ (time $date).Format ($.Site.Params.time_format | default \u0026quot;3:04 PM\u0026quot;) }} {{ with .Params.time_end }} \u0026amp;mdash; {{ (time .).Format ($.Site.Params.time_format | default \u0026quot;3:04 PM\u0026quot;) }} {{ end }} {{ end }}  删除一下内容，新版本的 featured image 的显示丑的没法忍：\n{{ $resource := (.Resources.ByType \u0026quot;image\u0026quot;).GetMatch \u0026quot;*featured*\u0026quot; }} {{ $anchor := .Params.image.focal_point | default \u0026quot;Smart\u0026quot; }} {{ with $resource }} {{ $image := .Fill (printf \u0026quot;918x517 q90 %s\u0026quot; $anchor) }} \u0026lt;div\u0026gt; \u0026lt;a href=\u0026quot;{{ $.RelPermalink }}\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;{{ $image.RelPermalink }}\u0026quot; class=\u0026quot;article-banner\u0026quot; itemprop=\u0026quot;image\u0026quot; alt=\u0026quot;\u0026quot;\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; {{end}}  将旧版本的横幅图片显示搬回来，在上面位置加入如下内容：\n{{ if .Params.image_preview }} {{ .Scratch.Set \u0026quot;image\u0026quot; .Params.image_preview }} {{ else if .Params.header.image }} {{ .Scratch.Set \u0026quot;image\u0026quot; .Params.header.image }} {{ end }} {{ if .Scratch.Get \u0026quot;image\u0026quot; }} \u0026lt;div\u0026gt; \u0026lt;a href=\u0026quot;{{ .RelPermalink }}\u0026quot;\u0026gt; {{ $img_src := urls.Parse (.Scratch.Get \u0026quot;image\u0026quot;) }} {{ if $img_src.Scheme }} \u0026lt;img src=\u0026quot;{{ .Scratch.Get \u0026quot;image\u0026quot; }}\u0026quot; class=\u0026quot;article-banner\u0026quot; itemprop=\u0026quot;image\u0026quot;\u0026gt; {{ else }} \u0026lt;img src=\u0026quot;{{ \u0026quot;/img/\u0026quot; | relURL }}{{ .Scratch.Get \u0026quot;image\u0026quot; }}\u0026quot; class=\u0026quot;article-banner\u0026quot; itemprop=\u0026quot;image\u0026quot;\u0026gt; {{ end }} \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; {{ end }}  publication 修改 themes/academic/layouts/partials/publication_li_card.html 文件。\n同样去掉featured images的代码，也同样将原来的横幅图片显示搬回来。\n然后作者信息在最上面，有些不好看，将这行移动到下面一点的位置：\n{{ partial \u0026quot;page_metadata\u0026quot; (dict \u0026quot;content\u0026quot; $ \u0026quot;is_list\u0026quot; 1) }}  post 修改 themes/academic/layouts/partials/post_li_card.html 文件。\n同样去掉featured images的代码，也同样将原来的横幅图片显示搬回来。\nproject 暂时还不清楚如何设置，后面再弄。\nleanging 学习笔记中，0.54 版本不再显示 header images了，改回来。\n需要修改 themes/academic/layouts/partials/doc_layout.html 文件 ，加入\n{{ partial \u0026quot;header_image.html\u0026quot; . }} 这一行代码：\n\u0026lt;article class=\u0026quot;article\u0026quot; itemscope itemtype=\u0026quot;http://schema.org/Article\u0026quot;\u0026gt; {{ partial \u0026quot;header_image.html\u0026quot; . }} \u0026lt;div class=\u0026quot;docs-article-container\u0026quot;\u0026gt;  然后将老版本的 header_image.html 文件复制到 themes/academic/layouts/partials/ 目录下。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/theme/material-docs.html",
	"title": "material-docs主题",
	"tags": [],
	"description": "介绍hugo的material-docs主题，使用方式和订制化",
	"content": " 主题介绍 material-docs官网：\nhttp://themes.gohugo.io/theme/material-docs/\n这个主题非常适合用于文档，左边的导航栏支持多级菜单，样式也简单美观，而且对移动设备支持很好。\n我主要用它来做学习笔记，替代之前长期使用的gitbook（gitbook的问题主要是本地生成内容速度太慢，而gitbook官方网站访问速度又不好）。当前这个hugo学习笔记用的就是此主题。\n准备工作 Fork并定制 material-docs的github仓库已经有很长时间没有更新，基本停留在两年前。从实践中看，有很多问题，对新的hugo版本的支持也很不好。\n因此，采用fork的方式，建立自己的仓库：\nhttps://github.com/skyao/hugo-material-docs\n期间做了很多了更新：\n PR那边有很多已经被发现而且修订提交的问题，但是一直没有merge，我手工合并到自己的仓库 弃用google统计，改用百度统计，具体做法和 academic 中的做法是一样的 同样进行了本地加速，参照 academic 中的做法 修改了layout文件，主要是删除了版权申明，作者信息，下载修改为意见反馈，现在的版面非常的干净，没有任何多余的东西 汉化，没有做标准的i18n，因为是给自己定制，因此直接在layout文件中修改为中文。 修改了exampleSite的内容，删除原有的页面和图片，改为学习笔记的常见页面如介绍，安装等，方便后续使用 提供了简单的gitbook模版文件支持，可以生成一个简单带有文字说明和链接的页面，以便将原有gitbook用户导流到新的hugo笔记  使用方式 以新建一个学习笔记为例，详细描述需要的步骤和命令。\n新建学习笔记  在github中新建仓库，名为 learning-cilium的Cilium学习笔记\n 在本地新建一个hugo站点\nhugo new site learning-cilium cd learning-cilium  下载更新主题的脚本并执行\nwget https://raw.githubusercontent.com/skyao/hugo-material-docs/master/exampleSite/update_theme.sh chmod +x update_theme.sh ./update_theme.sh  命令完成之后，themes/hugo-material-docs目录下就有我们自己的主题文件内容。\n 从exampleSite目录复制需要的站点初始化文件到新站点\ncd themes/hugo-material-docs # 复制config.toml文件 cp config.toml ../../../config.toml # 复制content目录和static目录 cp -r content/ ../../../content/ cp -r static/ ../../../static/ # 复制gitignore文件 cp gitignore-example ../../../.gitignore  修改新站点的config.toml文件\n以下内容必须修改：\ntitle = \u0026quot;学习笔记\u0026quot; repo_url = \u0026quot;https://github.com/skyao/learning-hugo\u0026quot;  此时已经开始运行hogo server命令来查看新站点的内容了\n 继续修改站点内容\n主要是content目录下的index.md以及installation和introduction两个目录下的文件，也可以继续修改config.toml文件，可以从浏览器上实时看到修改后的效果\n 复制content/index.md文件到根目录下，作为README.md文件\ncp content/index.md README.md  然后删除文件头部的hugo元数据。\n 提交第一个初始版本到github\ngit init # 检查一下要提交的文件是否如预期 git status git add -A git commit -m \u0026quot;first version\u0026quot; git remote add origin git@github.com:skyao/learning-cilium.git git push -u origin master  和gitbook共存\n由于原来的读书笔记是gitbook格式，因此为了让原来gitbook那边的老用户有机会找回到新的基于hugo的笔记，需要在gitbook那边好歹留一个简单页面说明。\n为此，保留gitbook的最少文件，如book.json和README.md即可。是的，SUMMARY.md文件都是可以不用的，而且README.md文件本来也可以用来作为在github仓库的首页文档，因此实质上只是多了一个book.json文件。\n内容示意如下：\n{ \u0026quot;gitbook\u0026quot;: \u0026quot;\u0026gt;=3.2.0\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;Hugo学习笔记\u0026quot;, \u0026quot;language\u0026quot;: \u0026quot;zh-hans\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;敖小剑\u0026quot;, \u0026quot;extension\u0026quot;: null, \u0026quot;generator\u0026quot;: \u0026quot;site\u0026quot;, \u0026quot;links\u0026quot; : { \u0026quot;sidebar\u0026quot; : { \u0026quot;敖小剑的博客\u0026quot;: \u0026quot;https://skyao.io\u0026quot; } }, \u0026quot;structure\u0026quot; : { }, \u0026quot;plugins\u0026quot;: [ \u0026quot;-search\u0026quot;, \u0026quot;-sharing\u0026quot; ], \u0026quot;pluginsConfig\u0026quot;: { }, \u0026quot;title\u0026quot;: \u0026quot;Hugo学习笔记\u0026quot;, \u0026quot;variables\u0026quot;: { } }  最后，准备好.gitignore文件\n.* !.gitignore _book/ node_modules/ public/ themes/ update_theme.sh   扩展和增强 三次菜单和自动隐藏 默认，material-docs主题的主菜单，只显示两层。修改代码之后可以支持三层菜单显示，以应对笔记内容比较多的情况。\n但是也引发了另外一个问题，内容比较多的笔记，三级菜单一起展开，主菜单项的内容实在太多了。而且material-docs主题的主菜单是每个页面都嵌入的，不是iframe那种，导致菜单项比很多页面的实际内容都要多。因此考虑实现菜单项的自动隐藏，当菜单项（或者子项）没有被打开时，就只打开一级菜单。\n需要修改hugo-material-docs/layouts/partials/nav.html文件：\n{{ $currentNode := . }} {{ range .Site.Menus.main.ByWeight }} {{ $.Scratch.Set \u0026quot;currentMenuEntry\u0026quot; . }} \u0026lt;li\u0026gt; {{ if .HasChildren }} {{ partial \u0026quot;nav_link\u0026quot; $currentNode }} {{ if hasPrefix ( $.Permalink | relURL | printf \u0026quot;%s\u0026quot; ) .URL }} \u0026lt;ul\u0026gt; {{ range .Children }} {{ $.Scratch.Set \u0026quot;currentMenuEntry\u0026quot; . }} \u0026lt;li\u0026gt; {{ if .HasChildren }} {{ partial \u0026quot;nav_link\u0026quot; $currentNode }} {{ if hasPrefix ( $.Permalink | relURL | printf \u0026quot;%s\u0026quot; ) .URL }} \u0026lt;ul\u0026gt; {{ range .Children }} {{ $.Scratch.Set \u0026quot;currentMenuEntry\u0026quot; . }} {{ partial \u0026quot;nav_link\u0026quot; $currentNode }} {{ end }} \u0026lt;/ul\u0026gt; {{ end }} {{ else }} {{ partial \u0026quot;nav_link\u0026quot; $currentNode }} {{ end }} \u0026lt;/li\u0026gt; {{ end }} \u0026lt;/ul\u0026gt; {{ end }} {{ else }} {{ partial \u0026quot;nav_link\u0026quot; $currentNode }} {{ end }} \u0026lt;/li\u0026gt; {{ end }}  因为不熟悉代码，暂时通过写笨代码的方式实现了第三级菜单，最好是能用递归的方式，这样就可以实现无限级的菜单了。{{ if hasPrefix ( $.Permalink | relURL | printf \u0026quot;%s\u0026quot; ) .URL }} 用来判断是当前菜单或者当前菜单的子项是否打开，这个判断在第二级和第三级菜单中执行。\n发现并修复的问题 主菜单上当前页的H2菜单不显示 这个主题有个特性，可以在主菜单中，在当前页面下会自动增加所有H2 titile作为子菜单。这个特性相当于自动增加了一级菜单，对于内容长的页面很有用。\n发现，如果baseURL是完全域名如\u0026rdquo;https://skyao.io/\u0026quot;或者\u0026quot;http://localhost:1313\u0026quot;时，工作正常。但是，如果baseURL是\u0026quot;https://skyao.io/learning-hugo/\u0026quot;或者\u0026quot;http://localhost:1313/learning-hugo/\u0026quot;这样带有子目录时，就会失效。\n检查发现，是themes/hugo-material-docs/layouts/partials下的nav_link.html中，这段代码判断错误：\n{{ $currentMenuEntry := .Scratch.Get \u0026quot;currentMenuEntry\u0026quot; }} {{ $isCurrent := eq .Permalink ($currentMenuEntry.URL | absURL | printf \u0026quot;%s\u0026quot;) }}  这里判断菜单项是否是当前页面时，判断的方式是将当前页面的实际URL Permalink(内容如https://skyao.io/learning-hugo/installation/seo/) 和菜单项URL地址$currentMenuEntry.URL(内容如/installation/seo/)进行比较，如果一致则表示是当前页面。为了得到菜单项URL地址的绝对路径，需要使用absURL函数，如($currentMenuEntry.URL | absURL | printf \u0026quot;%s\u0026quot;)。\n但是这里的absURL函数输出结果居然是不正确的！baseURL为https://skyao.io/learning-hugo/ ，参数为 /installation/seo/时，函数absURL的结果居然是https://skyao.io/installation/seo/，learning-hugo/子目录消失了。\n修改方式为通过获取Permalink地址的相对路径，然后和$currentMenuEntry.URL比较，这样就避开了absURL函数的问题：\n{{ $currentMenuEntry := .Scratch.Get \u0026quot;currentMenuEntry\u0026quot; }} {{ $isCurrent := eq ( .Permalink | relURL | printf \u0026quot;%s\u0026quot; ) $currentMenuEntry.URL }}  这里还发现一个要注意的地方，在config.toml文件中，主菜单项的配置，url一定要用\u0026rdquo;/\u0026ldquo;开头，即：\n[[menu.main]] name = \u0026quot;安装\u0026quot; identifier = \u0026quot;installation\u0026quot; url = \u0026quot;/installation/\u0026quot;\t# 这里一定不要设置为\u0026quot;installation/\u0026quot; weight = 200  测试验证OK！\nIndex页面变成空白页 这个问题来历有些特别，material-docs主题因为太长时间没有维护，所以和新版本的hugo有非常大的差异。\n体现在_index.md文件的使用上，material-docs主题的exampleSite，跑在新版本的hugo上，各个页面都直接报错\u0026rdquo;404\u0026rdquo;！看public目录发现，content目录下的除index.md文件外，其他内容包括子目录都没有被处理。\n解决的方式就是在每个目录（包括根目录）下放置一个_index.md文件。\n但是，首页会偶尔出现问题，/这个页面偶尔会出现空白，没有内容，有时有能正常显示index.md文件的内容。没有规律，有时发生。\n最后，解决的方式是：\n 修改主题布局文件 hugo-material-docs/layouts/index.html\n{{ range where .Site.Pages \u0026quot;Type\u0026quot; \u0026quot;index\u0026quot; }} \u0026lt;h1\u0026gt;{{ .Title }} {{ if .IsDraft }} (Draft){{ end }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ end }}  删除这里的range循环，不要这个功能（可以自动从其他type为index的页面提取Content然后聚合在最后生成的index.html文件里面，不好用）：\n\u0026lt;h1\u0026gt;{{ .Title }} {{ if .IsDraft }} (Draft){{ end }}\u0026lt;/h1\u0026gt; {{ .Content }}  ​\n 在根目录下只放置一个_index.md文件，原来index.md的内容都放在这个文件里面。或者说，将index.md文件改名为\u0026rdquo;_index.md\u0026rdquo;。其他目录下还是同时放index.md和_index.md文件。\n  上一页和下一页的准确性 页面排序有两个位置：\n 左边的主菜单栏：这个是通过config.toml文件中定义的main menu的weight来决定，配合每个页面的weight。\n注意这时单个目录下的子页面的排序是在当前目录下进行。\n 每个页面的底部有上一页和下一页\n默认是按照时间（即每个页面上的data信息）排序，所以和前面用weight排序的结果就会很有大出入。\n因此，需要修改模板文件将排序方式修改为按照weight排序。\n其次，这里的排序是全局（即所有页面）进行排序。和前面每个目录下单独排序不一样，因此要让页面的上一页和下一页显示的内容和主菜单一致，就必须保证两个方法排序的一致性。\n推荐的方式是：子目录之间分配好weight的范围，比如a目录是100-199，b目录是200-299。然后a目录下的页面的weight就一定要取值在100-199中，b目录下的页面的weight就一定要取值在200-299。\n  待解决的问题 主题已经不再更新 作者已经消失，一年多没有更新，包括PR也没有人合并。\n随着hugo的版本越来越新，这个主题的问题也越来越多。希望后面有人继续维护这个主题，或者有类似的替代gitbook适合编写学习笔记类的主题出现。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/theme/theme.html",
	"title": "主题列表",
	"tags": [],
	"description": "列举个人觉得不错的Hugo主题",
	"content": " 在这里列出一些个人觉得不错的Hugo主题。\n门户类 文档类 可以看官网的分类：\nhttps://themes.gohugo.io/tags/documentation/\n列出一些觉得还不错的：\n DocuAPI\n类slate风格，带code example列，特别适合API文档和配置文档。\nhttps://themes.gohugo.io/docuapi/\n看demo效果相当的不错！！\n Material Docs\n非常漂亮的文档主题。\nhttps://themes.gohugo.io/material-docs/\n docDock\n中规中矩，但是感觉界面不够精致，没有Material Docs的惊艳感。\nhttps://themes.gohugo.io/docdock/\n Bootie Docs\n适合文档，尤其软件文档。\nhttps://themes.gohugo.io/bootie-docs/\n自带TOC功能。\n simpledoc\n单页文档，适合Q\u0026amp;A之类。\nhttps://themes.gohugo.io/hugo-simpledoc-theme/\n learn\n类似gitbook。\nhttps://themes.gohugo.io/hugo-theme-learn/\n Alabaster\n类似gitbook，稍显呆板。\nhttps://themes.gohugo.io/hugo-alabaster-theme/\n Kube\n带blog/faq，适合用于小型项目。\nhttps://themes.gohugo.io/kube/\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo/theme/theme-compare.html",
	"title": "主题比较",
	"tags": [],
	"description": "列举个人觉得不错的Hugo主题, 并进行简单比较",
	"content": " 在这里列出一些个人觉得不错的Hugo主题。\n门户类 文档类 可以看官网的分类：\nhttps://themes.gohugo.io/tags/documentation/\n列出一些觉得还不错的：\n   主题\\特性 TOC 评论 TAG SEARCH i18n Star Edit 总结     Learn Y   Y 原生 Y Y Y 类似gitbook   Beautiful Y   Y Y      Material Docs      Y N    DocuAPI        类slate风格，带code example列，特别适合API文档和配置文档。   Alabaster      Y     Bootie Docs Y 自带       自带TOC     DocuAPI\n类slate风格，带code example列，特别适合API文档和配置文档。\nhttps://themes.gohugo.io/docuapi/\n看demo效果相当的不错！！\n Material Docs\n非常漂亮的文档主题。\nhttps://themes.gohugo.io/material-docs/\n  example之skyao:\n- https://github.com/skyao/learning-istio - [主题修改](https://github.com/skyao/hugo-material-docs)   docDock\n这个是基于 learn 主题二次开发的\n中规中矩，但是感觉界面不够精致，没有Material Docs的惊艳感。\nhttps://themes.gohugo.io/docdock/\n Bootie Docs\n适合文档，尤其软件文档。\nhttps://themes.gohugo.io/bootie-docs/\n自带TOC功能。\n simpledoc\n单页文档，适合Q\u0026amp;A之类。\nhttps://themes.gohugo.io/hugo-simpledoc-theme/\n learn\n类似gitbook。\nhttps://themes.gohugo.io/hugo-theme-learn/\n Alabaster\n类似gitbook，稍显呆板。\nhttps://themes.gohugo.io/hugo-alabaster-theme/\n  example之www.deanishe.net:\n- https://github.com/deanishe/deanishe.github.io - https://github.com/deanishe/www.deanishe.net - https://github.com/deanishe/alabastard   Kube\n带blog/faq，适合用于小型项目。\nhttps://themes.gohugo.io/kube/\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cloudnative.html",
	"title": "cloudnative",
	"tags": [],
	"description": "cloudnative",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes.html",
	"title": "kubernetes",
	"tags": [],
	"description": "kubernetes",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker.html",
	"title": "docker",
	"tags": [],
	"description": "docker",
	"content": " 内容介绍 这是个人博客, 主要包括一些学习笔记\n访问方式 请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher.html",
	"title": "rancher",
	"tags": [],
	"description": "rancher",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/aws.html",
	"title": "aws",
	"tags": [],
	"description": "aws",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/bigdata.html",
	"title": "bigdata",
	"tags": [],
	"description": "bigdata",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/databases.html",
	"title": "database",
	"tags": [],
	"description": "database",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb.html",
	"title": "mariadb",
	"tags": [],
	"description": "mariadb",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql.html",
	"title": "mysql",
	"tags": [],
	"description": "mysql",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/postgresql.html",
	"title": "postgresql",
	"tags": [],
	"description": "postgresql",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb.html",
	"title": "mongodb",
	"tags": [],
	"description": "mongodb",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/redis.html",
	"title": "redis",
	"tags": [],
	"description": "redis",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/swift.html",
	"title": "swift",
	"tags": [],
	"description": "swift",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph.html",
	"title": "ceph",
	"tags": [],
	"description": "blog",
	"content": " 内容介绍 这是个人博客, 主要包括一些学习笔记\n访问方式 请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rust.html",
	"title": "rust",
	"tags": [],
	"description": "rust",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang.html",
	"title": "golang",
	"tags": [],
	"description": "golang",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/javascript.html",
	"title": "javascript",
	"tags": [],
	"description": "javascript",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs.html",
	"title": "nodejs",
	"tags": [],
	"description": "nodejs",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/npm.html",
	"title": "npm",
	"tags": [],
	"description": "npm",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python.html",
	"title": "python",
	"tags": [],
	"description": "python",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/django.html",
	"title": "django",
	"tags": [],
	"description": "django",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/java.html",
	"title": "java",
	"tags": [],
	"description": "java",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ruby.html",
	"title": "ruby",
	"tags": [],
	"description": "ruby",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rails.html",
	"title": "rails",
	"tags": [],
	"description": "rails",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rvm.html",
	"title": "rvm",
	"tags": [],
	"description": "rvm",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/r.html",
	"title": "r",
	"tags": [],
	"description": "r",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/php.html",
	"title": "php",
	"tags": [],
	"description": "php",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs.html",
	"title": "emacs",
	"tags": [],
	"description": "emacs",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs.html",
	"title": "spacemacs",
	"tags": [],
	"description": "spacemacs",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vscode.html",
	"title": "vscode",
	"tags": [],
	"description": "vscode",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ide.html",
	"title": "ide",
	"tags": [],
	"description": "ide",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cli.html",
	"title": "cli",
	"tags": [],
	"description": "cli",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yasnippet.html",
	"title": "yasnippet",
	"tags": [],
	"description": "yasnippet",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/babun.html",
	"title": "babun",
	"tags": [],
	"description": "babun",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/scoop.html",
	"title": "scoop",
	"tags": [],
	"description": "scoop",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/wechat.html",
	"title": "wechat",
	"tags": [],
	"description": "wechat",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux.html",
	"title": "linux",
	"tags": [],
	"description": "linux",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu.html",
	"title": "ubuntu",
	"tags": [],
	"description": "ubuntu",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos.html",
	"title": "centos",
	"tags": [],
	"description": "centos",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows.html",
	"title": "windows",
	"tags": [],
	"description": "windows",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos.html",
	"title": "macos",
	"tags": [],
	"description": "macos",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/solaris.html",
	"title": "solaris",
	"tags": [],
	"description": "solaris",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vagrant.html",
	"title": "vagrant",
	"tags": [],
	"description": "vagrant",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox.html",
	"title": "virtualbox",
	"tags": [],
	"description": "virtualbox",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vmware.html",
	"title": "vmware",
	"tags": [],
	"description": "vmware",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/life.html",
	"title": "life",
	"tags": [],
	"description": "my life",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vm.html",
	"title": "vm",
	"tags": [],
	"description": "vm",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/shell.html",
	"title": "shell",
	"tags": [],
	"description": "shell",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/bash.html",
	"title": "bash",
	"tags": [],
	"description": "bash",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/zsh.html",
	"title": "zsh",
	"tags": [],
	"description": "zsh",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vim.html",
	"title": "vim",
	"tags": [],
	"description": "vim",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tmux.html",
	"title": "tmux",
	"tags": [],
	"description": "tmux",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor.html",
	"title": "monitor",
	"tags": [],
	"description": "monitor",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/zabbix.html",
	"title": "zabbix",
	"tags": [],
	"description": "zabbix",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git.html",
	"title": "git",
	"tags": [],
	"description": "git",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/github.html",
	"title": "github",
	"tags": [],
	"description": "github",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab.html",
	"title": "gitlab",
	"tags": [],
	"description": "gitlab",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/devops.html",
	"title": "devops",
	"tags": [],
	"description": "devops",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev.html",
	"title": "dev",
	"tags": [],
	"description": "dev",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/bitbucket.html",
	"title": "bitbucket",
	"tags": [],
	"description": "bitbucket",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets.html",
	"title": "cheatsheets",
	"tags": [],
	"description": "cheatsheets",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn.html",
	"title": "svn",
	"tags": [],
	"description": "svn",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/travis.html",
	"title": "travis",
	"tags": [],
	"description": "travis",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ansible.html",
	"title": "ansible",
	"tags": [],
	"description": "ansible",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/blog.html",
	"title": "blog",
	"tags": [],
	"description": "blog",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo.html",
	"title": "hugo",
	"tags": [],
	"description": "hugo",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitbook.html",
	"title": "gitbook",
	"tags": [],
	"description": "gitbook",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/jupyter.html",
	"title": "jupyter",
	"tags": [],
	"description": "jupyter",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown.html",
	"title": "markdown",
	"tags": [],
	"description": "markdown",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/org.html",
	"title": "org",
	"tags": [],
	"description": "org",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn.html",
	"title": "learn",
	"tags": [],
	"description": "learn",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource.html",
	"title": "resource",
	"tags": [],
	"description": "resource",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note.html",
	"title": "note",
	"tags": [],
	"description": "note",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/post.html",
	"title": "post",
	"tags": [],
	"description": "post",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hexo.html",
	"title": "hexo",
	"tags": [],
	"description": "hexo",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/jekyll.html",
	"title": "jekyll",
	"tags": [],
	"description": "jekyll",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network.html",
	"title": "network",
	"tags": [],
	"description": "network",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx.html",
	"title": "nginx",
	"tags": [],
	"description": "nginx",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ngrok.html",
	"title": "ngrok",
	"tags": [],
	"description": "ngrok",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/security.html",
	"title": "security",
	"tags": [],
	"description": "security",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/chrome.html",
	"title": "chrome",
	"tags": [],
	"description": "chrome",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/web.html",
	"title": "web",
	"tags": [],
	"description": "web",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vue.html",
	"title": "vue",
	"tags": [],
	"description": "vue",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yapi.html",
	"title": "yapi",
	"tags": [],
	"description": "yapi",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/html.html",
	"title": "html",
	"tags": [],
	"description": "html",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/eslint.html",
	"title": "eslint",
	"tags": [],
	"description": "eslint",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cookie.html",
	"title": "cookie",
	"tags": [],
	"description": "cookie",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yarn.html",
	"title": "yarn",
	"tags": [],
	"description": "yarn",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/taro.html",
	"title": "taro",
	"tags": [],
	"description": "taro",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/react.html",
	"title": "react",
	"tags": [],
	"description": "react",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/css.html",
	"title": "css",
	"tags": [],
	"description": "css",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/apps.html",
	"title": "apps",
	"tags": [],
	"description": "apps",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/baidu.html",
	"title": "baidu",
	"tags": [],
	"description": "baidu",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/analytics.html",
	"title": "analytics",
	"tags": [],
	"description": "analytics",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/elixir.html",
	"title": "elixir",
	"tags": [],
	"description": "elixir",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/enterprise.html",
	"title": "enterprise",
	"tags": [],
	"description": "enterprise",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/fitness.html",
	"title": "fitness",
	"tags": [],
	"description": "fitness",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/google.html",
	"title": "google",
	"tags": [],
	"description": "google",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ledger.html",
	"title": "ledger",
	"tags": [],
	"description": "ledger",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markup.html",
	"title": "markup",
	"tags": [],
	"description": "markup",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/keyboard.html",
	"title": "keyboard",
	"tags": [],
	"description": "keyboard",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/apple.html",
	"title": "apple",
	"tags": [],
	"description": "apple",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-health.html",
	"title": "health",
	"tags": ["health", "note"],
	"description": "",
	"content": " 健身前 热身  充分热身，如：拉伸身体各部位。 部分运动，请找好队友。如：卧推。  心态  告诉自己：自我感觉身体不适，请停止运动。 健康是一个长期的过程。  这里有多层意思，至少有：\n 不要想着一天就能增长好多肌肉或减少好多脂肪，这不可能。 坚持（这个是世界上最难的事情）。 要以健康为中心。任何不以健康为中心的健身，都是伪健身。 尽量避免运动中受伤(这也是个很难的事情)。  健身中 增肌 大肌肉群为主 杠铃，哑铃, 卧推\n 12次*4组模式 力竭*4组模式 单组能达50次，请进阶，加难度  呼吸  不可憋气。 出吐回吸。俯卧撑：下去，靠近地面，吐气；回来，靠近天空，吸气。 会有特殊情况，则有不同。  减脂 有氧运动为主  跑步是一个好方式。 心率的50-85% 持续不断20分钟  健身后 0-5分钟  慢走 放松体操 小动一下  不可以的事：\n 不宜洗澡 不宜立即吸烟 不宜贪吃冷饮 不宜蹲坐 不宜吃饭  健身结束后应该调整呼吸节奏，进行一些低热量的活动，比如说慢走，做几节放松体操或者说是进行简单的深呼吸，促进四肢血液能够回流心脏，这样有利于我们还清欠下的“氧债”，能够加快恢复身体机能，消除疲劳。\n5-20分钟  可坐可蹲了 小口多次喝水，不能喝多  不可以的事：\n 不宜洗澡 不宜立即吸烟 不宜贪吃冷饮 不宜吃饭  20-30分钟  宜洗澡  30-60分钟  洗澡。优先泡澡，再次淋浴 进食。先吃碳水化合物，再蛋白类。  60-120分钟  休息  运动了，很累的，让身体停下来。\n进食 健身中进食 在训练过程中碳水化各物的补充尤为重要，特别是减脂。\n注意  如果先进食，则进食后20分钟内不可以洗澡。 多蒸煮，少油。多蛋白，少辣椒。 少吃多餐。（最少一天要吃5顿，有条件8顿以上。早餐必吃） 晚餐不能大吃特吃 细嚼慢咽 重视蛋白质（一般人：体重公斤*1.1克，增股：体重公斤*2克） 每天要喝大量的白开水（不是饮料）  推荐食材  牛肉，鸡胸肉，羊肉（均为瘦肉） 鸡蛋(蛋白可多个，蛋黄不多于2个，且蛋黄要相互分开1小时吃) 酸奶，全脂奶 苹果汁(鲜榨) 白面包，意大利面 三文鱼，各种鱼 香蕉, 牛油果 橄榄油 地瓜 燕麦 紫菜  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-gitbook.html",
	"title": "gitbook（笔记）",
	"tags": ["gitbook", "note"],
	"description": "",
	"content": " 已移至 gitbook-handbook 仓库\n入门  https://www.jianshu.com/p/fa38ef97431d https://segmentfault.com/a/1190000011440899 https://www.jianshu.com/p/b0a11b9b8725 https://www.jianshu.com/p/09a1cac0a0d0  初步  http://www.ituring.com.cn/article/127744 http://www.chengweiyang.cn/gitbook/github-pages/README.html  进阶  https://github.com/zhangjikai/gitbook-use/  常见问题 Cannot find module \u0026lsquo;prismjs/components/prism-shell.js ➜ swift-docs git:(master) ✗ gitbook build ./ Failed to load prism syntax: shell { Error: Cannot find module 'prismjs/components/prism-shell.js' at Function.Module._resolveFilename (internal/modules/cjs/loader.js:613:15) at Function.Module._load (internal/modules/cjs/loader.js:539:25) at Module.require (internal/modules/cjs/loader.js:667:17) at require (internal/modules/cjs/helpers.js:20:18) at requireSyntax (/Users/tomtsang/gitbook/swift-docs/node_modules/gitbook-plugin-prism/index.js:31:3) at Object.code (/Users/tomtsang/gitbook/swift-docs/node_modules/gitbook-plugin-prism/index.js:103:11) at Record.TemplateBlock.applyBlock (/Users/tomtsang/.gitbook/versions/3.2.3/lib/models/templateBlock.js:205:23) at /Users/tomtsang/.gitbook/versions/3.2.3/lib/output/getModifiers.js:56:33 at /Users/tomtsang/.gitbook/versions/3.2.3/lib/output/modifiers/highlightCode.js:47:24 at /Users/tomtsang/.gitbook/versions/3.2.3/lib/output/modifiers/editHTMLElement.js:11:16 code: 'MODULE_NOT_FOUND' } info: \u0026gt;\u0026gt; generation finished with success in 1.8s ! ➜ swift-docs git:(master) ✗  根据报错信息，查看`/node_modules/gitbook-plugin-prism/index.js`文件及gitbook-plugin-prism插件配置可以知道，插件默认不支持以`shell`语法前缀作为`bash`语法前缀的别名，所以会报错，但是支持自定义，添加上以下配置即可：\n\u0026quot;pluginsConfig\u0026quot;: { \u0026quot;prism\u0026quot;: { \u0026quot;lang\u0026quot;: { \u0026quot;shell\u0026quot;: \u0026quot;bash\u0026quot; } } }  Ref  https://www.imooc.com/article/details/id/30528 https://github.com/flutterchina/flutter-in-action/pull/111  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs-install.html",
	"title": "nodejs 一定要通过 nvm安装",
	"tags": ["nodejs", "install", "nvm"],
	"description": "",
	"content": " 使用 nvm 管理不同版本的 node 与 npm\nstep 补充说明：Mac 下通过 brew install nvm 所安装的 nvm ，由于安装路径不同，无法正确启用。建议使用 brew uninstall nvm 卸载掉之后，通过本文的方案重新安装一次。\nnvm 是 Mac 下的 node 管理工具，有点类似管理 Ruby 的 rvm，如果是需要管理 Windows 下的 node，官方推荐是使用 nvmw 或 nvm-windows 。\n以下具体说下 Mac 系统中的安装与使用细节（Windows 系统仅供类比参考）。\n一、卸载已安装到全局的 node/npm 如果之前是在官网下载的 node 安装包，运行后会自动安装在全局目录，其中\n node 命令在 `/usr/local/bin/node` npm 命令在 `/usr/local/bin/npm` ，其实是 `/usr/local/lib/node_modules/npm/bin/npm-cli.js` 的软链接 全局 node_modules 目录在 `/usr/local/lib/node_modules/`  安装 nvm 之后最好先删除下已安装的 node 和全局 node 模块：\nnpm ls -g --depth=0 #查看已经安装在全局的模块，以便删除这些全局模块后再按照不同的 node 版本重新进行全局安装 sudo rm -rf /usr/local/lib/node_modules #删除全局 node_modules 目录 sudo rm /usr/local/bin/node #删除 node cd /usr/local/bin \u0026amp;\u0026amp; ls -l | grep \u0026quot;../lib/node_modules/\u0026quot; | awk '{print $9}'| xargs rm #删除全局 node 模块注册的软链  二、安装 nvm https://github.com/creationix/nvm\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.34.0/install.sh | bash  安装完成后请重新打开终端环境，Mac 下推荐使用 oh-my-zsh 代替默认的 bash shell。\n报错 The program \u0026lsquo;rbenv\u0026rsquo; is currently not installed 如果 nvm 安装过程中, 报出如下错误\nThe program 'rbenv' is currently not installed. You can install it by typing: sudo apt install rbenv  那么说明没有安装成功的。要依据提示做一下。\nu@DESKTOP-APB1HCJ:~$ sudo apt install rbenv  检查 u@DESKTOP-APB1HCJ:~$ which nvm DESKTOP-APB1HCJ% nvm --version 0.34.0 DESKTOP-APB1HCJ% nvm version v11.14.0 DESKTOP-APB1HCJ%  三、安装切换各版本 node/npm nvm install stable #安装最新稳定版 node，现在是 5.0.0 nvm install 4.2.2 #安装 4.2.2 版本 nvm install 0.12.7 #安装 0.12.7 版本 # 特别说明：以下模块安装仅供演示说明，并非必须安装模块 nvm use 0 #切换至 0.12.7 版本 npm install -g mz-fis #安装 mz-fis 模块至全局目录，安装完成的路径是 /Users/\u0026lt;你的用户名\u0026gt;/.nvm/versions/node/v0.12.7/lib/mz-fis nvm use 4 #切换至 4.2.2 版本 npm install -g react-native-cli #安装 react-native-cli 模块至全局目录，安装完成的路径是 /Users/\u0026lt;你的用户名\u0026gt;/.nvm/versions/node/v4.2.2/lib/react-native-cli nvm alias default 0.12.7 #设置默认 node 版本为 0.12.7  查看已经安装版本\nnvm ls  帮助\nnvm --help  四、使用 .nvmrc 文件配置项目所使用的 node 版本 如果你的默认 node 版本（通过 nvm alias 命令设置的）与项目所需的版本不同，则可在项目根目录或其任意父级目录中创建 .nvmrc 文件，在文件中指定使用的 node 版本号，例如：\ncd \u0026lt;项目根目录\u0026gt; #进入项目根目录 echo 4 \u0026gt; .nvmrc #添加 .nvmrc 文件 nvm use #无需指定版本号，会自动使用 .nvmrc 文件中配置的版本 node -v #查看 node 是否切换为对应版本  五、nvm 与 n 的区别 node 版本管理工具还有一个是 TJ 大神的 n 命令，n 命令是作为一个 node 的模块而存在，而 nvm 是一个独立于 node/npm 的外部 shell 脚本，因此 n 命令相比 nvm 更加局限。\n由于 npm 安装的模块路径均为 /usr/local/lib/node_modules ，当使用 n 切换不同的 node 版本时，实际上会共用全局的 node/npm 目录。 因此不能很好的满足『按不同 node 版本使用不同全局 node 模块』的需求。\n因此建议各位尽早开始使用 nvm ，以免出现全局模块无法更新的问题。\n当然，如果你用的是 windows 操作系统，我只能说 …… 朋友，能不能早点换个 Mac\nRef  http://www.cnblogs.com/kaiye/p/4937191.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/eslint/eslint-install.html",
	"title": "eslint入门",
	"tags": ["eslint", "install"],
	"description": "",
	"content": " 安装 npm install -g eslint babel-eslint eslint-plugin-react eslint-config-airbnb  在安装的时候得注意一点，eslint与eslint-config-airbnb要么都执行全局安装，要么都本地安装，必须相同哟。\n然后，把 https://github.com/airbnb/javascript/blob/master/linters/.eslintrc 下载到Project 中就可以了。\n使用 配置完相关信息后，就可以切到项目目录内然后执行检测啦：\n我们新建一个test.js进行检测\n$ eslint test.js  JavaScript Style Guide 关于 JavaScript Style Guide 可以直接参考\n https://github.com/airbnb/javascript  react eslint 优先查看：\n在React+Babel+Webpack环境中使用ESLint\n https://www.cnblogs.com/le0zh/p/5619350.html https://www.bbsmax.com/A/obzbX0j65E/  React-native ESLint \u0026amp; Airbnb 配置\n https://www.jianshu.com/p/1d66a10466d2  npm run lint 检查所有js文件 在根目录的 package.json文件下修改如下:\n\u0026quot;scripts\u0026quot;: { \u0026quot;lint\u0026quot;: \u0026quot;eslint --ext .js ./src --fix\u0026quot; }  根目录下运行:\nnpm run lint  再webpack配置中使用eslint加载器 添加 到：webpack.cofnig.js\n... eslint: { configFile: './.eslintrc' }, ...  pre-commit钩子 如果项目使用了git,可以通过使用pre-commit钩子在每次提交前检测，如果检测失败则禁止提交。可以在很大一定程度上保证代码质量。\n这里我们使用了pre-commitgit包来帮助我们实现这一目标。\n首先在package.json中添加script命令：\n\u0026quot;scripts\u0026quot;: { \u0026quot;eslint\u0026quot;: \u0026quot;eslint --ext .js src\u0026quot; }  其次，安装pre-commit\nnpm install pre-commit --save-dev  最后，在package.json中配置pre-commit需要运行的命令：\n\u0026quot;pre-commit\u0026quot;: [ \u0026quot;eslint\u0026quot; ]  完成之后，在每次提交之前，都会运行eslint命令进行检测，如果检测到有违反代码规则的情况，则会返回1，导致git commit失败。\nairbnb eslint 使用airbnb的eslint https://www.bbsmax.com/A/Ae5RYomYJQ/ https://www.cnblogs.com/samwu/p/5772778.html\nRef  https://segmentfault.com/a/1190000004965396 https://github.com/airbnb/javascript http://spacemacs.org/layers/+frameworks/react/README.html https://eslint.org/docs/user-guide/configuring https://csspod.com/getting-started-with-eslint/ https://www.jianshu.com/p/ad6784d028aa http://eslint.cn/docs/user-guide/configuring  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tools/tools.html",
	"title": "tools",
	"tags": ["tools"],
	"description": "",
	"content": " What are the best  https://www.slant.co  Learn to code egghead 通过一些短小视频，学习一系列实用技术\n https://egghead.io/  github issue https://issuehunt.io/\nbabel https://babeljs.io/\nhttps://babeljs.io/repl\nhttps://bugout2.testin.cn/\nFIGlet，是一种计算机程序，其生成各种字体的文本横幅，由由较小ASCII字符的集合构成的字母组成。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/taro/taro-msparis-install.html",
	"title": "初始化安装 taro-msparis",
	"tags": ["react", "taro"],
	"description": "",
	"content": " appjson [\u0026ldquo;tabBar\u0026rdquo;][\u0026ldquo;borderStyle\u0026rdquo;] be \u0026ldquo;white\u0026rdquo; or \u0026ldquo;black\u0026rdquo; dist/app.json中的 \u0026ldquo;tabBar\u0026rdquo;下的\u0026rdquo;borderStyle\u0026rdquo;要修改为： \u0026ldquo;black\u0026rdquo;\n微信小程序报错request:fail url not in domain list 报错提示说请求的url不在域名列表里，应该是还没有配置服务器域名，可点击开发者工具右上角 详情-域名信息，看看是否配置了域名； 不过没有配置域名其实开发者工具也是不能发送请求的； 文档：https://developers.weixin.qq.com/miniprogram/dev/api/wx.request.html\n然后，操作如下：\n 开发者工具里面要勾选不校验，也就是下面这句前打上勾：  Does not verify valid domain names, web-view (business domain names), TLS versions and HTTPS certificates\n 手机里面也要打开调试，也就是：  开发版小程序不是右上角有三个点点嘛，点击就能看到打开调试\n这样就可以.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/saleor/saleor-conf-templates-base.html",
	"title": "saleor 设置 templates base",
	"tags": ["saleor", "conf"],
	"description": "",
	"content": " 安装完了 saleor ，下一步，自然就是修改一些我们自己的Logo，页脚之类的东西了。\n页脚COPYRIGHT (saleor) ➜ saleor git:(master) ✗ grep \u0026quot;COPYRIGHT © 2009–2019 MIRUMEE SOFTWARE\u0026quot; -rn ./ ./templates/base.html:296: \u0026lt;div class=\u0026quot;col-8 footer__copy-text\u0026quot;\u0026gt;COPYRIGHT © 2009–2019 MIRUMEE SOFTWARE\u0026lt;/div\u0026gt; (saleor) ➜ saleor git:(master) ✗  把这里修改成我们自己的\n(saleor) ➜ saleor git:(master) ✗ vi templates/base.html (saleor) ➜ saleor git:(master) ✗ grep \u0026quot;COPYRIGHT © 2009–2019 \u0026quot; -rn ./ ../../../templates/base.html:296: \u0026lt;div class=\u0026quot;col-8 footer__copy-text\u0026quot;\u0026gt;COPYRIGHT © 2009–2019 谦谦科技\u0026lt;/div\u0026gt; (saleor) ➜ images git:(master) ✗  页脚Logo 只要审查元素就知道，这个 LOGO是 SVG图像。\n\u0026lt;div class=\u0026quot;col-4\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;{% url 'home' %}\u0026quot; class=\u0026quot;footer__logo float-md-left\u0026quot;\u0026gt; \u0026lt;svg data-src=\u0026quot;{% static \u0026quot;images/logo-document.svg\u0026quot; %}\u0026quot;/\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-8 footer__copy-text\u0026quot;\u0026gt;COPYRIGHT © 2009–2019 谦谦科技\u0026lt;/div\u0026gt;  位置在\n(saleor) ➜ saleor git:(master) ✗ ls ./saleor/static/images/logo-document.svg ./saleor/static/images/logo-document.svg (saleor) ➜ saleor git:(master) ✗  所以，我们这里要制造我们自己的SVG图像。\n因为我对这个SVG不了解，就直接去https://icomoon.io/app/#/select下载了个，并把它命名为 logo-test.svg。并放到指定的位置。\n(saleor) ➜ saleor git:(master) ✗ mv ./logo-test.svg ./saleor/static/images/logo-test.svg (saleor) ➜ saleor git:(master) ✗ git diff templates/base.html diff --git a/templates/base.html b/templates/base.html index f9f67b1..9c5caf0 100644 --- a/templates/base.html +++ b/templates/base.html @@ -290,10 +290,10 @@ \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-4\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;{% url 'home' %}\u0026quot; class=\u0026quot;footer__logo float-md-left\u0026quot;\u0026gt; - \u0026lt;svg data-src=\u0026quot;{% static \u0026quot;images/logo-document.svg\u0026quot; %}\u0026quot;/\u0026gt; + \u0026lt;svg data-src=\u0026quot;{% static \u0026quot;images/logo-test.svg\u0026quot; %}\u0026quot;/\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; - \u0026lt;div class=\u0026quot;col-8 footer__copy-text\u0026quot;\u0026gt;COPYRIGHT © 2009–2019 MIRUMEE SOFTWARE\u0026lt;/div\u0026gt; + \u0026lt;div class=\u0026quot;col-8 footer__copy-text\u0026quot;\u0026gt;COPYRIGHT © 2009–2019 千千科技\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; (END)  这样，就完成了页脚logo的替换。\n(可跳过)SVG 生成与展示 参考 https://www.jb51.net/article/105196.htm 。\n(saleor) ➜ saleor git:(master) ✗ sudo apt update \u0026amp;\u0026amp; sudo apt-get install libxml2-dev libxslt1-dev python-dev python-lxml python-cairosvg -y \u0026amp;\u0026amp; pip install pygal lxml cairosvg tinycss cssselect  页头 logo (saleor) ➜ saleor git:(master) ✗ grep \u0026quot;logo-document.svg\u0026quot; -rl ./templates/base.html | xargs sed -i \u0026quot;s/logo-document.svg/logo-document-qq.svg/g\u0026quot; (saleor) ➜ saleor git:(master) ✗ 想了一下，干脆，所有的地方都替换一下。 (saleor) ➜ saleor git:(master) ✗ grep logo-document.svg -rl ./saleor/core/emails.py | xargs sed -i \u0026quot;s/logo-document.svg/logo-document-qq.svg/g\u0026quot; (saleor) ➜ saleor git:(master) ✗ grep logo-document.svg -rl ./templates/ | xargs sed -i \u0026quot;s/logo-document.svg/logo-document-qq.svg/g\u0026quot; (saleor) ➜ saleor git:(master) ✗ grep logo-document.svg -rl ./saleor/static/dashboard-next/auth/components/LoginPage/LoginPage.tsx | xargs sed -i \u0026quot;s/logo-document.svg/logo-document-qq.svg/g\u0026quot; (saleor) ➜ saleor git:(master) ✗  dashboard logo (saleor) ➜ saleor git:(master) ✗ cp ./logo-document-qq.svg saleor/static/dashboard/images/logo-document-qq.svg (saleor) ➜ saleor git:(master) ✗ grep \u0026quot;logo.svg\u0026quot; -rl ./templates/dashboard/base.html | xargs sed -i \u0026quot;s/logo.svg/logo-document-qq.svg/g\u0026quot; (saleor) ➜ saleor git:(master) ✗  ref  https://icomoon.io/app/#/select  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/saleor/saleor-customization-docker.html",
	"title": "docker 安装 saleor",
	"tags": ["saleor", "install"],
	"description": "",
	"content": " https://docs.getsaleor.com/en/latest/customization/docker.html\n安装后 完成步骤后的效果如下：\n(saleor) ➜ saleor git:(master) ✗ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 202bd2594ad9 saleor_web \u0026quot;python manage.py ru…\u0026quot; About a minute ago Up 33 seconds 0.0.0.0:8000-\u0026gt;8000/tcp saleor_web_1 af1d1c556b35 saleor_celery \u0026quot;celery -A saleor wo…\u0026quot; About a minute ago Up 33 seconds 8000/tcp saleor_celery_1 aa067abbd302 postgres:latest \u0026quot;docker-entrypoint.s…\u0026quot; About a minute ago Up 34 seconds 0.0.0.0:5432-\u0026gt;5432/tcp saleor_db_1 dfb447947378 redis:latest \u0026quot;docker-entrypoint.s…\u0026quot; About a minute ago Up 33 seconds 0.0.0.0:6379-\u0026gt;6379/tcp saleor_redis_1 (saleor) ➜ saleor git:(master) ✗ docker images REPOSITORY TAG IMAGE ID CREATED SIZE saleor_celery latest ed5d34462667 3 minutes ago 619MB saleor_web latest ed5d34462667 3 minutes ago 619MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; df1c689ebe30 About an hour ago 619MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 0bd648a8810c About an hour ago 1.42GB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; f70f27cf8740 About an hour ago 1.39GB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; c0e63021a2e5 2 hours ago 965MB node 10 c481a0ff9f4f 14 hours ago 897MB postgres latest d03e2a8f3ed4 17 hours ago 312MB python 3.6-slim e9b00f8a90d8 5 days ago 138MB python 3.6 5b0503f864f4 5 days ago 922MB redis latest 82629e941a38 8 days ago 95MB hello-world latest fce289e99eb9 4 weeks ago 1.84kB (saleor) ➜ saleor git:(master) ✗  error1 如果打开 https://127.0.0.1:8000 出现了如下错误\nrelation \u0026quot;django_site\u0026quot; does not exist LINE 1: ...\u0026quot;django_site\u0026quot;.\u0026quot;domain\u0026quot;, \u0026quot;django_site\u0026quot;.\u0026quot;name\u0026quot; FROM \u0026quot;django_si...  则说明是没有进行 `./manage.py migrate` 这一命令。也就是说，很可能，你忘记进行本 小节的第2步骤。\ndocker-compose run web python3 manage.py migrate docker-compose run web python3 manage.py collectstatic docker-compose run web python3 manage.py populatedb --createsuperuser  当然，如果你确定，你是进行了上面的3个命令，还是有之前的那个报错，那么请进入 container，然后执行命令。\n(saleor) ➜ saleor git:(master) ✗ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 202bd2594ad9 saleor_web \u0026quot;python manage.py ru…\u0026quot; 30 minutes ago Up 29 minutes 0.0.0.0:8000-\u0026gt;8000/tcp saleor_web_1 af1d1c556b35 saleor_celery \u0026quot;celery -A saleor wo…\u0026quot; 30 minutes ago Up 29 minutes 8000/tcp saleor_celery_1 aa067abbd302 postgres:latest \u0026quot;docker-entrypoint.s…\u0026quot; 30 minutes ago Up 29 minutes 0.0.0.0:5432-\u0026gt;5432/tcp saleor_db_1 dfb447947378 redis:latest \u0026quot;docker-entrypoint.s…\u0026quot; 30 minutes ago Up 29 minutes 0.0.0.0:6379-\u0026gt;6379/tcp saleor_redis_1 (saleor) ➜ saleor git:(master) ✗ docker exec -it 202bd2594ad9 bash root@202bd2594ad9:/app# ./manage.py migrate root@202bd2594ad9:/app# ./manage.py collectstatic root@202bd2594ad9:/app# ./manage.py populatedb --createsuperuser  执行完成后，回到浏览器中去登陆 http://192.168.1.103:8000/zh-hans/account/login/ ，应该是没有问题的。\nadmin account : admin@example.com password : admin\nRef  https://stackoverflow.com/questions/23925726/django-relation-django-site-does-not-exist  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/pipenv-install-failed.html",
	"title": "pipenv install 报错",
	"tags": ["python", "pipenv", "faq"],
	"description": "",
	"content": "在某个项目中遇到了出错，如下：\n(saleor) ➜ saleor git:(master) pipenv install --dev Courtesy Notice: Pipenv found itself running within a virtual environment, so it will automatically use that environment, instead of creating its own for any project. You can set PIPENV_IGNORE_VIRTUALENVS =1 to force pipenv to ignore that environment and create its own instead. You can set PIPENV_VERBOSITY=-1 to suppress this warning. Installing dependencies from Pipfile.lock (0c0b26)… An error occurred while installing yarl==1.3.0 ; python_version \u0026gt;= '3.4' --hash=sha256:024ecdc12bc02b321bc66b41327f930d1c2c543fa9a561b39861da9388ba7aa9 --hash=sha256:2f3010703295fbe1aec51023740871e64bb966 4c789cba5a6bdf404e93f7568f --hash=sha256:3890ab952d508523ef4881457c4099056546593fa05e93da84c7250516e632eb --hash=sha256:3e2724eb9af5dc41648e5bb304fcf4891adc33258c6e14e2a7414ea32541e320 --hash=sha256:5badb 97dd0abf26623a9982cd448ff12cb39b8e4c94032ccdedf22ce01a64842 --hash=sha256:73f447d11b530d860ca1e6b582f947688286ad16ca42256413083d13f260b7a0 --hash=sha256:7ab825726f2940c16d92aaec7d204cfc34ac26c0040da727cf8 ba87255a33829 --hash=sha256:b25de84a8c20540531526dfbb0e2d2b648c13fd5dd126728c496d7c3fea33310 --hash=sha256:c6e341f5a6562af74ba55205dbd56d248daf1b5748ec48a0200ba227bb9e33f4 --hash=sha256:c9bb7c249c4432cd47 e75af3864bc02d26c9594f49c82e2a28624417f0ae63b8 --hash=sha256:e060906c0c585565c718d1c3841747b61c5439af2211e185f6739a9412dfbde1! Will try again. 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 151/151 — 00:02:25 Installing initially failed dependencies… [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 1874, in do_install [pipenv.exceptions.InstallError]: keep_outdated=keep_outdated [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 1253, in do_init [pipenv.exceptions.InstallError]: pypi_mirror=pypi_mirror, [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 859, in do_install_dependencies [pipenv.exceptions.InstallError]: retry_list, procs, failed_deps_queue, requirements_dir, **install_kwargs [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 763, in batch_install [pipenv.exceptions.InstallError]: _cleanup_procs(procs, not blocking, failed_deps_queue, retry=retry) [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 681, in _cleanup_procs [pipenv.exceptions.InstallError]: raise exceptions.InstallError(c.dep.name, extra=err_lines) [pipenv.exceptions.InstallError]: ['Looking in indexes: https://pypi.python.org/simple', 'Collecting yarl==1.3.0 (from -r /tmp/pipenv-umy9db73-requirements/pipenv-5nm2wwj2-requirement.txt (line 1))'] [pipenv.exceptions.InstallError]: ['Could not find a version that satisfies the requirement yarl==1.3.0 (from -r /tmp/pipenv-umy9db73-requirements/pipenv-5nm2wwj2-requirement.txt (line 1)) (from versions: 0.0.1, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.3.2, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0b2, 0.5.0b3, 0.5.0b4, 0.5.0b5, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.6.0, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.9.5, 0.9.6, 0.9.7, 0.9.8, 0.10.0, 0.10.1, 0.10.2, 0.10.3, 0.11.0, 0.12.0, 0.13.0, 0.14.0, 0.14.1, 0.14.2, 0.15.0, 0.16.0, 0.17.0, 0.18.0, 1.0.0, 1.1.0, 1.1.1, 1.2.0)' , 'No matching distribution found for yarl==1.3.0 (from -r /tmp/pipenv-umy9db73-requirements/pipenv-5nm2wwj2-requirement.txt (line 1))'] ERROR: ERROR: Package installation failed... (saleor) ➜ saleor git:(master)  其实在最开始的时候，就已经提示`An error occurred while installing yarl==1.3.0`, 这个时候，如果我们看到了，应该要停止安装接下来的包，因为，最后还是会报错的。\n一个简单有效的思路，就是手工安装一下 yarl 包，看是不是版本不对。\n(saleor) ➜ saleor git:(master) grep yarl -rn ./Pipfile* ./Pipfile.lock:1384: \u0026quot;yarl\u0026quot;: { (saleor) ➜ saleor git:(master) vi ./Pipfile.lock (saleor) ➜ saleor git:(master) pip install yarl==1.3 Collecting yarl==1.3 Could not find a version that satisfies the requirement yarl==1.3 (from versions: 0.0.1, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.3.2, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0b2, 0.5.0b3, 0.5.0b4, 0.5.0b5, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.6.0, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.9.5, 0.9.6, 0.9.7, 0.9.8, 0.10.0, 0.10.1, 0.10.2, 0.10.3, 0.11.0, 0.12.0, 0.13.0, 0.14.0, 0.14.1, 0.14.2, 0.15.0, 0.16.0, 0.17.0, 0.18.0, 1.0.0, 1.1.0, 1.1.1, 1.2.0) No matching distribution found for yarl==1.3 (saleor) ➜ saleor git:(master) pip install yarl Collecting yarl Downloading https://files.pythonhosted.org/packages/23/7d/41beef3b35c1836079fde8408aebfb3c0a24c6bf2e66078d351fc4cfa1ff/yarl-1.2.0-cp35-cp35m-manylinux1_x86_64.whl (252kB) 100% |████████████████████████████████| 256kB 520kB/s Requirement already satisfied: idna\u0026gt;=2.0 in /home/tom/.virtualenvs/saleor/lib/python3.5/site-packages (from yarl) (2.8) Requirement already satisfied: multidict\u0026gt;=4.0 in /home/tom/.virtualenvs/saleor/lib/python3.5/site-packages (from yarl) (4.5.2) Installing collected packages: yarl Successfully installed yarl-1.2.0 (saleor) ➜ saleor git:(master) vi ./Pipfile.lock (saleor) ➜ saleor git:(master) ✗ pipenv install --dev Courtesy Notice: Pipenv found itself running within a virtual environment, so it will automatically use that environment, instead of creating its own for any project. You can set PIPENV_IGNORE_VIRTUALENVS=1 to force pipenv to ignore that environment and create its own instead. You can set PIPENV_VERBOSITY=-1 to suppress this warning. Installing dependencies from Pipfile.lock (0c0b26)… 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 151/151 — 00:02:00 (saleor) ➜ saleor git:(master) ✗ ls apollo.config.js common.env docker-compose.yml LICENSE package.json Pipfile.lock requirements_dev.txt saleor templates tsconfig.json webpack.d.ts app.json deployment Dockerfile locale package-lock.json Procfile requirements.txt scripts tests tslint.json CHANGELOG.md docker-compose.override.yml docs manage.py Pipfile README.md runtime.txt setup.cfg tox.ini webpack.config.js (saleor) ➜ saleor git:(master) ✗  看到了吧。pip 直接安装的是 1.2.0 ,所以，把 Pipfile.lock 文件里的版本值 修改成 1.2.0 就可以了。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/how-to-install-sshpass-on-mac.html",
	"title": "mac 上安装 sshpass",
	"tags": ["mac", "sshpass"],
	"description": "",
	"content": " brew install https://raw.githubusercontent.com/kadwanev/bigboybrew/master/Library/Formula/sshpass.rb  Ref  https://stackoverflow.com/questions/32255660/how-to-install-sshpass-on-mac fs  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git-submodules-add-usage-delete.html",
	"title": "git中submodule子模块的添加、使用和删除",
	"tags": ["git", "submodules"],
	"description": "",
	"content": " 背景 项目中经常使用别人维护的模块，在git中使用子模块的功能能够大大提高开发效率。\n使用子模块后，不必负责子模块的维护，只需要在必要的时候同步更新子模块即可。\n本文主要讲解子模块相关的基础命令，详细使用请参考man page。\n子模块的添加 添加子模块非常简单，命令如下：\ngit submodule add \u0026lt;url\u0026gt; \u0026lt;path\u0026gt;  其中，url为子模块的路径，path为该子模块存储的目录路径。\n执行成功后，git status会看到项目中修改了.gitmodules，并增加了一个新文件（为刚刚添加的路径）\ngit diff \u0026ndash;cached查看修改内容可以看到增加了子模块，并且新文件下为子模块的提交hash摘要\ngit commit提交即完成子模块的添加\n子模块的使用 克隆项目后，默认子模块目录下无任何内容。需要在项目根目录执行如下命令完成子模块的下载：\ngit submodule init git submodule update  或：\ngit submodule update --init --recursive  执行后，子模块目录下就有了源码，再执行相应的makefile即可。\n子模块的更新 子模块的维护者提交了更新后，使用子模块的项目必须手动更新才能包含最新的提交。\n在项目中，进入到子模块目录下，执行 git pull更新，查看git log查看相应提交。\n完成后返回到项目目录，可以看到子模块有待提交的更新，使用git add，提交即可。\n修改Submodule URL 修改某模块URL\n 修改\u0026rsquo;.gitmodules\u0026rsquo;文件中对应模块的url属性; 使用`git submodule sync`命令，将新的URL更新到文件.git/config；  thinker-g@localhost: ~/app$ git submodule sync Synchronizing submodule url for 'gitmods/thinker_g/Helpers' thinker-g@localhost: ~/app$ # 运行后可观察到'.git/config'中对应模块的url属性被更新 thinker-g@localhost: ~/app$ git commit -am \u0026quot;Update submodule url.\u0026quot; # 提交变更  PS: 本实验使用git 2.7.4 完成，较低版本git可能不能自动更新.git/config文件，需要修修改完\u0026rdquo;.gitmodule\u0026rdquo;文件后手动修改.git/config.\n删除子模块 有时子模块的项目维护地址发生了变化，或者需要替换子模块，就需要删除原有的子模块。\n优雅的删除子模块 如何优雅的删除子模块(submodule)\n# 逆初始化模块，其中{MOD_NAME}为模块目录，执行后可发现模块目录被清空 git submodule deinit {MOD_NAME} # 删除.gitmodules中记录的模块信息（--cached选项清除.git/modules中的缓存） git rm --cached {MOD_NAME} # 提交更改到代码库，可观察到'.gitmodules'内容发生变更 git commit -am \u0026quot;Remove a submodule.\u0026quot;  Done! Nice \u0026amp; clean!\n（不推荐）非优雅的删除子模块 删除子模块较复杂，步骤如下：\n rm -rf 子模块目录 删除子模块目录及源码 vi .gitmodules 删除项目目录下.gitmodules文件中子模块相关条目 vi .git/config 删除配置项中子模块相关条目 rm .git/module/* 删除模块下的子模块目录，每个子模块对应一个目录，注意只删除对应的子模块目录即可  执行完成后，再执行添加子模块命令即可，如果仍然报错，执行如下：\ngit rm --cached 子模块名称  完成删除后，提交到仓库即可。\nRef  https://www.jianshu.com/p/ed0cb6c75e25 https://blog.csdn.net/guotianqing/article/details/82391665  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-tmux.html",
	"title": "tmux（笔记）",
	"tags": ["tmux", "note"],
	"description": "",
	"content": " 基础 http://blog.jobbole.com/87584/\n高效的结对编程 在Tmux 中使用 Tmate\n在文本间快速移动光标，复制文本 将复制下来的文本发送到系统的剪贴板中\nSelect and copy text\n调整 Tmux 以增强其同 Vim 的集成度 调整背景的配色方案\n调整光标的形状\n调整粘贴时的文本缩进\n美化 Tmux 的状态栏 tmux-plugins https://github.com/tmux-plugins\n查看version ➜ ~ git:(master) ✗ tmux -V tmux 2.1 ➜ ~ git:(master) ✗  滚屏 https://superuser.com/questions/209437/how-do-i-scroll-in-tmux\n复制文字 https://superuser.com/questions/196060/selecting-text-in-tmux-copy-mode\nRef  https://zhuanlan.zhihu.com/p/33369297 https://github.com/search?q=tmux https://github.com/gpakosz/.tmux https://yq.aliyun.com/articles/44513 https://www.jianshu.com/p/ccac114c522e https://superuser.com/questions/209437/how-do-i-scroll-in-tmux https://www.jianshu.com/p/ccac114c522e http://os.51cto.com/art/201410/453671.htm http://os.51cto.com/art/201410/453671.htm  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/add-user-to-docker-group.html",
	"title": "用户加入docker组",
	"tags": ["docker"],
	"description": "",
	"content": " Docker 创建docker用户组，应用用户加入docker组\n创建docker用户组 sudo groupadd docker  应用用户加入docker用户组 sudo usermod -aG docker ${USER}  重启docker服务 sudo systemctl restart docker  切换或者退出当前账户再从新登入 su root # 切换到root用户 su ${USER} # 再切换到原来的应用用户以上配置才生效  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-django-oscar.html",
	"title": "django-oscar(笔记)",
	"tags": ["oscar", "django", "note"],
	"description": "",
	"content": "(oscar) ➜ django-oscar git:(master) make sandbox pip install -r requirements.txt Collecting Werkzeug==0.14.1 (from -r requirements.txt (line 4)) Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB) 100% |████████████████████████████████| 327kB 8.8MB/s Collecting django-debug-toolbar==1.11 (from -r requirements.txt (line 5)) Downloading https://files.pythonhosted.org/packages/01/9a/3db232bd15882d90d3c53de1f34ce0a522327849593c9198899713267cfe/django_debug_toolbar-1.11-py2.py3-none-any.whl (201kB) 100% |████████████████████████████████| 204kB 24.9MB/s Collecting django-extensions==2.1.4 (from -r requirements.txt (line 6)) Downloading https://files.pythonhosted.org/packages/e4/56/6a854a56732f7cb6a0393b8a32ae8a37b82b004e638b7b2f153b66733ce5/django_extensions-2.1.4-py2.py3-none-any.whl (217kB) 100% |████████████████████████████████| 225kB 4.8MB/s Collecting psycopg2\u0026lt;2.8,\u0026gt;=2.7 (from -r requirements.txt (line 7)) Downloading https://files.pythonhosted.org/packages/63/54/c039eb0f46f9a9406b59a638415c2012ad7be9b4b97bfddb1f48c280df3a/psycopg2-2.7.7.tar.gz (427kB) 100% |████████████████████████████████| 430kB 4.1MB/s Complete output from command python setup.py egg_info: running egg_info creating pip-egg-info/psycopg2.egg-info writing pip-egg-info/psycopg2.egg-info/PKG-INFO writing dependency_links to pip-egg-info/psycopg2.egg-info/dependency_links.txt writing top-level names to pip-egg-info/psycopg2.egg-info/top_level.txt writing manifest file 'pip-egg-info/psycopg2.egg-info/SOURCES.txt' Error: pg_config executable not found. pg_config is required to build psycopg2 from source. Please add the directory containing pg_config to the $PATH or specify the full executable path with the option: python setup.py build_ext --pg-config /path/to/pg_config build ... or with the pg_config option in 'setup.cfg'. If you prefer to avoid building psycopg2 from source, please install the PyPI 'psycopg2-binary' package instead. For further information please check the 'doc/src/install.rst' file (also at \u0026lt;http://initd.org/psycopg/docs/install.html\u0026gt;). ---------------------------------------- Command \u0026quot;python setup.py egg_info\u0026quot; failed with error code 1 in /tmp/pip-install-e2o6_oa6/psycopg2/ Makefile:19: recipe for target 'install-python' failed make: *** [install-python] Error 1 (oscar) ➜ django-oscar git:(master)  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-close-ssh-connection-user.html",
	"title": "linux 关闭SSH 连接用户",
	"tags": ["linux", "ssh"],
	"description": "",
	"content": "1.查明登陆端口；\n$ who root pts/1 Apr 8 00:06 (172.29.0.29) root pts/2 Apr 8 04:15 (172.29.0.21)  2.通知该用户将要关闭他：\n$ echo \u0026quot;I will close your connection\u0026quot; \u0026gt; /dev/pts/2  这样他的终端将显示该信息。\n3.关闭用户连接\n$ fuser -k /dev/pts/2  这个在某些命令，导致ssh后续无法操作时，我们就可以使用这个方式。\n疑问：当有多个ssh 连接时，那怎么知道我们要kill 的是哪个 pts 呢？\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/can-scp-create-a-directory-if-it-doesnt-exist.html",
	"title": "Can scp create a directory if it doesn&#39;t exist?",
	"tags": ["shell", "scp"],
	"description": "",
	"content": " Can scp create a directory if it doesn\u0026rsquo;t exist?\nAs far as I know, scp itself cannot do that, no. However, you could just ssh to the target machine, create the directory and then copy. Something like:\nssh user@host \u0026quot;mkdir -p /target/path/\u0026quot; \u0026amp;\u0026amp; scp /path/to/source user@host:/target/path/  Note that if you are copying entire directories, the above is not needed. For example, to copy the directory ~/foo to the remote host, you could use the -r (recursive) flag:\nscp ~/foo/ user@host:~/  That will create the target directory ~/foo on the remote host. However, it can\u0026rsquo;t create the parent directory. scp ~/foo user@host:~/bar/foo will fail unless the target directory bar exists. In any case, the -r flag won\u0026rsquo;t help create a target directory if you are copying individual files.\nRef  https://unix.stackexchange.com/questions/193368/can-scp-create-a-directory-if-it-doesnt-exist  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-spacemacs.html",
	"title": "spacemacs(笔记)",
	"tags": ["spacemacs"],
	"description": "",
	"content": "load-themes(SPC T s) org-cycle(TAB)\nspacemacs打开org文件时默认没有自动折行。想要自动折行，则运行：\nM-x spacemacs/toggle-visual-line-navigation-on 现在发现下面这个也可以自动折行：\nM-x toggle-truncate-lines M-x toggle-truncate-lines-on M-x toggle-truncate-lines-off\n最后，其实都是查看 SPC h d v truncate-lines 这个变量的值是t 还是 nil\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-build-copy-failed-no-such-file-or-directory.html",
	"title": "docker build时运行 COPY 时报no such file or directory 错误",
	"tags": ["docker", "faq"],
	"description": "",
	"content": " env Expected behavior COPY command to copy a file from local to image\nActual behavior doing a simple COPY command in Dockerfile is throwing this error when the file is in a folder (not same level as Dockerfile file)\nDescription\nI have a Dockerfile that has the line:\nCOPY MyAgSourceAPI/conf/php/testsql.php var/www\nBut it causes the error:\nCOPY failed: stat /var/lib/docker/tmp/docker-builder918577595/MyAgSourceAPI/conf/php/testsql.php: no such file or directory\nstep 有一些解决方案在 https://github.com/docker/for-mac/issues/1922 提出来。\n我这里的解决方案是：指定 Dockerfile 路径(-f). 具体如下：\ndocker build . -f /home/ubuntu/tmp/docker-ide-ud-v3/Dockerfile -t tomtsang/ide-ok  Ref  https://github.com/docker/for-mac/issues/1922  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/django/djangoprojectcom-using-django-queries.html",
	"title": "using-django中的queries",
	"tags": ["django"],
	"description": "",
	"content": "本文是对 https://docs.djangoproject.com/zh-hans/2.1/topics/db/queries/ 这一小节的说明\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vmware/vmware-workstation-pro-install.html",
	"title": "vmware workstation pro 安装",
	"tags": ["vmware", "install"],
	"description": "",
	"content": " Vmware安装提示在关闭以下进程 之前，无法进行安装的解决办法\n如图，如果真的通过任务管理器关闭了VMware.exe的话，安装程序也就关闭了，后来才发现这个VMware.exe和VMware的主程序重名了，把安装程序改名为其他的就行了，比如VMware-install.exe\n安装最后一步是输入 激活密钥，请支持正版。\nRef  https://blog.csdn.net/u011666411/article/details/85998068 https://blog.csdn.net/aZhengjava520/article/details/81087847  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vmware/ubuntu-vmware-workstation-pro-new-partition.html",
	"title": "在vmware workstation pro 中给ubuntu增加新分区",
	"tags": ["ubuntu", "fdisk"],
	"description": "",
	"content": " env 在 vmware workstation pro 中安装的ubuntu server已经把20G的硬盘已经按默认的方式分区，且已经是把20G硬盘全占用。 此时，如果用 fdisk /dev/sda 然后 n 来新建分区的时候，会报出 no sector available 的错误。\n这个时候，有2个思路。\n 把原来的 sector和硬盘空间 释放出来，然后，新建立分区 把硬盘空间加大（不是另增加一块硬盘），然后，重新规划分区  step 思路1，本来是寄希望于 gpart 和 gparted 命令（通过 apt install 安装）的，但是，发现，文章已失效，-s -t 等命令的效果与原理明显不对了，所以思路1，中断。\n思路2，操作成功。下面就只介绍思路2.\n关虚拟机，打开，点击，设置/硬盘/扩展容量，增加10G到30G, 然后，磁盘整理，一下，开机。\n这个时候，fdisk -l 可以看到 sector 已经增加了。\n但是通过 n 后，并不能选择 l, 只能选择 p，且分配的大小，不超过1个G,明显不是我们想要的。\n这个时候，我直接把 原有的 1,2,5 三个分区的 2，5直接删除（d）,然后再 n, 这个时候，就可以分出我们想要的分区了。 最后我的效果是 1,2,5,6 其中6分区占用了新增磁盘的 8 GB .\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/eshell-zshrc-cannot-ok.html",
	"title": "eshell 中 没有完全加载 .zshrc 中的配置",
	"tags": ["emacs", "eshell", "zsh"],
	"description": "",
	"content": " Env 下面是终端上 zsh 的输出：\n➜ ~ cat /etc/shells # List of acceptable shells for chpass(1). # Ftpd will not allow users to connect who are not using # one of these shells. /bin/bash /bin/csh /bin/ksh /bin/sh /bin/tcsh /bin/zsh ➜ ~ echo $SHELL /bin/zsh ➜ ~ which js-beautify /usr/local/bin/js-beautify ➜ ~  下面是emacs中 eshell(`SPC \u0026lsquo;`开启)的输出：\nWelcome to the Emacs shell ~/org:master*? λ echo /etc/shells /etc/shells ~/org:master*? λ cat /etc/shells # List of acceptable shells for chpass(1). # Ftpd will not allow users to connect who are not using # one of these shells. /bin/bash /bin/csh /bin/ksh /bin/sh /bin/tcsh /bin/zsh ~/org:master*? λ echo $SHELL /bin/zsh ~/org:master*? λ which js-beautify which: no js-beautify in (/Users/tomtsang/.cask/bin:/Users/tomtsang/.gvm/pkgsets/go1.10/global/bin:/Users/tomtsang/.gvm/gos/go1.10/bin:/Users/tomtsang/.gvm/pkgsets/go1.10/global/overlay/bin:/Users/tomtsang/.gvm/bin:/Users/tomtsang/.gvm/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/Emacs.app/Contents/MacOS/bin-x86_64-10_10:/Applications/Emacs.app/Contents/MacOS/libexec-x86_64-10_10:/usr/local/go/bin) ~/org:master*? λ  导致在*.js文件中，不能使用js-beautify(打开方式`, =`）格式化js代码，报错信息如下：\nzsh:1: command not found: js-beautify  怎么办呢？\nStep  SPC h SPC eshell\n 查看文档 ~/.emacs.d/layers/+tools/shell/README.org 知道：\n原理：修改 shell-default-shell 从 eshell 到 shell\n操作：在配置文件 ~/.spacemacs.d/init.el 中修改 shell layer中的配置.\n(shell :variables shell-default-shell 'shell)  Ref  https://www.jb51.net/LINUXjishu/247797.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/shell/how-to-check-if-a-program-exists-from-a-bash-script.html",
	"title": "Shell(Bash)中如何判断是否存在某个命令",
	"tags": ["shell", "check"],
	"description": "",
	"content": "在编写bash时，如果要判断某条命令是否存在，应该如何写呢？ 下面以 foo 代表某个命令（如：wget）. 我尝试了如下的写法，\nwhich foo \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [ $? == 0 ]; then echo \u0026quot;exist\u0026quot; else echo \u0026quot;dose not exist\u0026quot; fi  但是： 最好避免使用 which，做为一个外部的工具，并不一定存在，在发行版之间也会有区别，有的系统的 which 命令不会设置有效的 exit status，存在一定的不确定性。\nBash 有提供一些内建命令如 hash、type、command 也能达到要求。\n$ command -v foo \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || { echo \u0026gt;\u0026amp;2 \u0026quot;I require foo but it's not installed. Aborting.\u0026quot;; exit 1; } $ type foo \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || { echo \u0026gt;\u0026amp;2 \u0026quot;I require foo but it's not installed. Aborting.\u0026quot;; exit 1; } $ hash foo 2\u0026gt;/dev/null || { echo \u0026gt;\u0026amp;2 \u0026quot;I require foo but it's not installed. Aborting.\u0026quot;; exit 1; }  详见 https://stackoverflow.com/questions/592620/how-to-check-if-a-program-exists-from-a-bash-script\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-interview-roadmap.html",
	"title": "python面试准备roadmap",
	"tags": ["python", "interview"],
	"description": "",
	"content": " step1 https://www.cnblogs.com/Vito2008/p/5044251.html\n#!/Users/tomtsang/.virtualenvs/quant-py3/bin/python # -*- coding:utf-8 -*- # Author: zengyunlong # 补充缺失的代码 def print_directory_contents(sPath): \u0026quot;\u0026quot;\u0026quot; 这个函数接受文件夹的名称作为输入参数， 返回该文件夹中文件的路径， 以及其包含文件夹中文件的路径。 \u0026quot;\u0026quot;\u0026quot; import os for sChild in os.listdir(sPath): sChildPath = os.path.join(sPath , sChild) if os.path.isdir(sChildPath): print_directory_contents(sChildPath) else: print(sChildPath) print(\u0026quot;this is before if __name__:%s\u0026quot;%__name__) if __name__=='__main__': print(\u0026quot;this is after if __name__:%s\u0026quot;%__name__) print(print_directory_contents(\u0026quot;.\u0026quot;))  TODO step2 https://www.cnblogs.com/goodhacker/p/3366618.html\nTODO step3 https://blog.csdn.net/weixin%5F41666747/article/details/79942847\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-login-faq.html",
	"title": "docker login failure,  unauthorized: incorrect username or password",
	"tags": ["docker", "login"],
	"description": "",
	"content": " 报错中出现类似“unauthorized: incorrect username or password”的话。\n➜ saleor git:(master) docker-compose run web python3 manage.py migrate Pulling db (library/postgres:latest)... latest: Pulling from library/postgres a5a6f2f73cd8: Already exists e50fbea8af5a: Pull complete 73b4855ad326: Pull complete ERROR: Get https://registry-1.docker.io/v2/library/postgres/manifests/latest: unauthorized: incorrect username or password ➜ saleor git:(master)  重新使用 docker.com 中的用户名登陆，而不是邮箱登陆。\n➜ saleor git:(master) docker logout Removing login credentials for https://index.docker.io/v1/ ➜ saleor git:(master) docker login Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one. Username: tomtsang Password: Login Succeeded ➜ saleor git:(master)  这样后续就正常了。\nRef  https://forums.docker.com/t/unauthorized-incorrect-username-or-password/35677/5  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/golang-channel-learning-a.html",
	"title": "golang channel",
	"tags": ["golang", "channel"],
	"description": "",
	"content": " goroutine 首先我们来看线程,在golang里面也叫goroutine\n在读这篇文章之前，我们需要了解一下并发与并行。golang的线程是一种并发机制，而不是并行。它们之间的区别大家可以上网搜一下，网上有很多的介绍。\n下面我们先来看一个例子吧\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { go fmt.Println(\u0026quot;1\u0026quot;) fmt.Println(\u0026quot;2\u0026quot;) }  在golang里面，使用go这个关键字，后面再跟上一个函数就可以创建一个线程。后面的这个函数可以是已经写好的函数，也可以是一个匿名函数\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { var i = 3 go func(a int) { fmt.Println(a) fmt.Println(\u0026quot;1\u0026quot;) }(i) fmt.Println(\u0026quot;2\u0026quot;) }  上面的代码就创建了一个匿名函数，并且还传入了一个参数i，下面括号里的i是实参，a是形参。\n那么上面的代码能按照我们预想的打印1、2、3吗？告诉你们吧，不能，程序只能打印出2。下面我把正确的代码贴出来吧\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { var i = 3 go func(a int) { fmt.Println(a) fmt.Println(\u0026quot;1\u0026quot;) }(i) fmt.Println(\u0026quot;2\u0026quot;) time.Sleep(1 * time.Second) }  我只是在最后加了一行让主线程休眠一秒的代码，程序就会依次打印出2、3、1。\n那为什么会这样呢？因为程序会优先执行主线程，主线程执行完成后，程序会立即退出，没有多余的时间去执行子线程。如果在程序的最后让主线程休眠1秒钟，那程序就会有足够的时间去执行子线程。\n线程先讲到这里，下面我们来看看通道吧。\nchannel 通道又叫channel，顾名思义，channel的作用就是在多线程之间传递数据的。\n创建无缓冲channel chreadandwrite :=make(chan int) chonlyread := make(\u0026lt;-chan int) //创建只读channel chonlywrite := make(chan\u0026lt;- int) //创建只写channel  下面我们来看一个例子：\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { ch := make(chan int) ch \u0026lt;- 1 go func() { \u0026lt;-ch fmt.Println(\u0026quot;1\u0026quot;) }() fmt.Println(\u0026quot;2\u0026quot;) }  这段代码执行时会出现一个错误：fatal error: all goroutines are asleep - deadlock!\n这个错误的意思是说线程陷入了死锁，程序无法继续往下执行。那么造成这种错误的原因是什么呢？\n我们创建了一个无缓冲的channel，然后给这个channel赋值了，程序就是在赋值完成后陷入了死锁。因为我们的channel是无缓冲的，即同步的，赋值完成后来不及读取channel，程序就已经阻塞了。\n这里介绍一个非常重要的概念：channel的机制是先进先出，如果你给channel赋值了，那么必须要读取它的值，不然就会造成阻塞，当然这个只对无缓冲的channel有效。对于有缓冲的channel，发送方会一直阻塞直到数据被拷贝到缓冲区；如果缓冲区已满，则发送方只能在接收方取走数据后才能从阻塞状态恢复。\n对于上面的例子有两种解决方案：\n1、给channel增加缓冲区，然后在程序的最后让主线程休眠一秒，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { ch :=make(chan int,1) ch \u0026lt;- 1 go func() { v := \u0026lt;-ch fmt.Println(v) }() time.Sleep(1 * time.Second) fmt.Println(\u0026quot;2\u0026quot;) }  这样的话程序就会依次打印出1、2\n2、把ch\u0026lt;-1这一行代码放到子线程代码的后面，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { ch := make(chan int) go func() { v := \u0026lt;-ch fmt.Println(v) }() ch \u0026lt;- 1 fmt.Println(\u0026quot;2\u0026quot;) }  这里就不用让主线程休眠了，因为channel在主线程中被赋值后，主线程就会阻塞，直到channel的值在子线程中被取出。\n最后我们看一个生产者和消费者的例子：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func produce(p chan\u0026lt;- int) { for i := 0; i \u0026lt; 10; i++ { p \u0026lt;- i fmt.Println(\u0026quot;send:\u0026quot;, i) time.Sleep(time.Millisecond * 100) } } func consumer(c \u0026lt;-chan int) { for i := 0; i \u0026lt; 10; i++ { v := \u0026lt;-c fmt.Println(\u0026quot;receive:\u0026quot;, v) time.Sleep(time.Millisecond * 100) } } func main() { ch := make(chan int) go produce(ch) go consumer(ch) time.Sleep(1 * time.Second) }  在这段代码中，因为channel是没有缓冲的，所以当生产者给channel赋值后，生产者这个线程会阻塞，直到消费者线程将channel中的数据取出。消费者第一次将数据取出后，进行下一次循环时，消费者的线程也会阻塞，因为生产者还没有将数据存入，这时程序会去执行生产者的线程。程序就这样在消费者和生产者两个线程间不断切换，直到循环结束。\n创建带缓冲channel 下面我们再看一个带缓冲的例子：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func produce(p chan\u0026lt;- int) { for i := 0; i \u0026lt; 10; i++ { p \u0026lt;- i fmt.Println(\u0026quot;send:\u0026quot;, i) } } func consumer(c \u0026lt;-chan int) { for i := 0; i \u0026lt; 10; i++ { v := \u0026lt;-c fmt.Println(\u0026quot;receive:\u0026quot;, v) } } func main() { ch := make(chan int, 10) go produce(ch) go consumer(ch) time.Sleep(1 * time.Second) }  在这个程序中，缓冲区可以存储10个int类型的整数，在执行生产者线程的时候，线程就不会阻塞，一次性将10个整数存入channel，在读取的时候，也是一次性读取。\nRef  https://blog.csdn.net/netdxy/article/details/54564436  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/works.html",
	"title": "my works",
	"tags": ["works"],
	"description": "",
	"content": " blog https://b.qqbb.app blog handbook https://book.qqmm.app cheatsheets https://c.eiu.app stock https://s.qqbb.app 论坛 http://www.hkshop.club:4567  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/devops/devops-ideas.html",
	"title": "devops ideas",
	"tags": ["devops", "ideas"],
	"description": "",
	"content": " windows 防止电脑被远程控制 https://jingyan.baidu.com/article/a948d65159fc890a2dcd2ea8.html\n对外开放端口 对外开放的端口的机器，随时都有被攻击，被挂掉的风险。\n所以，对外开放的端口的机器，必须只提供单一的对外服务，即使挂掉了，也没有关系。\n尽可能使用docker吧。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/kids-code.html",
	"title": "kids code",
	"tags": ["code"],
	"description": "",
	"content": "少儿编程网\nhttp://www.kidscode.cn/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-intro.html",
	"title": "ceph 安装，基于ubuntu, intro",
	"tags": ["ceph", "install", "intro"],
	"description": "",
	"content": "Contents:\n README Preflight Storage Cluster Quick Start Block Device Quick Start Filesystem Quick Start Object Storage Quick Start  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu.html",
	"title": "ceph 安装，基于ubuntu",
	"tags": ["ceph", "ubuntu"],
	"description": "",
	"content": " 本次安装，完全按照 官方文档 进行。\nenv 192.168.31.115 cephadmin 这个是admin节点 192.168.31.114 mon1 192.168.31.113 cephfsn2 192.168.31.173 cephfsn3  step 1 这里的配置注意点如下：\nceph-admin 节点： 安装时， with a stable Ceph release (e.g., luminous.) ，安装 luminous 或以上版本。\ncephu@cephadmin:~/my-cluster$ sudo cat /etc/apt/sources.list.d/ceph.list deb https://download.ceph.com/debian-luminous/ xenial main cephu@cephadmin:~/my-cluster$  配置 ~/.ssh/config 方便后续安装\ncephu@cephadmin:~/my-cluster$ cat ~/.ssh/config Host node0 Hostname cephadmin User cephu Host node1 Hostname mon1 User cephu Host node2 Hostname cephfsn2 User cephu Host node3 Hostname cephfsn3 User cephu cephu@cephadmin:~/my-cluster$  所有节点： cephu@cephadmin:~/my-cluster$ cat /etc/hosts 127.0.0.1 localhost 127.0.1.1 ubuntu #127.0.0.1 cephfs5 # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters 192.168.31.115 cephadmin 192.168.31.114 mon1 192.168.31.113 cephfsn2 192.168.31.173 cephfsn3  step 2 2.1 Create the cluster.\n ceph-deploy new node1 不生效的，要写成 ceph-deploy new mon1\n cephu@cephadmin:~/my-cluster$ ceph-deploy new mon1  2.2 - 2.3\ncephu@cephadmin:~/my-cluster$ cat ~/my-cluster/ceph.conf [global] fsid = d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 mon_initial_members = mon1 mon_host = 192.168.31.114 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public network = 192.168.31.1/24 ms bind ipv6 = true cephu@cephadmin:~/my-cluster$  2.4\ncephu@cephadmin:~/my-cluster$ ceph-deploy install node1 node2 node3  2.5\ncephu@cephadmin:~/my-cluster$ ceph-deploy mon create-initial  报错，然后，经过 农总在 https://my.oschina.net/u/2475751/blog/647777 查到要运行下面\ncephu@cephadmin:~/my-cluster$ ssh mon1 sudo ceph-create-keys --id mon1  再来一次\ncephu@cephadmin:~/my-cluster$ ceph-deploy mon create-initial  3.1\ncephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf admin node1 node2 node3 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin node1 node2 node3 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2c1fbe2440\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] client : ['node1', 'node2', 'node3'] [ceph_deploy.cli][INFO ] func : \u0026lt;function admin at 0x7f2c20489b18\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node1 [node1][DEBUG ] connection detected need for sudo [node1][DEBUG ] connected to host: node1 [node1][DEBUG ] detect platform information from remote host [node1][DEBUG ] detect machine type [node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node2 [node2][DEBUG ] connection detected need for sudo [node2][DEBUG ] connected to host: node2 [node2][DEBUG ] detect platform information from remote host [node2][DEBUG ] detect machine type [node2][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node3 [node3][DEBUG ] connection detected need for sudo [node3][DEBUG ] connected to host: node3 [node3][DEBUG ] detect platform information from remote host [node3][DEBUG ] detect machine type [node3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf cephu@cephadmin:~/my-cluster$  3.2\ncephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node1 usage: ceph-deploy [-h] [-v | -q] [--version] [--username USERNAME] [--overwrite-conf] [--cluster NAME] [--ceph-conf CEPH_CONF] COMMAND ... ceph-deploy: error: argument COMMAND: invalid choice: 'mgr' (choose from 'new', 'install', 'rgw', 'mon', 'mds', ' gatherkeys', 'disk', 'osd', 'admin', 'repo', 'config', 'uninstall', 'purge', 'purgedata', 'calamari', 'forgetkeys ', 'pkg') cephu@cephadmin:~/my-cluster$  报错\ncephu@cephadmin:~/my-cluster$ ceph-deploy -h usage: ceph-deploy [-h] [-v | -q] [--version] [--username USERNAME] [--overwrite-conf] [--cluster NAME] [--ceph-conf CEPH_CONF] COMMAND ... Easy Ceph deployment -^- / \\ |O o| ceph-deploy v1.5.32 ).-.( '/|||\\` | '|` | '|` Full documentation can be found at: http://ceph.com/ceph-deploy/docs optional arguments: -h, --help show this help message and exit -v, --verbose be more verbose -q, --quiet be less verbose --version the current installed version of ceph-deploy --username USERNAME the username to connect to the remote host --overwrite-conf overwrite an existing conf file on remote host (if present) --cluster NAME name of the cluster --ceph-conf CEPH_CONF use (or reuse) a given ceph.conf file commands: COMMAND description new Start deploying a new cluster, and write a CLUSTER.conf and keyring for it. install Install Ceph packages on remote hosts. rgw Ceph RGW daemon management mon Ceph MON Daemon management mds Ceph MDS daemon management gatherkeys Gather authentication keys for provisioning new nodes. disk Manage disks on a remote host. osd Prepare a data disk on remote host. admin Push configuration and client.admin key to a remote host. repo Repo definition management config Copy ceph.conf to/from remote host(s) uninstall Remove Ceph packages from remote hosts. purge Remove Ceph packages from remote hosts and purge all data. purgedata Purge (delete, destroy, discard, shred) any Ceph data from /var/lib/ceph calamari Install and configure Calamari nodes. Assumes that a repository with Calamari packages is already configured. Refer to the docs for examples (http://ceph.com/ceph-deploy/docs/conf.html) forgetkeys Remove authentication keys from the local directory. pkg Manage packages on remote hosts. cephu@cephadmin:~/my-cluster$  我去，真的没有 mgr 命令。\n版本升级吧\ncephu@cephadmin:~/my-cluster$ pip install ceph-deploy Collecting ceph-deploy Downloading ceph-deploy-1.5.39.tar.gz (114kB) 100% |████████████████████████████████| 122kB 292kB/s Collecting setuptools (from ceph-deploy) Downloading setuptools-36.6.0-py2.py3-none-any.whl (481kB) 100% |████████████████████████████████| 481kB 968kB/s Building wheels for collected packages: ceph-deploy Running setup.py bdist_wheel for ceph-deploy ... done Stored in directory: /home/cephu/.cache/pip/wheels/5e/4a/c5/5759b04fedf1eaa17d4453b562ab28a2142dbf93ced0c37e5d Successfully built ceph-deploy Installing collected packages: setuptools, ceph-deploy Successfully installed ceph-deploy-1.5.32 setuptools-20.7.0 You are using pip version 8.1.1, however version 9.0.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. cephu@cephadmin:~/my-cluster$ ceph-deploy --version 1.5.39 cephu@cephadmin:~/my-cluster$ ceph-deploy -h  这下有了。重新来一下\ncephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy mgr create node1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('node1', 'node1')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa24a321ab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7fa24a993578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts node1:node1 [ceph_deploy][ERROR ] RuntimeError: bootstrap-mgr keyring not found; run 'gatherkeys'  哇，又来错误。\n提示了 run \u0026lsquo;gatherkeys\u0026rsquo; 。\ncephu@cephadmin:~/my-cluster$ ceph-deploy gatherkeys mon1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy gatherkeys mon1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbfda5f8a70\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] mon : ['mon1'] [ceph_deploy.cli][INFO ] func : \u0026lt;function gatherkeys at 0x7fbfda8570c8\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.gatherkeys][INFO ] Storing keys in temp directory /tmp/tmpZ8THzr [mon1][DEBUG ] connection detected need for sudo [mon1][DEBUG ] connected to host: mon1 [mon1][DEBUG ] detect platform information from remote host [mon1][DEBUG ] detect machine type [mon1][DEBUG ] get remote short hostname [mon1][DEBUG ] fetch remote file [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.mon1.asok mon_status [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.admin [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-mds [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-mgr [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-osd [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-rgw [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.client.admin.keyring' already exists [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.bootstrap-mds.keyring' already exists [ceph_deploy.gatherkeys][INFO ] Storing ceph.bootstrap-mgr.keyring [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.mon.keyring' already exists [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.bootstrap-osd.keyring' already exists [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.bootstrap-rgw.keyring' already exists [ceph_deploy.gatherkeys][INFO ] Destroy temp directory /tmp/tmpZ8THzr cephu@cephadmin:~/my-cluster$  再走一个\ncephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy mgr create node1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('node1', 'node1')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5d02a1bab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7f5d0308d578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts node1:node1 [node1][DEBUG ] connection detected need for sudo [node1][DEBUG ] connected to host: node1 [node1][DEBUG ] detect platform information from remote host [node1][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to node1 [node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.mgr][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite [ceph_deploy][ERROR ] GenericError: Failed to create 1 MGRs  提示了 use \u0026ndash;overwrite-conf\n再来\ncephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf mgr create mon1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy --overwrite-conf mgr create mon1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('mon1', 'mon1')] [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe415166ab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7fe4157d8578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts mon1:mon1 [mon1][DEBUG ] connection detected need for sudo [mon1][DEBUG ] connected to host: mon1 [mon1][DEBUG ] detect platform information from remote host [mon1][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to mon1 [mon1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [mon1][WARNIN] mgr keyring does not exist yet, creating one [mon1][DEBUG ] create a keyring file [mon1][DEBUG ] create path if it doesn't exist [mon1][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.mon1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-mon1/keyring [mon1][INFO ] Running command: sudo systemctl enable ceph-mgr@mon1 [mon1][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@mon1.service to /lib/systemd/system/ceph-mgr@.service. [mon1][INFO ] Running command: sudo systemctl start ceph-mgr@mon1 [mon1][INFO ] Running command: sudo systemctl enable ceph.target cephu@cephadmin:~/my-cluster$  终于成功了。\n3.3\ncephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf osd create node1:sdb node2:sdb node3:sdc ... [node3][DEBUG ] Warning: The kernel is still using the old partition table. [node3][DEBUG ] The new table will be used at the next reboot or after you [node3][DEBUG ] run partprobe(8) or kpartx(8) [node3][DEBUG ] The operation has completed successfully. [node3][WARNIN] update_partition: Calling partprobe on prepared device /dev/sdc [node3][WARNIN] command_check_call: Running command: /sbin/udevadm settle --timeout=600 [node3][WARNIN] command: Running command: /usr/bin/flock -s /dev/sdc /sbin/partprobe /dev/sdc [node3][WARNIN] command_check_call: Running command: /sbin/udevadm settle --timeout=600 [node3][WARNIN] command_check_call: Running command: /sbin/udevadm trigger --action=add --sysname-match sdc1 [node3][INFO ] Running command: sudo systemctl enable ceph.target [node3][INFO ] checking OSD status... [node3][DEBUG ] find the location of an executable [node3][INFO ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json [node3][WARNIN] there is 1 OSD down [node3][WARNIN] there is 1 OSD out [ceph_deploy.osd][DEBUG ] Host node3 is now ready for osd use. cephu@cephadmin:~/my-cluster$  成功\n3.4\ncephu@cephadmin:~/my-cluster$ ssh node1 sudo ceph health HEALTH_OK cephu@cephadmin:~/my-cluster$ ssh node2 sudo ceph health HEALTH_OK cephu@cephadmin:~/my-cluster$ ssh node3 sudo ceph health HEALTH_OK cephu@cephadmin:~/my-cluster$ ssh node3 sudo ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_OK services: mon: 1 daemons, quorum mon1 mgr: mon1(active) osd: 3 osds: 3 up, 3 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 bytes usage: 3164 MB used, 80500 MB / 83664 MB avail pgs: cephu@cephadmin:~/my-cluster$  到这里，我们应该是完成了基础的搭建\n附加项：expanding your cluster ADD A METADATA SERVER ceph-deploy mds create node1\nADDING MONITORS ceph-deploy mon add node2 node3 会报错\n换成：\ncephu@cephadmin:~/my-cluster$ ceph-deploy mon add cephfsn2 cephu@cephadmin:~/my-cluster$ ceph-deploy mon add cephfsn3  验证\ncephu@cephadmin:~/my-cluster$ ssh cephfsn2 ceph quorum_status --format json-pretty 2017-10-24 10:40:24.959942 7f261141a700 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.admin.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory 2017-10-24 10:40:24.959973 7f261141a700 -1 monclient: ERROR: missing keyring, cannot use cephx for authentication 2017-10-24 10:40:24.959975 7f261141a700 0 librados: client.admin initialization error (2) No such file or directory [errno 2] error connecting to the cluster cephu@cephadmin:~/my-cluster$ ssh cephfsn2 sudo ceph quorum_status --format json-pretty { \u0026quot;election_epoch\u0026quot;: 14, \u0026quot;quorum\u0026quot;: [ 0, 1, 2 ], \u0026quot;quorum_names\u0026quot;: [ \u0026quot;cephfsn2\u0026quot;, \u0026quot;mon1\u0026quot;, \u0026quot;cephfsn3\u0026quot; ], \u0026quot;quorum_leader_name\u0026quot;: \u0026quot;cephfsn2\u0026quot;, \u0026quot;monmap\u0026quot;: { \u0026quot;epoch\u0026quot;: 3, \u0026quot;fsid\u0026quot;: \u0026quot;d0aa5af1-4f8e-4953-9448-7f1b2448b8a5\u0026quot;, \u0026quot;modified\u0026quot;: \u0026quot;2017-10-24 10:32:19.273831\u0026quot;, \u0026quot;created\u0026quot;: \u0026quot;2017-10-23 15:22:32.766470\u0026quot;, \u0026quot;features\u0026quot;: { \u0026quot;persistent\u0026quot;: [ \u0026quot;kraken\u0026quot;, \u0026quot;luminous\u0026quot; ], \u0026quot;optional\u0026quot;: [] }, \u0026quot;mons\u0026quot;: [ { \u0026quot;rank\u0026quot;: 0, \u0026quot;name\u0026quot;: \u0026quot;cephfsn2\u0026quot;, \u0026quot;addr\u0026quot;: \u0026quot;192.168.31.113:6789/0\u0026quot;, \u0026quot;public_addr\u0026quot;: \u0026quot;192.168.31.113:6789/0\u0026quot; }, { \u0026quot;rank\u0026quot;: 1, \u0026quot;name\u0026quot;: \u0026quot;mon1\u0026quot;, \u0026quot;addr\u0026quot;: \u0026quot;192.168.31.114:6789/0\u0026quot;, \u0026quot;public_addr\u0026quot;: \u0026quot;192.168.31.114:6789/0\u0026quot; }, { \u0026quot;rank\u0026quot;: 2, \u0026quot;name\u0026quot;: \u0026quot;cephfsn3\u0026quot;, \u0026quot;addr\u0026quot;: \u0026quot;192.168.31.173:6789/0\u0026quot;, \u0026quot;public_addr\u0026quot;: \u0026quot;192.168.31.173:6789/0\u0026quot; } ] } } cephu@cephadmin:~/my-cluster$  ADDING MANAGERS cephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node2 node3 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy mgr create node2 node3 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('node2', 'node2'), ('node3', 'node3')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb9043a4ab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7fb904a16578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts node2:node2 node3:node3 [node2][DEBUG ] connection detected need for sudo [node2][DEBUG ] connected to host: node2 [node2][DEBUG ] detect platform information from remote host [node2][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to node2 [node2][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [node2][WARNIN] mgr keyring does not exist yet, creating one [node2][DEBUG ] create a keyring file [node2][DEBUG ] create path if it doesn't exist [node2][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.node2 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-node2/keyring [node2][INFO ] Running command: sudo systemctl enable ceph-mgr@node2 [node2][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@node2.service to /lib/systemd/system/ceph-mgr@.service. [node2][INFO ] Running command: sudo systemctl start ceph-mgr@node2 [node2][INFO ] Running command: sudo systemctl enable ceph.target [node3][DEBUG ] connection detected need for sudo [node3][DEBUG ] connected to host: node3 [node3][DEBUG ] detect platform information from remote host [node3][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to node3 [node3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [node3][WARNIN] mgr keyring does not exist yet, creating one [node3][DEBUG ] create a keyring file [node3][DEBUG ] create path if it doesn't exist [node3][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.node3 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-node3/keyring [node3][INFO ] Running command: sudo systemctl enable ceph-mgr@node3 [node3][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@node3.service to /lib/systemd/system/ceph-mgr@.service. [node3][INFO ] Running command: sudo systemctl start ceph-mgr@node3 [node3][INFO ] Running command: sudo systemctl enable ceph.target cephu@cephadmin:~/my-cluster$  验证\ncephu@cephadmin:~/my-cluster$ ssh node1 sudo ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_WARN clock skew detected on mon.cephfsn3 services: mon: 3 daemons, quorum cephfsn2,mon1,cephfsn3 mgr: mon1(active), standbys: node2, node3 osd: 3 osds: 3 up, 3 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 bytes usage: 3164 MB used, 80500 MB / 83664 MB avail pgs: cephu@cephadmin:~/my-cluster$ ssh node3 sudo ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_WARN clock skew detected on mon.cephfsn3 services: mon: 3 daemons, quorum cephfsn2,mon1,cephfsn3 mgr: mon1(active), standbys: node2, node3 osd: 3 osds: 3 up, 3 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 bytes usage: 3164 MB used, 80500 MB / 83664 MB avail pgs: cephu@cephadmin:~/my-cluster$  ADD AN RGW INSTANCE ceph-deploy rgw create node1  好了。\nSTORING/RETRIEVING OBJECT DATA 这一个小节，现在先不动。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-intro.html",
	"title": "ceph 安装 intro",
	"tags": ["ceph", "intro"],
	"description": "",
	"content": "Contents:\n install-by-docker install.FAQ install-by-ubuntu/index  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-intro.html",
	"title": "ceph intro",
	"tags": ["ceph", "intro"],
	"description": "",
	"content": "Contents:\n cephfs/index install  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos-update-kernel.html",
	"title": "centos更新内核",
	"tags": ["centos", "kernel"],
	"description": "",
	"content": "https://linux.cn/article-8310-1.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-desktop-set-apt-source.html",
	"title": "set apt source",
	"tags": ["desktop", "ubuntu", "apt"],
	"description": "",
	"content": "https://github.com/vnpy/vnpy/wiki/Ubuntu%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/jd-kubernetes-openstack.html",
	"title": "jd.com从openstack转到kubernetes",
	"tags": ["kubernetes", "openstack"],
	"description": "",
	"content": "http://www.infoq.com/cn/news/2017/03/jd-kubernetes-openstack\nhttp://blog.kubernetes.io/2017/02/inside-jd-com-shift-to-kubernetes-from-openstack.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/web-framework-benchmarks.html",
	"title": "web框架",
	"tags": ["framework", "benchmarks"],
	"description": "",
	"content": "一个超级好的 Web Framewosrk Benchmarks\nhttp://www.techempower.com/whatwedo.html\nhttp://www.techempower.com/benchmarks/\nhttp://www.techempower.com/benchmarks/#section=data-r14\u0026amp;hw=ph\u0026amp;test=update\n这里面才是真正的压力测试结果。里面可以看到 市面上 最全的:\n web 架构方案， 数据库， 程序语言language，\n的表现。\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-intro.html",
	"title": "ubuntu intro",
	"tags": ["ubuntu", "intro"],
	"description": "",
	"content": "Contents:\n update-kernel/index how-to-install-certificates-for-command-line ubuntu-desktop/index  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-nfs-yaml.html",
	"title": "kubernetes 使用 nfs 存储",
	"tags": ["kubernetes", "nfs"],
	"description": "",
	"content": " test-claim.yaml root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/StatefulSet-Basics/v# cat test-claim.yaml kind: PersistentVolumeClaim apiVersion: v1 metadata: name: test-claim annotations: volume.beta.kubernetes.io/storage-class: \u0026quot;managed-nfs-storage\u0026quot; spec: accessModes: - ReadWriteMany resources: requests: storage: 1Mi  class.yaml root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/StatefulSet-Basics/v# cat class.yaml apiVersion: storage.k8s.io/v1beta1 kind: StorageClass metadata: name: managed-nfs-storage provisioner: fuseim.pri/ifs # or choose another name, must match deployment's env PROVISIONER_NAME'  deployment.yaml root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/StatefulSet-Basics/v# cat deployment.yaml kind: Deployment apiVersion: extensions/v1beta1 metadata: name: nfs-client-provisioner spec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: nfs-client-provisioner spec: containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest imagePullPolicy: IfNotPresent volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs - name: NFS_SERVER value: 192.168.31.232 - name: NFS_PATH value: /data/nfs-storage/k8s-storage/ssd volumes: - name: nfs-client-root nfs: server: 192.168.31.232 path: /data/nfs-storage/k8s-storage/ssd root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/StatefulSet-Basics/v#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-intro.html",
	"title": "kubernetes cephfs intro",
	"tags": ["kubernetes", "ceph", "cephfs", "intro"],
	"description": "",
	"content": "REAEME cephfs-stateful cephfs-k8s-make-by-go-get cephfs-k8s-deployment-faq cephfs-k8s-yaml cephfs-k8s-make cephfs-k8s-faq\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-storage-practise.html",
	"title": "kubernetes storage",
	"tags": ["kubernetes", "storage"],
	"description": "",
	"content": " nfs 环境：192.168.31.232\n成功\ncephfs http://tonybai.com/2017/05/08/mount-cephfs-acrossing-nodes-in-kubernetes-cluster/\n成功\nceph rbd Glusterfs rook 存储 http://dockone.io/article/2156\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-clusters-upgrade-from-v173-to-v183.html",
	"title": "更新kubeadm clusters 从v1.7.3至v1.8.3",
	"tags": ["kubernetes", "upgrade", "kubeadm"],
	"description": "",
	"content": " Upgrading kubeadm clusters from 1.7 to 1.8\nhttps://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-8/\nenv 192.168.31.120 km, master 192.168.31.119 kn1 192.168.31.118 kn2  下载 kubeadm  https://dl.k8s.io/release/v1.8.2/bin/linux/amd64/kubeadm\n root@km:~# sudo chmod a+rx /usr/bin/kubeadm root@km:~# kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;8\u0026quot;, GitVersion:\u0026quot;v1.8.2\u0026quot;, GitCommit:\u0026quot;bdaeafa71f6c7c04636251031f93464384d54963\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2017-10-24T19:38:10Z\u0026quot;, GoVersion:\u0026quot;go1.8.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} root@km:~#  上传 root@km:~# kubeadm config upload from-file --config ./admin.conf unable to decode config from \u0026quot;./admin.conf\u0026quot; [no kind \u0026quot;Config\u0026quot; is registered for version \u0026quot;v1\u0026quot;]  不是这样的 conf 文件呀。\nroot@km:~# kubeadm config upload from-flags [] unable to get URL \u0026quot;https://dl.k8s.io/release/stable-1.8.txt\u0026quot;: Get https://storage.googleapis.com/kubernetes-release/release/stable-1.8.txt: read tcp 192.168.31.120:47118-\u0026gt;172.217.24.16:443: read: connection reset by peer root@km:~#  要FQ呀。\nproxy FQ root@km:~# cat proxy.sh #!/bin/bash NO_PROXY=localhost,127.0.0.1/8,192.168.31.1/24 export NO_PROXY export http_proxy=http://192.168.31.10:1080/ export https_proxy=http://192.168.31.10:1080/ root@km:~#  kubeadm upgrade apply v1.8.3 FQ后，重新来过\nroot@km:~# cp kubeadm.v1.8.3 kubeadm root@km:~# mv kubeadm /usr/bin/ root@km:~# chmod a+rx /usr/bin/kubeadm root@km:~# kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;8\u0026quot;, GitVersion:\u0026quot;v1.8.3\u0026quot;, GitCommit:\u0026quot;f0efb3cb883751c5ffdbe6d515f3cb4fbe7b7acd\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2017-11-08T18:27:48Z\u0026quot;, GoVersion:\u0026quot;go1.8.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} root@km:~# kubeadm config upload from-flags [] [uploadconfig] Storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace root@km:~# kubeadm upgrade plan [preflight] Running pre-flight checks [upgrade] Making sure the cluster is healthy: [upgrade/health] Checking API Server health: Healthy [upgrade/health] Checking Node health: All Nodes are healthy [upgrade/health] Checking Static Pod manifests exists on disk: All manifests exist on disk [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.7.3 [upgrade/versions] kubeadm version: v1.8.3 [upgrade/versions] Latest stable version: v1.8.3 [upgrade/versions] Latest version in the v1.7 series: v1.7.10 Components that must be upgraded manually after you've upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 3 x v1.7.3 v1.7.10 Upgrade to the latest version in the v1.7 series: COMPONENT CURRENT AVAILABLE API Server v1.7.3 v1.7.10 Controller Manager v1.7.3 v1.7.10 Scheduler v1.7.3 v1.7.10 Kube Proxy v1.7.3 v1.7.10 Kube DNS 1.14.5 1.14.5 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.7.10 _____________________________________________________________________ Components that must be upgraded manually after you've upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 3 x v1.7.3 v1.8.3 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.7.3 v1.8.3 Controller Manager v1.7.3 v1.8.3 Scheduler v1.7.3 v1.8.3 Kube Proxy v1.7.3 v1.8.3 Kube DNS 1.14.5 1.14.5 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.8.3 _____________________________________________________________________ root@km:~# kubeadm upgrade apply v1.8.3 [preflight] Running pre-flight checks [upgrade] Making sure the cluster is healthy: [upgrade/health] Checking API Server health: Healthy [upgrade/health] Checking Node health: All Nodes are healthy [upgrade/health] Checking Static Pod manifests exists on disk: All manifests exist on disk [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade/version] You have chosen to upgrade to version \u0026quot;v1.8.3\u0026quot; [upgrade/versions] Cluster version: v1.7.3 [upgrade/versions] kubeadm version: v1.8.3 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler] [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-controller-manager. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026quot;v1.8.3\u0026quot;... [upgrade/staticpods] Writing upgraded Static Pod manifests to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests025451644\u0026quot; [controlplane] Wrote Static Pod manifest for component kube-apiserver to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests025451644/kube-apiserver.yaml\u0026quot; [controlplane] Wrote Static Pod manifest for component kube-controller-manager to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests025451644/kube-controller-manager.yaml\u0026quot; [controlplane] Wrote Static Pod manifest for component kube-scheduler to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests025451644/kube-scheduler.yaml\u0026quot; [upgrade/staticpods] Moved upgraded manifest to \u0026quot;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests188726187/kube-apiserver.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/apply] FATAL: couldn't upgrade control plane. kubeadm has tried to recover everything into the earlier state. Errors faced: [timed out waiting for the condition] root@km:~#  报错了。\n解决报错 加入 kubeadm init 参数 通过 kubeadm upgrade \u0026ndash;help 发现，要先把之前 kubeadm init 的参数，作为configmap传进来。 回忆一下，之前是 kubeadm init \u0026ndash;pod-network-cidr=10.244.0.0/16，所以这里把它加进去\nroot@km:~# kubeadm config upload from-flags [--pod-network-cidr=10.244.0.0/16] [uploadconfig] Storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace root@km:~# root@km:~# k get configmap kubeadm-config -n kube-system NAME DATA AGE kubeadm-config 1 1d root@km:~# k describe configmap kubeadm-config -n kube-system Name: kubeadm-config Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Data ==== MasterConfiguration: ---- api: advertiseAddress: 192.168.31.120 bindPort: 6443 authorizationModes: - Node - RBAC certificatesDir: /etc/kubernetes/pki cloudProvider: \u0026quot;\u0026quot; etcd: caFile: \u0026quot;\u0026quot; certFile: \u0026quot;\u0026quot; dataDir: /var/lib/etcd endpoints: null image: \u0026quot;\u0026quot; keyFile: \u0026quot;\u0026quot; imageRepository: gcr.io/google_containers kubernetesVersion: v1.8.3 networking: dnsDomain: cluster.local podSubnet: \u0026quot;\u0026quot; serviceSubnet: 10.96.0.0/12 nodeName: km token: \u0026quot;\u0026quot; tokenTTL: 24h0m0s unifiedControlPlaneImage: \u0026quot;\u0026quot; Events: \u0026lt;none\u0026gt; root@km:~#  呀！没把参数 \u0026ndash;pod-network-cidr=10.244.0.0/16，加入呀（如果加入了 podSubnet: \u0026ldquo;\u0026rdquo; 会变成 podSubnet: 10.244.0.0/16 的）\n看来刚刚不能加 [] 这个中括号。 再来。\nroot@km:~# kubeadm config upload from-flags --pod-network-cidr=10.244.0.0/16 [uploadconfig] Storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace root@km:~# k get cm kubeadm-config -n kube-system -o yaml apiVersion: v1 data: MasterConfiguration: | api: advertiseAddress: 192.168.31.120 bindPort: 6443 authorizationModes: - Node - RBAC certificatesDir: /etc/kubernetes/pki cloudProvider: \u0026quot;\u0026quot; etcd: caFile: \u0026quot;\u0026quot; certFile: \u0026quot;\u0026quot; dataDir: /var/lib/etcd endpoints: null image: \u0026quot;\u0026quot; keyFile: \u0026quot;\u0026quot; imageRepository: gcr.io/google_containers kubernetesVersion: v1.8.3 networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 serviceSubnet: 10.96.0.0/12 nodeName: km token: \u0026quot;\u0026quot; tokenTTL: 24h0m0s unifiedControlPlaneImage: \u0026quot;\u0026quot; kind: ConfigMap metadata: creationTimestamp: 2017-11-14T10:04:45Z name: kubeadm-config namespace: kube-system resourceVersion: \u0026quot;10542232\u0026quot; selfLink: /api/v1/namespaces/kube-system/configmaps/kubeadm-config uid: 3de0d764-c923-11e7-96bf-000c299a346f root@km:~#  成功。\nkubeadm upgrade plan root@km:~# kubeadm upgrade plan [preflight] Running pre-flight checks [upgrade] Making sure the cluster is healthy: [upgrade/health] Checking API Server health: Healthy [upgrade/health] Checking Node health: All Nodes are healthy [upgrade/health] Checking Static Pod manifests exists on disk: All manifests exist on disk [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.7.3 [upgrade/versions] kubeadm version: v1.8.3 [upgrade/versions] Latest stable version: v1.8.3 [upgrade/versions] Latest version in the v1.7 series: v1.7.10 Components that must be upgraded manually after you've upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 3 x v1.7.3 v1.7.10 Upgrade to the latest version in the v1.7 series: COMPONENT CURRENT AVAILABLE API Server v1.7.3 v1.7.10 Controller Manager v1.7.3 v1.7.10 Scheduler v1.7.3 v1.7.10 Kube Proxy v1.7.3 v1.7.10 Kube DNS 1.14.5 1.14.5 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.7.10 _____________________________________________________________________ Components that must be upgraded manually after you've upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 3 x v1.7.3 v1.8.3 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.7.3 v1.8.3 Controller Manager v1.7.3 v1.8.3 Scheduler v1.7.3 v1.8.3 Kube Proxy v1.7.3 v1.8.3 Kube DNS 1.14.5 1.14.5 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.8.3 _____________________________________________________________________ root@km:~#  kubeadm upgrade apply 如果说kubernetes的配置文件不是默认/etc/kubernetes/admin.conf，那则在这里加 \u0026ndash;kubeconfig /root/admin.conf 就行了。 如：\nroot@km:~# kubeadm upgrade apply v1.8.3 --kubeconfig /root/admin.conf --force  多打印一些信息吧\nroot@km:~# kubeadm upgrade apply v1.8.3 --print-config --skip-preflight-checks [preflight] Skipping pre-flight checks [upgrade] Making sure the cluster is healthy: [upgrade/health] Checking API Server health: Healthy [upgrade/health] Checking Node health: All Nodes are healthy [upgrade/health] Checking Static Pod manifests exists on disk: All manifests exist on disk [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade/config] Configuration used: api: advertiseAddress: 192.168.31.120 bindPort: 6443 authorizationModes: - Node - RBAC certificatesDir: /etc/kubernetes/pki cloudProvider: \u0026quot;\u0026quot; etcd: caFile: \u0026quot;\u0026quot; certFile: \u0026quot;\u0026quot; dataDir: /var/lib/etcd endpoints: null image: \u0026quot;\u0026quot; keyFile: \u0026quot;\u0026quot; imageRepository: gcr.io/google_containers kubernetesVersion: v1.8.3 networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 serviceSubnet: 10.96.0.0/12 nodeName: km token: ef36c0.2aa43b08712e4d54 tokenTTL: 24h0m0s unifiedControlPlaneImage: \u0026quot;\u0026quot; [upgrade/version] You have chosen to upgrade to version \u0026quot;v1.8.3\u0026quot; [upgrade/versions] Cluster version: v1.7.3 [upgrade/versions] kubeadm version: v1.8.3 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler] [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-controller-manager. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026quot;v1.8.3\u0026quot;... [upgrade/staticpods] Writing upgraded Static Pod manifests to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests076595912\u0026quot; [controlplane] Wrote Static Pod manifest for component kube-apiserver to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests076595912/kube-apiserver.yaml\u0026quot; [controlplane] Wrote Static Pod manifest for component kube-controller-manager to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests076595912/kube-controller-manager.yaml\u0026quot; [controlplane] Wrote Static Pod manifest for component kube-scheduler to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests076595912/kube-scheduler.yaml\u0026quot; [upgrade/staticpods] Moved upgraded manifest to \u0026quot;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests094178183/kube-apiserver.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/apply] FATAL: couldn't upgrade control plane. kubeadm has tried to recover everything into the earlier state. Errors faced: [timed out waiting for the condition] root@km:~#  还是失败了。 彻底失败了。\n没有办法了。\n新的尝试 按照下面的办法再试一下吧。 http://www.youruncloud.com/docker/1%5F106.html\n发现还是不行呀。\n全新安装 v1.8.3 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-install-faq-kubelet-cni.html",
	"title": "kubeadm-kubelet-cni",
	"tags": ["kubernetes", "install", "faq", "cni"],
	"description": "",
	"content": " 问题1 kubelet 没有初始化 cni 现场 root@km:~# cat k8.export.sh sudo cp /etc/kubernetes/admin.conf $HOME/ sudo chown $(id -u):$(id -g) $HOME/admin.conf export KUBECONFIG=$HOME/admin.conf root@km:~# export KUBECONFIG=$HOME/admin.conf root@km:~# k get nodes NAME STATUS ROLES AGE VERSION km NotReady master 18h v1.8.4 kn1 Ready \u0026lt;none\u0026gt; 29s v1.8.4 kn2 Ready \u0026lt;none\u0026gt; 29s v1.8.4  出错了。\ndescibe root@km:~# k describe node km Name: km Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/hostname=km node-role.kubernetes.io/master= Annotations: node.alpha.kubernetes.io/ttl=0 volumes.kubernetes.io/controller-managed-attach-detach=true Taints: node-role.kubernetes.io/master:NoSchedule CreationTimestamp: Tue, 21 Nov 2017 17:36:14 +0800 Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Wed, 22 Nov 2017 11:58:45 +0800 Tue, 21 Nov 2017 17:36:14 +0800 KubeletHasSufficientDisk kubelet has sufficient disk space available MemoryPressure False Wed, 22 Nov 2017 11:58:45 +0800 Tue, 21 Nov 2017 17:36:14 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Wed, 22 Nov 2017 11:58:45 +0800 Tue, 21 Nov 2017 17:36:14 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure Ready False Wed, 22 Nov 2017 11:58:45 +0800 Tue, 21 Nov 2017 17:36:14 +0800 KubeletNotReady runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized Addresses: InternalIP: 192.168.31.120 Hostname: km Capacity: cpu: 4 memory: 8175088Ki pods: 110 Allocatable: cpu: 4 memory: 8072688Ki pods: 110 System Info: Machine ID: 78cb13728eba6f6c819e6dea599a5db9 System UUID: 564D7A67-BDF7-E109-61AC-DDC9929A346F Boot ID: 8f8d7bb3-abb6-4d6a-b1ee-261cd1a2cc74 Kernel Version: 4.4.0-62-generic OS Image: Ubuntu 16.04.3 LTS Operating System: linux Architecture: amd64 Container Runtime Version: docker://Unknown Kubelet Version: v1.8.4 Kube-Proxy Version: v1.8.4 PodCIDR: 10.244.0.0/24 ExternalID: km Non-terminated Pods: (5 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits --------- ---- ------------ ---------- --------------- ------------- kube-system etcd-km 0 (0%) 0 (0%) 0 (0%) 0 (0%) kube-system kube-apiserver-km 250m (6%) 0 (0%) 0 (0%) 0 (0%) kube-system kube-controller-manager-km 200m (5%) 0 (0%) 0 (0%) 0 (0%) kube-system kube-proxy-v24fg 0 (0%) 0 (0%) 0 (0%) 0 (0%) kube-system kube-scheduler-km 100m (2%) 0 (0%) 0 (0%) 0 (0%) Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) CPU Requests CPU Limits Memory Requests Memory Limits ------------ ---------- --------------- ------------- 550m (13%) 0 (0%) 0 (0%) 0 (0%) Events: \u0026lt;none\u0026gt; root@km:~#  重点是这一句： runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker network plugin is not ready: cni config uninitialized\n那明显是 cni 插件 出错了。\n找 kubeadm 哪里 与 cni 相关 看 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 也可以知道，这个地方是 \u0026ndash;cni-conf-dir=/etc/cni/net.d 与 KUBELET_NETWORK_ARGS 相关\nroot@km:~# cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf [Service] Environment=\u0026quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf\u0026quot; Environment=\u0026quot;KUBELET_SYSTEM_PODS_ARGS=--pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true\u0026quot; Environment=\u0026quot;KUBELET_NETWORK_ARGS=--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin\u0026quot; Environment=\u0026quot;KUBELET_DNS_ARGS=--cluster-dns=10.96.0.10 --cluster-domain=cluster.local\u0026quot; Environment=\u0026quot;KUBELET_AUTHZ_ARGS=--authorization-mode=Webhook --client-ca-file=/etc/kubernetes/pki/ca.crt\u0026quot; # Value should match Docker daemon settings. # Defaults are \u0026quot;cgroupfs\u0026quot; for Debian/Ubuntu/OpenSUSE and \u0026quot;systemd\u0026quot; for Fedora/CentOS/RHEL Environment=\u0026quot;KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs\u0026quot; Environment=\u0026quot;KUBELET_CADVISOR_ARGS=--cadvisor-port=0\u0026quot; Environment=\u0026quot;KUBELET_CERTIFICATE_ARGS=--rotate-certificates=true\u0026quot; #ExecStart= ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CGROUP_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS root@km:~#  之前，只有 Kubelet 与 cni 相关，去找 kubelet\n看 kubelet root@km:/opt/cni/bin# systemctl status kubelet -l ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Tue 2017-11-21 17:32:53 CST; 18h ago Docs: http://kubernetes.io/docs/ Main PID: 12169 (kubelet) Tasks: 18 Memory: 53.0M CPU: 37min 39.889s CGroup: /system.slice/kubelet.service └─12169 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true --network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin Nov 22 12:06:47 km kubelet[12169]: E1122 12:06:47.325019 12169 kubelet.go:2095] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized Nov 22 12:06:48 km kubelet[12169]: E1122 12:06:48.015039 12169 fs.go:418] Stat fs failed. Error: no such file or directory Nov 22 12:06:52 km kubelet[12169]: W1122 12:06:52.326529 12169 cni.go:196] Unable to update cni config: No networks found in /etc/cni/net.d Nov 22 12:06:52 km kubelet[12169]: E1122 12:06:52.326863 12169 kubelet.go:2095] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized Nov 22 12:06:56 km kubelet[12169]: W1122 12:06:56.240582 12169 helpers.go:847] eviction manager: no observation found for eviction signal allocatableNodeFs.available Nov 22 12:06:57 km kubelet[12169]: W1122 12:06:57.328311 12169 cni.go:196] Unable to update cni config: No networks found in /etc/cni/net.d Nov 22 12:06:57 km kubelet[12169]: E1122 12:06:57.328571 12169 kubelet.go:2095] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized Nov 22 12:07:00 km kubelet[12169]: E1122 12:07:00.897325 12169 fs.go:418] Stat fs failed. Error: no such file or directory Nov 22 12:07:02 km kubelet[12169]: W1122 12:07:02.329909 12169 cni.go:196] Unable to update cni config: No networks found in /etc/cni/net.d Nov 22 12:07:02 km kubelet[12169]: E1122 12:07:02.330121 12169 kubelet.go:2095] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized root@km:/opt/cni/bin# root@km:/opt/cni/bin# ls /etc/cni/net.d root@km:/opt/cni/bin#  Unable to update cni config: No networks found in /etc/cni/net.d, 说明这下面少了文件嘛。\n加 10-flannel.conf 文件 那到 kn1，kn2 下看这个地方的文件是什么，copy过来试一下。\nroot@km:/opt/cni/bin# cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/cni/net.d/10-flannel.conf { \u0026quot;name\u0026quot;: \u0026quot;cbr0\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;flannel\u0026quot;, \u0026quot;delegate\u0026quot;: { \u0026quot;isDefaultGateway\u0026quot;: true } } root@km:/opt/cni/bin# cat /etc/cni/net.d/10-flannel.conf { \u0026quot;name\u0026quot;: \u0026quot;cbr0\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;flannel\u0026quot;, \u0026quot;delegate\u0026quot;: { \u0026quot;isDefaultGateway\u0026quot;: true } } root@km:/opt/cni/bin#  重启 kubelet root@km:/opt/cni/bin# sudo systemctl restart kubelet.service root@km:/opt/cni/bin# sudo systemctl status kubelet.service ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Wed 2017-11-22 12:13:17 CST; 6s ago Docs: http://kubernetes.io/docs/ Main PID: 20922 (kubelet) Tasks: 16 Memory: 30.3M CPU: 1.433s CGroup: /system.slice/kubelet.service └─20922 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true --network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.194931 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;lib-modules\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/60948ce8-cea3-11e7-b022-000c299a346f-lib-modules\u0026quot;) pod \u0026quot;kube-proxy Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195034 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;kube-proxy-token-x4p78\u0026quot; (UniqueName: \u0026quot;kubernetes.io/secret/60948ce8-cea3-11e7-b022-000c299a346f-kube-proxy-token-x4p7 Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195100 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;kubeconfig\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/bfaf9b679f8fe6133395d353696bb6a8-kubeconfig\u0026quot;) pod \u0026quot;kube-scheduler-k Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195162 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;etcd\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/d76e26fba3bf2bfd215eb29011d55250-etcd\u0026quot;) pod \u0026quot;etcd-km\u0026quot; (UID: \u0026quot;d76e26fba3bf Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195223 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;k8s-certs\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/05a0699921507cc649967b80b3386902-k8s-certs\u0026quot;) pod \u0026quot;kube-apiserver-km\u0026quot; Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195278 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;ca-certs\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/05a0699921507cc649967b80b3386902-ca-certs\u0026quot;) pod \u0026quot;kube-apiserver-km\u0026quot; ( Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195337 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;k8s-certs\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/f561b959c5fd24759a4bcc1002f17d77-k8s-certs\u0026quot;) pod \u0026quot;kube-controller-ma Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195394 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;ca-certs\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/f561b959c5fd24759a4bcc1002f17d77-ca-certs\u0026quot;) pod \u0026quot;kube-controller-mana Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195481 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;kubeconfig\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/f561b959c5fd24759a4bcc1002f17d77-kubeconfig\u0026quot;) pod \u0026quot;kube-controller- Nov 22 12:13:23 km kubelet[20922]: I1122 12:13:23.195556 20922 reconciler.go:212] operationExecutor.VerifyControllerAttachedVolume started for volume \u0026quot;flexvolume-dir\u0026quot; (UniqueName: \u0026quot;kubernetes.io/host-path/f561b959c5fd24759a4bcc1002f17d77-flexvolume-dir\u0026quot;) pod \u0026quot;kube-con root@km:/opt/cni/bin#  再查 node状态 root@km:/opt/cni/bin# k get nodes NAME STATUS ROLES AGE VERSION km Ready master 18h v1.8.4 kn1 Ready \u0026lt;none\u0026gt; 16m v1.8.4 kn2 Ready \u0026lt;none\u0026gt; 16m v1.8.4 root@km:/opt/cni/bin#  检查网络 事后发现，flannel 与 docker无关，与 ps 无关。\nroot@km:~# docker ps | grep flannel root@km:/opt/cni/bin# ps -ef | grep flannel root 22240 16316 0 12:32 pts/0 00:00:00 grep --color=auto flannel root@km:/opt/cni/bin#  但是 ip a 可查看有这个网络\nroot@km:/opt/cni/bin# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens160: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:9a:34:6f brd ff:ff:ff:ff:ff:ff inet 192.168.31.120/24 brd 192.168.31.255 scope global ens160 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe9a:346f/64 scope link valid_lft forever preferred_lft forever 3: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:05:cf:43:c1 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:5ff:fecf:43c1/64 scope link valid_lft forever preferred_lft forever 4: flannel.1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UNKNOWN group default link/ether b2:6d:04:a9:38:8d brd ff:ff:ff:ff:ff:ff inet 10.244.0.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::b06d:4ff:fea9:388d/64 scope link valid_lft forever preferred_lft forever 5: cni0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000 link/ether 0a:58:0a:f4:00:01 brd ff:ff:ff:ff:ff:ff inet 10.244.0.1/24 scope global cni0 valid_lft forever preferred_lft forever inet6 fe80::2827:4dff:fe51:9390/64 scope link valid_lft forever preferred_lft forever root@km:/opt/cni/bin#  game over "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/shell/shell-get-dir-name.html",
	"title": "Shell获取某目录下所有文件夹的名称",
	"tags": ["shell", "file-name"],
	"description": "",
	"content": "  方法一  #!/bin/bash dir=$(ls -l D:/temp/ |awk '/^d/ {print $NF}') for i in $dir do echo $i done   方法二  #!/bin/bash for dir in $(ls D:/tmep/) do [ -d $dir ] \u0026amp;\u0026amp; echo $dir done   方法三  #!/bin/bash ls -l D:/temp/ |awk '/^d/ {print $NF}' ## 其实同方法一，直接就可以显示不用for循环   方法四  #!/bin/bash ls -l |awk '/^d/ {print $NF}' ## get file *.rst name ls -l *.rst |awk '/^-/ {print $NF}'  Ref  https://blog.csdn.net/sidely/article/details/40426725  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-registry.html",
	"title": "docker registry",
	"tags": ["docker", "registry"],
	"description": "",
	"content": "docker registry\n 在 192.168.31.240 ， 10.10.12.17 中建立了 registry 输入用户zimug，密码zimug_password  192.168.31.171 client\nroot 用户\nsudo mkdir -p /etc/docker/certs.d/reg.jlch.com:5000 sudo echo 192.168.31.240 reg.jlch.com \u0026gt;\u0026gt; /etc/hosts sudo scp -r tom@192.168.31.240:/home/tom/registry/certs/registry.crt /etc/docker/certs.d/reg.jlch.com:5000  root@k-m:/home/jlch# docker login reg.jlch.com:5000 Username: zimug Password: Login Succeeded root@k-m:/home/jlch# docker images REPOSITORY TAG IMAGE ID CREATED SIZE ceph/daemon latest dc9781d1d530 20 hours ago 983MB hello-world latest 1815c82652c0 4 months ago 1.84kB root@k-m:/home/jlch# docker tag ceph/daemon reg.jlch.com:5000/ceph/daemon:latest root@k-m:/home/jlch# docker push reg.jlch.com:5000/ceph/daemon:latest  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-install-intro.html",
	"title": "k8s安装系列",
	"tags": ["kubernetes", "install", "intro"],
	"description": "",
	"content": " env  kubeadm: v1.8.4 os: ubuntu 16.04  step kubernetes-before-install kubeadm-init-before-v1.8.3 kubeadm-install-ubuntu-v1.8.4 kubeadm-join upgrade-v1.8.3-failure-install-v1.8.3 kubeadm-install-v1.8.3 kubeadm-init-use-local-image kubeadm-build delete-node kubeadm-install-FAQ\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes.html",
	"title": "kubernetes系列",
	"tags": ["kubernetes", "intro"],
	"description": "",
	"content": "Contents:\ninstall/index upgrade/index storage cephfs/index nfs-k8s source\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu16-update-kernel.html",
	"title": "ubuntu16.04升级内核至 4.10 以上",
	"tags": ["ubuntu", "update-kernel"],
	"description": "",
	"content": " ubuntu16.04 update-kernel env 192.168.31.118 192.168.31.119  step 浏览器打开 http://kernel.ubuntu.com/~kernel-ppa/mainline/\n找到适合的 内核版本（这时v4.12), 进入，\n找到合适的内核文件(linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb)\nwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb  然后安装就可以了。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-install-ubuntu.html",
	"title": "ubuntu中安装docker",
	"tags": ["docker", "install", "ubuntu"],
	"description": "",
	"content": " root@km:~# sudo apt-get update ... Ign:56 http://cn.archive.ubuntu.com/ubuntu xenial-backports/multiverse Translation-en_US Fetched 3,967 kB in 37min 32s (1,761 B/s) Reading package lists... Done W: The repository 'http://cn.archive.ubuntu.com/ubuntu xenial-updates Release' does not have a Release file. N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use. N: See apt-secure(8) manpage for repository creation and user configuration details. W: The repository 'http://cn.archive.ubuntu.com/ubuntu xenial-backports Release' does not have a Release file. N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use. N: See apt-secure(8) manpage for repository creation and user configuration details. root@km:~# apt-cache madison docker-ce docker-ce | 17.09.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.2~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.2~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages root@km:~# sudo apt-get install docker-ce=v17.03 Reading package lists... Done Building dependency tree Reading state information... Done E: Version 'v17.03' for 'docker-ce' was not found root@km:~# apt-cache madison docker-ce docker-ce | 17.09.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.2~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.2~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages root@km:~# sudo apt-get install docker-ce=17.03.2~ce-0~ubuntu-xenial -y Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: aufs-tools cgroupfs-mount libltdl7 Suggested packages: mountall The following NEW packages will be installed: aufs-tools cgroupfs-mount docker-ce libltdl7 0 upgraded, 4 newly installed, 0 to remove and 22 not upgraded. Need to get 38.3 kB/19.3 MB of archives. After this operation, 89.4 MB of additional disk space will be used. Get:1 http://cn.archive.ubuntu.com/ubuntu xenial/main amd64 libltdl7 amd64 2.4.6-0.1 [38.3 kB] Fetched 12.5 kB in 0s (446 kB/s) Selecting previously unselected package aufs-tools. (Reading database ... 106140 files and directories currently installed.) Preparing to unpack .../aufs-tools_1%3a3.2+20130722-1.1ubuntu1_amd64.deb ... Unpacking aufs-tools (1:3.2+20130722-1.1ubuntu1) ... Selecting previously unselected package cgroupfs-mount. Preparing to unpack .../cgroupfs-mount_1.2_all.deb ... Unpacking cgroupfs-mount (1.2) ... Selecting previously unselected package libltdl7:amd64. Preparing to unpack .../libltdl7_2.4.6-0.1_amd64.deb ... Unpacking libltdl7:amd64 (2.4.6-0.1) ... Selecting previously unselected package docker-ce. Preparing to unpack .../docker-ce_17.03.2~ce-0~ubuntu-xenial_amd64.deb ... Unpacking docker-ce (17.03.2~ce-0~ubuntu-xenial) ... Processing triggers for libc-bin (2.23-0ubuntu9) ... Processing triggers for man-db (2.7.5-1) ... Processing triggers for ureadahead (0.100.0-19) ... Processing triggers for systemd (229-4ubuntu21) ... Setting up aufs-tools (1:3.2+20130722-1.1ubuntu1) ... Setting up cgroupfs-mount (1.2) ... Setting up libltdl7:amd64 (2.4.6-0.1) ... Setting up docker-ce (17.03.2~ce-0~ubuntu-xenial) ... Installing new version of config file /etc/init.d/docker ... Processing triggers for libc-bin (2.23-0ubuntu9) ... Processing triggers for systemd (229-4ubuntu21) ... Processing triggers for ureadahead (0.100.0-19) ... root@km:~# sudo docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ root@km:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES root@km:~# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e27a404beed2 hello-world \u0026quot;/hello\u0026quot; 8 seconds ago Exited (0) 8 seconds ago hopeful_hodgkin root@km:~#  Ref  https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#install-docker-ce-1  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/go-tour-zh-local-install.html",
	"title": "go-tour-zh离线安装(本地安装)",
	"tags": ["golang", "tour", "install"],
	"description": "",
	"content": " 中文文档 最近尝试学习golang，在某个网站（真忘了）上发现gotour是一款灰常叼的教程\u0026amp;指南，之后搜索发现有前辈给出了本地安装离线gotour的方法，但实际安装过程中发现一些问题：\n1.通过go get bitbucket.org/mikespook/go-tour-zh/gotour 命令安装时报错，提示missing Mercurial command，原来是先需要安装Mercurial；\n➜ bitbucket git:(master) ✗ go get bitbucket.org/mikespook/go-tour-zh/gotour go: missing Mercurial command. See https://golang.org/s/gogetcmd package bitbucket.org/mikespook/go-tour-zh/gotour: exec: \u0026quot;hg\u0026quot;: executable file not found in $PATH ➜ bitbucket git:(master) ✗ brew install mercurial Updating Homebrew... ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/mercurial-4.8.mojave.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring mercurial-4.8.mojave.bottle.tar.gz ==\u0026gt; Caveats Bash completion has been installed to: /usr/local/etc/bash_completion.d zsh completions have been installed to: /usr/local/share/zsh/site-functions ==\u0026gt; Summary 🍺 /usr/local/Cellar/mercurial/4.8: 618 files, 9.9MB ➜ bitbucket git:(master) ✗ hg clone https://bitbucket.org/mikespook/go-tour-zh  2.顺利用以上命令安装成功后，原贴说直接运行gotour命令即可通过http://127.0.0.1:3999 进行本地访问gotour，然而，bin目录下没有gotour\u0026hellip; 解决方法\n综上，本帖将整体安装过程梳理一遍（go语言安装及配置就不再赘诉了）\n1.下载并安装Mercurial及Git\n　Mercurial：https://www.mercurial-scm.org/wiki/Download\n　Git：https://git-scm.com/download/win\n　（如无法访问请科学上网或百度寻找国内下载源）\n2.用Mercurial下载gotour离线包，命令如下\n　hg clone https://bitbucket.org/mikespook/go-tour-zh\n3.用Git下载goTools\u0026amp;goNet，命令如下\n　go get github.com/golang/net\n　go get github.com/golang/tools\n4.调整文件路径，确保以上所下载的三个文件夹分别在以下路径中\n　gotour离线包：$GOPATH/src/bitbucket.org/mikespook\n　net：$GOPATH/src/golang.org/x/\n　tools：$GOPATH/src/golang.org/x/\n　（$GOPATH指代你自己定义的GOPATH路径，请参考go语言环境配置，需要注意的是，GOPATH下要建立src、bin、pkg三个文件夹）\n5.在命令行中切换到$GOPATH/src/bitbucket.org/mikespook/go-tour-zh/gotour，执行以下命令\n　go install\n6.至此，在$GOPATH/bin目录下已经生成gotour文件了，将其复制到$GOROOT/bin目录下\n7.命令行中执行gotour，到浏览器中访问http://127.0.0.1:3999 就可以查看本地的gotour了\nRef  http://www.cnblogs.com/Vulpers/p/5562586.html 构建离线Go编程指南——gotour golang - revel安装手记 go-tour-zh离线安装 Go语言开发环境配置  英文文档 ➜ ~ git:(master) ✗ godoc -http=:6060  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-zsh-list-file-name-only.html",
	"title": "在mac zsh下，ls只显示文件名",
	"tags": ["mac", "file"],
	"description": "",
	"content": "ls只显示文件名\n$ ls -a1  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/yasnippet.html",
	"title": "yasnippet-setup",
	"tags": ["emacs", "yasnippet"],
	"description": "",
	"content": " 功能  可以实现各种代码模板，包括注释模板。 可以参考emacs自带的yasnippet文档。命令是：c-h f yas-minor-mode 可以利用emacs的elisp代码，实现功能命令输出。  You can also include lisp code in your template. For example, you might want to have a date stamp. Here’s a example that insert user’s email address and datestamp.\n`user-mail-address` `(current-time-string)`\n直接看完下文就可以基本了解了：\n在Spacemacs中为Yasnippet添加自定义snippet\nRef  https://blog.csdn.net/u011729865/article/details/53240101 在Spacemacs中为Yasnippet添加自定义snippet https://github.com/joaotavora/yasnippet http://joaotavora.github.io/yasnippet/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-key-binding.html",
	"title": "spacemacs key binding",
	"tags": ["spacemacs", "keybinding"],
	"description": "",
	"content": " Table  | Key | Function | 中文解释 | 其它 | |\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;| | SPC t n | linum-mode | 显示行号 | | | SPC j l | goto-line | 跳转到行号 | | | C-c \u0026gt; | python-indent-region | 代码块右移 | python leyer | | C-c \u0026lt; | python-indent-region | 代码块左移 | python leyer |\n有一些网址已经帮我们总结了很多的快捷键，罗列在这里：\nhttps://blog.csdn.net/u011729865/article/details/52793134\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git-multi-ssh-keys.html",
	"title": "配置公私钥别名",
	"tags": ["git"],
	"description": "",
	"content": " 配置公私钥别名 私钥权限不是600 ➜ tom-finsoftinfo git:(master) ✗ ssh-add id_rsa_finsoftinfo @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: UNPROTECTED PRIVATE KEY FILE! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Permissions 0644 for 'id_rsa_finsoftinfo' are too open. It is required that your private key files are NOT accessible by others. This private key will be ignored. ➜ tom-finsoftinfo git:(master) ✗  看提示，就知道是权限不对了。修改为600，就可以了。\n➜ tom-finsoftinfo git:(master) ✗ l total 16K drwxr-xr-x 6 tomtsang 192 Nov 13 22:56 . drwx--x--x 7 tomtsang 224 Oct 15 11:20 .. -rw-r--r-- 1 tomtsang 1.7K Nov 13 22:56 id_rsa_finsoftinfo -rw-r--r-- 1 tomtsang 399 Nov 13 22:56 id_rsa_finsoftinfo.pub ➜ tom-finsoftinfo git:(master) ✗ chmod 600 id_rsa_finsoftinfo ➜ tom-finsoftinfo git:(master) ✗ l total 16K drwxr-xr-x 6 tomtsang 192 Nov 13 22:56 . drwx--x--x 7 tomtsang 224 Oct 15 11:20 .. -rw------- 1 tomtsang 1.7K Nov 13 22:56 id_rsa_finsoftinfo -rw-r--r-- 1 tomtsang 399 Nov 13 22:56 id_rsa_finsoftinfo.pub ➜ tom-finsoftinfo git:(master) ✗ ssh-add id_rsa_finsoftinfo Identity added: id_rsa_finsoftinfo (id_rsa_finsoftinfo) ➜ tom-finsoftinfo git:(master) ✗ ssh-add -l 2048 SHA256:KnwSrbgqEaN9EZdTrfME/KJCDvMdATgdzS9GVHV9wBY id_rsa_finsoftinfo (RSA) ➜ tom-finsoftinfo git:(master) ✗ ssh -T finsoftinfo Hi finsoftinfo! You've successfully authenticated, but GitHub does not provide shell access. ➜  ➜ .ssh git:(master) ✗ cd /Users/tomtsang/github/finsoftinfo/finsoftinfo.github.io ➜ finsoftinfo.github.io git:(master) g pull finsoftinfo master ERROR: Repository not found. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. ➜ finsoftinfo.github.io git:(master) g remote -v finsoftinfo\tfinsoftinfo:finsoftinfo.github.io (fetch) finsoftinfo\tfinsoftinfo:finsoftinfo.github.io (push) ➜ finsoftinfo.github.io git:(master)  Could not read from remote repository 别名的仓库url 不对 ➜ finsoftinfo.github.io git:(master) pwd /Users/tomtsang/github/finsoftinfo/finsoftinfo.github.io ➜ finsoftinfo.github.io git:(master) g pull finsoftinfo master ERROR: Repository not found. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. ➜ finsoftinfo.github.io git:(master)  注意看一下仓库名，修改正确就行了。这里特别注意一下，总共出现了三次的`finsoftinfo`\n➜ finsoftinfo.github.io git:(master) g remote -v finsoftinfo\tfinsoftinfo:finsoftinfo.github.io (fetch) finsoftinfo\tfinsoftinfo:finsoftinfo.github.io (push) ➜ finsoftinfo.github.io git:(master) g remote set-url finsoftinfo finsoftinfo:finsoftinfo/finsoftinfo.github.io ➜ finsoftinfo.github.io git:(master) g remote -v finsoftinfo\tfinsoftinfo:finsoftinfo/finsoftinfo.github.io (fetch) finsoftinfo\tfinsoftinfo:finsoftinfo/finsoftinfo.github.io (push) ➜ finsoftinfo.github.io git:(master)  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/sed-string-replace.html",
	"title": "linux sed 批量替换字符串",
	"tags": ["sed", "linux", "replace"],
	"description": "",
	"content": " Linux下批量替换多个文件中的字符串的简单方法。\n用sed命令可以批量替换多个文件中的字符串 命令如下：\nsed -i \u0026quot;s/原字符串/新字符串/g\u0026quot; `grep 原字符串 -rl 所在目录`  例如：我要把 charset=gb2312 替换为 charset=UTF-8，执行命令：\nsed -i \u0026quot;s/charset=gb2312/charset=UTF-8/g\u0026quot; `grep charset=gb2312 -rl /www`  即可。\n解释一下：\n-i 表示inplace edit，就地修改文件\n-r 表示搜索子目录\n-l 表示输出匹配的文件名\n这个命令组合很强大，要注意备份文件。\n关于 sed 的更多说明：  替换  sed 'y/1234567890/ABCDEFGHIJ/' test_sed  test_sed的内容是：\n1234567890 2345678901 3456789012 4567890123  执行后，test_sed的内容是：\nABCDEFGHIJ BCDEFGHIJA CDEFGHIJAB DEFGHIJABC  注意变换关系是按两个list的位置对应变换\n 替换每行所有匹配  sed \u0026rsquo;s/01/Ab/g\u0026rsquo; test_sed\n1234567890\n23456789Ab\n3456789Ab2\n456789Ab23\n注意：第一行的0，1没有分别替换为A,b\n删除：d命令 $ sed '2d' example  删除example文件的第二行。\n$ sed '2,$d' example  删除example文件的第二行到末尾所有行。\n$ sed '$d' example  删除example文件的最后一行。\n$ sed '/test/'d example  删除example文件所有包含test的行。\n替换：s命令 $ sed 's/test/mytest/g' example  在整行范围内把test替换为mytest。如果没有g标记，则只有每行第一个匹配的test被替换成mytest。\n$ sed -n 's/^test/mytest/p' example  (-n)选项和p标志一起使用表示只打印那些发生替换的行。也就是说，如果某一行开头的test被替换成mytest，就打印它。\n$ sed 's/^192.168.0.1/\u0026amp;localhost/'example  \u0026amp;符号表示替换换字符串中被找到的部份。所有以192.168.0.1开头的行都会被替换成它自已加localhost，变成192.168.0.1localhost。\n$ sed -n 's/\\(love\\)able/\\1rs/p' example  love被标记为1，所有loveable会被替换成lovers，而且替换的行会被打印出来。\n$ sed \u0026rsquo;s#10#100#g\u0026rsquo; example\n不论什么字符，紧跟着s命令的都被认为是新的分隔符，所以，“#”在这里是分隔符，代替了默认的“/”分隔符。表示把所有10替换成100。\n选定行的范围：逗号 $ sed -n '/test/,/check/p' exampl  所有在模板test和check所确定的范围内的行都被打印。\n$ sed -n '5,/^test/p' example  打印从第五行开始到第一个包含以test开始的行之间的所有行。\n$ sed '/test/,/check/s/$/sed test/' example  对于模板test和west之间的行，每行的末尾用字符串sed test替换。\n多点编辑：e命令 $ sed -e '1,5d' -e 's/test/check/'example  (-e)选项允许在同一行里执行多条命令。如例子所示，第一条命令删除1至5行，第二条命令用check替换test。命令的执行顺序对结果有影响。如果两个命令都是替换命令，那么第一个替换命令将影响第二个替换命令的结果。\n$ sed --expression='s/test/check/' --expression='/love/d' example  一个比-e更好的命令是–expression。它能给sed表达式赋值。\n从文件读入：r命令 $ sed '/test/r file' example  file里的内容被读进来，显示在与test匹配的行后面，如果匹配多行，则file的内容将显示在所有匹配行的下面。\n写入文件：w命令 $ sed -n '/test/w file' example  在example中所有包含test的行都被写入file里。\n追加命令：a命令 $ sed '/^test/a\\\\---\u0026gt;this is a example' example\u0026lt;  ‘this is a example’被追加到以test开头的行后面，sed要求命令a后面有一个反斜杠。\n插入：i命令 $ sed '/test/i\\\\ new line -------------------------' example  如果test被匹配，则把反斜杠后面的文本插入到匹配行的前面。\n下一个：n命令 $ sed '/test/{ n; s/aa/bb/; }' example  如果test被匹配，则移动到匹配行的下一行，替换这一行的aa，变为bb，并打印该行，然后继续。\n变形：y命令 $ sed '1,10y/abcde/ABCDE/' example  把1–10行内所有abcde转变为大写，注意，正则表达式元字符不能使用这个命令。\n退出：q命令 $ sed '10q' example  打印完第10行后，退出sed。\n保持和获取：h命令和G命令 $ sed -e '/test/h' -e '$Gexample  在sed处理文件的时候，每一行都被保存在一个叫模式空间的临时缓冲区中，除非行被删除或者输出被取消，否则所有被处理的行都将打印在屏幕上。接着模式空间被清空，并存入新的一行等待处理。在这个例子里，匹配test的行被找到后，将存入模式空间，h命令将其复制并存入一个称为保持缓存区的特殊缓冲区内。第二条语句的意思是，当到达最后一行后，G命令取出保持缓冲区的行，然后把它放回模式空间中，且追加到现在已经存在于模式空间中的行的末尾。在这个例子中就是追加到最后一行。简单来说，任何包含test的行都被复制并追加到该文件的末尾。\n保持和互换：h命令和x命令 $ sed -e '/test/h' -e '/check/x' example  互换模式空间和保持缓冲区的内容。也就是把包含test与check的行互换。\nRef  http://www.frostsky.com/2014/01/linux-sed-command/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vim/vim-redo.html",
	"title": "vi撤销与恢复撤销",
	"tags": ["vi", "undo"],
	"description": "",
	"content": " Step 在vi中按u可以撤销一次操作\n u 撤销上一步的操作 Ctrl+r 恢复上一步被撤销的操作  注意： 如果你输入“u”两次，你的文本恢复原样，那应该是你的Vim被配置在Vi兼容模式了。 重做 如果你撤销得太多，你可以输入CTRL-R（redo）回退前一个命令。换句话说，它撤销一个撤销。 要看执行的例子，输入CTRL-R两次。字符A和它后面的空格就出现了： young intelligent turtle\n 有一个特殊版本的撤销命令：“U”（行撤销）。  行撤销命令撤销所有在前一个编辑行 上的操作。 输入这些命令两次取消前一个“U”： A very intelligent turtle\n xxxx 删除very  A intelligent turtle\n xxxxxx 删除turtle  A intelligent\n 用“U”恢复行  A very intelligent turtle\n 用“u”撤销“U”  A intelligent\n “U”命令自己改变自己，“u”命令撤销操作，CTRL-R命令重做操作。这有点乱，但不用  担心，用“u”和CTRL-R命令你可以切换到任何状态。\nRef  https://blog.csdn.net/xiongzhengxiang/article/details/7206691  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/easy-hugo-and-ox-hugo-qa.html",
	"title": "关于 hugo, easy-hugo, ox-hugo, spacemacs 集成相关的问题",
	"tags": ["org", "ox-hugo", "easy-hugo", "sapcemacs"],
	"description": "",
	"content": " ox-hugo，easy-hugo, spacemacs的集成 ox-hugo 写文档 这里，在写文档的时候，配置好就可以了,无需修改 spacemacs的配置。\n具体的配置，见 ox-hugo-example-2.org, aa.org, ox-hugo-example-1.org\n导出至easy-hugo的content/xxx文件夹中 这一步，可以被 auto-save 函数替换了。\nC-c C-e H H\neasy-hugo preview C-c e p\n用 easy-hugo preview 有时会因为缓存问题，而失真哟 当时有一个 pages/about.md 文件导致的失真。在右上角的Menu中始终存在。\n解决方式，清缓存。\nEXPORT_HUGO_SECTION 失效 当 content 下，没有pages文件夹时，在 *.org 的\n:EXPORT_HUGO_SECTION: pages  会失效，且，.md 文件会在 easy-hugo 的配置项 easy-hugo-postdir（我这里设置的是 content/posts/）下 .\n同时有 .org 和 .md 文件，.org 有效，.md 失效 当 content/posts/ 下同时有 .org 和 .md 文件，则 .org 文件有效，.md 失效\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-jane-transmitter-from-beautifulhugo.html",
	"title": "使用hugo的jane主题时，categories 书写不规范",
	"tags": ["hugo", "jane", "categories"],
	"description": "",
	"content": "categories 不是列表 ➜ tomtsang-rootsongjc-hugo git:(master) ✗ hugo server Building sites … ERROR 2018/11/26 01:07:40 Error while rendering \u0026quot;page\u0026quot; in \u0026quot;posts/\u0026quot;: template: _default/single.html:11:5: executing \u0026quot;_default/single.html\u0026quot; at \u0026lt;partial \u0026quot;head.html\u0026quot; ...\u0026gt;: error calling partial: template: partials/head.html:28:16: executing \u0026quot;partials/head.html\u0026quot; at \u0026lt;index ($.Site.Data.a...\u0026gt;: error calling index: value has type []string; should be string ERROR 2018/11/26 01:07:40 Error while rendering \u0026quot;page\u0026quot; in \u0026quot;post/\u0026quot;: template: post/single.html:14:21: executing \u0026quot;content\u0026quot; at \u0026lt;.\u0026gt;: range can't iterate over cloud-native ERROR 2018/11/26 01:07:40 in .Render: Failed to execute template \u0026quot;post/summary.html\u0026quot;: template: post/summary.html:11:19: executing \u0026quot;post/summary.html\u0026quot; at \u0026lt;.\u0026gt;: range can't iterate over cloud-native Total in 687 ms Error: Error building site: logged 3 error(s) ➜ tomtsang-rootsongjc-hugo git:(master) ✗  看上面的提示，知道，是与：\n 某一个在 content/post 文件夹下的 page 相关 文档内容中包含了 \u0026ldquo;cloud-native\u0026rdquo; 字符串  所以搜索，知道，是在 文档的 header 部分\n--- categories: \u0026quot;cloud-native\u0026quot; ---  而不是\n--- categories: [\u0026quot;cloud-native\u0026quot;] ---  所以，出错了。\n现在这个看起来，好像没有问题了\n批量处理 ➜ tomtsang-rootsongjc-hugo git:(master) ✗ grep \u0026quot;categories: \\\u0026quot;\u0026quot; -rn ./content/  把所有出现的 categories 放在 categories.txt 中，执行下面shell，就可以了。\nfor str in `cat categories.txt` do echo ${str} sed -i \u0026quot;s/categories: \\\u0026quot;${str}\\\u0026quot;/categories: \\[\\\u0026quot;${str}\\\u0026quot;\\]/g\u0026quot; `grep \u0026quot;categories: \\\u0026quot;${str}\\\u0026quot;\u0026quot; -rl ./../content/post/` done  author 要为 字符串 但是，过一会，又出错了\n➜ tomtsang-rootsongjc-hugo git:(master) ✗ hugo serve | ZH-CN +------------------|-------+ Pages | 336 Paginator pages | 0 Non-page files | 0 Static files | 19 Processed images | 0 Aliases | 122 Sitemaps | 1 Cleaned | 0 Total in 321 ms Watching for changes in /Users/tomtsang/bitbucket/qqbb/tomtsang-rootsongjc-hugo/{content,static,themes} Watching for config changes in /Users/tomtsang/bitbucket/qqbb/tomtsang-rootsongjc-hugo/config.toml Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop Change detected, rebuilding site 2018-11-26 16:36:04.511 +0800 Source changed \u0026quot;/Users/tomtsang/bitbucket/qqbb/tomtsang-rootsongjc-hugo/content/posts/test-aa-topic-post-title.md\u0026quot;: WRITE ERROR 2018/11/26 16:36:04 Error while rendering \u0026quot;page\u0026quot; in \u0026quot;posts/\u0026quot;: template: _default/single.html:11:5: executing \u0026quot;_default/single.html\u0026quot; at \u0026lt;partial \u0026quot;head.html\u0026quot; ...\u0026gt;: error calling partial: template: partials/head.html:28:16: executing \u0026quot;partials/head.html\u0026quot; at \u0026lt;index ($.Site.Data.a...\u0026gt;: error calling index: value has type []string; should be string Total in 23 ms ERROR 2018/11/26 16:36:04 Failed to rebuild site: logged 1 error(s)  这下发现，只要一加入这个新的.md文件就出错了。\n看*.md文件，知道, header部分是这样的：\n+++ title = \u0026quot;Post Title\u0026quot; author = [\u0026quot;Bryce\u0026quot;] date = 2017-12-19T17:00:00+08:00 lastmod = 2018-11-26T16:36:03+08:00 tags = [\u0026quot;post\u0026quot;, \u0026quot;tags\u0026quot;] categories = [\u0026quot;topic\u0026quot;] draft = false +++  其中categories格式正确，但是，这个 author 渲染不了。 如果此时，修改 author = [\u0026ldquo;Bryce\u0026rdquo;] 为 author = \u0026ldquo;Bryce\u0026rdquo; ，则能够正常渲染。\n那怎么办？\n 修改 author ，去除中括号 去除 author 。  思路1。不容易，原因： 这个中括号，是由 ox-hugo 自动生成的，且，不容易修改 ox-hugo 的配置文件 `~/.emacs.d/elpa/develop/org-plus-contrib-20181029/ox.el`。\n思路2。可以在 一级标题下的 PROPERTIES 中 加入 `:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true` ，我们看一下效果。在不修改 ox-hugo 配置的情况下，会使用 `author = [\u0026ldquo;tom tsang\u0026rdquo;] ` 。所以还是没有效果。\n经过查询ox-hugo官方文档，得知，要在 org 文档的头部添加：\n#+author: #+hugo_custom_front_matter: :author \u0026quot;Bryce\u0026quot;  这个时候，export得到的 .md文件，会有 `author = \u0026ldquo;Bryce\u0026rdquo;` 。 如果不想要author, 则直接写成下面这样：\n#+author: #+hugo_custom_front_matter: :author \u0026quot;\u0026quot;  这个时候，导出的.md文件就没有author。\nRef  https://ox-hugo.scripter.co/doc/author/#forcing-author-to-be-a-string--alternative "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-server-faq.html",
	"title": "hugo-server-faq",
	"tags": ["hugo"],
	"description": "",
	"content": " Error building site: EOF ➜ tomtsang-rootsongjc-hugo git:(master) ✗ hugo server Building sites … ERROR 2018/11/17 15:50:31 EOF for org/aaaa.org Total in 108 ms Error: Error building site: EOF ➜ tomtsang-rootsongjc-hugo git:(master) ✗  其实这个时候，查看一下 org/aaaa.org文件，没有内容，所以，删除了就可以 hugo server了的。\n➜ tomtsang-rootsongjc-hugo git:(master) ✗ cat content/org/aaaa.org #+TITLE: aaaa #+DATE: 2018-11-16T23:38:13+08:00 #+PUBLISHDATE: 2018-11-16T23:38:13+08:00 #+DRAFT: nil #+TAGS: nil, nil #+DESCRIPTION: Short description ➜ tomtsang-rootsongjc-hugo git:(master) ✗ rm -rf ./content/org ➜ tomtsang-rootsongjc-hugo git:(master) ✗  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/saleor/saleor-customization-tests.html",
	"title": "saleor 测试（笔记）",
	"tags": ["saleor", "note"],
	"description": "",
	"content": "https://docs.getsaleor.com/en/latest/customization/tests.html\n(saleor) ➜ saleor git:(master) pipenv install --dev Courtesy Notice: Pipenv found itself running within a virtual environment, so it will automatically use that environment, instead of creating its own for any project. You can set PIPENV_IGNORE_VIRTUALENVS =1 to force pipenv to ignore that environment and create its own instead. You can set PIPENV_VERBOSITY=-1 to suppress this warning. Installing dependencies from Pipfile.lock (0c0b26)… An error occurred while installing yarl==1.3.0 ; python_version \u0026gt;= '3.4' --hash=sha256:024ecdc12bc02b321bc66b41327f930d1c2c543fa9a561b39861da9388ba7aa9 --hash=sha256:2f3010703295fbe1aec51023740871e64bb966 4c789cba5a6bdf404e93f7568f --hash=sha256:3890ab952d508523ef4881457c4099056546593fa05e93da84c7250516e632eb --hash=sha256:3e2724eb9af5dc41648e5bb304fcf4891adc33258c6e14e2a7414ea32541e320 --hash=sha256:5badb 97dd0abf26623a9982cd448ff12cb39b8e4c94032ccdedf22ce01a64842 --hash=sha256:73f447d11b530d860ca1e6b582f947688286ad16ca42256413083d13f260b7a0 --hash=sha256:7ab825726f2940c16d92aaec7d204cfc34ac26c0040da727cf8 ba87255a33829 --hash=sha256:b25de84a8c20540531526dfbb0e2d2b648c13fd5dd126728c496d7c3fea33310 --hash=sha256:c6e341f5a6562af74ba55205dbd56d248daf1b5748ec48a0200ba227bb9e33f4 --hash=sha256:c9bb7c249c4432cd47 e75af3864bc02d26c9594f49c82e2a28624417f0ae63b8 --hash=sha256:e060906c0c585565c718d1c3841747b61c5439af2211e185f6739a9412dfbde1! Will try again. 🐍 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 151/151 — 00:03:59 Installing initially failed dependencies… [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 1874, in do_install [pipenv.exceptions.InstallError]: keep_outdated=keep_outdated [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 1253, in do_init [pipenv.exceptions.InstallError]: pypi_mirror=pypi_mirror, [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 859, in do_install_dependencies [pipenv.exceptions.InstallError]: retry_list, procs, failed_deps_queue, requirements_dir, **install_kwargs [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 763, in batch_install [pipenv.exceptions.InstallError]: _cleanup_procs(procs, not blocking, failed_deps_queue, retry=retry) [pipenv.exceptions.InstallError]: File \u0026quot;/home/tom/.virtualenvs/saleor/lib/python3.5/site-packages/pipenv/core.py\u0026quot;, line 681, in _cleanup_procs [pipenv.exceptions.InstallError]: raise exceptions.InstallError(c.dep.name, extra=err_lines) [pipenv.exceptions.InstallError]: ['Looking in indexes: https://pypi.python.org/simple', 'Collecting yarl==1.3.0 (from -r /tmp/pipenv-25r_kf3l-requirements/pipenv-i6tr8___-requirement.txt (line 1))'] [pipenv.exceptions.InstallError]: ['Could not find a version that satisfies the requirement yarl==1.3.0 (from -r /tmp/pipenv-25r_kf3l-requirements/pipenv-i6tr8___-requirement.txt (line 1)) (from versions: 0.0.1, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.3.2, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0b2, 0.5.0b3, 0.5.0b4, 0.5.0b5, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.6.0, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.9.5, 0.9.6, 0.9.7, 0.9.8, 0.10.0, 0.10.1, 0.10.2, 0.10.3, 0.11.0, 0.12.0, 0.13.0, 0.14.0, 0.14.1, 0.14.2, 0.15.0, 0.16.0, 0.17.0, 0.18.0, 1.0.0, 1.1.0, 1.1.1, 1.2.0)' , 'No matching distribution found for yarl==1.3.0 (from -r /tmp/pipenv-25r_kf3l-requirements/pipenv-i6tr8___-requirement.txt (line 1))'] ERROR: ERROR: Package installation failed... (saleor) ➜ saleor git:(master)  怎么办？\n查看 这里\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-tmuxinator.html",
	"title": "tmuxinator（笔记）",
	"tags": ["tmux", "note"],
	"description": "",
	"content": " tmux进阶之tmuxinator\n在Tmuxinator中配置layout https://blog.suisuijiang.com/tmux-course-terminal-manage/\n我们可能会需要指定窗格的排班规则，tmuxinator支持设置tmux中的5种默认layout样式：\neven-horizontal Panes are spread out evenly from left to right across the window. even-vertical Panes are spread evenly from top to bottom. main-horizontal A large (main) pane is shown at the top of the window and the remaining panes are spread from left to right in the leftover space at the bottom. Use the main-pane-height window option to specify the height of the top pane. main-vertical Similar to main-horizontal but the large pane is placed on the left and the others spread from top to bottom along the right. See the main-pane-width window option. tiled Panes are spread out as evenly as possible over the window in both rows and columns.  但是默认的5种样式不能让我们自由的设定每个窗格的大小，所以我们要使用自定义的 layout，在tmux中可以使用C-b + 方向键调整窗格的大小。 tmuxinator中可以直接使用tmux中的layout值，在终端输入tmux list-windows可以查看每个窗口的layout值，我们只需将这个值写入tmuxinator项目配置配置中的layout即可。\n自定义layout https://stackoverflow.com/questions/9812000/specify-pane-percentage-in-tmuxinator-project/9976282#9976282 http://zuyunfei.com/2013/08/09/tmuxinator-best-mate-of-tmux/\nhtml view tmux https://github.com/k3rni/tmuxinator\n运维利器-tmuxinator与glances 运维经常需要同时查看各台windows/linux服务器的实时状态。有没有方便的方法能够同时查看状态，而且支持windows和linux呢？tmuxinator，tmux, 结合使用glances可以达到目的。\nglances 是一款用于 Linux、BSD、windows 的开源命令行系统监视工具，它使用 Python 语言开发，能够监视 CPU、负载、内存、磁盘 I/O、网络流量、文件系统、系统温度等信息。glances可以以服务模式启动，以服务模式启动后，可以从任意一台linux客户端用glances命令连接到glances服务，从而显示服务器的状态，而达到从客户端远程监控服务器的目的。\ntmux是linux下面的一个分屏幕，可以把你的屏幕分成多个工作区，同时进行不同的工作。而tmuxinator则让tmux可以按照预先的设置，同时在一个界面的多块区域分别运行指定的命令。这样我们可以利用tmuxinator同时运行多个glances命令, 监控多台服务器的状态。\nglances: https://github.com/nicolargo/glances\ntmuxinator: https://github.com/tmuxinator/tmuxinator\ntmuxinator结合glances，可同时看到多台服务器上的预警和严重问题（严重问题，告警在glances中会显示红色，黄色）。 各台server启动glances server: glances -s 0.0.0.0， 找一台linux客户端可以同时显示多台服务器的状态。(glances可以监控windows/linux/mac的状态)\n示例文件~/.tmuxinator/glances.yml的配置:\nname: glances root: ~/ windows: - editor: #layout: main-vertical layout: tiled panes: - glances -c 127.0.0.1 - glances -c 192.168.1.5 - glances -c localhost - glances -c 127.0.0.1 - glances -c 127.0.0.1  tmuxinator start glances，运行效果如图：\nRef  tmuxinator github README.md 中文 https://github.com/tmuxinator/tmuxinator https://blog.csdn.net/u014717036/article/details/60139776  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-compose-installed-then-error-specify-DOCKER_HOST.html",
	"title": "docker-compose安装后报&#34;specify DOCKER_HOST&#34;错误",
	"tags": ["docker", "docker-compose"],
	"description": "",
	"content": " 按照官网 https://docs.docker.com/compose/install/ 安装完 docker-compose 后，要重 新进入一下用户(比如切换为root，再次切换为user)，配置才生效。\n否则会报出下面的错误：\nERROR: Couldn’t connect to Docker daemon at http+docker://localunixsocket - is it running? If it’s at a non-standard location, specify the URL with the DOCKER_HOST environment variable.  Ref  https://blog.csdn.net/xiojing825/article/details/79494408  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-ln-s-make-soft-link.html",
	"title": "linux 软连接 不能加/号",
	"tags": ["linux"],
	"description": "",
	"content": " 对某个目录创建符号连接\n[root@A home]# ln -s /home/kk /home/abc\n此命令表示在/home目录下创建一个链接到/home/kk目录的名字为abc的符号连接。\n注意：\n 目标是一个软连接符号，所以不要带上 / 号。带上后，就是指把 软连接放在这个目录下  ➜ org git:(master) ✗ ln -s /home/ubuntu/tom/jinweilai/blog-jwl/org-jwl/org/ ~/org ➜ org git:(master) ✗ ln -s /home/ubuntu/tom/jinweilai/blog-jwl/org-jwl/org/ ~/org/ ➜ org git:(master) ✗ ls ~/org gtd.org org ➜ org git:(master) ✗  Ref  https://blog.csdn.net/liuzhenwen/article/details/8152764  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vmware/vmware-copy-vm-from-other-hosts.html",
	"title": "vmware创建新VM（从其它机器中复制VM方式）",
	"tags": ["vmware"],
	"description": "",
	"content": "把vm的文件，放至一个合适的位置，然后，打开vmware workstation pro 点击 文件，打开， 选中相应文件就可以了。 当然，最好重命名一下。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-pyenv-install-with-mac.html",
	"title": "mac中python安装pyenv",
	"tags": ["python", "pyenv"],
	"description": "",
	"content": " pyenv 用于同时管理多个python版本，它可以为每个工作目录设定使用指定的py版本，在不同目录下使用不同的版本可以同时开发不同版本的项目。\nUbuntu安装 ➜ oscar git:(master) ✗ git clone https://github.com/pyenv/pyenv ~/.pyenv Cloning into '/Users/tomtsang/.pyenv'... remote: Enumerating objects: 63, done. remote: Counting objects: 100% (63/63), done. remote: Compressing objects: 100% (37/37), done. remote: Total 16547 (delta 24), reused 50 (delta 20), pack-reused 16484 Receiving objects: 100% (16547/16547), 3.24 MiB | 497.00 KiB/s, done. Resolving deltas: 100% (11211/11211), done. ➜ oscar git:(master) ✗ git clone https://github.com/pyenv/pyenv-virtualenv ~/.pyenv/plugins/pyenv-virtualenv Cloning into '/Users/tomtsang/.pyenv/plugins/pyenv-virtualenv'... remote: Enumerating objects: 2027, done. remote: Total 2027 (delta 0), reused 0 (delta 0), pack-reused 2027 Receiving objects: 100% (2027/2027), 572.01 KiB | 340.00 KiB/s, done. Resolving deltas: 100% (1384/1384), done. ➜ oscar git:(master) ✗  将PYENV_ROOT和pyenv init加入bash的~/.bashrc（或zsh的~/.zshrc）\necho 'export PYENV_ROOT=\u0026quot;$HOME/.pyenv\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc echo 'export PATH=\u0026quot;$PYENV_ROOT/bin:$PATH\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc echo 'eval \u0026quot;$(pyenv init -)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc echo 'eval \u0026quot;$(pyenv virtualenv-init -)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc  激活pyenv\nsource ~/.bashrc（或zsh的`~/.zshrc`）\nMac 安装 更新brew\nbrew update  使用brew安装pyenv\nbrew install pyenv  配置环境变量\necho 'eval \u0026quot;$(pyenv init -)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc echo 'eval \u0026quot;$(pyenv virtualenv-init -)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc  或vim直接编辑\n激活环境\nsource ~/.zshrc  检验 pyenv -v  pyenv: no such command `sh-activate` 如果这个时候，会出现 “pyenv: no such command `sh-activate`”错误，再安装 pyenv-virtualenv 就可以了。\n➜ ~ git:(master) ✗ pyenv -v pyenv 1.2.8 pyenv: no such command `sh-activate' ➜ ~ git:(master) ✗ brew install pyenv-virtualenv Updating Homebrew... ==\u0026gt; Downloading https://github.com/pyenv/pyenv-virtualenv/archive/v1.1.3.tar.gz ==\u0026gt; Downloading from https://codeload.github.com/pyenv/pyenv-virtualenv/tar.gz/v1.1.3 ######################################################################## 100.0% ==\u0026gt; ./install.sh ==\u0026gt; Caveats To enable auto-activation add to your profile: if which pyenv-virtualenv-init \u0026gt; /dev/null; then eval \u0026quot;$(pyenv virtualenv-init -)\u0026quot;; fi ==\u0026gt; Summary 🍺 /usr/local/Cellar/pyenv-virtualenv/1.1.3: 20 files, 62.2KB, built in 12 seconds ➜ ~ git:(master) ✗ pyenv -v pyenv 1.2.8 ➜ ~ git:(master) ✗  Ref  https://stackoverflow.com/questions/37152659/bash-environment-variable-setting-of-home-returns-pyenv-no-such-command-sh  常用命令 pyenv install --list # 列出可安装版本 pyenv install \u0026lt;version\u0026gt; # 安装对应版本 pyenv install -v \u0026lt;version\u0026gt; # 安装对应版本，若发生错误，可以显示详细的错误信息 pyenv versions # 显示当前使用的python版本 pyenv which python # 显示当前python安装路径 pyenv global \u0026lt;version\u0026gt; # 设置默认Python版本 pyenv local \u0026lt;version\u0026gt; # 当前路径创建一个.python-version, 以后进入这个目录自动切换为该版本 pyenv shell \u0026lt;version\u0026gt; # 当前shell的session中启用某版本，优先级高于global 及 local  使用virtualenv\npyenv virtualenv env # 从默认版本创建虚拟环境 pyenv virtualenv 3.6.4 env-3.6.4 # 创建3.6.4版本的虚拟环境 pyenv activate env-3.6.4 # 激活 env-3.6.4 这个虚拟环境 pyenv deactivate # 停用当前的虚拟环境 # 自动激活 # 使用pyenv local 虚拟环境名 # 会把`虚拟环境名`写入当前目录的.python-version文件中 # 关闭自动激活 -\u0026gt; pyenv deactivate # 启动自动激活 -\u0026gt; pyenv activate env-3.6.4 pyenv local env-3.6.4 pyenv uninstall env-3.6.4 # 删除 env-3.6.4 这个虚拟环境  实践过程中发现创建虚拟环境后会多出两个，但是可以不用管，好像没什么影响\n安装3.7.0 提示了\u0026rdquo; zlib not available \u0026ldquo; ➜ ~ git:(master) ✗ pyenv install 3.7.0 python-build: use openssl from homebrew python-build: use readline from homebrew Downloading Python-3.7.0.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz Installing Python-3.7.0... python-build: use readline from homebrew BUILD FAILED (OS X 10.14 using python-build 20180424) Inspect or clean up the working tree at /var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216140437.92921 Results logged to /var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216140437.92921.log Last 10 log lines: File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216140437.92921/Python-3.7.0/Lib/ensurepip/__main__.py\u0026quot;, line 5, in \u0026lt;module\u0026gt; sys.exit(ensurepip._main()) File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216140437.92921/Python-3.7.0/Lib/ensurepip/__init__.py\u0026quot;, line 204, in _main default_pip=args.default_pip, File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216140437.92921/Python-3.7.0/Lib/ensurepip/__init__.py\u0026quot;, line 117, in _bootstrap return _run_pip(args + [p[0] for p in _PROJECTS], additional_paths) File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216140437.92921/Python-3.7.0/Lib/ensurepip/__init__.py\u0026quot;, line 27, in _run_pip import pip._internal zipimport.ZipImportError: can't decompress data; zlib not available make: *** [install] Error 1 ➜ ~ git:(master) ✗  提示了\u0026rdquo; zlib not availabl\u0026rdquo;, 安装 zlib 后继续吧。\n➜ ~ git:(master) ✗ brew install zlib Updating Homebrew... ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/zlib-1.2.11.mojave.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring zlib-1.2.11.mojave.bottle.tar.gz ==\u0026gt; Caveats zlib is keg-only, which means it was not symlinked into /usr/local, because macOS already provides this software and installing another version in parallel can cause all kinds of trouble. For compilers to find zlib you may need to set: export LDFLAGS=\u0026quot;-L/usr/local/opt/zlib/lib\u0026quot; export CPPFLAGS=\u0026quot;-I/usr/local/opt/zlib/include\u0026quot; For pkg-config to find zlib you may need to set: export PKG_CONFIG_PATH=\u0026quot;/usr/local/opt/zlib/lib/pkgconfig\u0026quot; ==\u0026gt; Summary 🍺 /usr/local/Cellar/zlib/1.2.11: 12 files, 373KB ➜ ~ git:(master) ✗  这样安装完成后，还是会有机同的提示，所以我们要完成刚刚的3个export，之后再次尝试。\n➜ ~ git:(master) ✗ pyenv install 3.7.0 python-build: use openssl from homebrew python-build: use readline from homebrew Downloading Python-3.7.0.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz Installing Python-3.7.0... python-build: use readline from homebrew BUILD FAILED (OS X 10.14 using python-build 20180424) Inspect or clean up the working tree at /var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216141406.7026 Results logged to /var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216141406.7026.log Last 10 log lines: File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216141406.7026/Python-3.7.0/Lib/ensurepip/__main__.py\u0026quot;, line 5, in \u0026lt;module\u0026gt; sys.exit(ensurepip._main()) File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216141406.7026/Python-3.7.0/Lib/ensurepip/__init__.py\u0026quot;, line 204, in _main default_pip=args.default_pip, File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216141406.7026/Python-3.7.0/Lib/ensurepip/__init__.py\u0026quot;, line 117, in _bootstrap return _run_pip(args + [p[0] for p in _PROJECTS], additional_paths) File \u0026quot;/private/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/python-build.20181216141406.7026/Python-3.7.0/Lib/ensurepip/__init__.py\u0026quot;, line 27, in _run_pip import pip._internal zipimport.ZipImportError: can't decompress data; zlib not available make: *** [install] Error 1 ➜ ~ git:(master) ✗ which zlib zlib not found ➜ ~ git:(master) ✗ export LDFLAGS=\u0026quot;-L/usr/local/opt/zlib/lib\u0026quot; ➜ ~ git:(master) ✗ which zlib zlib not found ➜ ~ git:(master) ✗ export CPPFLAGS=\u0026quot;-I/usr/local/opt/zlib/include\u0026quot; ➜ ~ git:(master) ✗ export PKG_CONFIG_PATH=\u0026quot;/usr/local/opt/zlib/lib/pkgconfig\u0026quot; ➜ ~ git:(master) ✗ which zlib zlib not found ➜ ~ git:(master) ✗ pyenv install 3.7.0 python-build: use openssl from homebrew python-build: use readline from homebrew Downloading Python-3.7.0.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz Installing Python-3.7.0... python-build: use readline from homebrew WARNING: The Python sqlite3 extension was not compiled. Missing the SQLite3 lib? Installed Python-3.7.0 to /Users/tomtsang/.pyenv/versions/3.7.0 ➜ ~ git:(master) ✗  FAQ 莫名其妙的BUILD FEILED (Ubuntu 16.04 using python-build 1.2.2) 问题是缺少依赖包，各个系统见以下链接\nhttps://github.com/pyenv/pyenv/wiki/Common-build-problems\n我的安装 # # if your system is ubuntu # git clone https://github.com/yyuu/pyenv.git ~/.pyenv # git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv # echo 'export PYENV_ROOT=\u0026quot;$HOME/.pyenv\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc # echo 'export PATH=\u0026quot;$PYENV_ROOT/bin:$PATH\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc # # else if your system is mac brew install openssl readline sqlite3 xz zlib brew install pyenv brew install pyenv-virtualenv # 配置 echo 'eval \u0026quot;$(pyenv init -)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc echo 'eval \u0026quot;$(pyenv virtualenv-init -)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc # 激活配置 source ~/.zshrc # # 判断有没有wget command -v wget \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || { echo \u0026gt;\u0026amp;2 \u0026quot;I require wget but it's not installed. Aborting.\u0026quot;; exit 1; } # # 不喜写兼容代码，所有代码均向 3.5+ 靠拢 v=3.7.0 | wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v v=2.7.14 \u0026amp;\u0026amp; wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v # v=2.7.10 | wget http://mirrors.sohu.com/python/$v/Python-$v.tar.xz -P ~/.pyenv/cache/;pyenv install $v # # 设置 Global Python 为 2.7.10, 备注：尽量不要把 Py3 设置为全局，否则由于 Homebrew 本身有一些应用是依赖于 Py2 的，设置为Py2容易出现一些奇怪的问题。 # pyenv global 2.7.14 pip install -i https://pypi.doubanio.com/simple requests # 下面这个是用于安装基本的代码补全功能 pip install -i https://pypi.doubanio.com/simple --upgrade \u0026quot;jedi\u0026gt;=0.9.0\u0026quot; \u0026quot;json-rpc\u0026gt;=1.8.1\u0026quot; \u0026quot;service_factory\u0026gt;=0.1.5\u0026quot; flake8 pytest autoflake hy pyenv virtualenv 3.7.0 py3-daily pyenv activate py3-daily # 安装依赖包 # pip install -i https://pypi.doubanio.com/simple requests # pip install -i https://pypi.doubanio.com/simple beatutifulsoup4 # pip install -i https://pypi.doubanio.com/simple ipython[notebook] # pip install -i https://pypi.doubanio.com/simple jupyter # # 下面这个是用于安装基本的代码补全功能 # pip install -i https://pypi.doubanio.com/simple --upgrade \u0026quot;jedi\u0026gt;=0.9.0\u0026quot; \u0026quot;json-rpc\u0026gt;=1.8.1\u0026quot; \u0026quot;service_factory\u0026gt;=0.1.5\u0026quot; flake8 pytest autoflake hy # 关闭自动激活,停用虚拟环境 # pyenv deactivate # 卸载 # pyenv uninstall py3-daily  Ref  https://www.jianshu.com/p/c5cc672aae63 https://www.jianshu.com/p/af1f8d7b6b31 https://www.jianshu.com/p/ad2cdcaef9e6 https://www.cnblogs.com/saneri/p/7642316.html https://www.jianshu.com/p/5e00ca8a10d5 http://www.qingpingshan.com/m/view.php?aid=393729  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-readme.html",
	"title": "ceph-install-base-ubuntu READM",
	"tags": ["ceph", "install", "readme"],
	"description": "",
	"content": " 本次安装，完全按照 官方文档 http://docs.ceph.com/docs/master/start/ 进行。\nenv 192.168.31.115 cephadmin # 这个是admin节点 192.168.31.114 mon1 # 存储节点 192.168.31.113 cephfsn2 # 存储节点 192.168.31.173 cephfsn3 # 存储节点 192.168.31.172 ceph-client # 客户端节点  上面这几个，可以全部写进 /etc/hosts 中。且各节点的 hostname 必须对应相同（否则安装容易出错）。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-docker.html",
	"title": "ceph安装，基于docker",
	"tags": ["ceph", "docker"],
	"description": "",
	"content": " https://github.com/ceph/ceph-docker\nm1 http://ceph.com/planet/%E5%9F%BA%E4%BA%8Edocker%E9%83%A8%E7%BD%B2ceph%E4%BB%A5%E5%8F%8A%E4%BF%AE%E6%94%B9docker-image/\nhttp://www.sebastien-han.fr/blog/2015/06/23/bootstrap-your-ceph-cluster-in-docker/\nhttp://www.topjishu.com/10455.html\nhttp://ceph.com/planet/%E5%9F%BA%E4%BA%8Edocker-ui-%E9%85%8D%E7%BD%AEceph%E9%9B%86%E7%BE%A4/\nm2 http://www.dockerinfo.net/445.html\nm3 http://www.jianshu.com/p/f08ed7287416\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/cephfs-install.html",
	"title": "cephfs 安装",
	"tags": ["ceph", "cephfs", "install"],
	"description": "",
	"content": " 环境： 192.168.31.115 192.168.31.114 192.168.31.113  line1 官网, 成功安装 我的安装设计是这样的：\nadmin-node, deploy-node(ceph-deploy)：192.168.31.115 cephfs5 mon.0: 192.168.31.114 cephfs4 osd.0: 192.168.31.113 cephfs3 osd.1: 192.168.31.115 cephfs5 mds.0: 192.168.31.113 cephfs3 mds.1: 192.168.31.114 cephfs4  还是要结合一下 https://linux.cn/article-8182-1.html\nline2 http://tonybai.com/2017/05/08/mount-cephfs-acrossing-nodes-in-kubernetes-cluster/\nover "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-desktop-setup.html",
	"title": "Ubuntu Desktop 环境安装",
	"tags": ["desktop", "ubuntu", "setup"],
	"description": "",
	"content": " 安装Ubuntu 全部安装流程：\n推荐的Ubuntu环境：\n 版本：Ubuntu 16.04 LTS 语言：简体中文 时区：Shanghai 硬件：64位，4G内存以上   引用官方安装教程：点击查看\n 更新软件源 apt源\n操作步骤如下：\n进行上述操作之后，系统会花几分钟时间进行服务器速度的测试。测试完毕之后，点击『选择服务器』，后面根据提示输入密码和重新载入软件信息即可。\npip源\n创建pip的配置文件，在终端中执行如下命令创建.pip文件夹\nmkdir ~/.pip/  再执行如下命令创建pip.conf文件并编辑\nvim ~/.pip/pip.conf  这时候会出现pip.conf的编辑窗口，按字母键a进入到编辑模式，这时候内容为空，并把如下内容输入到编辑框里面\n[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple  编辑完后保存并退出vim： ESC -\u0026gt; shift+; -\u0026gt; x -\u0026gt; Enter\n安装Python 下载Anaconda2并安装，在终端中顺序执行下面3行命令\nwget https://repo.continuum.io/archive/Anaconda2-4.0.0-Linux-x86_64.sh  chmod +x Anaconda2-4.0.0-Linux-x86_64.sh  ./Anaconda2-4.0.0-Linux-x86_64.sh  然后开始进行安装：\n后面根据提示按回车或者输入yes即可，要注意一下在提示是否要在.bashrc文件中更新PATH变量时，一定要输入Yes：\n安装完毕之后执行如下命令让bash的配置文件即时生效\nsource ~/.bashrc  执行完之后执行python命令进行验证，如果安装成功会出现 Anaconda 4.0.0 的字样：\n由于vnpy最近对python3的兼容，需要安装future模块，ImportError: No module named \u0026lsquo;Queue\u0026rsquo;\npip install future  安装依赖项 执行如下两行命令分别安装应用软件和pip的库\nsudo apt-get install mongodb sudo apt-get install libboost-all-dev sudo apt-get install cmake sudo apt-get install git sudo apt-get install libsnappy-dev sudo apt-get install python-snappy  最后两个包的原因请看 https://github.com/vnpy/vnpy/issues/639 如果安装的时候报找不到mongodb，就更新一下apt的源文件信息 sudo apt-get update\n安装和配置MongoDB 安装MongoDB\nsudo apt-get install mongodb  经过测试发现在ubuntu16.04 LTS下安装MongoDB后默认就安装为了自启动的系统服务。\n如果大家想查看MongoDB的数据文件和日志文件的具体位置，可以用如下命令进行查看：\nhead /etc/mongodb.conf  会显示如下内容：\n# mongodb.conf # Where to store the data. dbpath=/var/lib/mongodb #where to log logpath=/var/log/mongodb/mongodb.log  dbpath 是数据文件存储路径，logpath 是日志文件存储路径。\nMongoDB客户端方面推荐使用Robomongo，下载官方压缩包，解压后进入到bin目录，双击robomongo即可。\n准备编译工具 apt-get install build-essential apt-get install python-dev  中文字体安装（如果使用的是英文版ubuntu Linux） 如果系统中没有安装中文字体，图形界面中的中文就会显示为方块。解决方案：\nsudo apt install fonts-wqy-zenhei  Ref  https://github.com/vnpy/vnpy/wiki/Ubuntu%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/how-to-install-certificates-for-command-line-2.html",
	"title": "命令行下如何安装或者更新 CA.crt 文件",
	"tags": ["ubuntu", "certificates"],
	"description": "",
	"content": "https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line\nenv 192.168.31.120\nstep 尝试直接 apt install\njlch@km:~$ sudo apt install ./CA.crt [sudo] password for jlch: Reading package lists... Done E: Unsupported file ./CA.crt given on commandline jlch@km:~$  不行，那尝试一下\njlch@km:~$ dpkg-query -L ca-certificates /. /etc /etc/ssl /etc/ssl/certs /etc/ca-certificates /etc/ca-certificates/update.d /usr /usr/sbin /usr/sbin/update-ca-certificates /usr/share /usr/share/ca-certificates /usr/share/ca-certificates/mozilla ... # 看到了好多 mozilla 的证书相关信息呀。 /usr/share/ca-certificates/mozilla/DigiCert_Global_Root_CA.crt /usr/share/doc /usr/share/doc/ca-certificates /usr/share/doc/ca-certificates/examples ... # 好多 examples /usr/share/doc/ca-certificates/examples/ca-certificates-local/README /usr/share/doc/ca-certificates/changelog.gz /usr/share/doc/ca-certificates/copyright /usr/share/doc/ca-certificates/README.Debian /usr/share/doc/ca-certificates/NEWS.Debian.gz /usr/share/man /usr/share/man/man8 /usr/share/man/man8/update-ca-certificates.8.gz jlch@km:~$  那查一下 update-ca-certificates\njlch@km:~$ which update-ca-certificates jlch@km:~$ sudo which update-ca-certificates [sudo] password for jlch: /usr/sbin/update-ca-certificates jlch@km:~$  好了, 根据 https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line 来更新吧\njlch@km:~$ cd /usr/sbin/update-ca-certificates jlch@km:/usr/share/ca-certificates/xxnet$ sudo cp /home/jlch/CA.crt . jlch@km:/usr/share/ca-certificates/xxnet$ sudo /usr/sbin/update-ca-certificates Updating certificates in /etc/ssl/certs... 0 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d... done. jlch@km:/usr/share/ca-certificates/xxnet$  好了，CA证书已经更新成功了。\n测试 jlch@km:~$ export http_proxy=http://192.168.31.10:8087 jlch@km:~$ curl -sSL https://dl.k8s.io/release/stable.txt jlch@km:~$ "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/how-to-install-certificates-for-command-line-2.html",
	"title": "命令行下如何安装或者更新 CA.crt 文件",
	"tags": ["ubuntu", "certificates"],
	"description": "",
	"content": "https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line\nenv 192.168.31.120\nstep 尝试直接 apt install\njlch@km:~$ sudo apt install ./CA.crt [sudo] password for jlch: Reading package lists... Done E: Unsupported file ./CA.crt given on commandline jlch@km:~$  不行，那尝试一下\njlch@km:~$ dpkg-query -L ca-certificates /. /etc /etc/ssl /etc/ssl/certs /etc/ca-certificates /etc/ca-certificates/update.d /usr /usr/sbin /usr/sbin/update-ca-certificates /usr/share /usr/share/ca-certificates /usr/share/ca-certificates/mozilla ... # 看到了好多 mozilla 的证书相关信息呀。 /usr/share/ca-certificates/mozilla/DigiCert_Global_Root_CA.crt /usr/share/doc /usr/share/doc/ca-certificates /usr/share/doc/ca-certificates/examples ... # 好多 examples /usr/share/doc/ca-certificates/examples/ca-certificates-local/README /usr/share/doc/ca-certificates/changelog.gz /usr/share/doc/ca-certificates/copyright /usr/share/doc/ca-certificates/README.Debian /usr/share/doc/ca-certificates/NEWS.Debian.gz /usr/share/man /usr/share/man/man8 /usr/share/man/man8/update-ca-certificates.8.gz jlch@km:~$  那查一下 update-ca-certificates\njlch@km:~$ which update-ca-certificates jlch@km:~$ sudo which update-ca-certificates [sudo] password for jlch: /usr/sbin/update-ca-certificates jlch@km:~$  好了, 根据 https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line 来更新吧\njlch@km:~$ cd /usr/sbin/update-ca-certificates jlch@km:/usr/share/ca-certificates/xxnet$ sudo cp /home/jlch/CA.crt . jlch@km:/usr/share/ca-certificates/xxnet$ sudo /usr/sbin/update-ca-certificates Updating certificates in /etc/ssl/certs... 0 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d... done. jlch@km:/usr/share/ca-certificates/xxnet$  好了，CA证书已经更新成功了。\n测试 jlch@km:~$ export http_proxy=http://192.168.31.10:8087 jlch@km:~$ curl -sSL https://dl.k8s.io/release/stable.txt jlch@km:~$ "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cloudnative/awesome-cloud-native.html",
	"title": "awesome cloud-native",
	"tags": ["kubernetes", "source", "cloud-native"],
	"description": "",
	"content": "https://jimmysong.io/awesome-cloud-native/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-readme.html",
	"title": "kubernetes cephfs README",
	"tags": ["kubernetes", "ceph", "cephfs", "readme"],
	"description": "",
	"content": "本次, k8s cephfs 结合, 前前后后, 花了差不多1个月的时间, 终于是有结果了.\n主要大过程是:\n安装 k8s.v1.7.3 flannel 网络 成功 安装 ceph 安装 cephfs 然后 k8s + cephfs make \u0026amp;\u0026amp; make push deployment.yaml 失败 docker 成功 test-pod 成功 检查 SUCCESS 失败 Input/Output Error 发现不对, 升级内核 升级 k8s.v1.7.3 至 k8s.v1.8.3 升级失败 科学上网 XX-net 失败 加速度 成功 全新安装 k8s.v1.8.4 remove kube* 成功 install kube* 成功 init 成功 apply -f kube-flannel.yml 然后 k8s + cephfs docker 成功, 关闭 重新设置 cni0 secret 成功 configmap.yaml 成功 deployment.yaml 成功 class.yaml 成功 claim.yaml 成功 test-pod.yaml 成功 检查 mount mount , ceph-client 失败 mount , kn1 成功 Game over!  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-flannel-ping-wrong.html",
	"title": "flannel网络模式下ping出错",
	"tags": ["kubernetes", "install", "faq", "flannel"],
	"description": "",
	"content": " Environment 所有节点都要安装 kubeadm, kubelet, kubectl\n安装时，全使用 root 用户。直到 kubeadm join 成功后，全使用 非root用户\n192.168.31.120 km master 192.168.31.119 kn1 node 192.168.31.118 kn2 node  问题 网络出了问题了，ping 不了 kn1, kn2 中的pod的IP\n解决 https://github.com/coreos/flannel/blob/476abd9ef37e7111a1268c41afbd7154046b492a/Documentation/troubleshooting.md#firewalls\nroot@km:~# k get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE default cephfs-provisioner-cff8d95c-6tgcs 1/1 Running 2 11d 10.244.1.90 kn1 default mysql-0 2/2 Running 2 22h 10.244.1.87 kn1 default mysql-1 2/2 Running 0 22h 10.244.2.243 kn2 default mysql-2 2/2 Running 2 22h 10.244.1.89 kn1 default nginx-665ff4c6f7-rgrz6 1/1 Running 1 1d 10.244.1.88 kn1 default nginx-665ff4c6f7-tmfft 1/1 Running 0 1d 10.244.2.240 kn2 kube-system etcd-km 1/1 Running 8 13d 192.168.31.120 km kube-system kube-apiserver-km 1/1 Running 4 13d 192.168.31.120 km kube-system kube-controller-manager-km 1/1 Running 4 13d 192.168.31.120 km kube-system kube-dns-545bc4bfd4-2p847 3/3 Running 391 13d 10.244.2.231 kn2 kube-system kube-flannel-ds-fz28b 1/1 Running 0 5h 192.168.31.120 km kube-system kube-flannel-ds-mfmvm 1/1 Running 0 5h 192.168.31.118 kn2 kube-system kube-flannel-ds-s5ps6 1/1 Running 1 5h 192.168.31.119 kn1 kube-system kube-proxy-hlbc5 1/1 Running 9 13d 192.168.31.118 kn2 kube-system kube-proxy-v24fg 1/1 Running 4 13d 192.168.31.120 km kube-system kube-proxy-wxjg8 1/1 Running 6 13d 192.168.31.119 kn1 kube-system kube-scheduler-km 1/1 Running 4 13d 192.168.31.120 km  通过查看 kn1 下的 /var/log/syslog\n可以知道是 flannel 的问题。\n从 下面这个地方知道\nhttps://github.com/coreos/flannel/blob/476abd9ef37e7111a1268c41afbd7154046b492a/Documentation/troubleshooting.md#firewalls\n要打开 UDP port 8472\n那就在 km, kn1, kn2, 三机子上\nufw allow 8472/udp  然后再检查，就ping成功了。\nroot@km:~# ping 10.244.2.231 PING 10.244.2.231 (10.244.2.231) 56(84) bytes of data. 64 bytes from 10.244.2.231: icmp_seq=1 ttl=63 time=0.463 ms 64 bytes from 10.244.2.231: icmp_seq=2 ttl=63 time=0.403 ms ^C --- 10.244.2.231 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.403/0.433/0.463/0.030 ms root@km:~# ping 10.244.1.90 PING 10.244.1.90 (10.244.1.90) 56(84) bytes of data. 64 bytes from 10.244.1.90: icmp_seq=1 ttl=63 time=0.435 ms 64 bytes from 10.244.1.90: icmp_seq=2 ttl=63 time=0.410 ms ^C --- 10.244.1.90 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.410/0.422/0.435/0.024 ms root@km:~#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-registry-ui.html",
	"title": "docker registry ui",
	"tags": ["docker", "registry", "registry-ui"],
	"description": "",
	"content": " http://blog.csdn.net/mideagroup/article/details/52052618\nenv 192.168.31.240\nhome/tom/hyper-docker-registry-web-config 下\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/shell/shell-replace-file-houzhui.html",
	"title": "shell批量替换文件扩展名",
	"tags": ["shell", "file-name"],
	"description": "",
	"content": " 早上本想将一些照片上传到相册中，但是由于所有照片的扩展名都是JPG而不是小写的jpg，因此造成了“格式不正确”而不能上传照片。此刻就产生了这样一个问题：使用shell脚本如何批量将所有文件的扩展名JPG都改成小写的jpg？\n既然要批量替换文件名，那么肯定得用一个for循环依次遍历指定目录下的每个文件。对于每个文件，假如该文件的名称为name.oldext，那么我们必须原始文件名中挖出name，再将它与新的文件扩展名newext拼接形成新的文件名name.newext。依照这样的思路，就诞生了下面的脚本：\n#!/bin/bash oldext=\u0026quot;JPG\u0026quot; newext=\u0026quot;jpg\u0026quot; dir=\u0026quot;/home/edsionte/mypic\u0026quot; cd $dir for file in $(ls $dir | grep .$oldext) do name=$(ls $file | cut -d. -f1) mv $file ${name}.$newext done  下面对针对这个程序作简单说明：\n1.变量oldext和newext分别指定旧的扩展名和新的扩展名。dir指定文件所在目录；\n2.“ls $dir | grep .$oldext”用来在指定目录dir中获取扩展名为旧扩展名的所有文件；\n3.在循环体内先利用cut命令将文件名中“.”之前的字符串剪切出来，并赋值给name变量；接着将当前的文件名重命名为新的文件名。\n通过这个脚本，所有照片的扩展名都成功修改。为了使这个脚本更具有通用型，我们可以增加几条read命令实现脚本和用户之间的交互。改进版的脚本如下：\n#!/bin/bash read -p \u0026quot;old extension:\u0026quot; oldext read -p \u0026quot;new extension:\u0026quot; newext read -p \u0026quot;The directory:\u0026quot; dir cd $dir for file in $(ls $dir | grep .$oldext) do name=$(ls $file | cut -d. -f1) mv $file ${name}.$newext echo \u0026quot;$name.$oldext ====\u0026gt; $name.$newext\u0026quot; done echo \u0026quot;all files has been modified.\u0026quot;  修改后的脚本可以批量修改任意扩展名。done。\nRef  https://note.youdao.com/web/#/file/recent/note/wcp1542961015800180/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-file-name-end-with-asterisk.html",
	"title": "Mac下为什么有的文件名后带一个*星号",
	"tags": ["mac", "file"],
	"description": "",
	"content": " Mac下为什么有的文件名后带一个*星号？ 这个*号仅仅是ls命令显示的，表示有可执行权限，实际文件名不带*号。\n$ ls -F  可执行文件名后就会加*号。\n显示一个或多个文件的相关信息。 ls [options] [file-list]\n参数 默认情况下，ls按照文件名的字母顺序列出文件的信息，file-list可以是任意文件或目录 当file-list包含多个目录时，ls将显示目录的名称，不显示子目录和子文件 当file-list为普通文件时，ls则显示该文件的相关信息\nRef  http://www.cnblogs.com/jackbo/p/7201885.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/org/org-visual-line-navigation.html",
	"title": "org-折行显示",
	"tags": [],
	"description": "",
	"content": "  M-x spacemacs/toggle-visual-line-navigation-on\n Ref  https://emacs-china.org/t/spacemacs-org/428  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/org/blogging-with-org-mode-and-ox-hugo.html",
	"title": "使用org-mode和ox-hugo写文档",
	"tags": ["easy-hugo", "org", "ox-hugo"],
	"description": "",
	"content": " Env  os: mac Emacs: 26.1 Spacemacs: 0.300.0 Org: 9.1.2 Hugo: v0.41 ox-hugo: 20181106.2350 prodigy: 20180511.938  Step Part 1: Blog Setup Download Hugo pacman -S hugo  Initialize Project hugo new site test-blog cd test-blog git init  Download a Theme (YMMV) This seems like a clean, simple theme.\nYou can use a submodule like this:\ngit submodule add https://github.com/goodroot/hugo-classic.git themes/hugo-classic  Or you can just clone it\nmkdir themes/ git clone git@github.com:goodroot/hugo-classic.git themes/hugo-classic  Copy the necessary files from the theme Warning: This will destroy your config.toml file, so, optionally back yours up.\ncp -r themes/hugo-classic/exampleSite/* .  Part 2: Emacs/Org-Mode/OX-Hugo integration Installing ox-hugo Add the following to your .emacs or ~/.emacs.d/init.el file.\n(use-package ox-hugo :ensure t :after ox)  Configuring Ox-hugo Create a new org-mode file to represent your blog. This file shouldlive in the root of the blog.\ntouch blog.org  Create your blog content in org-mode Here’s a starter template for the blog.org file:\n#+HUGO_BASE_DIR: . * Pages :PROPERTIES: :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true :nocomment true :nodate true :nopaging true :noread true :EXPORT_HUGO_MENU: :menu main # 把 .md文件显示在 menu 中. 所以这个一般情况注释掉 :EXPORT_HUGO_TITLE: hmm :EXPORT_HUGO_SECTION: pages # 把.md文件放在 content/pages/ 下 :EXPORT_HUGO_WEIGHT: auto :END: ** About Page :PROPERTIES: :EXPORT_FILE_NAME: about # 导出的.md 文件名为 about.md :END: This is my about page. * Posts :PROPERTIES: # :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true :nocomment true :nodate true :nopaging true :noread true :EXPORT_HUGO_MENU: :menu main :EXPORT_HUGO_SECTION: posts :EXPORT_HUGO_WEIGHT: auto :END: ** First Post :PROPERTIES: :EXPORT_FILE_NAME: some-file-name :EXPORT_DATE: \u0026lt;2018-03-19 Mon 22:08\u0026gt; # 导出的时间 :EXPORT_HUGO_DRAFT: true # 是否为draft :END:  Export your content to hugo with ox-hugo When editing the blog.org file, export it through org-export-dispatch:\nThis will export all the content from the blog.org file into the hugo project.\nC-c C-e H A  Sometimes you just want to export one post/page (aka subtree in org-mode terms):\nC-c C-e H H  Start the Server At this point, you\nhugo server -D  Extras MathJax If you’d like to have nice equation support, check this link: https://ox-hugo.scripter.co/doc/equations/\nHere’s an example of a LaTeX formatted equation: E=−J∑Ni=1sisi+1\nAdd this to the footer.html to get MathJax support:\n\u0026lt;script type=\u0026quot;text/x-mathjax-config\u0026quot;\u0026gt; MathJax.Hub.Config({ displayAlign: \u0026quot;center\u0026quot;, displayIndent: \u0026quot;0em\u0026quot;, \u0026quot;HTML-CSS\u0026quot;: { scale: 100, linebreaks: { automatic: \u0026quot;false\u0026quot; }, webFont: \u0026quot;TeX\u0026quot; }, SVG: {scale: 100, linebreaks: { automatic: \u0026quot;false\u0026quot; }, font: \u0026quot;TeX\u0026quot;}, NativeMML: {scale: 100}, TeX: { equationNumbers: {autoNumber: \u0026quot;AMS\u0026quot;}, MultLineWidth: \u0026quot;85%\u0026quot;, TagSide: \u0026quot;right\u0026quot;, TagIndent: \u0026quot;.8em\u0026quot; } }); \u0026lt;/script\u0026gt; \u0026lt;!-- https://gohugo.io/content-management/formats/#mathjax-with-hugo --\u0026gt; \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; --\u0026gt;  Ref  https://gohugo.io/tools/editors/#emacs https://www.shanesveller.com/blog/2018/02/13/blogging-with-org-mode-and-ox-hugo/ https://www.xianmin.org/post/ox-hugo/ https://lakedenman.com/blog/posts/bloggin-hugo-ox-hugo/ https://www.baty.net/2018/lets-try-using-ox-hugo-again/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-jane-add-baidu-tongji.html",
	"title": "jane主题中安装百度统计",
	"tags": ["hugo", "jane", "baidu"],
	"description": "",
	"content": " 获取百度统计代码 登陆百度统计/管理/自有网站/获取代码, 得到形如\n\u0026lt;script\u0026gt; var _hmt = _hmt || []; (function() { var hm = document.createElement(\u0026quot;script\u0026quot;); hm.src = \u0026quot;https://hm.baidu.com/hm.js?9dd8aaaaaaaaaaa7a8bde80b13fe8eaf\u0026quot;; var s = document.getElementsByTagName(\u0026quot;script\u0026quot;)[0]; s.parentNode.insertBefore(hm, s); })(); \u0026lt;/script\u0026gt;  我们要的就是 \u0026ldquo;https://hm.baidu.com/hm.js?9dd8aaaaaaaaaaa7a8bde80b13fe8eaf\u0026rdquo; 中的 9dd8aaaaaaaaaaa7a8bde80b13fe8eaf\n放入config.toml 文件中 [params] baidu_push = false # baidu push # 百度 baidu_analytics = \u0026quot;9dd8aaaaaaaaaaa7a8bde80b13fe8eaf\u0026quot; # Baidu Analytics baidu_verification = \u0026quot;\u0026quot; # Baidu Verification  代码安装检查 登陆百度统计/管理/自有网站/代码检查, 得到形如：\n 页面代码安装状态：代码安装正确  表示已经加入了百度统计。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-wemux.html",
	"title": "wemux (笔记)",
	"tags": ["tmux", "wemux"],
	"description": "",
	"content": "https://github.com/zolrath/wemux\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-remove-images-multy.html",
	"title": "批量删除docker images",
	"tags": ["docker", "images"],
	"description": "",
	"content": " docker ps -a | grep \u0026quot;Exited\u0026quot; | awk '{print $1 }'|xargs docker stop docker ps -a | grep \u0026quot;Exited\u0026quot; | awk '{print $1 }'|xargs docker rm docker images|grep none|awk '{print $3 }'|xargs docker rmi  Ref  https://blog.csdn.net/p656456564545/article/details/50097145  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-get-os-lsb-release.html",
	"title": "ubuntu 获取 系统版本信息",
	"tags": ["linux"],
	"description": "",
	"content": "(oscar) ➜ proxy-os git:(master) ✗ lsb_release --help Usage: lsb_release [options] Options: -h, --help show this help message and exit -v, --version show LSB modules this system supports -i, --id show distributor ID -d, --description show description of this distribution -r, --release show release number of this distribution -c, --codename show code name of this distribution -a, --all show all of the above information -s, --short show requested information in short format (oscar) ➜ proxy-os git:(master) ✗ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 16.04.5 LTS Release: 16.04 Codename: xenial (oscar) ➜ proxy-os git:(master) ✗ lsb_release -s -c xenial (oscar) ➜ proxy-os git:(master) ✗  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-hard-links-soft-links.html",
	"title": "mac 系统中文件的软链接、硬链接",
	"tags": ["mac", "links"],
	"description": "",
	"content": " 最近有这么个需求，由于我在多台设备上使用 Surge ，因此我想把 Surge 的配置文件使用 Dropbox 进行同步，但是 Dropbox 的路径在 ~/User/slark/Dropbox/surge.conf 下，而 Surge 的配置文件位于 ~/.surge.conf，每次修改 .surge.conf 后，我都会手动把文件另存到 Dropbox 中，比较麻烦。\n开始想用一款本地文件同步工具来满足这个需求，比如 GoodSync，这个工具也确实能满足需求，但是就这么小的需求也要用软件来实现？经过 Google 后，发现可以通过创建文件的 硬链接 来完美满足这个需求。\n文件的 软链接 和 硬链接 在 Unix 系统中，可以对文件创建 硬链接 和 软链接。简单来说，链接就是可以指向文件系统中其他位置的一个快捷方式，比如 Windows 系统下的快捷方式。那么，硬链接和软链接有什么区别呢？\n硬链接 硬链接是一个目录条目，它指具有同一个 i-node（硬盘上的物理位置）的另一个文件，事实上只存在一个文件，比如我对 Dropbox 中的 surge.conf 文件创建一个硬链接：\n格式：ln [原文件] [硬链接文件] ln ~/Dropbox/surge.conf ~/.surge.conf  原文件和硬链接的详细信息对比：\n硬链接有这么几个特点：\n 文件的所有的硬链接指向的是同一个文件，硬盘中只实际只存储一份文件； 所有硬链接与原文件的大小，修改时间，权限都相同；  因为是硬链接，所以 ~/Dropbox/surge.conf 和 ~/.surge.conf 指向的是同一个文件，删除任何一个链接都不会真正的删除文件。\n可以这么理解，在 Unix 系统下，任何文件的实际路径都是一个硬链接，该文件的硬链接数为 1，每创建一个硬链接后，硬链接数 +1，删除一个硬链接，硬链接数 -1，硬链接数为 0 时这个文件实际就被删除了。好比程序中的指针，实际的对象只有一份，指向这个对象的指针却有多个，删除任何一个指针并不会删除这个对象，只有把最后一个指针删掉，这个对象才算是删除掉了。\n软链接 软链接则和 windows 中的快捷方式类似，是一个独立的文件，其中包含了指向一个位置的指针，使用如下命令可以创建一个软链接：\n格式：ln -s [原文件] [软链接文件] ln -s .surge.conf mac_surge.conf  原文件和软链接的详细信息对比：\n因为是软链接，删除原文件，所有的软链接都会失效，修改软链接并不会影响原文件，仅仅修改的是该软链接指向的位置而已。\n关于文件链接使用的选择 基于上面的介绍，我的需求就只有硬链接可以满足了，修改一处，每处都会发生变化。硬链接用于原始文件和目标文件位于当前同一个文件系统。好处是能提供真实文件的有关信息，在原始文件被删除或移动时，也不会成为空链接。但是，如果需要连接目录或位于另一个文件系统的文件时，就必须采用软链接。\nRef  https://slarker.me/mac-file-link/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-faq.html",
	"title": "ceph安装FAQ",
	"tags": ["ceph", "faq"],
	"description": "",
	"content": " Q1 ceph-deploy install ceph-admin ceph-osd1 ceph-osd2 mon1 ... [ceph-osd1][DEBUG ] Get:40 https://download.ceph.com/debian-jewel xenial/main amd64 python-rbd amd64 10.2.10-1xenial [1,449 kB] [ceph-osd1][DEBUG ] Get:41 https://download.ceph.com/debian-jewel xenial/main amd64 ceph-common amd64 10.2.10-1xenial [15.5 MB] [ceph-osd1][DEBUG ] Get:42 https://download.ceph.com/debian-jewel xenial/main amd64 ceph-base amd64 10.2.10-1xenial [50.5 MB] [ceph-osd1][WARNIN] No data was received after 300 seconds, disconnecting... [ceph-osd1][INFO ] Running command: sudo ceph --version [ceph-osd1][ERROR ] Traceback (most recent call last): [ceph-osd1][ERROR ] File \u0026quot;/usr/lib/python2.7/dist-packages/ceph_deploy/lib/vendor/remoto/process.py\u0026quot;, line 119, in run [ceph-osd1][ERROR ] reporting(conn, result, timeout) [ceph-osd1][ERROR ] File \u0026quot;/usr/lib/python2.7/dist-packages/ceph_deploy/lib/vendor/remoto/log.py\u0026quot;, line 13, in reporting [ceph-osd1][ERROR ] received = result.receive(timeout) [ceph-osd1][ERROR ] File \u0026quot;/usr/lib/python2.7/dist-packages/ceph_deploy/lib/vendor/remoto/lib/vendor/execnet/gateway_base.py\u0026quot;, line 704, in receive [ceph-osd1][ERROR ] raise self._getremoteerror() or EOFError() [ceph-osd1][ERROR ] RemoteError: Traceback (most recent call last): [ceph-osd1][ERROR ] File \u0026quot;\u0026lt;string\u0026gt;\u0026quot;, line 1036, in executetask [ceph-osd1][ERROR ] File \u0026quot;\u0026lt;remote exec\u0026gt;\u0026quot;, line 12, in _remote_run [ceph-osd1][ERROR ] File \u0026quot;/usr/lib/python2.7/subprocess.py\u0026quot;, line 711, in __init__ [ceph-osd1][ERROR ] errread, errwrite) [ceph-osd1][ERROR ] File \u0026quot;/usr/lib/python2.7/subprocess.py\u0026quot;, line 1343, in _execute_child [ceph-osd1][ERROR ] raise child_exception [ceph-osd1][ERROR ] OSError: [Errno 2] No such file or directory [ceph-osd1][ERROR ] [ceph-osd1][ERROR ] [ceph_deploy][ERROR ] RuntimeError: Failed to execute command: ceph --version cephuser@cephfs5:~/my-cluster$  https://blog.54im.com/2016/12/15/centos-install-ceph-doc/ 超时问题\nQ2 https://serverfault.com/questions/659308/unable-to-add-initial-monitor-to-ceph-in-ubuntu\n[global] fsid = 33cb5c76-a685-469e-8cdd-fee7c98c3f4d mon_initial_members = ceph1,ceph2 mon_host = 192.168.61.39,192.168.61.40 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx filestore_xattr_use_omap = true public_network = 192.168.61.0/24 And the running the command: $ ceph-deploy --overwrite-conf mon create \u0026lt;ceph-node\u0026gt;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-auth.html",
	"title": "ceph auth",
	"tags": ["ceph", "cephfs", "auth"],
	"description": "",
	"content": "cephu@cephadmin:~/my-cluster$ ceph auth ls installed auth entries: mds.node1 key: AQADpu5ZJgEAAhAA6Om+UrlNn3s4v728UGIuTQ== caps: [mds] allow caps: [mon] allow profile mds caps: [osd] allow rwx osd.0 key: AQCAou5ZbAFBCRAANHUYj3trYJm+bbpzM68Czw== caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.1 key: AQCNou5Z0AEiChAAoXaQS1KsqnygVzIdK4LeBQ== caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.2 key: AQCaou5ZckceFxAArxSTMrgL94Pe9wGqhT2tGA== caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * client.admin key: AQCtj+5ZnNTvGRAA2RxAGcIQZJnaJSPEz4jdGw== caps: [mds] allow * caps: [mgr] allow * caps: [mon] allow * caps: [osd] allow * client.bootstrap-mds key: AQCuj+5ZL4meKBAAQ/AJ/63mw4XD3HIcx1+ojw== caps: [mon] allow profile bootstrap-mds client.bootstrap-mgr key: AQDYne5Zf3L3BxAAt/PZfcXS1b0ioDrgZX8v8w== caps: [mon] allow profile bootstrap-mgr client.bootstrap-osd key: AQCtj+5ZEe+yMhAAX8vyaP2g7cBznN5dk48mBQ== caps: [mon] allow profile bootstrap-osd client.bootstrap-rbd key: AQCvj+5Zpj97BRAAeBH22SI5YQ8+iI4+V+Kopg== caps: [mon] allow profile bootstrap-rbd client.bootstrap-rgw key: AQCuj+5ZRqQKEBAABXu387mLGQGPwkvcVBhPyg== caps: [mon] allow profile bootstrap-rgw client.kubernetes-dynamic-user-02edf53a-bec3-11e7-bda7-000c299a346f key: AQBTV/lZenwMKhAAFI7qG14jcFj6kScyg65DsQ== caps: [mds] allow r caps: [mon] allow r caps: [osd] client.kubernetes-dynamic-user-34d65a6c-bed2-11e7-bda7-000c299a346f key: AQDRcPlZ9MBSNBAAsDbLR8rEWslQmq9fhcsZrw== caps: [mds] allow r,allow rw path=/volumes/kubernetes/kubernetes-dynamic-pvc-34d659ff-bed2-11e7-bda7-000c299a346f caps: [mon] allow r caps: [osd] allow rw pool=cephfs_data namespace=fsvolumens_kubernetes-dynamic-pvc-34d659ff-bed2-11e7-bda7-000c299a346f client.kubernetes-dynamic-user-34fb64a9-be15-11e7-8636-000c299a346f key: AQC7M/hZxmS/DhAAZR/ybQ7WSBEvmF3ZYMarRw== caps: [mds] allow r caps: [mon] allow r caps: [osd] client.kubernetes-dynamic-user-612fd2ba-be13-11e7-8636-000c299a346f key: AQCqMPhZ0fWTFxAAN5nMfYyNHjMqVamVjmQsCA== caps: [mds] allow r caps: [mon] allow r caps: [osd] client.rgw.ceph-client key: AQDoM/BZiyLcHBAASXop8G7HJPJQfVYDrA5BkQ== caps: [mon] allow rw caps: [osd] allow rwx client.rgw.node1 key: AQCGr+5ZQDQRLRAAw9WB8JbSUSeUkJ7k7+cCAg== caps: [mon] allow rw caps: [osd] allow rwx mgr.mon1 key: AQDvne5ZbU0JOhAAotdp7L9xiVaL54awr26lcA== caps: [mds] allow * caps: [mon] allow profile mgr caps: [osd] allow * mgr.node2 key: AQBhqO5ZEy2gMxAAfG496CAtCeVdApXfffwf+Q== caps: [mds] allow * caps: [mon] allow profile mgr caps: [osd] allow * mgr.node3 key: AQBjqO5ZM0l9HBAALhWmqYNbpOFUvPfHv4aOug== caps: [mds] allow * caps: [mon] allow profile mgr caps: [osd] allow * cephu@cephadmin:~/my-cluster$ ceph auth get client.kubernetes-dynamic-user-02edf53a-bec3-11e7-bda7-000c299a346f exported keyring for client.kubernetes-dynamic-user-02edf53a-bec3-11e7-bda7-000c299a346f [client.kubernetes-dynamic-user-02edf53a-bec3-11e7-bda7-000c299a346f] key = AQBTV/lZenwMKhAAFI7qG14jcFj6kScyg65DsQ== caps mds = \u0026quot;allow r\u0026quot; caps mon = \u0026quot;allow r\u0026quot; caps osd = \u0026quot;\u0026quot; cephu@cephadmin:~/my-cluster$ ceph auth ls | grep kubernetes-dynamic-pvc-34d659ff-bed2-11e7-bda7-000c299a346f installed auth entries: caps: [mds] allow r,allow rw path=/volumes/kubernetes/kubernetes-dynamic-pvc-34d659ff-bed2-11e7-bda7-000c299a346f caps: [osd] allow rw pool=cephfs_data namespace=fsvolumens_kubernetes-dynamic-pvc-34d659ff-bed2-11e7-bda7-000c299a346f cephu@cephadmin:~/my-cluster$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-quick-start-preflight.html",
	"title": "ceph-install-base-ubuntu quick-start-preflight",
	"tags": ["ceph", "install"],
	"description": "",
	"content": " 这里的配置注意点如下：\nceph-admin 节点： 安装时， with a stable Ceph release (e.g., luminous.) ，安装 luminous 或以上版本。\ncephu@cephadmin:~/my-cluster$ sudo cat /etc/apt/sources.list.d/ceph.list deb https://download.ceph.com/debian-luminous/ xenial main cephu@cephadmin:~/my-cluster$  配置 ~/.ssh/config 方便后续安装\ncephu@cephadmin:~/my-cluster$ cat ~/.ssh/config Host node0 Hostname cephadmin User cephu Host node1 Hostname mon1 User cephu Host node2 Hostname cephfsn2 User cephu Host node3 Hostname cephfsn3 User cephu cephu@cephadmin:~/my-cluster$  这里，我后来想了一下，应该把这个地方，修改成 全用 node0, node1, node2, node3, 然后，各节点的　Hostname 也修改成这些，这样子才是真的方便安装。如下：\ncephu@cephadmin:~/my-cluster$ cat ~/.ssh/config Host node0 Hostname node0 User cephu Host node1 Hostname node1 User cephu Host node2 Hostname node2 User cephu Host node3 Hostname node3 User cephu cephu@cephadmin:~/my-cluster$  存储节点： cephu@cephadmin:~/my-cluster$ cat /etc/hosts 127.0.0.1 localhost 127.0.1.1 ubuntu #127.0.0.1 cephfs5 # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters 192.168.31.115 cephadmin 192.168.31.114 mon1 192.168.31.113 cephfsn2 192.168.31.173 cephfsn3  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-stateful.html",
	"title": "使用 cephfs 完成 statefulset 的练习",
	"tags": ["kubernetes", "ceph", "cephfs", "statefulset"],
	"description": "",
	"content": " 环境 k8s-master 192.168.31.120 km master k8s-node1 192.168.31.119 kn1 node1 k8s-node2 192.168.31.118 kn2 node2 cephfs-admin 192.168.31.115 cephfs-monitor 192.168.31.114 cephfs-client 192.168.31.172  各 k8s-node 安装完 ceph-common(sudo apt install ceph-common -y)\n准备 在进行操作前，请完成下面的操作：\n1）阅读\nhttp://www.cnblogs.com/iiiiher/p/7159810.html\nhttps://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client\n注意：\nhttps://github.com/kubernetes-incubator/external-storage 这个仓库，是官方提供之外的 External storage plugins, provisioners, and helper libraries ，因为我们在官方文档 中看到了 nfs 是不支持 provisioners 的，所以要来这里了哟\u0026gt;。\n2）git clone\n git clone https://github.com/kubernetes-incubator/external-storage\ncd external-storage/nfs-client/deploy/\n 3）按步骤来进行。\n现在打开 https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/cephfs\n开始动手了\nstep Compile the provisioner 见 cephfs-k8s-make-by-go-get.rst\n这个地方，请参看 http://blogtt.readthedocs.io/en/latest/k8s/cephfs/cephfs-k8s-make-by-go-get.html\nMake the container image and push to the registry 这个地方，看公司情况。主要是 把 docker image 放到仓库去，然后让 k8s各个节点机，docker pull 这个make 后的 image.\nStart Kubernetes local cluster 略\n配置 configmap 这个小步骤，https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/cephfs 并没有写。但是确实是要走的。\njlch@km:~/cephfs$ ls cephfs_provisioner cephfs-provisioner.go ceph-secret-admin.yaml CHANGELOG.md claim.yaml class.yaml configmap.yaml deployment.yaml Dockerfile local-start.sh Makefile OWNERS README.md test-pod.yaml jlch@km:~/cephfs$ k apply -f configmap.yaml jlch@km:~/cephfs$ k get cm NAME DATA AGE cephfs-provisioner 1 23h jlch@km:~/cephfs$  Create a Ceph admin secret 在 cephfs-admin 下\nceph auth get client.admin 2\u0026gt;\u0026amp;1 |grep \u0026quot;key = \u0026quot; |awk '{print $3'} |xargs echo -n \u0026gt; /tmp/secret  把这个/tmp/secret 弄到 k8s-master 的 /tmp/secret\n在 k8s-master 下\nkubectl create secret generic ceph-secret-admin --from-file=/tmp/secret --namespace=kube-system  Start CephFS provisioner 方法1 deployment.yaml 此方法的具体细节见 cephfs-k8s-deployment-faq.rst\nkubectl create -f deployment.yaml  方法2 docker docker run -ti -v /root/.kube:/kube -v /var/run/kubernetes:/var/run/kubernetes --privileged --net=host cephfs-provisioner /usr/local/bin/cephfs-provisioner -master=http://127.0.0.1:8080 -kubeconfig=/kube/config -id=cephfs-provisioner-1  这个官方的配置肯定与我们的实际不同，修改一下配置哟。\n kube配置文件  因为我们的机器是 /root/admin.conf 了哈, 所以直接修改名字成 config\nroot@km:~# cat k8.export.sh sudo cp /etc/kubernetes/admin.conf $HOME/ sudo chown $(id -u):$(id -g) $HOME/admin.conf export KUBECONFIG=$HOME/admin.conf root@km:~# cp admin.conf config root@km:~#   image  我们 make 后的 image 是 quay.io/external_storage/cephfs-provisioner:latest\n ceph参数 -master  看一下service\nroot@km:~/cephfs# k get svc --all-namespaces | grep default | grep kubernetes default kubernetes 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 71d root@km:~/cephfs#  所以我们这里是 -master=https://10.96.0.1/ 或者 -master=https://10.96.0.1:443/\n综合一下，我们的操作应该是：\nroot@km:~# docker run -ti -v /root/:/kube -v /var/run/kubernetes:/var/run/kubernetes --privileged --net=host quay.io/external_storage/cephfs-provisioner /usr/local/bin/cephfs-provisioner -master=https://10.96.0.1/ -kubeconfig=/kube/config -id=cephfs-provisioner-1  好了，基于 docker 方式的 pv 应该是跑起来了。\n方法1 deployment.yaml 与 方法2 docker 的对应关系 方法2 docker\ndocker run -ti -v /home/jlch:/kube -v /var/run/kubernetes:/var/run/kubernetes --privileged --net=host quay.io/external_storage/cephfs-provisioner /usr/local/bin/cephfs-provisioner -master=https://10.96.0.1/ -kubeconfig=/kube/admin.conf -id=cephfs-provisioner-1  对应于 方法1 deployment.yaml\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: cephfs-provisioner spec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: cephfs-provisioner spec: containers: - name: cephfs-provisioner image: \u0026quot;quay.io/external_storage/cephfs-provisioner:latest\u0026quot; # 对应 镜像 imagePullPolicy: IfNotPresent env: - name: PROVISIONER_NAME valueFrom: configMapKeyRef: key: provisioner.name name: cephfs-provisioner command: # 这里对应 命令 - \u0026quot;/usr/local/bin/cephfs-provisioner\u0026quot; args: # 这里对应三个参数 - \u0026quot;-id=cephfs-provisioner-1\u0026quot; - \u0026quot;-master=https://10.96.0.1/\u0026quot; - \u0026quot;-kubeconfig=/kube/admin.conf\u0026quot; volumeMounts: # 对应 -v - mountPath: /kube name: kube-config - mountPath: /var/run/kubernetes name: kube-run-env volumes: - name: kube-config hostPath: # directory location on host path: /home/jlch # this field is optional type: Directory - name: kube-run-env hostPath: # directory location on host path: /var/run/kubernetes # this field is optional type: Directory  Create a CephFS Storage Class Replace Ceph monitor\u0026rsquo;s IP in class.yaml with your own and create storage class:\nkubectl create -f class.yaml  Create a claim kubectl create -f claim.yaml  Create a Pod using the claim kubectl create -f test-pod.yaml  因为我之前安装过 flannel 的缘故，所以部署在 kn2 上的时候，报出 Failed create pod sandbox. 错误来了。\njlch@km:~/cephfs$ k describe pod test-pod Name: test-pod Namespace: default Node: kn2/192.168.31.118 Start Time: Fri, 24 Nov 2017 11:29:18 +0800 Labels: \u0026lt;none\u0026gt; Annotations: kubectl.kubernetes.io/last-applied-configuration={\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Pod\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;test-pod\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;containers\u0026quot;:[{\u0026quot;args\u0026quot;:[\u0026quot;-c\u0026quot;,\u0026quot;touch /mnt/S... Status: Pending IP: Containers: test-pod: Container ID: Image: gcr.io/google_containers/busybox:v1.1.1 Image ID: Port: \u0026lt;none\u0026gt; Command: /bin/sh Args: -c touch /mnt/SUCCESS \u0026amp;\u0026amp; exit 0 || exit 1 State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /mnt from pvc (rw) /var/run/secrets/kubernetes.io/serviceaccount from default-token-np6qz (ro) Conditions: Type Status Initialized True Ready False PodScheduled True Volumes: pvc: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: claim1 ReadOnly: false default-token-np6qz: Type: Secret (a volume populated by a Secret) SecretName: default-token-np6qz Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.alpha.kubernetes.io/notReady:NoExecute for 300s node.alpha.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 39s default-scheduler Successfully assigned test-pod to kn2 Normal SuccessfulMountVolume 39s kubelet, kn2 MountVolume.SetUp succeeded for volume \u0026quot;default-token-np6qz\u0026quot; Normal SuccessfulMountVolume 38s kubelet, kn2 MountVolume.SetUp succeeded for volume \u0026quot;pvc-a2bdd1d1-d0c7-11e7-85d4-000c299a346f\u0026quot; Warning FailedCreatePodSandBox 31s (x8 over 38s) kubelet, kn2 Failed create pod sandbox. Warning FailedSync 31s (x8 over 38s) kubelet, kn2 Error syncing pod Normal SandboxChanged 31s (x7 over 38s) kubelet, kn2 Pod sandbox changed, it will be killed and re-created. jlch@km:~/cephfs$  这里同样地，参考一下 cephfs-k8s-deployment-faq.rst 就可以了。\n查看一下pod\njlch@km:~/cephfs$ k get pod NAME READY STATUS RESTARTS AGE cephfs-provisioner-cff8d95c-6tgcs 1/1 Running 1 22m jlch@km:~/cephfs$  我的pod 去哪里了？？？ 噢。因为我的 pod 是一次性的任务，它直接Completed了。所以要 带 -a 参数。\njlch@km:~/cephfs$ k get pod -a NAME READY STATUS RESTARTS AGE cephfs-provisioner-cff8d95c-6tgcs 1/1 Running 1 23m test-pod 0/1 Completed 0 2m jlch@km:~/cephfs$  好了，确实是pod执行完了。\n确认 cephfs 数据 那怎么看我的效果呢？\ncephfs-client （内核版本4.4）验证 cephu@ceph-client:~/mycephfs$ sudo mount -t ceph 192.168.31.114:6789:/ /mnt/mycephfs -o name=admin,secretfile=admin.secret unable to read secretfile: No such file or directory error reading secret file failed to parse ceph_options cephu@ceph-client:~/mycephfs$ cd # 这个目录不对，没有 admin.secret 文件 cephu@ceph-client:~$ ls admin.secret mycephfs release.asc cephu@ceph-client:~$ cat admin.secret # 看到了吧，这个密码，就是 cephfs 的密码呀。重要 AQCtj+****************IQZJnaJSPEz4jdGw== cephu@ceph-client:~$ cephu@ceph-client:~$ sudo mount -t ceph 192.168.31.114:6789:/ /mnt/mycephfs -o name=admin,secretfile=admin.secret # mount 成功 cephu@ceph-client:~$ ls /mnt/mycephfs/ a.txt b.txt c.txt h.txt volumes cephu@ceph-client:~$ cd /mnt/mycephfs/ cephu@ceph-client:/mnt/mycephfs$ ls a.txt b.txt c.txt h.txt volumes cephu@ceph-client:/mnt/mycephfs$ cd volumes/ cephu@ceph-client:/mnt/mycephfs/volumes$ ls _deleting k8s kubernetes _kubernetes:kubernetes-dynamic-pvc-5467e02a-c132-11e7-bda7-000c299a346f.meta _kubernetes:kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148.meta cephu@ceph-client:/mnt/mycephfs/volumes$ cd kubernetes/ cephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$ ls haha hahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa hahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb kubernetes-dynamic-pvc-5467e02a-c132-11e7-bda7-000c299a346f kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148 cephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$ ll total 0 drwxr-xr-x 1 root root 0 Nov 24 11:29 ./ drwxr-xr-x 1 root root 0 Nov 24 11:29 ../ drwxr-xr-x 1 root root 0 Nov 1 14:35 haha/ drwxr-xr-x 1 root root 0 Nov 1 14:36 hahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/ drwxr-xr-x 1 root root 0 Nov 1 14:38 hahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb/ drwxr-xr-x 1 root root 0 Nov 4 15:37 kubernetes-dynamic-pvc-5467e02a-c132-11e7-bda7-000c299a346f/ drwxr-xr-x 1 root root 0 Nov 24 11:36 kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/ # 哈哈，从时间上看，这个就是我们要的文件夹。 cephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$ ll kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/ ls: reading directory 'kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/': Input/output error # what? 又是这个问题。升级内核去吧。我们这里不升级了哈。见 cephfs-k8s-faq.rst total 0 drwxr-xr-x 1 root root 0 Nov 24 11:36 ./ drwxr-xr-x 1 root root 0 Nov 24 11:29 ../ cephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$ cd  好了，这里没用，换一个内核版本 4.10.0 以上的机器来吧。先umount 吧。\ncephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$ cd cephu@ceph-client:~$ umount /mnt/mycephfs/ cephu@ceph-client:~$ ls /mnt/mycephfs/ cephu@ceph-client:~$ mount sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime) proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) udev on /dev type devtmpfs (rw,nosuid,relatime,size=4067060k,nr_inodes=1016765,mode=755) devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000) tmpfs on /run type tmpfs (rw,nosuid,noexec,relatime,size=817444k,mode=755) /dev/mapper/ubuntu--vg-root on / type ext4 (rw,relatime,errors=remount-ro,data=ordered) securityfs on /sys/kernel/security type securityfs (rw,nosuid,nodev,noexec,relatime) tmpfs on /dev/shm type tmpfs (rw,nosuid,nodev) tmpfs on /run/lock type tmpfs (rw,nosuid,nodev,noexec,relatime,size=5120k) tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755) cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd) pstore on /sys/fs/pstore type pstore (rw,nosuid,nodev,noexec,relatime) cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer) cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory) cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb) cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event) cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio) cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices) cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct) cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio) cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids) cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset) systemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=32,pgrp=1,timeout=0,minproto=5,maxproto=5,direct) hugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime) debugfs on /sys/kernel/debug type debugfs (rw,relatime) mqueue on /dev/mqueue type mqueue (rw,relatime) fusectl on /sys/fs/fuse/connections type fusectl (rw,relatime) /dev/sda1 on /boot type ext2 (rw,relatime,block_validity,barrier,user_xattr,acl) lxcfs on /var/lib/lxcfs type fuse.lxcfs (rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other) /dev/mapper/ubuntu--vg-root on /var/lib/docker/aufs type ext4 (rw,relatime,errors=remount-ro,data=ordered) none on /var/lib/docker/aufs/mnt/3ebf0690df4cb6798be2be8c6bee8a77eacfa7e89c42acacc2a97ea2bc3af09a type aufs (rw,relatime,si=781e745ed7325e3c,dio,dirperm1) nsfs on /run/docker/netns/default type nsfs (rw) shm on /var/lib/docker/containers/9e4d9c65734a4e566b4303071ec85f0ea1a18efb2f077e51d09d8457039b725d/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k) none on /var/lib/docker/aufs/mnt/1a10a53a1baa1de36489cc6f35562790a3659b0dfa08331ee3521d5b89f4f848 type aufs (rw,relatime,si=781e745c1d80ee3c,dio,dirperm1) shm on /var/lib/docker/containers/9ceeadb3b8184a36d946bd1aeb98a50a0682b75de141c2195373faa3786bbe66/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k) tmpfs on /run/user/113 type tmpfs (rw,nosuid,nodev,relatime,size=817444k,mode=700,uid=113,gid=120) tmpfs on /run/user/1003 type tmpfs (rw,nosuid,nodev,relatime,size=817444k,mode=700,uid=1003,gid=1003) tmpfs on /run/user/1000 type tmpfs (rw,nosuid,nodev,relatime,size=817444k,mode=700,uid=1000,gid=1000) cephu@ceph-client:~$ ls /mnt/mycephfs/ cephu@ceph-client:~$  可以了。\nkn1 （内核版本4.12.0）验证 查内核版本\njlch@kn1:~$ uname -a Linux kn1 4.12.0-041200-generic #201707022031 SMP Mon Jul 3 00:32:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux jlch@kn1:~$  查一下mount下已有的ceph\njlch@kn1:~$ mount | grep ceph jlch@kn1:~$  把密码文件admin.secret搞过来\njlch@kn1:~$ ls 10-kubeadm.conf apt.conf etc.kubernetes hpa-example.sh k3-dockerlibraryk8s.sh linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb nginx-dockerlibraryk8s.sh redis.sh admin.conf busybox-dockerlibraryk8s.sh hello-frontend.sh image k8 liveness-dockerlibraryk8s.sh node-hello.sh registry.crt admin.secret docker hello-go-gke.sh job-wq-2 k8.export.sh mydockersimages.tar proxy.sh xtrabackup-dockerlibraryk8s.sh  mount\njlch@kn1:~$ sudo mount -t ceph 192.168.31.114:6789:/ /mnt/mycephfs -o name=admin,secretfile=admin.secret jlch@kn1:~$ mount | grep ceph 192.168.31.114:6789:/ on /mnt/mycephfs type ceph (rw,relatime,name=admin,secret=\u0026lt;hidden\u0026gt;,acl) jlch@kn1:~$  成功了，查一下文件\njlch@kn1:~$ ls /mnt/mycephfs/ a.txt b.txt c.txt h.txt volumes/ jlch@kn1:~$ cd /mnt/mycephfs/volumes/ jlch@kn1:/mnt/mycephfs/volumes$ ls _deleting k8s kubernetes _kubernetes:kubernetes-dynamic-pvc-5467e02a-c132-11e7-bda7-000c299a346f.meta _kubernetes:kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148.meta jlch@kn1:/mnt/mycephfs/volumes$ cd kubernetes/ jlch@kn1:/mnt/mycephfs/volumes/kubernetes$ ll total 0 drwxr-xr-x 1 root root 5 Nov 24 11:29 ./ drwxr-xr-x 1 root root 5 Nov 24 11:29 ../ drwxr-xr-x 1 root root 0 Nov 1 14:35 haha/ drwxr-xr-x 1 root root 0 Nov 1 14:36 hahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/ drwxr-xr-x 1 root root 0 Nov 1 14:38 hahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb/ drwxr-xr-x 1 root root 1 Nov 4 15:37 kubernetes-dynamic-pvc-5467e02a-c132-11e7-bda7-000c299a346f/ drwxr-xr-x 1 root root 1 Nov 24 11:36 kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/ # 哈哈，从时间上看，这个就是我们要的文件夹。 jlch@kn1:/mnt/mycephfs/volumes/kubernetes$ cd kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/ jlch@kn1:/mnt/mycephfs/volumes/kubernetes/kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148$ ls SUCCESS jlch@kn1:/mnt/mycephfs/volumes/kubernetes/kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148$  哈哈，找到了之前由 test-pod 创建的文件 SUCCESS。\n到此，https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/cephfs 的几个步骤已全走完了。\ngame over!\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-registry-push-pull.html",
	"title": "docker-registry-push-pull",
	"tags": ["docker", "registry"],
	"description": "",
	"content": "请查看\nhttps://gitee.com/tomt/tom%5Fdocker%5Fregistry%5Fpush%5Fpull.git\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-init-before-v1_8_3.html",
	"title": "运行 kubeadm init 之前",
	"tags": ["kubernetes", "install", "before"],
	"description": "",
	"content": " 在运行 kubeadm init 之前的动作\nkubelet 服务检查 后来发现，在这里应该测试一下 kubelet.service。\n原来，虽然我 apt install kubelet , 但是， 遗留了之前 kubeadm 的一些配置.(应该把它们清空的.) 如: /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n让我们来吧。\n删除这个新安装的 kubelet root@km:/etc/cni/net.d# root@km:/etc/cni/net.d# apt remove kubelet Reading package lists... Done Building dependency tree Reading state information... Done The following packages were automatically installed and are no longer required: ebtables golang-1.8-go golang-1.8-race-detector-runtime golang-1.8-src kubernetes-cni socat Use 'apt autoremove' to remove them. The following packages will be REMOVED: kubeadm kubelet 0 upgraded, 0 newly installed, 2 to remove and 11 not upgraded. After this operation, 274 MB disk space will be freed. Do you want to continue? [Y/n] y (Reading database ... 113087 files and directories currently installed.) Removing kubeadm (1.8.3-00) ... Removing kubelet (1.8.3-00) ... root@km:/etc/cni/net.d# root@km: ~# cd /lib/systemd/system root@km:/lib/systemd/system# ls kube* ls: cannot access 'kube*': No such file or directory root@km:/lib/systemd/system#  删除原 conf 文件 删除从 /lib/systemd/system/kubelet.service 下看到的这个 conf 文件\nroot@km:/opt/cni/bin# cd /etc/systemd/system/kubelet.service.d/ root@km:/etc/systemd/system/kubelet.service.d# ls 10-kubeadm.conf root@km:/etc/systemd/system/kubelet.service.d# rm 10-kubeadm.conf root@km:/etc/systemd/system/kubelet.service.d# cd .. root@km:/etc/systemd/system# rmdir kubelet.service.d/ root@km:/etc/systemd/system#  再安装 kubelet root@km:/lib/systemd/system# apt install kubelet Reading package lists... Done Setting up kubelet (1.8.3-00) ... root@km:/lib/systemd/system# systemctl start kubelet root@km:/lib/systemd/system# systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Active: activating (auto-restart) (Result: exit-code) since Fri 2017-11-17 17:34:35 CST; 1s ago Docs: http://kubernetes.io/docs/ Process: 25074 ExecStart=/usr/bin/kubelet (code=exited, status=1/FAILURE) Main PID: 25074 (code=exited, status=1/FAILURE) Nov 17 17:34:35 km systemd[1]: kubelet.service: Unit entered failed state. Nov 17 17:34:35 km systemd[1]: kubelet.service: Failed with result 'exit-code'. root@km:/lib/systemd/system#  还出错了\nroot@km:/lib/systemd/system# cat kubelet.service [Unit] Description=kubelet: The Kubernetes Node Agent Documentation=http://kubernetes.io/docs/ [Service] ExecStart=/usr/bin/kubelet Restart=always StartLimitInterval=0 RestartSec=10 [Install] WantedBy=multi-user.target root@km:/lib/systemd/system# journalctl -xe ..... Nov 17 17:36:51 km kubelet[25463]: error: failed to run Kubelet: Running with swap on is not supported, please disable swap! or set --fail-swap-on flag to false. /proc/swaps contained: [Filename  从信息中看到，要把 swap 关闭，或者带 \u0026ndash;fail-swap-on 参数。 那就带参数试一下先。\nroot@km:/lib/systemd/system# kubelet --fail-swap-on=false  成功逃过这个错误。 但是报了另一个错误。\nroot@km:/lib/systemd/system# kubelet --fail-swap-on=false W1117 17:48:12.355020 27348 cni.go:196] Unable to update cni config: No networks found in /etc/cni/net.d I1117 17:48:12.361647 27348 docker_service.go:207] Docker cri networking managed by kubernetes.io/no-op error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: \u0026quot;cgroupfs\u0026quot; is different from docker cgroup driver: \u0026quot;systemd\u0026quot;  这个显然与 docker 相关。\nroot@km:/lib/systemd/system# cat /etc/docker/daemon.json { \u0026quot;exec-opts\u0026quot;: [\u0026quot;native.cgroupdriver=systemd\u0026quot;], \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://0d6wdn2y.mirror.aliyuncs.com\u0026quot;] }  那好了，先把这个后来加进来的 \u0026ldquo;exec-opts\u0026rdquo;: [\u0026ldquo;native.cgroupdriver=systemd\u0026rdquo;], 删除了吧。\nroot@km:/lib/systemd/system# cat /etc/docker/daemon.json { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://0d6wdn2y.mirror.aliyuncs.com\u0026quot;] } root@km:/lib/systemd/system# sudo systemctl restart docker ... root@km:/lib/systemd/system# kubelet --fail-swap-on=false I1117 17:52:52.954982 28490 feature_gate.go:156] feature gates: map[] I1117 17:52:52.955098 28490 controller.go:114] kubelet config controller: starting controller I1117 17:52:52.955117 28490 controller.go:118] kubelet config controller: validating combination of defaults and flags I1117 17:52:52.974917 28490 client.go:75] Connecting to docker on unix:///var/run/docker.sock I1117 17:52:52.974977 28490 client.go:95] Start docker client with request timeout=2m0s W1117 17:52:52.977139 28490 cni.go:196] Unable to update cni config: No networks found in /etc/cni/net.d I1117 17:52:52.983192 28490 feature_gate.go:156] feature gates: map[] W1117 17:52:52.983420 28490 server.go:289] --cloud-provider=auto-detect is deprecated. The desired cloud provider should be set explicitly W1117 17:52:52.983465 28490 server.go:324] standalone mode, no API client I1117 17:52:52.983810 28490 manager.go:149] cAdvisor running in container: \u0026quot;/sys/fs/cgroup/cpu,cpuacct/user.slice\u0026quot; W1117 17:52:53.017865 28490 manager.go:157] unable to connect to Rkt api service: rkt: cannot tcp Dial rkt api service: dial tcp [::1]:15441: getsockopt: connection refused W1117 17:52:53.018035 28490 manager.go:166] unable to connect to CRI-O api service: Get http://%2Fvar%2Frun%2Fcrio.sock/info: dial unix /var/run/crio.sock: connect: no such file or directory I1117 17:52:53.049774 28490 fs.go:139] Filesystem UUIDs: map[90ef4dc9-3b9e-4031-ad7f-209b328d2f3b:/dev/sda1 2017-02-15-20-36-22-00:/dev/sr0 3687da9b-d812-42a1-b42c-a3d3e7178372:/dev/dm-0 8679fa71-e60b-4686-a5fa-9a0cc5023568:/dev/dm-1] I1117 17:52:53.049836 28490 fs.go:140] Filesystem partitions: map[tmpfs:{mountpoint:/run major:0 minor:19 fsType:tmpfs blockSize:0} /dev/mapper/ubuntu--vg-root:{mountpoint:/var/lib/docker/aufs major:252 minor:0 fsType:ext4 blockSize:0} /dev/sda1:{mountpoint:/boot major:8 minor:1 fsType:ext2 blockSize:0}] I1117 17:52:53.052104 28490 manager.go:216] Machine: {NumCores:4 CpuFrequency:2097571 MemoryCapacity:8371290112 HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] MachineID:78cb13728eba6f6c819e6dea599a5db9 SystemUUID:564D7A67-BDF7-E109-61AC-DDC9929A346F BootID:8f8d7bb3-abb6-4d6a-b1ee-261cd1a2cc74 Filesystems:[{Device:tmpfs DeviceMajor:0 DeviceMinor:19 Capacity:837132288 Type:vfs Inodes:1021886 HasInodes:true} {Device:/dev/mapper/ubuntu--vg-root DeviceMajor:252 DeviceMinor:0 Capacity:75452612608 Type:vfs Inodes:4694016 HasInodes:true} {Device:/dev/sda1 DeviceMajor:8 DeviceMinor:1 Capacity:494512128 Type:vfs Inodes:124928 HasInodes:true}] DiskMap:map[252:0:{Name:dm-0 Major:252 Minor:0 Size:76793511936 Scheduler:none} 252:1:{Name:dm-1 Major:252 Minor:1 Size:8589934592 Scheduler:none} 2:0:{Name:fd0 Major:2 Minor:0 Size:4096 Scheduler:deadline} 8:0:{Name:sda Major:8 Minor:0 Size:85899345920 Scheduler:deadline}] NetworkDevices:[{Name:cni0 MacAddress:0a:58:0a:f4:00:01 Speed:0 Mtu:1500} {Name:ens160 MacAddress:00:0c:29:9a:34:6f Speed:10000 Mtu:1500} {Name:flannel.1 MacAddress:b2:6d:04:a9:38:8d Speed:0 Mtu:1450}] Topology:[{Id:0 Memory:8371290112 Cores:[{Id:0 Threads:[0] Caches:[]} {Id:1 Threads:[1] Caches:[]} {Id:2 Threads:[2] Caches:[]} {Id:3 Threads:[3] Caches:[]}] Caches:[{Size:20971520 Type:Unified Level:3}]}] CloudProvider:Unknown InstanceType:Unknown InstanceID:None} I1117 17:52:53.053151 28490 manager.go:222] Version: {KernelVersion:4.4.0-62-generic ContainerOsVersion:Ubuntu 16.04.3 LTS DockerVersion:17.05.0-ce DockerAPIVersion:1.29 CadvisorVersion: CadvisorRevision:} W1117 17:52:53.053992 28490 server.go:232] No api server defined - no events will be sent to API server. I1117 17:52:53.054023 28490 server.go:422] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulting to / I1117 17:52:53.056245 28490 container_manager_linux.go:252] container manager verified user specified cgroup-root exists: / I1117 17:52:53.056284 28490 container_manager_linux.go:257] Creating Container Manager object based on Node Config: {RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:docker CgroupsPerQOS:true CgroupRoot:/ CgroupDriver:cgroupfs ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[{Signal:memory.available Operator:LessThan Value:{Quantity:100Mi Percentage:0} GracePeriod:0s MinReclaim:\u0026lt;nil\u0026gt;} {Signal:nodefs.available Operator:LessThan Value:{Quantity:\u0026lt;nil\u0026gt; Percentage:0.1} GracePeriod:0s MinReclaim:\u0026lt;nil\u0026gt;} {Signal:nodefs.inodesFree Operator:LessThan Value:{Quantity:\u0026lt;nil\u0026gt; Percentage:0.05} GracePeriod:0s MinReclaim:\u0026lt;nil\u0026gt;}]} ExperimentalQOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalCPUManagerReconcilePeriod:10s} I1117 17:52:53.056462 28490 container_manager_linux.go:288] Creating device plugin handler: false W1117 17:52:53.061351 28490 kubelet_network.go:69] Hairpin mode set to \u0026quot;promiscuous-bridge\u0026quot; but kubenet is not enabled, falling back to \u0026quot;hairpin-veth\u0026quot; I1117 17:52:53.061391 28490 kubelet.go:517] Hairpin mode set to \u0026quot;hairpin-veth\u0026quot; W1117 17:52:53.065042 28490 cni.go:196] Unable to update cni config: No networks found in /etc/cni/net.d I1117 17:52:53.071790 28490 docker_service.go:207] Docker cri networking managed by kubernetes.io/no-op I1117 17:52:53.102961 28490 docker_service.go:224] Setting cgroupDriver to cgroupfs I1117 17:52:53.140011 28490 remote_runtime.go:43] Connecting to runtime service unix:///var/run/dockershim.sock I1117 17:52:53.142110 28490 kuberuntime_manager.go:178] Container runtime docker initialized, version: 17.05.0-ce, apiVersion: 1.29.0 W1117 17:52:53.142331 28490 probe.go:215] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating. I1117 17:52:53.144299 28490 server.go:718] Started kubelet v1.8.3 E1117 17:52:53.144359 28490 kubelet.go:1234] Image garbage collection failed once. Stats initialization may not have completed yet: failed to get imageFs info: unable to find data for container / W1117 17:52:53.144478 28490 kubelet.go:1318] No api server defined - no node status update will be sent. I1117 17:52:53.144496 28490 server.go:128] Starting to listen on 0.0.0.0:10250 I1117 17:52:53.145570 28490 kubelet_node_status.go:280] Setting node annotation to enable volume controller attach/detach I1117 17:52:53.146415 28490 server.go:296] Adding debug handlers to kubelet server. I1117 17:52:53.159723 28490 fs_resource_analyzer.go:66] Starting FS ResourceAnalyzer I1117 17:52:53.159773 28490 status_manager.go:136] Kubernetes client is nil, not starting status manager. I1117 17:52:53.159791 28490 kubelet.go:1768] Starting kubelet main sync loop. I1117 17:52:53.159842 28490 kubelet.go:1779] skipping pod synchronization - [container runtime is down PLEG is not healthy: pleg was last seen active 2562047h47m16.854775807s ago; threshold is 3m0s] W1117 17:52:53.160705 28490 container_manager_linux.go:869] CPUAccounting not enabled for pid: 28490 W1117 17:52:53.160728 28490 container_manager_linux.go:872] MemoryAccounting not enabled for pid: 28490 E1117 17:52:53.160816 28490 container_manager_linux.go:603] [ContainerManager]: Fail to get rootfs information unable to find data for container / I1117 17:52:53.160887 28490 volume_manager.go:246] Starting Kubelet Volume Manager I1117 17:52:53.228692 28490 factory.go:355] Registering Docker factory W1117 17:52:53.228739 28490 manager.go:265] Registration of the rkt container factory failed: unable to communicate with Rkt api service: rkt: cannot tcp Dial rkt api service: dial tcp [::1]:15441: getsockopt: connection refused W1117 17:52:53.228910 28490 manager.go:276] Registration of the crio container factory failed: Get http://%2Fvar%2Frun%2Fcrio.sock/info: dial unix /var/run/crio.sock: connect: no such file or directory I1117 17:52:53.228931 28490 factory.go:54] Registering systemd factory I1117 17:52:53.229203 28490 factory.go:86] Registering Raw factory I1117 17:52:53.229466 28490 manager.go:1140] Started watching for new ooms in manager I1117 17:52:53.230193 28490 manager.go:311] Starting recovery of all containers I1117 17:52:53.342529 28490 manager.go:316] Recovery completed I1117 17:52:53.487640 28490 kubelet_node_status.go:280] Setting node annotation to enable volume controller attach/detach E1117 17:52:53.522074 28490 summary.go:92] Failed to get system container stats for \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot;: failed to get cgroup stats for \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot;: failed to get container info for \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot;: unknown container \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot; W1117 17:52:53.522142 28490 helpers.go:847] eviction manager: no observation found for eviction signal allocatableNodeFs.available I1117 17:53:03.522396 28490 kubelet_node_status.go:280] Setting node annotation to enable volume controller attach/detach E1117 17:53:03.554477 28490 summary.go:92] Failed to get system container stats for \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot;: failed to get cgroup stats for \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot;: failed to get container info for \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot;: unknown container \u0026quot;/user.slice/user-1000.slice/session-553.scope\u0026quot; W1117 17:53:03.554543 28490 helpers.go:847] eviction manager: no observation found for eviction signal allocatableNodeFs.available  这下是真的成功了。\n打断它。把 \u0026ndash;fail-swap-on=false 参数，加到 启动文件下吧。\ncd /lib/systemd/system root@km:/lib/systemd/system# vi kubelet.service root@km:/lib/systemd/system# cat kubelet.service root@km:/lib/systemd/system# systemctl daemon-reload root@km:/lib/systemd/system# systemctl start kubelet root@km:/lib/systemd/system# systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2017-11-17 17:54:21 CST; 15s ago Docs: http://kubernetes.io/docs/ Main PID: 28824 (kubelet) Tasks: 14 Memory: 22.5M CPU: 1.005s CGroup: /system.slice/kubelet.service └─28824 /usr/bin/kubelet --fail-swap-on=false Nov 17 17:54:21 km kubelet[28824]: I1117 17:54:21.815998 28824 factory.go:54] Registering systemd factory Nov 17 17:54:21 km kubelet[28824]: I1117 17:54:21.816270 28824 factory.go:86] Registering Raw factory Nov 17 17:54:21 km kubelet[28824]: I1117 17:54:21.816520 28824 manager.go:1140] Started watching for new ooms in manager Nov 17 17:54:21 km kubelet[28824]: I1117 17:54:21.817206 28824 manager.go:311] Starting recovery of all containers Nov 17 17:54:21 km kubelet[28824]: I1117 17:54:21.915504 28824 manager.go:316] Recovery completed Nov 17 17:54:22 km kubelet[28824]: I1117 17:54:22.050494 28824 kubelet_node_status.go:280] Setting node annotation to enable volume controller attach/detach Nov 17 17:54:22 km kubelet[28824]: W1117 17:54:22.082192 28824 helpers.go:847] eviction manager: no observation found for eviction signal allocatableNodeFs.available Nov 17 17:54:31 km systemd[1]: Started kubelet: The Kubernetes Node Agent. Nov 17 17:54:32 km kubelet[28824]: I1117 17:54:32.082476 28824 kubelet_node_status.go:280] Setting node annotation to enable volume controller attach/detach Nov 17 17:54:32 km kubelet[28824]: W1117 17:54:32.114163 28824 helpers.go:847] eviction manager: no observation found for eviction signal allocatableNodeFs.available root@km:/lib/systemd/system#  如果说, 想保证重开机也生效,那就直接 https://askubuntu.com/questions/214805/how-do-i-disable-swap 来吧.\nsudo swapoff -a  成功了。\nkubelet stop 因为 kubeadm v1.8.3 在 kubeadm init 的过程中会自动启动 kubelet ,所以这里要把 kubelet stop了。\nroot@km:/lib/systemd/system# systemctl stop kubelet  好了。kubelet 这一块是OK了。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-0-notes.html",
	"title": "Spacemacs Rocks Day 0, Intro",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": "本spacemacs rocks day系列是针对子龙山人的 spacemacs rocks season 1 的 11个优酷视频教程而整理的笔记。 相应的子龙山人的本人对教程的介绍，请看：https://zilongshanren.com/blog/2015-12-06-spacemacs-rocks.html\n因为我本人之前已有相关的spacemacs的使用经历，所以，我在看的时候，次序有点不对。 新人可以按下面的次序观看视频。\n 了解: 10, 11, 9 入门: 1, 2, 3, 4, 5, 6, 7, 8  注意：视频中的很多命令，早已不能再使用，且有一些我也没有摸索出来，如有知道的请留言探讨。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-1-notes.html",
	"title": "Spacemacs Rocks Day 1, Features &amp; Workflow",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " spacemacs-rocks(1)\n跳到函数定义，并返回  , g g 然后 C-o\n Navigation functions in current file  SPC s l （已经失效，因为没有找到这个快捷键）\n 替换成\n M-x helm-jump-in-buffer\n 这样，就可以把它们绑定一下。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/sshpass-let-ssh-login-with-password.html",
	"title": "ssh登录时如何直接在参数中加入登录密码",
	"tags": ["linux", "ssh"],
	"description": "",
	"content": " sshpass: 用于非交互的ssh 密码验证\n　ssh登陆不能在命令行中指定密码，也不能以shell中随处可见的，sshpass 的出现，解决了这一问题。它允许你用 -p 参数指定明文密码，然后直接登录远程服务器。 它支持密码从命令行,文件,环境变量中读取。\n　办法找到了，现在先在自己机器上安装。\n　对于debian/ubuntu系统来说，安装方式很简单：\nsudo apt-get install sshpass  　对于其他系统来说，可以通过编译源码：\nwget http://sourceforge.net/projects/sshpass/files/sshpass/1.05/sshpass-1.05.tar.gz tar xvzf sshpass-1.05.tar.gz ./configure make sudo make install  　./configure 后可以添加参数指定安装目录，比如：\n./configure --prefix=/usr/local/Cellar/sshpass/1.05  　来把sshpass安装到自己喜欢的位置，如果没有这个参数，则安装到默认位置。\n　安装好了后，输入sshpass来查看是否安装好了：\n➜ ~ git:(master) ✗ sshpass -V sshpass 1.05 (C) 2006-2011 Lingnu Open Source Consulting Ltd. This program is free software, and can be distributed under the terms of the GPL See the COPYING file for more information. ➜ ~ git:(master) ✗  　这样就可以通过：\nsshpass -p [passwd] ssh -p [port] root@192.168.X.X  　来登录远程主机了。\nRef  https://www.cnblogs.com/linxiong945/p/4226211.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-tips.html",
	"title": "python小技巧",
	"tags": ["python", "tips"],
	"description": "",
	"content": " Python查看安装路径 \u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.path  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-tips.html",
	"title": "mac tips",
	"tags": ["mac", "tips"],
	"description": "",
	"content": " 卸载软件 为什么在我的mac上面下了腾讯电脑管家就卸载不了了？点击没有小叉叉也不能移到废纸篓.\nfinder－应用程序－右键－移到废纸篓  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-storage-cluster-quick-start.html",
	"title": "ceph-install-base-ubuntu Storage Cluster Quick Start",
	"tags": ["ceph", "install", "ubuntu"],
	"description": "",
	"content": " 2.1 Create the cluster.\n ceph-deploy new node1 不生效的，要写成 ceph-deploy new mon1\n cephu@cephadmin:~/my-cluster$ ceph-deploy new mon1  2.2 - 2.3\ncephu@cephadmin:~/my-cluster$ cat ~/my-cluster/ceph.conf [global] fsid = d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 mon_initial_members = mon1 mon_host = 192.168.31.114 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public network = 192.168.31.1/24 ms bind ipv6 = true cephu@cephadmin:~/my-cluster$  2.4\ncephu@cephadmin:~/my-cluster$ ceph-deploy install node1 node2 node3  2.5\ncephu@cephadmin:~/my-cluster$ ceph-deploy mon create-initial  报错，然后，经过 农总在 https://my.oschina.net/u/2475751/blog/647777 查到要运行下面\ncephu@cephadmin:~/my-cluster$ ssh mon1 sudo ceph-create-keys --id mon1  再来一次\ncephu@cephadmin:~/my-cluster$ ceph-deploy mon create-initial  3.1\ncephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf admin node1 node2 node3 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.32): /usr/bin/ceph-deploy --overwrite-conf admin node1 node2 node3 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2c1fbe2440\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] client : ['node1', 'node2', 'node3'] [ceph_deploy.cli][INFO ] func : \u0026lt;function admin at 0x7f2c20489b18\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node1 [node1][DEBUG ] connection detected need for sudo [node1][DEBUG ] connected to host: node1 [node1][DEBUG ] detect platform information from remote host [node1][DEBUG ] detect machine type [node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node2 [node2][DEBUG ] connection detected need for sudo [node2][DEBUG ] connected to host: node2 [node2][DEBUG ] detect platform information from remote host [node2][DEBUG ] detect machine type [node2][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node3 [node3][DEBUG ] connection detected need for sudo [node3][DEBUG ] connected to host: node3 [node3][DEBUG ] detect platform information from remote host [node3][DEBUG ] detect machine type [node3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf cephu@cephadmin:~/my-cluster$  3.2\ncephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node1 usage: ceph-deploy [-h] [-v | -q] [--version] [--username USERNAME] [--overwrite-conf] [--cluster NAME] [--ceph-conf CEPH_CONF] COMMAND ... ceph-deploy: error: argument COMMAND: invalid choice: 'mgr' (choose from 'new', 'install', 'rgw', 'mon', 'mds', ' gatherkeys', 'disk', 'osd', 'admin', 'repo', 'config', 'uninstall', 'purge', 'purgedata', 'calamari', 'forgetkeys ', 'pkg') cephu@cephadmin:~/my-cluster$  报错\ncephu@cephadmin:~/my-cluster$ ceph-deploy -h usage: ceph-deploy [-h] [-v | -q] [--version] [--username USERNAME] [--overwrite-conf] [--cluster NAME] [--ceph-conf CEPH_CONF] COMMAND ... Easy Ceph deployment -^- / \\ |O o| ceph-deploy v1.5.32 ).-.( '/|||\\` | '|` | '|` Full documentation can be found at: http://ceph.com/ceph-deploy/docs optional arguments: -h, --help show this help message and exit -v, --verbose be more verbose -q, --quiet be less verbose --version the current installed version of ceph-deploy --username USERNAME the username to connect to the remote host --overwrite-conf overwrite an existing conf file on remote host (if present) --cluster NAME name of the cluster --ceph-conf CEPH_CONF use (or reuse) a given ceph.conf file commands: COMMAND description new Start deploying a new cluster, and write a CLUSTER.conf and keyring for it. install Install Ceph packages on remote hosts. rgw Ceph RGW daemon management mon Ceph MON Daemon management mds Ceph MDS daemon management gatherkeys Gather authentication keys for provisioning new nodes. disk Manage disks on a remote host. osd Prepare a data disk on remote host. admin Push configuration and client.admin key to a remote host. repo Repo definition management config Copy ceph.conf to/from remote host(s) uninstall Remove Ceph packages from remote hosts. purge Remove Ceph packages from remote hosts and purge all data. purgedata Purge (delete, destroy, discard, shred) any Ceph data from /var/lib/ceph calamari Install and configure Calamari nodes. Assumes that a repository with Calamari packages is already configured. Refer to the docs for examples (http://ceph.com/ceph-deploy/docs/conf.html) forgetkeys Remove authentication keys from the local directory. pkg Manage packages on remote hosts. cephu@cephadmin:~/my-cluster$  我去，真的没有 mgr 命令。\n版本升级吧\ncephu@cephadmin:~/my-cluster$ pip install ceph-deploy Collecting ceph-deploy Downloading ceph-deploy-1.5.39.tar.gz (114kB) 100% |████████████████████████████████| 122kB 292kB/s Collecting setuptools (from ceph-deploy) Downloading setuptools-36.6.0-py2.py3-none-any.whl (481kB) 100% |████████████████████████████████| 481kB 968kB/s Building wheels for collected packages: ceph-deploy Running setup.py bdist_wheel for ceph-deploy ... done Stored in directory: /home/cephu/.cache/pip/wheels/5e/4a/c5/5759b04fedf1eaa17d4453b562ab28a2142dbf93ced0c37e5d Successfully built ceph-deploy Installing collected packages: setuptools, ceph-deploy Successfully installed ceph-deploy-1.5.32 setuptools-20.7.0 You are using pip version 8.1.1, however version 9.0.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. cephu@cephadmin:~/my-cluster$ ceph-deploy --version 1.5.39 cephu@cephadmin:~/my-cluster$ ceph-deploy -h  这下有了。重新来一下\ncephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy mgr create node1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('node1', 'node1')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa24a321ab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7fa24a993578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts node1:node1 [ceph_deploy][ERROR ] RuntimeError: bootstrap-mgr keyring not found; run 'gatherkeys'  哇，又来错误。\n提示了 run \u0026lsquo;gatherkeys\u0026rsquo; 。\ncephu@cephadmin:~/my-cluster$ ceph-deploy gatherkeys mon1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy gatherkeys mon1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbfda5f8a70\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] mon : ['mon1'] [ceph_deploy.cli][INFO ] func : \u0026lt;function gatherkeys at 0x7fbfda8570c8\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.gatherkeys][INFO ] Storing keys in temp directory /tmp/tmpZ8THzr [mon1][DEBUG ] connection detected need for sudo [mon1][DEBUG ] connected to host: mon1 [mon1][DEBUG ] detect platform information from remote host [mon1][DEBUG ] detect machine type [mon1][DEBUG ] get remote short hostname [mon1][DEBUG ] fetch remote file [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.mon1.asok mon_status [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.admin [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-mds [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-mgr [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-osd [mon1][INFO ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-mon1/keyring auth get client.bootstrap-rgw [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.client.admin.keyring' already exists [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.bootstrap-mds.keyring' already exists [ceph_deploy.gatherkeys][INFO ] Storing ceph.bootstrap-mgr.keyring [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.mon.keyring' already exists [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.bootstrap-osd.keyring' already exists [ceph_deploy.gatherkeys][INFO ] keyring 'ceph.bootstrap-rgw.keyring' already exists [ceph_deploy.gatherkeys][INFO ] Destroy temp directory /tmp/tmpZ8THzr cephu@cephadmin:~/my-cluster$  再走一个\ncephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy mgr create node1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('node1', 'node1')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5d02a1bab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7f5d0308d578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts node1:node1 [node1][DEBUG ] connection detected need for sudo [node1][DEBUG ] connected to host: node1 [node1][DEBUG ] detect platform information from remote host [node1][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to node1 [node1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.mgr][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite [ceph_deploy][ERROR ] GenericError: Failed to create 1 MGRs  提示了 use \u0026ndash;overwrite-conf\n再来\ncephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf mgr create mon1 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy --overwrite-conf mgr create mon1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('mon1', 'mon1')] [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe415166ab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7fe4157d8578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts mon1:mon1 [mon1][DEBUG ] connection detected need for sudo [mon1][DEBUG ] connected to host: mon1 [mon1][DEBUG ] detect platform information from remote host [mon1][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to mon1 [mon1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [mon1][WARNIN] mgr keyring does not exist yet, creating one [mon1][DEBUG ] create a keyring file [mon1][DEBUG ] create path if it doesn't exist [mon1][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.mon1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-mon1/keyring [mon1][INFO ] Running command: sudo systemctl enable ceph-mgr@mon1 [mon1][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@mon1.service to /lib/systemd/system/ceph-mgr@.service. [mon1][INFO ] Running command: sudo systemctl start ceph-mgr@mon1 [mon1][INFO ] Running command: sudo systemctl enable ceph.target cephu@cephadmin:~/my-cluster$  终于成功了。\n3.3\ncephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf osd create node1:sdb node2:sdb node3:sdc ... [node3][DEBUG ] Warning: The kernel is still using the old partition table. [node3][DEBUG ] The new table will be used at the next reboot or after you [node3][DEBUG ] run partprobe(8) or kpartx(8) [node3][DEBUG ] The operation has completed successfully. [node3][WARNIN] update_partition: Calling partprobe on prepared device /dev/sdc [node3][WARNIN] command_check_call: Running command: /sbin/udevadm settle --timeout=600 [node3][WARNIN] command: Running command: /usr/bin/flock -s /dev/sdc /sbin/partprobe /dev/sdc [node3][WARNIN] command_check_call: Running command: /sbin/udevadm settle --timeout=600 [node3][WARNIN] command_check_call: Running command: /sbin/udevadm trigger --action=add --sysname-match sdc1 [node3][INFO ] Running command: sudo systemctl enable ceph.target [node3][INFO ] checking OSD status... [node3][DEBUG ] find the location of an executable [node3][INFO ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json [node3][WARNIN] there is 1 OSD down [node3][WARNIN] there is 1 OSD out [ceph_deploy.osd][DEBUG ] Host node3 is now ready for osd use. cephu@cephadmin:~/my-cluster$  成功\n3.4\ncephu@cephadmin:~/my-cluster$ ssh node1 sudo ceph health HEALTH_OK cephu@cephadmin:~/my-cluster$ ssh node2 sudo ceph health HEALTH_OK cephu@cephadmin:~/my-cluster$ ssh node3 sudo ceph health HEALTH_OK cephu@cephadmin:~/my-cluster$ ssh node3 sudo ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_OK services: mon: 1 daemons, quorum mon1 mgr: mon1(active) osd: 3 osds: 3 up, 3 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 bytes usage: 3164 MB used, 80500 MB / 83664 MB avail pgs: cephu@cephadmin:~/my-cluster$  到这里，我们应该是完成了基础的搭建\n附加项：expanding your cluster ADD A METADATA SERVER ceph-deploy mds create node1\nADDING MONITORS ceph-deploy mon add node2 node3 会报错\n换成：\ncephu@cephadmin:~/my-cluster$ ceph-deploy mon add cephfsn2 cephu@cephadmin:~/my-cluster$ ceph-deploy mon add cephfsn3  验证\ncephu@cephadmin:~/my-cluster$ ssh cephfsn2 ceph quorum_status --format json-pretty 2017-10-24 10:40:24.959942 7f261141a700 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.admin.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory 2017-10-24 10:40:24.959973 7f261141a700 -1 monclient: ERROR: missing keyring, cannot use cephx for authentication 2017-10-24 10:40:24.959975 7f261141a700 0 librados: client.admin initialization error (2) No such file or directory [errno 2] error connecting to the cluster cephu@cephadmin:~/my-cluster$ ssh cephfsn2 sudo ceph quorum_status --format json-pretty { \u0026quot;election_epoch\u0026quot;: 14, \u0026quot;quorum\u0026quot;: [ 0, 1, 2 ], \u0026quot;quorum_names\u0026quot;: [ \u0026quot;cephfsn2\u0026quot;, \u0026quot;mon1\u0026quot;, \u0026quot;cephfsn3\u0026quot; ], \u0026quot;quorum_leader_name\u0026quot;: \u0026quot;cephfsn2\u0026quot;, \u0026quot;monmap\u0026quot;: { \u0026quot;epoch\u0026quot;: 3, \u0026quot;fsid\u0026quot;: \u0026quot;d0aa5af1-4f8e-4953-9448-7f1b2448b8a5\u0026quot;, \u0026quot;modified\u0026quot;: \u0026quot;2017-10-24 10:32:19.273831\u0026quot;, \u0026quot;created\u0026quot;: \u0026quot;2017-10-23 15:22:32.766470\u0026quot;, \u0026quot;features\u0026quot;: { \u0026quot;persistent\u0026quot;: [ \u0026quot;kraken\u0026quot;, \u0026quot;luminous\u0026quot; ], \u0026quot;optional\u0026quot;: [] }, \u0026quot;mons\u0026quot;: [ { \u0026quot;rank\u0026quot;: 0, \u0026quot;name\u0026quot;: \u0026quot;cephfsn2\u0026quot;, \u0026quot;addr\u0026quot;: \u0026quot;192.168.31.113:6789/0\u0026quot;, \u0026quot;public_addr\u0026quot;: \u0026quot;192.168.31.113:6789/0\u0026quot; }, { \u0026quot;rank\u0026quot;: 1, \u0026quot;name\u0026quot;: \u0026quot;mon1\u0026quot;, \u0026quot;addr\u0026quot;: \u0026quot;192.168.31.114:6789/0\u0026quot;, \u0026quot;public_addr\u0026quot;: \u0026quot;192.168.31.114:6789/0\u0026quot; }, { \u0026quot;rank\u0026quot;: 2, \u0026quot;name\u0026quot;: \u0026quot;cephfsn3\u0026quot;, \u0026quot;addr\u0026quot;: \u0026quot;192.168.31.173:6789/0\u0026quot;, \u0026quot;public_addr\u0026quot;: \u0026quot;192.168.31.173:6789/0\u0026quot; } ] } } cephu@cephadmin:~/my-cluster$  ADDING MANAGERS cephu@cephadmin:~/my-cluster$ ceph-deploy mgr create node2 node3 [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /usr/bin/ceph-deploy mgr create node2 node3 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] mgr : [('node2', 'node2'), ('node3', 'node3')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb9043a4ab8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function mgr at 0x7fb904a16578\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts node2:node2 node3:node3 [node2][DEBUG ] connection detected need for sudo [node2][DEBUG ] connected to host: node2 [node2][DEBUG ] detect platform information from remote host [node2][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to node2 [node2][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [node2][WARNIN] mgr keyring does not exist yet, creating one [node2][DEBUG ] create a keyring file [node2][DEBUG ] create path if it doesn't exist [node2][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.node2 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-node2/keyring [node2][INFO ] Running command: sudo systemctl enable ceph-mgr@node2 [node2][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@node2.service to /lib/systemd/system/ceph-mgr@.service. [node2][INFO ] Running command: sudo systemctl start ceph-mgr@node2 [node2][INFO ] Running command: sudo systemctl enable ceph.target [node3][DEBUG ] connection detected need for sudo [node3][DEBUG ] connected to host: node3 [node3][DEBUG ] detect platform information from remote host [node3][DEBUG ] detect machine type [ceph_deploy.mgr][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.mgr][DEBUG ] remote host will use systemd [ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to node3 [node3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [node3][WARNIN] mgr keyring does not exist yet, creating one [node3][DEBUG ] create a keyring file [node3][DEBUG ] create path if it doesn't exist [node3][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.node3 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-node3/keyring [node3][INFO ] Running command: sudo systemctl enable ceph-mgr@node3 [node3][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@node3.service to /lib/systemd/system/ceph-mgr@.service. [node3][INFO ] Running command: sudo systemctl start ceph-mgr@node3 [node3][INFO ] Running command: sudo systemctl enable ceph.target cephu@cephadmin:~/my-cluster$  验证\ncephu@cephadmin:~/my-cluster$ ssh node1 sudo ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_WARN clock skew detected on mon.cephfsn3 services: mon: 3 daemons, quorum cephfsn2,mon1,cephfsn3 mgr: mon1(active), standbys: node2, node3 osd: 3 osds: 3 up, 3 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 bytes usage: 3164 MB used, 80500 MB / 83664 MB avail pgs: cephu@cephadmin:~/my-cluster$ ssh node3 sudo ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_WARN clock skew detected on mon.cephfsn3 services: mon: 3 daemons, quorum cephfsn2,mon1,cephfsn3 mgr: mon1(active), standbys: node2, node3 osd: 3 osds: 3 up, 3 in data: pools: 0 pools, 0 pgs objects: 0 objects, 0 bytes usage: 3164 MB used, 80500 MB / 83664 MB avail pgs: cephu@cephadmin:~/my-cluster$  ADD AN RGW INSTANCE ceph-deploy rgw create node1  好了。\nSTORING/RETRIEVING OBJECT DATA 这一个小节，现在先不动。\n算了，还是动吧。\ncephu@cephadmin:~/my-cluster$ sudo apt install ceph-common -y cephu@cephadmin:~/my-cluster$ ls /etc/ceph/* cephu@cephadmin:~/my-cluster$ ceph-deploy admin cephadmin cephu@cephadmin:~/my-cluster$ ls /etc/ceph/* ## 这里可以看到新增3个文件 cephu@cephadmin:~/my-cluster$ ceph-deploy gatherkeys cephadmin  在 admin 与 ceph-client 节点，都运行一下。\njlch@k-m:/etc/apt/sources.list.d$ sudo chmod +r /etc/ceph/ceph.client.admin.keyring  现在可以开始执行命令了\njlch@k-m:/etc/apt/sources.list.d$ echo {Test-data} \u0026gt; testfile.txt jlch@k-m:/etc/apt/sources.list.d$ ceph osd pool create mytest 8 jlch@k-m:/etc/apt/sources.list.d$ rados put test-object-1 testfile.txt --pool=mytest jlch@k-m:/etc/apt/sources.list.d$ rados -p mytest ls jlch@k-m:/etc/apt/sources.list.d$ ceph osd map mytest test-object-1  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-make-by-go-get.html",
	"title": "kubernetes-cephfs-make-by-go-get",
	"tags": ["kubernetes", "ceph", "cephfs", "make"],
	"description": "",
	"content": " ENV k8s-master 192.168.31.120 km master k8s-node1 192.168.31.119 kn1 node1 k8s-node2 192.168.31.118 kn2 node2 ceph-client 192.168.31.172 ceph-mon1 192.168.31.114  这次的make, 可以在任何地方完成，只要满足：golang 1.7 以上的版本\n我在 km,ceph-client,ceph-mon1 上都完成过\n安装golang 如果已有安装，请忽略这一步\n安装 golang 1.7 以上的版本。 我们这里安装 1.9.1\n cd home/jlch tar -xvf go1.9.2.linux-amd64.tar ls go export PATH=$PATH:/home/jlch/go/bin\n 验证go go version  配置 GOPATH mkdir gopath export GOPATH=/home/jlch/gopath/  go get go get github.com/kubernetes-incubator/external-storage  配置 Dockerfile 后来发现 docker image 的文件不对。\n这个地方的 ENV CEPH_VERSION \u0026ldquo;jewel\u0026rdquo; 应该修改成 ENV CEPH_VERSION \u0026ldquo;luminous\u0026rdquo;\n然后再 make\ncd /github.com/kubernetes-incubator/external-storage/ceph/cephfs/ vi Dockerfile  看一下。\nroot@km:~/cephfs# cat ~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs/Dockerfile # Copyright 2017 The Kubernetes Authors. # # Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. FROM centos:7 ENV CEPH_VERSION \u0026quot;jewel\u0026quot; RUN rpm -Uvh https://download.ceph.com/rpm-$CEPH_VERSION/el7/noarch/ceph-release-1-1.el7.noarch.rpm \u0026amp;\u0026amp; \\ yum install -y epel-release \u0026amp;\u0026amp; \\ yum install -y ceph-common python-cephfs COPY cephfs-provisioner /usr/local/bin/cephfs-provisioner COPY cephfs_provisioner/cephfs_provisioner.py /usr/local/bin/cephfs_provisioner CMD [\u0026quot;chmod\u0026quot;, \u0026quot;o+x\u0026quot;, \u0026quot;/usr/local/bin/cephfs_provisioner\u0026quot;] root@km:~/cephfs#  make cd gopath/src/ cd ./github.com/kubernetes-incubator/external-storage/  这里如果 make ceph/cephfs/ 直接这么走，会报如下错误。\n[tom@test_240 external-storage]$ make ceph/cephfs/ make: 对“ceph/cephfs/”无需做任何事。 [tom@test_240 external-storage]$  所以要 cd ceph/cephfs/ \u0026amp;\u0026amp; make ，如下：\n[tom@test_240 external-storage]$ cd ceph/cephfs/ [tom@test_240 cephfs]$ ls cephfs_provisioner ceph-secret-admin.yaml claim.yaml configmap.yaml Dockerfile Makefile README.md cephfs-provisioner.go CHANGELOG.md class.yaml deployment.yaml local-start.sh OWNERS test-pod.yaml [tom@test_240 cephfs]$ make CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags \u0026quot;-static\u0026quot;' -o cephfs-provisioner cephfs-provisioner.go [tom@test_240 cephfs]$  这个时候，在 ceph/cephfs/ 下会多出一个 cephfs-provisioner 文件\n[tom@test_240 cephfs]$ ls cephfs_provisioner cephfs-provisioner cephfs-provisioner.go ceph-secret-admin.yaml CHANGELOG.md claim.yaml class.yaml configmap.yaml deployment.yaml Dockerfile local-start.sh Makefile OWNERS README.md test-pod.yaml [tom@test_240 cephfs]$  make push 生成 docker image , quay.io/external_storage/cephfs-provisioner\nmake push  如果说出现下面这个样子，说明是 make 成了 docker image了，但是 Push没有成功（应该是指 push 到 docker.io 没有成功）\n79c182856123: Preparing cf516324493c: Preparing unauthorized: access to the requested resource is not authorized make: *** [push] 错误 1 [tom@test_240 cephfs]$  push 到 registry 因为有 reg.jlch.com:5000 这个 registry 了，先登录\ndocker login reg.jlch.com:5000 docker tag quay.io/external_storage/cephfs-provisioner:latest reg.jlch.com:5000/quay.io/external_storage/cephfs-provisioner:20171114 docker push reg.jlch.com:5000/quay.io/external_storage/cephfs-provisioner:20171114  删除\ndocker rmi reg.jlch.com:5000/quay.io/external_storage/cephfs-provisioner:20171114  game over "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-install-base-ubuntu.html",
	"title": "ubuntu中安装kubeadm",
	"tags": ["kubernetes", "install", "kubeadm"],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-v184-install-base-ubuntu.html",
	"title": "ubuntu中安装kubeadm v1.8.4",
	"tags": ["kubernetes", "install", "kubeadm"],
	"description": "",
	"content": " Environment  kubeadm: v1.8.4\n所有节点都要安装 kubeadm, kubelet, kubectl\n安装时，全使用 root 用户。直到 kubeadm join 成功后，全使用 非root用户\n192.168.31.120 km master 192.168.31.119 kn1 node 192.168.31.118 kn2 node   加代理 准备FQ网络\n 命令行  加代理原因：kubeadm init 会去检查最新版本，及最新版本镜像是什么，镜像是否要更新。 如果本地有了相同的docker image id，就不会下载，不会更新。 这意味着，我们前几天的手工build kubeadm，达成 在 etc/kubernetes/mainfest 下的 *.yaml 文件 加上 \u0026ldquo;imagePullPolicy: IfNotPresent\u0026rdquo; , 没有意义了。\nroot@km:~# export http_proxy=\u0026quot;http://192.168.31.239:8118/\u0026quot; root@km:~# export https_proxy=\u0026quot;http://192.168.31.239:8118/\u0026quot; root@km:~# export no_proxy=\u0026quot;localhost,127.0.0.1,192.168.31.120,10.96.0.10,github.com,ubuntu.com\u0026quot;   apt  加代理原因： apt update 要去 google.com 下载\nroot@km:~# cat /etc/apt/apt.conf Acquire::http::proxy \u0026quot;http://192.168.31.239:8118/\u0026quot;; Acquire::https::proxy \u0026quot;https://192.168.31.239:8118/\u0026quot;; Acquire::no::proxy \u0026quot;ubuntu.com\u0026quot;; root@km:~#   docker  加代理原因：当 kubeadm init 中下载完了最新的images后，要通过 docker 专有的环境去下载镜像，并启动。这个过程，需要代理。\n重点是加了\n Environment=\u0026ldquo;HTTP_PROXY=http://192.168.31.239:8118/\u0026ldquo; \u0026ldquo;HTTPS_PROXY=http://192.168.31.239:8118/\u0026rdquo; \u0026ldquo;NO_PROXY=localhost,127.0.0.1,docker.io\u0026rdquo;\n 具体如下：\nroot@km:~# cat /lib/systemd/system/docker.service [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network.target docker.socket firewalld.service Requires=docker.socket [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker Environment=\u0026quot;HTTP_PROXY=http://192.168.31.239:8118/\u0026quot; \u0026quot;HTTPS_PROXY=http://192.168.31.239:8118/\u0026quot; \u0026quot;NO_PROXY=localhost,127.0.0.1,docker.io\u0026quot; ExecStart=/usr/bin/dockerd -H fd:// ExecReload=/bin/kill -s HUP $MAINPID LimitNOFILE=1048576 # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNPROC=infinity LimitCORE=infinity # Uncomment TasksMax if your systemd version supports it. # Only systemd 226 and above support this version. TasksMax=infinity TimeoutStartSec=0 # set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes # kill only the docker process, not all processes in the cgroup KillMode=process [Install] WantedBy=multi-user.target root@km:~#  卸载之前已安装的kube* root@km:~# sudo apt remove kubelet kubeadm kubectl -y  卸载完之后检查\nroot@km:~# which kubeadm root@km:~# which kubelet root@km:~# which kubectl  具体如下\n卸载 jlch@kn1:~$ sudo apt remove kubelet kubeadm kubectl Reading package lists... Done Building dependency tree Reading state information... Done Package 'kubeadm' is not installed, so not removed Package 'kubelet' is not installed, so not removed The following packages were automatically installed and are no longer required: ebtables kubernetes-cni socat Use 'sudo apt autoremove' to remove them. The following packages will be REMOVED: kubectl 0 upgraded, 0 newly installed, 1 to remove and 86 not upgraded. After this operation, 72.4 MB disk space will be freed. Do you want to continue? [Y/n] y (Reading database ... 67947 files and directories currently installed.) Removing kubectl (1.7.3-01) ... jlch@kn1:~$  检查 jlch@kn1:~$ which kubelet jlch@kn1:~$ which kubeadm jlch@kn1:~$ root@kn1:~# which kubectl /usr/local/bin/kubectl root@kn1:~# kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;7\u0026quot;, GitVersion:\u0026quot;v1.7.3\u0026quot;, GitCommit:\u0026quot;2c2fe6e8278a5db2d15a013987b53968c743f2a1\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2017-08-03T07:00:21Z\u0026quot;, GoVersion:\u0026quot;go1.8.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} The connection to the server localhost:8080 was refused - did you specify the right host or port? root@kn1:~# mv /usr/local/bin/kubectl /usr/local/bin/kubectl.v1.7.3 root@kn1:~# which kubectl /usr/bin/kubectl root@kn1:~# root@kn1:~# su - jlch jlch@kn1:~$ kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;8\u0026quot;, GitVersion:\u0026quot;v1.8.4\u0026quot;, GitCommit:\u0026quot;9befc2b8928a9426501d3bf62f72849d5cbcd5a3\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2017-11-20T05:28:34Z\u0026quot;, GoVersion:\u0026quot;go1.8.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} The connection to the server localhost:8080 was refused - did you specify the right host or port? jlch@kn1:~$  安装docer 看官网\n根据官网安装其它 root@kn1:~# curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - OK root@kn1:~# cat /etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io/ kubernetes-xenial main  安装kube* 安装kubelet kubeadm kubectl 看官网\nroot@kn1:~# apt-get install -y kubelet kubeadm kubectl Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: kubeadm kubectl kubelet 0 upgraded, 3 newly installed, 0 to remove and 87 not upgraded. Need to get 46.0 MB of archives. After this operation, 326 MB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.8.4-00 [19.2 MB] Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.8.4-00 [8,612 kB] Get:3 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.8.4-00 [18.1 MB] Fetched 46.0 MB in 1min 22s (557 kB/s) Selecting previously unselected package kubelet. (Reading database ... 67946 files and directories currently installed.) Preparing to unpack .../kubelet_1.8.4-00_amd64.deb ... Unpacking kubelet (1.8.4-00) ... Selecting previously unselected package kubectl. Preparing to unpack .../kubectl_1.8.4-00_amd64.deb ... Unpacking kubectl (1.8.4-00) ... Selecting previously unselected package kubeadm. Preparing to unpack .../kubeadm_1.8.4-00_amd64.deb ... Unpacking kubeadm (1.8.4-00) ... Setting up kubelet (1.8.4-00) ... Setting up kubectl (1.8.4-00) ... Setting up kubeadm (1.8.4-00) ... Installing new version of config file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf ... root@kn1:~#  kubeadm init kubeadm init kubeadm init --pod-network-cidr=10.244.0.0/16 --skip-preflight-checks  安装 flannel kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml  flannel 各节点开端口\nhttps://github.com/coreos/flannel/blob/476abd9ef37e7111a1268c41afbd7154046b492a/Documentation/troubleshooting.md#firewalls\nufw allow 8472  测试 ping 各pod 的 IP\nkubeadm join 看 kubeadm-join.rst\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-login-failure.html",
	"title": "docker 登陆失败",
	"tags": ["docker", "registry", "login"],
	"description": "",
	"content": " login failure - 代理问题 root@km:~/dockerRegistry# docker login reg.jlch.com:5000 Username (zimug): Password: Error response from daemon: Get https://reg.jlch.com:5000/v1/users/: EOF root@km:~/dockerRegistry# vi /lib/systemd/system/docker.service  重点把 reg.jlch.com 加入 Environment 中。\nroot@km:~# cat /lib/systemd/system/docker.service [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network.target docker.socket firewalld.service Requires=docker.socket [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker Environment=\u0026quot;HTTP_PROXY=http://192.168.31.239:8118/\u0026quot; \u0026quot;HTTPS_PROXY=http://192.168.31.239:8118/\u0026quot; \u0026quot;NO_PROXY=localhost,127.0.0.1,docker.io,reg.jlch.com\u0026quot; ExecStart=/usr/bin/dockerd -H fd:// ExecReload=/bin/kill -s HUP $MAINPID LimitNOFILE=1048576 # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNPROC=infinity LimitCORE=infinity # Uncomment TasksMax if your systemd version supports it. # Only systemd 226 and above support this version. TasksMax=infinity TimeoutStartSec=0 # set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes # kill only the docker process, not all processes in the cgroup KillMode=process [Install] WantedBy=multi-user.target root@km:~#  重启docker\n root@km:~/dockerRegistry# systemctl daemon-reload root@km:~/dockerRegistry# systemctl restart docker.service root@km:~/dockerRegistry# docker login reg.jlch.com:5000 Username (zimug): Password: Login Succeeded root@km:~/dockerRegistry#\n "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/shane-sveller-blog-about-ox-hugo.html",
	"title": "shane sveller blog 笔记",
	"tags": ["org", "ox-hugo"],
	"description": "",
	"content": " notes Blogging with org-mode and ox-hugo 这篇文章，写得很好，主要讲了下面几点。\n install Global settings and metadatad STARTUP: content AUTHOR: Shane Sveller HUGO_BASE_DIR: . HUGO_AUTO_SET_LASTMOD: t Creating posts Setup hugo project category and tag. Excluding/heading sub-headings from export（it’s a :noexport: tag） Automatic export on save Marking a post as a Draft Optional: Live reload without a separate shell tab Emacs Lisp Snippets  其中几个说明一下。\nAutomatic export on save  * Footnotes * COMMENT Local Variables :ARCHIVE: # Local Variables: # eval: (add-hook 'after-save-hook #'org-hugo-export-wim-to-md :append :local) # eval: (auto-fill-mode 1) # End:   其中，查一下函数（SPC h d f) 知道，要把 org-hugo-export-wim-to-md-after-save 修改成 org-hugo-export-wim-to-md。\nMarking a post as a Draft 把文章的标题，设置为 TODO 。就可以了。\n所以，要忽略文章，或者说草稿部分，就2种方法:\n 文章：设置为 TODO 文章中的某部分：设置 :noexport: tag  Optional: Live reload without a separate shell tab (prodigy-define-service :name \u0026quot;Hugo Server beautifulhugo\u0026quot; :command \u0026quot;/usr/local/bin/hugo\u0026quot; :args '(\u0026quot;server\u0026quot; \u0026quot;-D\u0026quot; \u0026quot;--navigateToChanged\u0026quot; \u0026quot;-t\u0026quot; \u0026quot;beautifulhugo\u0026quot;) :cwd \u0026quot;~/******jc-hugo\u0026quot; :tags '(hugo server) :stop-signal 'sigkill :init (lambda () (browse-url \u0026quot;http://localhost:1313\u0026quot;)) :kill-process-buffer-on-stop t)  其中 Emacs Lisp Snippets 的功能，已经通过 `:init (lambda () (browse-url \u0026ldquo;http://localhost:1313\u0026rdquo;))`实现了。\nRef  https://www.shanesveller.com/blog/2018/02/13/blogging-with-org-mode-and-ox-hugo/ https://ox-hugo.scripter.co/doc/auto-export-on-saving/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-filesystem-quick-start.html",
	"title": "ceph-install-base-ubuntu Filesystem Quick Start",
	"tags": ["ceph", "install", "ubuntu"],
	"description": "",
	"content": " http://docs.ceph.com/docs/master/start/quick-cephfs/\nPREREQUISITES admin 节点：\nceph -s  看一下，是不是都正常。 这里是看不到 mds 的，要看，要去 moniter 节点\nmoniter 节点： 我们环境的是 192.168.31.114\ncephu@mon1:~$ ps -ef | grep ceph root 7541 7227 0 Oct23 pts/0 00:00:00 su - cephu cephu 7542 7541 0 Oct23 pts/0 00:00:00 -su cephu 20793 7542 0 12:39 pts/0 00:00:00 ps -ef cephu 20794 7542 0 12:39 pts/0 00:00:00 grep --color=auto ceph ceph 21275 1 0 Oct23 ? 00:07:50 /usr/bin/ceph-mon -f --cluster ceph --id mon1 --setuser ceph --setgroup ceph ceph 22756 1 0 Oct24 ? 00:03:30 /usr/bin/ceph-mgr -f --cluster ceph --id mon1 --setuser ceph --setgroup ceph ceph 25536 1 0 Oct24 ? 00:04:25 /usr/bin/ceph-osd -f --cluster ceph --id 0 --setuser ceph --setgroup ceph ceph 26870 1 0 Oct24 ? 00:00:30 /usr/bin/ceph-mds -f --cluster ceph --id node1 --setuser ceph --setgroup ceph ceph 29545 1 0 Oct24 ? 00:03:06 /usr/bin/radosgw -f --cluster ceph --name client.rgw.node1 --setuser ceph --setgroup ceph cephu@mon1:~$ cephu@mon1:~$ ps -ef | grep ceph | grep mds cephu 21152 7542 0 12:45 pts/0 00:00:00 grep --color=auto mds ceph 26870 1 0 Oct24 ? 00:00:30 /usr/bin/ceph-mds -f --cluster ceph --id node1 --setuser ceph --setgroup ceph cephu@mon1:~$  CREATE A FILESYSTEM admin 节点：\ncephu@cephadmin:~/my-cluster$ ceph osd pool create cephfs_data 8 pool 'cephfs_data' created cephu@cephadmin:~/my-cluster$ ceph osd pool create cephfs_metadata 8 pool 'cephfs_metadata' created cephu@cephadmin:~/my-cluster$ ceph fs new cephfs-jlch cephfs_metadata cephfs_data new fs with metadata pool 8 and data pool 7 cephu@cephadmin:~/my-cluster$ ceph fs ls name: cephfs-jlch, metadata pool: cephfs_metadata, data pools: [cephfs_data ] cephu@cephadmin:~/my-cluster$ cephu@cephadmin:~/my-cluster$ ceph mds stat cephfs-jlch-1/1/1 up {0=node1=up:active} cephu@cephadmin:~/my-cluster$  CREATE A SECRET FILE admin 节点：\ncephu@cephadmin:~/my-cluster$ cat ceph.client.admin.keyring [client.admin] key = AQCtj+5ZnNTvGRAA2RxAGcIQZJnaJSPEz4jdGw== cephu@cephadmin:~/my-cluster$ echo \u0026quot;AQCtj+5ZnNTvGRAA2RxAGcIQZJnaJSPEz4jdGw==\u0026quot; \u0026gt; admin.secret cephu@cephadmin:~/my-cluster$ ls admin.secret ceph.bootstrap-osd.keyring ceph.conf testfile.txt ceph.bootstrap-mds.keyring ceph.bootstrap-rgw.keyring ceph-deploy-ceph.log ceph.bootstrap-mgr.keyring ceph.client.admin.keyring ceph.mon.keyring cephu@cephadmin:~/my-cluster$ cat admin.secret AQCtj+5ZnNTvGRAA2RxAGcIQZJnaJSPEz4jdGw== cephu@cephadmin:~/my-cluster$  KERNEL DRIVER cephu@cephadmin:~/my-cluster$ sudo mkdir /mnt/mycephfs cephu@cephadmin:~/my-cluster$ sudo mount -t ceph 192.168.31.114:6789:/ /mnt/mycephfs mount error 22 = Invalid argument cephu@cephadmin:~/my-cluster$ sudo mount -t ceph 192.168.31.114:6789:/ /mnt/mycephfs -o name=admin,secretfile=admin.secret cephu@cephadmin:~/my-cluster$  如下可以看出， cephfs 将3个物理节点上的磁盘全部空间（82G = 16G + 16G + 50G）作为了自己的空间。\ncephu@cephadmin:~/my-cluster$ df -h Filesystem Size Used Avail Use% Mounted on udev 3.9G 0 3.9G 0% /dev tmpfs 799M 79M 720M 10% /run /dev/mapper/ubuntu--vg-root 71G 4.7G 62G 8% / tmpfs 3.9G 0 3.9G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/loop0 84M 84M 0 100% /snap/core/3017 /dev/loop2 82M 82M 0 100% /snap/core/2898 /dev/sda1 472M 58M 391M 13% /boot tmpfs 799M 0 799M 0% /run/user/1000 /dev/loop3 84M 84M 0 100% /snap/core/3247 192.168.31.114:6789:/ 82G 4.2G 78G 6% /mnt/mycephfs cephu@cephadmin:~/my-cluster$  FILESYSTEM IN USER SPACE (FUSE) cephu@cephadmin:~/my-cluster$ sudo ceph-fuse -k ./ceph.client.admin.keyring -m 192.168.31.114:6789 ~/mycephfs sudo: ceph-fuse: command not found cephu@cephadmin:~/my-cluster$  没有这个命令。\n农总这个时候，让我去 ceph-client 节点\nceph-client 节点：\ncephu@ceph-client:~$ which ceph-fuse cephu@ceph-client:~$ apt search ceph-fuse Sorting... Done Full Text Search... Done ceph-fuse/stable 10.2.10-1xenial amd64 FUSE-based client for the Ceph distributed file system ceph-fuse-dbg/stable 10.2.10-1xenial amd64 debugging symbols for ceph-fuse cephu@ceph-client:~$ sudo apt install ceph-fuse Reading package lists... Done Building dependency tree Reading state information... Done The following packages were automatically installed and are no longer required: libboost-program-options1.58.0 libboost-random1.58.0 libboost-regex1.58.0 libcephfs1 libfcgi0ldbl libllvm3.8 libmircommon5 linux-headers-4.4.0-31 linux-headers-4.4.0-31-generic linux-image-4.4.0-31-generic linux-image-extra-4.4.0-31-generic Use 'sudo apt autoremove' to remove them. The following NEW packages will be installed: ceph-fuse 0 upgraded, 1 newly installed, 0 to remove and 48 not upgraded. Need to get 2,926 kB of archives. After this operation, 7,873 kB of additional disk space will be used. Get:1 https://download.ceph.com/debian-jewel xenial/main amd64 ceph-fuse amd64 10.2.10-1xenial [2,926 kB] Fetched 2,926 kB in 20s (145 kB/s) Selecting previously unselected package ceph-fuse. (Reading database ... 152232 files and directories currently installed.) Preparing to unpack .../ceph-fuse_10.2.10-1xenial_amd64.deb ... Unpacking ceph-fuse (10.2.10-1xenial) ... Processing triggers for man-db (2.7.5-1) ... Setting up ceph-fuse (10.2.10-1xenial) ... cephu@ceph-client:~$ sudo mkdir ~/mycephfs cephu@ceph-client:~$ sudo ceph-fuse -m 192.168.31.114:6789 ~/mycephfs ceph-fuse[28422]: starting ceph client 2017-10-25 14:10:35.041539 7fb1f6430f00 -1 init, newargv = 0x5608ad4acf60 newargc=11 ceph-fuse[28422]: starting fuse cephu@ceph-client:~$  可以了，成功了。\n看一下状态\ncephu@ceph-client:~$ ceph mds stat cephfs-jlch-1/1/1 up {0=node1=up:active} cephu@ceph-client:~$ df -h Filesystem Size Used Avail Use% Mounted on udev 3.9G 0 3.9G 0% /dev tmpfs 799M 9.0M 790M 2% /run /dev/mapper/ubuntu--vg-root 35G 4.2G 29G 13% / tmpfs 3.9G 528K 3.9G 1% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/sda1 472M 153M 295M 35% /boot tmpfs 799M 0 799M 0% /run/user/113 tmpfs 799M 0 799M 0% /run/user/1000 /dev/rbd0 3.9G 8.0M 3.8G 1% /mnt/ceph-block-device ceph-fuse 82G 4.2G 78G 6% /home/cephu/mycephfs cephu@ceph-client:~$  ADDITIONAL INFORMATION 这里没有什么了。\n测试一下 回到 admin 节点吧。\ncephu@cephadmin:~/my-cluster$ df -h Filesystem Size Used Avail Use% Mounted on udev 3.9G 0 3.9G 0% /dev tmpfs 799M 79M 720M 10% /run /dev/mapper/ubuntu--vg-root 71G 4.7G 62G 8% / tmpfs 3.9G 0 3.9G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/loop0 84M 84M 0 100% /snap/core/3017 /dev/loop2 82M 82M 0 100% /snap/core/2898 /dev/sda1 472M 58M 391M 13% /boot tmpfs 799M 0 799M 0% /run/user/1000 /dev/loop3 84M 84M 0 100% /snap/core/3247 192.168.31.114:6789:/ 82G 4.2G 78G 6% /mnt/mycephfs cephu@cephadmin:~/my-cluster$ touch /mnt/mycephfs/h.txt touch: cannot touch '/mnt/mycephfs/h.txt': Permission denied cephu@cephadmin:~/my-cluster$  为什么这样子？？？ Permission denied 这不是玩我么？\ncephu@cephadmin:~/my-cluster$ sudo touch /mnt/mycephfs/h.txt cephu@cephadmin:~/my-cluster$ sudo vi /mnt/mycephfs/h.txt cephu@cephadmin:~/my-cluster$ sudo ls -l /mnt/mycephfs/ total 1 -rw-r--r-- 1 root root 14 Oct 25 14:33 h.txt  那直接修改目录权限。\ncephu@cephadmin:~/my-cluster$ sudo chown -R cephu:cephu /mnt/mycephfs/ cephu@cephadmin:~/my-cluster$ touch /mnt/mycephfs/a.txt cephu@cephadmin:~/my-cluster$ echo \u0026quot;hello, world\u0026quot; \u0026gt; /mnt/mycephfs/b.txt cephu@cephadmin:~/my-cluster$ cat /mnt/mycephfs/b.txt hello, world cephu@cephadmin:~/my-cluster$ sudo ls -l /mnt/mycephfs/ total 1 -rw-rw-r-- 1 cephu cephu 0 Oct 25 14:34 a.txt -rw-rw-r-- 1 cephu cephu 2 Oct 25 14:35 b.txt -rw-r--r-- 1 cephu cephu 14 Oct 25 14:33 h.txt cephu@cephadmin:~/my-cluster$  好了。这下成功了。\n再回到 ceph-client 下测试吧（因为其下的 mount 方式不同，是 ceph-fuse，也测试一下咯）。\nceph-client节点：\ncephu@ceph-client:~$ ls mycephfs/ a.txt b.txt h.txt  文件是看到了。 创建一下。\ncephu@ceph-client:~$ echo \u0026quot;c\u0026quot; \u0026gt; mycephfs/b.txt cephu@ceph-client:~$ cat mycephfs/b.txt c cephu@ceph-client:~$  OK。成功。\numount 到我们这个文档结束的时候，记得要 umount 一下哟。（这里只写 admin节点了，ceph-client节点是一样样的。）\nadmin:\ncephu@cephadmin:~/my-cluster$ sudo umount /mnt/mycephfs  检查一下：\ncephu@cephadmin:~/my-cluster$ mount sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime) proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) udev on /dev type devtmpfs (rw,nosuid,relatime,size=4067352k,nr_inodes=1016838,mode=755) devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000) tmpfs on /run type tmpfs (rw,nosuid,noexec,relatime,size=817512k,mode=755) /dev/mapper/ubuntu--vg-root on / type ext4 (rw,relatime,errors=remount-ro,data=ordered) securityfs on /sys/kernel/security type securityfs (rw,nosuid,nodev,noexec,relatime) tmpfs on /dev/shm type tmpfs (rw,nosuid,nodev) tmpfs on /run/lock type tmpfs (rw,nosuid,nodev,noexec,relatime,size=5120k) tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755) cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd) pstore on /sys/fs/pstore type pstore (rw,nosuid,nodev,noexec,relatime) cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event) cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio) cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio) cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct) cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer) cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory) cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices) cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids) cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb) cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset) systemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=27,pgrp=1,timeout=0,minproto=5,maxproto=5,direct) mqueue on /dev/mqueue type mqueue (rw,relatime) hugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime) debugfs on /sys/kernel/debug type debugfs (rw,relatime) fusectl on /sys/fs/fuse/connections type fusectl (rw,relatime) /var/lib/snapd/snaps/core_3017.snap on /snap/core/3017 type squashfs (ro,nodev,relatime) /var/lib/snapd/snaps/core_2898.snap on /snap/core/2898 type squashfs (ro,nodev,relatime) /dev/sda1 on /boot type ext2 (rw,relatime,block_validity,barrier,user_xattr,acl) lxcfs on /var/lib/lxcfs type fuse.lxcfs (rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other) /dev/mapper/ubuntu--vg-root on /var/lib/docker/aufs type ext4 (rw,relatime,errors=remount-ro,data=ordered) tmpfs on /run/user/1000 type tmpfs (rw,nosuid,nodev,relatime,size=817512k,mode=700,uid=1000,gid=1000) /var/lib/snapd/snaps/core_3247.snap on /snap/core/3247 type squashfs (ro,nodev,relatime) tmpfs on /run/snapd/ns type tmpfs (rw,nosuid,noexec,relatime,size=817512k,mode=755) nsfs on /run/snapd/ns/core.mnt type nsfs (rw) cephu@cephadmin:~/my-cluster$  确实没有了。安心。\n到此，应该这一小节结束。 喝杯水，压压惊！~~~~~~~~~~\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-deployment-faq.html",
	"title": "kubernetes中cephfs的deployment的FAQ",
	"tags": ["kubernetes", "ceph", "cephfs", "faq"],
	"description": "",
	"content": " k8s cephfs 在 deployment.yaml 中的使用 Environment k8s-master 192.168.31.120 km master k8s-node1 192.168.31.119 kn1 node1 k8s-node2 192.168.31.118 kn2 node2  配置 deployment.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: cephfs-provisioner spec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: cephfs-provisioner spec: containers: - name: cephfs-provisioner image: \u0026quot;quay.io/external_storage/cephfs-provisioner:latest\u0026quot; # 对应 镜像 imagePullPolicy: IfNotPresent env: - name: PROVISIONER_NAME valueFrom: configMapKeyRef: key: provisioner.name name: cephfs-provisioner command: # 这里对应 命令 - \u0026quot;/usr/local/bin/cephfs-provisioner\u0026quot; args: # 这里对应三个参数 - \u0026quot;-id=cephfs-provisioner-1\u0026quot; - \u0026quot;-master=https://10.96.0.1/\u0026quot; - \u0026quot;-kubeconfig=/kube/admin.conf\u0026quot; volumeMounts: # 对应 -v - mountPath: /kube name: kube-config - mountPath: /var/run/kubernetes name: kube-run-env volumes: - name: kube-config hostPath: # directory location on host path: /home/jlch # this field is optional type: Directory - name: kube-run-env hostPath: # directory location on host path: /var/run/kubernetes # this field is optional type: Directory  对应于\n方法1 docker\ndocker run -ti -v /home/jlch:/kube -v /var/run/kubernetes:/var/run/kubernetes --privileged --net=host quay.io/external_storage/cephfs-provisioner /usr/local/bin/cephfs-provisioner -master=https://10.96.0.1/ -kubeconfig=/kube/admin.conf -id=cephfs-provisioner-1  apply jlch@km:~/cephfs$ k apply -f deployment.yaml deployment \u0026quot;cephfs-provisioner\u0026quot; created jlch@km:~/cephfs$ k get pods NAME READY STATUS RESTARTS AGE cephfs-provisioner-cff8d95c-8b498 0/1 ContainerCreating 0 3s  describe 报错了\njlch@km:~/cephfs$ k describe pod cephfs-provisioner-cff8d95c-8b498 Name: cephfs-provisioner-cff8d95c-8b498 Namespace: default Node: kn1/192.168.31.119 Start Time: Fri, 24 Nov 2017 11:13:06 +0800 Labels: app=cephfs-provisioner pod-template-hash=79948517 Annotations: kubernetes.io/created-by={\u0026quot;kind\u0026quot;:\u0026quot;SerializedReference\u0026quot;,\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;reference\u0026quot;:{\u0026quot;kind\u0026quot;:\u0026quot;ReplicaSet\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;,\u0026quot;name\u0026quot;:\u0026quot;cephfs-provisioner-cff8d95c\u0026quot;,\u0026quot;uid\u0026quot;:\u0026quot;645fa2f3-d0c5-11e7-85d4-000c... Status: Pending IP: Created By: ReplicaSet/cephfs-provisioner-cff8d95c Controlled By: ReplicaSet/cephfs-provisioner-cff8d95c Containers: cephfs-provisioner: Container ID: Image: quay.io/external_storage/cephfs-provisioner:latest Image ID: Port: \u0026lt;none\u0026gt; Command: /usr/local/bin/cephfs-provisioner Args: -id=cephfs-provisioner-1 -master=https://10.96.0.1/ -kubeconfig=/kube/admin.conf State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: PROVISIONER_NAME: \u0026lt;set to the key 'provisioner.name' of config map 'cephfs-provisioner'\u0026gt; Optional: false Mounts: /kube from kube-config (rw) /var/run/kubernetes from kube-run-env (rw) /var/run/secrets/kubernetes.io/serviceaccount from default-token-np6qz (ro) Conditions: Type Status Initialized True Ready False PodScheduled True Volumes: kube-config: Type: HostPath (bare host directory volume) Path: /home/jlch kube-run-env: Type: HostPath (bare host directory volume) Path: /var/run/kubernetes default-token-np6qz: Type: Secret (a volume populated by a Secret) SecretName: default-token-np6qz Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.alpha.kubernetes.io/notReady:NoExecute for 300s node.alpha.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 20s default-scheduler Successfully assigned cephfs-provisioner-cff8d95c-8b498 to kn1 Normal SuccessfulMountVolume 19s kubelet, kn1 MountVolume.SetUp succeeded for volume \u0026quot;kube-run-env\u0026quot; Normal SuccessfulMountVolume 19s kubelet, kn1 MountVolume.SetUp succeeded for volume \u0026quot;kube-config\u0026quot; Normal SuccessfulMountVolume 19s kubelet, kn1 MountVolume.SetUp succeeded for volume \u0026quot;default-token-np6qz\u0026quot; Warning FailedCreatePodSandBox 12s (x7 over 18s) kubelet, kn1 Failed create pod sandbox. Warning FailedSync 11s (x8 over 18s) kubelet, kn1 Error syncing pod Normal SandboxChanged 11s (x7 over 17s) kubelet, kn1 Pod sandbox changed, it will be killed and re-created. jlch@km:~/cephfs$  看到了吧。是 部署在 kn1 上的时候，报出 Failed create pod sandbox. 错误来了。 那就要去 kn1 上查看日志了。\nroot@kn1:~# vi /var/log/syslog ... # 查找 ceph Nov 24 09:09:19 kn1 systemd-udevd[23014]: Could not generate persistent MAC address for vethf620eecc: No such file or directory Nov 24 09:09:19 kn1 kubelet[6008]: E1124 09:09:19.678998 6008 cni.go:301] Error adding network: \u0026quot;cni0\u0026quot; already has an IP address different from 10.244.1.1/24 Nov 24 09:09:19 kn1 kubelet[6008]: E1124 09:09:19.679048 6008 cni.go:250] Error while adding to cni network: \u0026quot;cni0\u0026quot; already has an IP address different from 10.244.1.1/24 Nov 24 09:09:19 kn1 kernel: [1788519.065714] cni0: port 1(vethf620eecc) entered disabled state ...  查找关键字 ceph， 找到了上面的信息，明显是与 cni0 相关。这上面讲了，\u0026rdquo;cni0\u0026rdquo; already has an IP address different from 10.244.1.1/24， 也就是说，可能现有已有一个cni0, 但是与kubernetes自动给它分配的ip: 10.244.1.1\u0026frasl;24, 不一致了。 查一下ip,\nroot@kn1:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens160: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:6f:74:6a brd ff:ff:ff:ff:ff:ff inet 192.168.31.119/24 brd 192.168.31.255 scope global ens160 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe6f:746a/64 scope link valid_lft forever preferred_lft forever 3: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:96:2d:2c:25 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:96ff:fe2d:2c25/64 scope link valid_lft forever preferred_lft forever 4: flannel.1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 9e:b7:c9:ed:7e:cb brd ff:ff:ff:ff:ff:ff inet 10.244.2.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::9cb7:c9ff:feed:7ecb/64 scope link valid_lft forever preferred_lft forever 4639: cni0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether 0a:58:0a:f4:02:01 brd ff:ff:ff:ff:ff:ff inet 10.244.2.1/24 scope global cni0 valid_lft forever preferred_lft forever inet6 fe80::b401:beff:fedf:2203/64 scope link valid_lft forever preferred_lft forever 4640: veth3fec5211@if3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue master cni0 state UP group default link/ether 72:3c:c8:35:61:6f brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::703c:c8ff:fe35:616f/64 scope link valid_lft forever preferred_lft forever root@kn1:~#  我去，果然是。这里面的是 10.244.2.1/24。我靠。 怎么办？怎么办？ 修改cni0呗。\n修改 cni0 root@kn1:~# systemctl stop docker root@kn1:~# ip a root@kn1:~# brctl --help root@kn1:~# brctl # 这里会提示怎么安装。 root@kn1:~# apt install bridge-utils root@kn1:~# brctl --help root@kn1:~# ifconfig cni0 down root@kn1:~# brctl delbr cni0 root@kn1:~# ip a root@kn1:~# systemctl start docker root@kn1:~# ip a # 这个时候，docker 启动的 containers 会自动帮助把 cni0 启动起来的。  检查 最后的效果\nroot@kn1:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens160: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:6f:74:6a brd ff:ff:ff:ff:ff:ff inet 192.168.31.119/24 brd 192.168.31.255 scope global ens160 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe6f:746a/64 scope link valid_lft forever preferred_lft forever 3: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:96:2d:2c:25 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:96ff:fe2d:2c25/64 scope link valid_lft forever preferred_lft forever 4: flannel.1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UNKNOWN group default link/ether ba:84:65:bb:4d:68 brd ff:ff:ff:ff:ff:ff inet 10.244.1.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::b884:65ff:febb:4d68/64 scope link valid_lft forever preferred_lft forever 4639: cni0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UP group default qlen 1000 link/ether 0a:58:0a:f4:01:01 brd ff:ff:ff:ff:ff:ff inet 10.244.1.1/24 scope global cni0 valid_lft forever preferred_lft forever inet6 fe80::f48c:7eff:fecd:4e08/64 scope link valid_lft forever preferred_lft forever 4640: veth3fec5211@if3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue master cni0 state UP group default link/ether 72:3c:c8:35:61:6f brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::703c:c8ff:fe35:616f/64 scope link valid_lft forever preferred_lft forever root@kn1:~#  好了，再回到 km ，检查 deployment,\njlch@km:~/cephfs$ k get pods NAME READY STATUS RESTARTS AGE cephfs-provisioner-cff8d95c-6tgcs 1/1 Running 1 3h jlch@km:~/cephfs$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-join.html",
	"title": "kubeadm join",
	"tags": ["kubernetes", "install"],
	"description": "",
	"content": " Environment 已安装 kubeadm, kubelet, kubectl\n安装时，全使用 root 用户。直到 kubeadm join 成功后，全使用 非root用户\n192.168.31.120 km master 192.168.31.119 kn1 node 192.168.31.118 kn2 node  kubeadm join /etc/kubernetes/pki/ca.crt already exists sudo kubeadm join --token ce4253.8322cc2590378260 192.168.31.120:6443 --discovery-token-ca-cert-hash sha256:bb0b9ef27e5ffef06776ca10a87ed548cefedc703ddaf904316c87d4a7f3655d  这个来自于 master节点， kubeadm init 后的提示。\njlch@kn1:~$ sudo kubeadm join --token ce4253.8322cc2590378260 192.168.31.120:6443 --discovery-token-ca-cert-hash sha256:bb0b9ef27e5ffef06776ca10a87ed548cefedc703ddaf904316c87d4a7f3655d [kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters. [preflight] Running pre-flight checks [preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.05.0-ce. Max validated version: 17.03 [preflight] Some fatal errors occurred: /etc/kubernetes/pki/ca.crt already exists /etc/kubernetes/kubelet.conf already exists running with swap on is not supported. Please disable swap [preflight] If you know what you are doing, you can skip pre-flight checks with `--skip-preflight-checks` jlch@kn1:~$ mkdir etc.kubernetes jlch@kn1:~$ mkdir etc.kubernetes/pki/ jlch@kn1:~$ sudo mv /etc/kubernetes/pki/ca.crt etc.kubernetes/pki/ jlch@kn1:~$ sudo mv /etc/kubernetes/kubelet.conf etc.kubernetes/  Please disable swap jlch@kn1:~$ sudo kubeadm join --token ce4253.8322cc2590378260 192.168.31.120:6443 --discovery-token-ca-cert-hash sha256:bb0b9ef27e5ffef06776ca10a87ed548cefedc703ddaf904316c87d4a7f3655d [kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters. [preflight] Running pre-flight checks [preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.05.0-ce. Max validated version: 17.03 [preflight] Some fatal errors occurred: running with swap on is not supported. Please disable swap [preflight] If you know what you are doing, you can skip pre-flight checks with `--skip-preflight-checks` jlch@kn1:~$ sudo swapoff -a  再来 jlch@kn1:~$ sudo kubeadm join --token ce4253.8322cc2590378260 192.168.31.120:6443 --discovery-token-ca-cert-hash sha256:bb0b9ef27e5ffef06776ca10a87ed548cefedc703ddaf904316c87d4a7f3655d [kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters. [preflight] Running pre-flight checks [preflight] WARNING: docker version is greater than the most recently validated version. Docker version: 17.05.0-ce. Max validated version: 17.03 [discovery] Trying to connect to API Server \u0026quot;192.168.31.120:6443\u0026quot; [discovery] Created cluster-info discovery client, requesting info from \u0026quot;https://192.168.31.120:6443\u0026quot; [discovery] Requesting info from \u0026quot;https://192.168.31.120:6443\u0026quot; again to validate TLS against the pinned public key [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \u0026quot;192.168.31.120:6443\u0026quot; [discovery] Successfully established connection with API Server \u0026quot;192.168.31.120:6443\u0026quot; [bootstrap] Detected server version: v1.8.4 [bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1) Node join complete: * Certificate signing request sent to master and response received. * Kubelet informed of new secure connection details. Run 'kubectl get nodes' on the master to see this machine join. jlch@kn1:~$  成功了。\n回 master 检查一下。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-3-notes.html",
	"title": "Spacemacs Rocks Day 3, Emacs as a C/C++ IDE",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " emacs-as-c-ide(youku)\n先看 github的 README.org\n因为我并没有开发C/C++, 所以我这里只记录一下。\n代码跳转 tag 跳转\n , g d\n 精确 跳转\n , g g\n 还有一个\n , g a\n 返回到跳转前\n C-o\n 生成 .ycm_extra_conf.py 文件 TODO 自动生成.ycm_extra_conf.py 文件的程序，会在其github中放出 python config_gen.py ~/Github/Spacemacs-rocks/c++-project  安装ycmd  https://github.com/Valloric/ycmd  Compile?? 推荐使用shell\nDebugging?? 推荐使用 shell + lldb\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/jupyter/jupyter-notebook-login-with-token.html",
	"title": "jupyter-notebook 密码查询",
	"tags": ["python", "notebook"],
	"description": "",
	"content": " 有一些场景，需要连接jupyter-notebook, 这时，需要提供登陆密码.\n这个密码就是 token.\n(py3) ➜ learn-python3 git:(master) ✗ /Users/tomtsang/Downloads/.ana/bin/jupyter-notebook list Currently running servers: http://localhost:8888/?token=b488be28e8f4bdf6f11b3e863ee92896d99c50ed70e67bde :: /Users/tomtsang (py3) ➜ learn-python3 git:(master) ✗  如果是安装的 anaconda ，则在 anaconda 启动 jupyter-notebook 的过程中会提示出这个 token. 如下：\n➜ ~ git:(master) ✗ /Users/tomtsang/Downloads/.ana/bin/jupyter_mac.command ; exit; [I 09:36:46.923 NotebookApp] JupyterLab extension loaded from /Users/tomtsang/Downloads/.ana/lib/python3.7/site-packages/jupyterlab [I 09:36:46.924 NotebookApp] JupyterLab application directory is /Users/tomtsang/Downloads/.ana/share/jupyter/lab [I 09:36:46.931 NotebookApp] Serving notebooks from local directory: /Users/tomtsang [I 09:36:46.931 NotebookApp] The Jupyter Notebook is running at: [I 09:36:46.931 NotebookApp] http://localhost:8888/?token=b488be28e8f4bdf6f11b3e863ee92896d99c50ed70e67bde [I 09:36:46.931 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). [C 09:36:46.936 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=b488be28e8f4bdf6f11b3e863ee92896d99c50ed70e67bde [I 09:36:47.210 NotebookApp] Accepting one-time-token-authenticated connection from ::1  第6行中的 `http://localhost:8888/?token=b488be28e8f4bdf6f11b3e863ee92896d99c50ed70e67bde` 就是地址和token了。\nRef  https://blog.csdn.net/e35t66/article/details/76274714  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-block-device-quick-start.html",
	"title": "ceph-install-base-ubuntu Block Device Quick Start",
	"tags": ["ceph", "install", "ubuntu"],
	"description": "",
	"content": " env 192.168.31.172 ceph-client\n修改 hostname 为 ceph-client\nINSTALL CEPH admin 节点：\nceph-deploy install ceph-client ceph-deploy admin ceph-client  ceph-client 节点：\nsudo chmod +r /etc/ceph/ceph.client.admin.keyring  CREATE A BLOCK DEVICE POOL admin 节点：\n原来在 admin 节点，是没有这个 rbd 命令的。\n要通过 sudo apt install ceph-common 之后，才会有。所以先运行一下。\ncephu@cephadmin:~/my-cluster$ sudo apt install ceph-common -y cephu@cephadmin:~/my-cluster$ rbd pool init jlch 2017-10-24 15:57:45.951917 7fde4fa6e0c0 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.admin.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory 2017-10-24 15:57:45.951937 7fde4fa6e0c0 -1 monclient: ERROR: missing keyring, cannot use cephx for authentication 2017-10-24 15:57:45.951942 7fde4fa6e0c0 0 librados: client.admin initialization error (2) No such file or directory rbd: couldn't connect to the cluster! cephu@cephadmin:~/my-cluster$  ceph-client 节点：\njlch@k-m:/etc/apt/sources.list.d$ sudo ls /etc/ceph/* -l [sudo] password for jlch: -rw-r--r-- 1 root root 63 Oct 24 15:32 /etc/ceph/ceph.client.admin.keyring -rw-r--r-- 1 root root 249 Oct 24 15:32 /etc/ceph/ceph.conf -rw-r--r-- 1 root root 92 Apr 21 2017 /etc/ceph/rbdmap -rw------- 1 root root 0 Oct 24 11:20 /etc/ceph/tmp2IJh4C jlch@k-m:/etc/apt/sources.list.d$  我去，明明有的，为什么说 unable to find a keyring on *******，哪里出的问题?\n哈哈，这个问题的原因找到了。需要把 上一小节的 最后一个部分，执行一下。\n而且，要按上一小节的方式，osd create 一个 pool 出来，才能在这里 pool init .\n比如之前就是创建了 pool mytest. 这里就是\nrbd pool init mytest  CONFIGURE A BLOCK DEVICE On the ceph-client node\ncephu@ceph-client:~$ rbd create mytest --size 4096 -m mon1 -k /etc/ceph/ceph.client.admin.keyring rbd: error opening default pool 'rbd' Ensure that the default pool has been created or specify an alternate pool name. cephu@ceph-client:~$  报错，因为，这里说了，opening default pool \u0026lsquo;rbd\u0026rsquo; 出错，为啥？因为之前没有建立过 pool rbd 呀，之前，只有 pool mytest 呀。 怎么办？2个方法。1）重新新建立一个 pool rbd, 2）指向到已建立的pool, 如 pool mytest 。\n我们走 方法2.\n方法1\n回 ceph-admin 节点：\ncephu@cephadmin:~/my-cluster$ ceph osd pool create rbd 8 pool 'rbd' created cephu@cephadmin:~/my-cluster$ rbd pool init rbd cephu@cephadmin:~/my-cluster$  回 ceph-client 节点：\ncephu@ceph-client:~$ rbd create foo --size 4096 -m mon1 -k /etc/ceph/ceph.client.admin.keyring  方法2\ncephu@ceph-client:~$ rbd help create # 这里会发现是加 -p 参数来指定 pool cephu@ceph-client:~$ rbd create foo --size 4096 -m mon1 -k /etc/ceph/ceph.client.admin.keyring -p mytest cephu@ceph-client:~$  好了，可以走下一步了。 我们继续。\nOn the ceph-client node, map the image to a block device.\ncephu@ceph-client:~$ sudo rbd map foo --image client.admin -m mon1 -p mytest rbd: sysfs write failed rbd: error opening image client.admin: (2) No such file or directory In some cases useful info is found in syslog - try \u0026quot;dmesg | tail\u0026quot;. rbd: map failed: (110) Connection timed out cephu@ceph-client:~$  报错了。\ncephu@ceph-client:~$ dmesg | tail -n 100 ... [692522.117250] libceph: mon0 192.168.31.114:6789 missing required protocol features [692532.096436] libceph: mon0 192.168.31.114:6789 feature set mismatch, my 106b84a842a42 \u0026lt; server's 40106b84a842a42, missing 400000000000000 [692532.099897] libceph: mon0 192.168.31.114:6789 missing required protocol features [692542.111938] libceph: mon0 192.168.31.114:6789 feature set mismatch, my 106b84a842a42 \u0026lt; server's 40106b84a842a42, missing 400000000000000 [692542.115603] libceph: mon0 192.168.31.114:6789 missing required protocol features  http://www.hl10502.com/2017/08/01/ceph-rbdmap-error-1/\n上面有一些详细的原理\n又要农总出马了。\nhttp://blog.csdn.net/lk142500/article/details/78275910\n这里指出了解决方法。来吧。\nadmin 节点\ncephu@cephadmin:~/my-cluster$ ceph -v ceph version 12.2.1 (3e7492b9ada8bdc9a5cd0feafd42fbca27f9c38e) luminous (stable) cephu@cephadmin:~/my-cluster$ ceph osd crush tunables optimal adjusted tunables profile to optimal cephu@cephadmin:~/my-cluster$ ceph osd crush rule ls replicated_rule cephu@cephadmin:~/my-cluster$ ceph osd crush rule dump [ { \u0026quot;rule_id\u0026quot;: 0, \u0026quot;rule_name\u0026quot;: \u0026quot;replicated_rule\u0026quot;, \u0026quot;ruleset\u0026quot;: 0, \u0026quot;type\u0026quot;: 1, \u0026quot;min_size\u0026quot;: 1, \u0026quot;max_size\u0026quot;: 10, \u0026quot;steps\u0026quot;: [ { \u0026quot;op\u0026quot;: \u0026quot;take\u0026quot;, \u0026quot;item\u0026quot;: -1, \u0026quot;item_name\u0026quot;: \u0026quot;default\u0026quot; }, { \u0026quot;op\u0026quot;: \u0026quot;chooseleaf_firstn\u0026quot;, \u0026quot;num\u0026quot;: 0, \u0026quot;type\u0026quot;: \u0026quot;host\u0026quot; }, { \u0026quot;op\u0026quot;: \u0026quot;emit\u0026quot; } ] } ] cephu@cephadmin:~/my-cluster$ ceph osd crush show-tunables { \u0026quot;choose_local_tries\u0026quot;: 0, \u0026quot;choose_local_fallback_tries\u0026quot;: 0, \u0026quot;choose_total_tries\u0026quot;: 50, \u0026quot;chooseleaf_descend_once\u0026quot;: 1, \u0026quot;chooseleaf_vary_r\u0026quot;: 1, \u0026quot;chooseleaf_stable\u0026quot;: 1, \u0026quot;straw_calc_version\u0026quot;: 1, \u0026quot;allowed_bucket_algs\u0026quot;: 54, \u0026quot;profile\u0026quot;: \u0026quot;jewel\u0026quot;, \u0026quot;optimal_tunables\u0026quot;: 1, \u0026quot;legacy_tunables\u0026quot;: 0, \u0026quot;minimum_required_version\u0026quot;: \u0026quot;jewel\u0026quot;, \u0026quot;require_feature_tunables\u0026quot;: 1, \u0026quot;require_feature_tunables2\u0026quot;: 1, \u0026quot;has_v2_rules\u0026quot;: 0, \u0026quot;require_feature_tunables3\u0026quot;: 1, \u0026quot;has_v3_rules\u0026quot;: 0, \u0026quot;has_v4_buckets\u0026quot;: 1, \u0026quot;require_feature_tunables5\u0026quot;: 1, \u0026quot;has_v5_rules\u0026quot;: 0 } cephu@cephadmin:~/my-cluster$ ceph osd crush -h General usage: ============== usage: ceph [-h] [-c CEPHCONF] [-i INPUT_FILE] [-o OUTPUT_FILE] [--id CLIENT_ID] [--name CLIENT_NAME] [--cluster CLUSTER] [--admin-daemon ADMIN_SOCKET] [-s] [-w] [--watch-debug] [--watch-info] [--watch-sec] [--watch-warn] [--watch-error] [--watch-channel WATCH_CHANNEL] [--version] [--verbose] [--concise] [-f {json,json-pretty,xml,xml-pretty,plain}] [--connect-timeout CLUSTER_TIMEOUT] Ceph administration tool optional arguments: -h, --help request mon help -c CEPHCONF, --conf CEPHCONF ceph configuration file -i INPUT_FILE, --in-file INPUT_FILE input file, or \u0026quot;-\u0026quot; for stdin -o OUTPUT_FILE, --out-file OUTPUT_FILE output file, or \u0026quot;-\u0026quot; for stdout --id CLIENT_ID, --user CLIENT_ID client id for authentication --name CLIENT_NAME, -n CLIENT_NAME client name for authentication --cluster CLUSTER cluster name --admin-daemon ADMIN_SOCKET submit admin-socket commands (\u0026quot;help\u0026quot; for help -s, --status show cluster status -w, --watch watch live cluster changes --watch-debug watch debug events --watch-info watch info events --watch-sec watch security events --watch-warn watch warn events --watch-error watch error events --watch-channel WATCH_CHANNEL which log channel to follow when using -w/--watch. One of ['cluster', 'audit', '*' --version, -v display version --verbose make verbose --concise make less verbose -f {json,json-pretty,xml,xml-pretty,plain}, --format {json,json-pretty,xml,xml-pretty,plain} --connect-timeout CLUSTER_TIMEOUT set a timeout for connecting to the cluster Local commands: =============== ping \u0026lt;mon.id\u0026gt; Send simple presence/life test to a mon \u0026lt;mon.id\u0026gt; may be 'mon.*' for all mons daemon {type.id|path} \u0026lt;cmd\u0026gt; Same as --admin-daemon, but auto-find admin socket daemonperf {type.id | path} [stat-pats] [priority] [\u0026lt;interval\u0026gt;] [\u0026lt;count\u0026gt;] daemonperf {type.id | path} list|ls [stat-pats] [priority] Get selected perf stats from daemon/admin socket Optional shell-glob comma-delim match string stat-pats Optional selection priority (can abbreviate name): critical, interesting, useful, noninteresting, debug List shows a table of all available stats Run \u0026lt;count\u0026gt; times (default forever), once per \u0026lt;interval\u0026gt; seconds (default 1) Monitor commands: ================= osd crush add \u0026lt;osdname (id|osd.id)\u0026gt; \u0026lt;float[0.0-]\u0026gt; \u0026lt;args\u0026gt; [\u0026lt;args\u0026gt;...] add or update crushmap position and weight for \u0026lt;name\u0026gt; with \u0026lt;weight\u0026gt; and location \u0026lt;args\u0026gt; osd crush add-bucket \u0026lt;name\u0026gt; \u0026lt;type\u0026gt; add no-parent (probably root) crush bucket \u0026lt;name\u0026gt; of type \u0026lt;type\u0026gt; osd crush class ls list all crush device classes osd crush class ls-osd \u0026lt;class\u0026gt; list all osds belonging to the specific \u0026lt;class\u0026gt; osd crush class rename \u0026lt;srcname\u0026gt; \u0026lt;dstname\u0026gt; rename crush device class \u0026lt;srcname\u0026gt; to \u0026lt;dstname\u0026gt; osd crush create-or-move \u0026lt;osdname (id|osd.id)\u0026gt; \u0026lt;float[0.0-]\u0026gt; \u0026lt;args\u0026gt; [\u0026lt;args\u0026gt;...] create entry or move existing entry for \u0026lt;name\u0026gt; \u0026lt;weight\u0026gt; at/to location \u0026lt;args\u0026gt; osd crush dump dump crush map osd crush get-tunable straw_calc_version get crush tunable \u0026lt;tunable\u0026gt; osd crush link \u0026lt;name\u0026gt; \u0026lt;args\u0026gt; [\u0026lt;args\u0026gt;...] link existing entry for \u0026lt;name\u0026gt; under location \u0026lt;args\u0026gt; osd crush ls \u0026lt;node\u0026gt; list items beneath a node in the CRUSH tree osd crush move \u0026lt;name\u0026gt; \u0026lt;args\u0026gt; [\u0026lt;args\u0026gt;...] move existing entry for \u0026lt;name\u0026gt; to location \u0026lt;args\u0026gt; osd crush remove \u0026lt;name\u0026gt; {\u0026lt;ancestor\u0026gt;} remove \u0026lt;name\u0026gt; from crush map (everywhere, or just at \u0026lt;ancestor\u0026gt;) osd crush rename-bucket \u0026lt;srcname\u0026gt; \u0026lt;dstname\u0026gt; rename bucket \u0026lt;srcname\u0026gt; to \u0026lt;dstname\u0026gt; osd crush reweight \u0026lt;name\u0026gt; \u0026lt;float[0.0-]\u0026gt; change \u0026lt;name\u0026gt;'s weight to \u0026lt;weight\u0026gt; in crush map osd crush reweight-all recalculate the weights for the tree to ensure they sum correctly osd crush reweight-subtree \u0026lt;name\u0026gt; \u0026lt;float[0.0-]\u0026gt; change all leaf items beneath \u0026lt;name\u0026gt; to \u0026lt;weight\u0026gt; in crush map osd crush rm \u0026lt;name\u0026gt; {\u0026lt;ancestor\u0026gt;} remove \u0026lt;name\u0026gt; from crush map (everywhere, or just at \u0026lt;ancestor\u0026gt;) osd crush rm-device-class \u0026lt;ids\u0026gt; [\u0026lt;ids\u0026gt;...] remove class of the osd(s) \u0026lt;id\u0026gt; [\u0026lt;id\u0026gt;...],or use \u0026lt;all|any|*\u0026gt; to remove all. osd crush rule create-erasure \u0026lt;name\u0026gt; {\u0026lt;profile\u0026gt;} create crush rule \u0026lt;name\u0026gt; for erasure coded pool created with \u0026lt;profile\u0026gt; (default default) osd crush rule create-replicated \u0026lt;name\u0026gt; \u0026lt;root\u0026gt; \u0026lt;type\u0026gt; {\u0026lt;class\u0026gt;} create crush rule \u0026lt;name\u0026gt; for replicated pool to start from \u0026lt;root\u0026gt;, replicate across buckets of type \u0026lt;type\u0026gt;, using a choose mode of \u0026lt;firstn|indep\u0026gt; (default firstn; indep best for erasure pools) osd crush rule create-simple \u0026lt;name\u0026gt; \u0026lt;root\u0026gt; \u0026lt;type\u0026gt; {firstn|indep} create crush rule \u0026lt;name\u0026gt; to start from \u0026lt;root\u0026gt;, replicate across buckets of type \u0026lt;type\u0026gt;, using a choose mode of \u0026lt;firstn|indep\u0026gt; (default firstn; indep best for erasure pools) osd crush rule dump {\u0026lt;name\u0026gt;} dump crush rule \u0026lt;name\u0026gt; (default all) osd crush rule ls list crush rules osd crush rule ls-by-class \u0026lt;class\u0026gt; list all crush rules that reference the same \u0026lt;class\u0026gt; osd crush rule rename \u0026lt;srcname\u0026gt; \u0026lt;dstname\u0026gt; rename crush rule \u0026lt;srcname\u0026gt; to \u0026lt;dstname\u0026gt; osd crush rule rm \u0026lt;name\u0026gt; remove crush rule \u0026lt;name\u0026gt; osd crush set \u0026lt;osdname (id|osd.id)\u0026gt; \u0026lt;float[0.0-]\u0026gt; \u0026lt;args\u0026gt; [\u0026lt;args\u0026gt;...] update crushmap position and weight for \u0026lt;name\u0026gt; to \u0026lt;weight\u0026gt; with location \u0026lt;args\u0026gt; osd crush set {\u0026lt;int\u0026gt;} set crush map from input file osd crush set-device-class \u0026lt;class\u0026gt; \u0026lt;ids\u0026gt; [\u0026lt;ids\u0026gt;...] set the \u0026lt;class\u0026gt; of the osd(s) \u0026lt;id\u0026gt; [\u0026lt;id\u0026gt;...],or use \u0026lt;all|any|*\u0026gt; to set all. osd crush set-tunable straw_calc_version \u0026lt;int\u0026gt; set crush tunable \u0026lt;tunable\u0026gt; to \u0026lt;value\u0026gt; osd crush show-tunables show current crush tunables osd crush swap-bucket \u0026lt;source\u0026gt; \u0026lt;dest\u0026gt; {--yes-i-really-mean-it} swap existing bucket contents from (orphan) bucket \u0026lt;source\u0026gt; and \u0026lt;target\u0026gt; osd crush tree {--show-shadow} dump crush buckets and items in a tree view osd crush tunables legacy|argonaut|bobtail|firefly|hammer|jewel|optimal|default set crush tunables values to \u0026lt;profile\u0026gt; osd crush unlink \u0026lt;name\u0026gt; {\u0026lt;ancestor\u0026gt;} unlink \u0026lt;name\u0026gt; from crush map (everywhere, or just at \u0026lt;ancestor\u0026gt;) osd crush weight-set create \u0026lt;poolname\u0026gt; flat|positional create a weight-set for a given pool osd crush weight-set create-compat create a default backward-compatible weight-set osd crush weight-set dump dump crush weight sets osd crush weight-set ls list crush weight sets osd crush weight-set reweight \u0026lt;poolname\u0026gt; \u0026lt;item\u0026gt; \u0026lt;float[0.0-]\u0026gt; [\u0026lt;float[0.0-]\u0026gt;...] set weight for an item (bucket or osd) in a pool's weight-set osd crush weight-set reweight-compat \u0026lt;item\u0026gt; \u0026lt;float[0.0-]\u0026gt; [\u0026lt;float[0.0-]\u0026gt;...] set weight for an item (bucket or osd) in the backward-compatible weight-set osd crush weight-set rm \u0026lt;poolname\u0026gt; remove the weight-set for a given pool osd crush weight-set rm-compat remove the backward-compatible weight-set cephu@cephadmin:~/my-cluster$ ceph osd crush tunables hammer adjusted tunables profile to hammer cephu@cephadmin:~/my-cluster$ ceph osd crush show-tunables { \u0026quot;choose_local_tries\u0026quot;: 0, \u0026quot;choose_local_fallback_tries\u0026quot;: 0, \u0026quot;choose_total_tries\u0026quot;: 50, \u0026quot;chooseleaf_descend_once\u0026quot;: 1, \u0026quot;chooseleaf_vary_r\u0026quot;: 1, \u0026quot;chooseleaf_stable\u0026quot;: 0, \u0026quot;straw_calc_version\u0026quot;: 1, \u0026quot;allowed_bucket_algs\u0026quot;: 54, \u0026quot;profile\u0026quot;: \u0026quot;hammer\u0026quot;, \u0026quot;optimal_tunables\u0026quot;: 0, \u0026quot;legacy_tunables\u0026quot;: 0, \u0026quot;minimum_required_version\u0026quot;: \u0026quot;hammer\u0026quot;, \u0026quot;require_feature_tunables\u0026quot;: 1, \u0026quot;require_feature_tunables2\u0026quot;: 1, \u0026quot;has_v2_rules\u0026quot;: 0, \u0026quot;require_feature_tunables3\u0026quot;: 1, \u0026quot;has_v3_rules\u0026quot;: 0, \u0026quot;has_v4_buckets\u0026quot;: 1, \u0026quot;require_feature_tunables5\u0026quot;: 0, \u0026quot;has_v5_rules\u0026quot;: 0 } cephu@cephadmin:~/my-cluster$  回 ceph-client 节点：\ncephu@ceph-client:~$ ceph -v ceph version 12.2.1 (3e7492b9ada8bdc9a5cd0feafd42fbca27f9c38e) luminous (stable) cephu@ceph-client:~$ rbd ls foo cephu@ceph-client:~$ sudo rbd map foo --name client.admin /dev/rbd0 cephu@ceph-client:~$ ls /dev/rbd rbd/ rbd0 cephu@ceph-client:~$ ls /dev/rbd/rbd/foo /dev/rbd/rbd/foo cephu@ceph-client:~$ ls /dev/rbd0 /dev/rbd0 cephu@ceph-client:~$ ls /dev/rbd0 -l brw-rw---- 1 root disk 251, 0 Oct 25 12:03 /dev/rbd0 cephu@ceph-client:~$  成功了。。继续。。\nUse the block device by creating a file system on the ceph-client node.\ncephu@ceph-client:~$ sudo mkfs.ext4 -m0 /dev/rbd/rbd/foo mke2fs 1.42.13 (17-May-2015) Discarding device blocks: done Creating filesystem with 1048576 4k blocks and 262144 inodes Filesystem UUID: d83ebc8d-1956-4d81-b9db-391f939634ac Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done cephu@ceph-client:~$  Mount the file system on the ceph-client node.\ncephu@ceph-client:~$ sudo mkdir /mnt/ceph-block-device cephu@ceph-client:~$ sudo mount /dev/rbd/rbd/foo /mnt/ceph-block-device cephu@ceph-client:~$ cd /mnt/ceph-block-device cephu@ceph-client:/mnt/ceph-block-device$ ls lost+found cephu@ceph-client:/mnt/ceph-block-device$  好了，这小一节，结束了。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-yaml.html",
	"title": "k8s 中 cephfs 成功的 yaml 文件",
	"tags": ["ceph", "cephfs", "kubernetes", "yaml"],
	"description": "",
	"content": " https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/cephfs\n对 我们好不容易成功安装的 k8s-cephfs 进行一个记录呀！\n环境 k8s-master 192.168.31.120 km master k8s-node1 192.168.31.119 kn1 node1 k8s-node2 192.168.31.118 kn2 node2 cephfs-admin 192.168.31.115 cephfs-monitor 192.168.31.114 cephfs-client 192.168.31.172  git remote jlch@km:~/cephfs$ git remote -v origin https://github.com/kubernetes-incubator/external-storage (fetch) origin https://github.com/kubernetes-incubator/external-storage (push) jlch@km:~/cephfs$ git log | head commit f1eb2a4ddf944fdd35a16e686ae104c1db8753b2 Merge: 06aaf46 52a4da4 Author: Matthew Wong \u0026lt;mawong@redhat.com\u0026gt; Date: Tue Nov 21 01:48:43 2017 -0500 Merge pull request #468 from sathieu/patch-1 flex: Fix file shbang commit 06aaf46950c9f6f741b34afc1d9f7807bdbe078c jlch@km:~/cephfs$  git status 记录一下主要的修改点\njlch@km:~/cephfs$ git status On branch master Your branch is up-to-date with 'origin/master'. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: ceph-secret-admin.yaml modified: claim.yaml modified: class.yaml modified: deployment.yaml modified: test-pod.yaml no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) jlch@km:~/cephfs$  git diff ceph-secret-admin.yaml jlch@km:~/cephfs$ git diff ceph-secret-admin.yaml diff --git a/ceph/cephfs/ceph-secret-admin.yaml b/ceph/cephfs/ceph-secret-admin.yaml index c3a741a..1ebaac3 100644 --- a/ceph/cephfs/ceph-secret-admin.yaml +++ b/ceph/cephfs/ceph-secret-admin.yaml @@ -5,4 +5,5 @@ metadata: type: \u0026quot;kubernetes.io/cephfs\u0026quot; data: #Please note this value is base64 encoded. - key: QVFDTXBIOVlNNFExQmhBQVhHTlF5eU9uZThac1hxV0dvbi9kSVE9PQ== + #key: QVFDTXBIOVlNNFExQmhBQVhHTlF5eU9uZThac1hxV0dvbi9kSVE9PQ== + key: AQCtj+5ZnNTvGRAA2RxAGcIQZJnaJSPEz4jdGw== jlch@km:~/cephfs$  claim.yaml jlch@km:~/cephfs$ git diff claim.yaml diff --git a/ceph/cephfs/claim.yaml b/ceph/cephfs/claim.yaml index 2dca6ae..280a7a9 100644 --- a/ceph/cephfs/claim.yaml +++ b/ceph/cephfs/claim.yaml @@ -9,4 +9,4 @@ spec: - ReadWriteMany resources: requests: - storage: 1Gi + storage: 10Gi jlch@km:~/cephfs$  class.yaml   jlch@km:~/cephfs$ git diff class.yaml diff --git a/ceph/cephfs/class.yaml b/ceph/cephfs/class.yaml index 91c73c0..b2825a3 100644 --- a/ceph/cephfs/class.yaml +++ b/ceph/cephfs/class.yaml @@ -4,7 +4,7 @@ metadata: name: cephfs provisioner: ceph.com/cephfs parameters: - monitors: 172.24.0.6:6789 + monitors: 192.168.31.114:6789 adminId: admin adminSecretName: ceph-secret-admin adminSecretNamespace: \u0026quot;kube-system\u0026quot; jlch@km:~/cephfs$  test-pod.yaml jlch@km:~/cephfs$ git diff test-pod.yaml diff --git a/ceph/cephfs/test-pod.yaml b/ceph/cephfs/test-pod.yaml index 4888676..ece87e8 100644 --- a/ceph/cephfs/test-pod.yaml +++ b/ceph/cephfs/test-pod.yaml @@ -5,7 +5,8 @@ metadata: spec: containers: - name: test-pod - image: gcr.io/google_containers/busybox:1.24 + image: gcr.io/google_containers/busybox:latest + imagePullPolicy: IfNotPresent command: - \u0026quot;/bin/sh\u0026quot; args: jlch@km:~/cephfs$  deployment.yaml jlch@km:~/cephfs$ git diff deployment.yaml diff --git a/ceph/cephfs/deployment.yaml b/ceph/cephfs/deployment.yaml index 37c5f87..dc0315c 100644 --- a/ceph/cephfs/deployment.yaml +++ b/ceph/cephfs/deployment.yaml @@ -14,6 +14,7 @@ spec: containers: - name: cephfs-provisioner image: \u0026quot;quay.io/external_storage/cephfs-provisioner:latest\u0026quot; + imagePullPolicy: IfNotPresent env: - name: PROVISIONER_NAME valueFrom: @@ -24,3 +25,23 @@ spec: - \u0026quot;/usr/local/bin/cephfs-provisioner\u0026quot; args: - \u0026quot;-id=cephfs-provisioner-1\u0026quot; + - \u0026quot;-master=https://10.96.0.1/\u0026quot; + - \u0026quot;-kubeconfig=/kube/admin.conf\u0026quot; + volumeMounts: + - mountPath: /kube + name: kube-config + - mountPath: /var/run/kubernetes + name: kube-run-env + volumes: + - name: kube-config + hostPath: + # directory location on host + path: /home/jlch + # this field is optional + type: Directory + - name: kube-run-env + hostPath: + # directory location on host + path: /var/run/kubernetes + # this field is optional + type: Directory  cat jlch@km:~/cephfs$ ls cephfs_provisioner cephfs-provisioner.go ceph-secret-admin.yaml CHANGELOG.md claim.yaml class.yaml configmap.yaml deployment.yaml Dockerfile local-start.sh Makefile OWNERS README.md test-pod.yaml jlch@km:~/cephfs$ cat ceph-secret-admin.yaml apiVersion: v1 kind: Secret metadata: name: ceph-secret-admin type: \u0026quot;kubernetes.io/cephfs\u0026quot; data: #Please note this value is base64 encoded. #key: QVFDTXBIOVlNNFExQmhBQVhHTlF5eU9uZThac1hxV0dvbi9kSVE9PQ== key: AQCtj+5ZnNTvGRAA2RxAGcIQZJnaJSPEz4jdGw== jlch@km:~/cephfs$ cat claim.yaml kind: PersistentVolumeClaim apiVersion: v1 metadata: name: claim1 annotations: volume.beta.kubernetes.io/storage-class: \u0026quot;cephfs\u0026quot; spec: accessModes: - ReadWriteMany resources: requests: storage: 10Gi jlch@km:~/cephfs$ cat class.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: cephfs provisioner: ceph.com/cephfs parameters: monitors: 192.168.31.114:6789 adminId: admin adminSecretName: ceph-secret-admin adminSecretNamespace: \u0026quot;kube-system\u0026quot; jlch@km:~/cephfs$ cat test-pod.yaml kind: Pod apiVersion: v1 metadata: name: test-pod spec: containers: - name: test-pod image: gcr.io/google_containers/busybox:latest imagePullPolicy: IfNotPresent command: - \u0026quot;/bin/sh\u0026quot; args: - \u0026quot;-c\u0026quot; - \u0026quot;touch /mnt/SUCCESS \u0026amp;\u0026amp; exit 0 || exit 1\u0026quot; volumeMounts: - name: pvc mountPath: \u0026quot;/mnt\u0026quot; restartPolicy: \u0026quot;Never\u0026quot; volumes: - name: pvc persistentVolumeClaim: claimName: claim1 jlch@km:~/cephfs$ cat deployment.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: cephfs-provisioner spec: replicas: 1 strategy: type: Recreate template: metadata: labels: app: cephfs-provisioner spec: containers: - name: cephfs-provisioner image: \u0026quot;quay.io/external_storage/cephfs-provisioner:latest\u0026quot; imagePullPolicy: IfNotPresent env: - name: PROVISIONER_NAME valueFrom: configMapKeyRef: key: provisioner.name name: cephfs-provisioner command: - \u0026quot;/usr/local/bin/cephfs-provisioner\u0026quot; args: - \u0026quot;-id=cephfs-provisioner-1\u0026quot; - \u0026quot;-master=https://10.96.0.1/\u0026quot; - \u0026quot;-kubeconfig=/kube/admin.conf\u0026quot; volumeMounts: - mountPath: /kube name: kube-config - mountPath: /var/run/kubernetes name: kube-run-env volumes: - name: kube-config hostPath: # directory location on host path: /home/jlch # this field is optional type: Directory - name: kube-run-env hostPath: # directory location on host path: /var/run/kubernetes # this field is optional type: Directory jlch@km:~/cephfs$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-upgrade-failure-from-v183-to-v184.html",
	"title": "kubeadm从v1.8.3更新至v1.8.4失败",
	"tags": ["kubernetes", "install", "upgrade"],
	"description": "",
	"content": " Installing Docker root@km:~# cat /etc/apt/sources.list.d/docker.list deb https://apt.dockerproject.org/repo ubuntu-xenial main root@km:~# cat /etc/docker/daemon.json { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://0d6wdn2y.mirror.aliyuncs.com\u0026quot;] } root@km:~# vi /etc/docker/daemon.json root@km:~# cat /etc/docker/daemon.json { \u0026quot;exec-opts\u0026quot;: [\u0026quot;native.cgroupdriver=systemd\u0026quot;], \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://0d6wdn2y.mirror.aliyuncs.com\u0026quot;] } root@km:~# apt-get install -y curl apt-transport-https Reading package lists... Done Building dependency tree Reading state information... Done apt-transport-https is already the newest version (1.2.24). curl is already the newest version (7.47.0-1ubuntu2.4). The following packages were automatically installed and are no longer required: golang-1.8-go golang-1.8-race-detector-runtime golang-1.8-src Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. 1 not fully installed or removed. After this operation, 0 B of additional disk space will be used. Setting up etcd (2.2.5+dfsg-1ubuntu1) ... insserv: warning: current start runlevel(s) (empty) of script `etcd' overrides LSB defaults (2 3 4 5). insserv: warning: current stop runlevel(s) (0 1 2 3 4 5 6) of script `etcd' overrides LSB defaults (0 1 6).  Installing kubeadm, kubelet and kubectl root@km:~# apt-get install -y apt-transport-https Reading package lists... Done Building dependency tree Reading state information... Done apt-transport-https is already the newest version (1.2.24). The following packages were automatically installed and are no longer required: golang-1.8-go golang-1.8-race-detector-runtime golang-1.8-src Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. root@km:~# cat /etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io/ kubernetes-xenial main root@km:~# apt-get install -y kubelet kubeadm kubectl Reading package lists... Done Building dependency tree Reading state information... Done kubeadm is already the newest version (1.8.3-00). kubectl is already the newest version (1.8.3-00). kubectl set to manually installed. kubelet is already the newest version (1.8.3-00). The following packages were automatically installed and are no longer required: golang-1.8-go golang-1.8-race-detector-runtime golang-1.8-src Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. root@km:~#  去下一个页面吧 https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-4-notes.html",
	"title": "Spacemacs Rocks Day 4, Magit workflow",
	"tags": ["emacs", "spacemacs", "magit"],
	"description": "",
	"content": " 如果magit状态下，不知道按键，则 SPC g s 后按 ? 号，查看。\nMagit init, commit and commit messages  SPC g i(magit-init) SPC u S(所有文件加入版本库) 按TAB查看文件的修改 SPC g s(magit-status) s-1 (goto unstaged section) press tab to view diffs(code review) s to stage all changes c c -\u0026gt; c-c c-c to commit editing the commit message and the diff on the right  Commits in Action  Ammend ( c a) 就是把之前的commit作修改。把最近的修改，加入到上一次的 commit 之中。 write good commit messages squash unpushed commits (r l) reset commits (l l #) select a few line to commits discard changes, file wide or line wide revert commits  git push  SPC g s M a(remote name, remote url) P 第一次的话，按 - u(git push) 按提示，一般是 p或u  git rebase squash 把2个或者多个 commit ，合并成一个。  SPC g s 多个commit, 但是没有 push 找到最前的一个commit(commit 1) 按r i，进入一个commit 列表。 C-c, C-c 按 r 再按s , 表示进入到 squash 状态 按 , c 进入最终的commit Message 编辑 C-c C-c 退出。这时，观察到，2个commit已经合并成一个了。 git push 吧。  git reset  https://magit.vc/manual/magit/Resetting.html  SPC h d f 查找 magit-reset 函数, 知道，是在 git status状态下, 光标到希望reset 的 commit 的地方，然后按 o ，然后回车或者另选择。\ndiscard unstaged changes  discard 整个修改过的文件，直接在文件处按 x discard 文件中的部分修改，TAB后，按v选中，按x  总之就是先选中，然后按x,然后确认。\nselect a few line to commits  press tab to view diffs(code review) v 选中修改的行 s stage  这样就只选择部分进行 commit . 注意，有些应该是要删除原来的语句的哟。\nrevert commits 按 -\nBranching basics  b B to create branch m m to merge b b to switch branch  create a new branch 好像 b B 已经失效\n SPC g s b c\n merge develop branch  SPC g s m m\n Rebase  squash unpushed rebase to other branch interactive rebase  pull, push \u0026amp; send Pull request  P P f f / f o to fetch branch F to pull s-g to send pull request  Misc  cherry pick view github files  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/jupyter/jupyter-notebook-with-emacs.html",
	"title": "Emacs与Jupyter notebook之间的集成",
	"tags": ["python", "notebook", "emacs", "spacemacs"],
	"description": "",
	"content": " emacs配置ein包 具体配置可以参考我的个人配置\n启动notebook服务器 连接notebook服务器  M-x ein:notebooklist-open 选择 New Notebook , 然后输入 token\n 使用 使用的时候，查看 菜单栏 或者 C-c 出现大多数你想要的命令。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph-install-base-ubuntu-object-storage-quick-start.html",
	"title": "ceph-install-base-ubuntu Object Storage Quick Start",
	"tags": ["ceph", "install", "ubuntu"],
	"description": "",
	"content": " INSTALLING CEPH OBJECT GATEWAY ceph-client：\ncephu@ceph-client:~$ sudo ufw allow 7480 Rule added Rule added (v6) cephu@ceph-client:~$ sudo ufw status Status: active To Action From -- ------ ---- 22 ALLOW Anywhere 7480 ALLOW Anywhere 22 (v6) ALLOW Anywhere (v6) 7480 (v6) ALLOW Anywhere (v6) cephu@ceph-client:~$  ceph-admin:\ncephu@cephadmin:~/my-cluster$ ping ceph-client PING ceph-client (192.168.31.172) 56(84) bytes of data. 64 bytes from ceph-client (192.168.31.172): icmp_seq=1 ttl=64 time=0.558 ms ^C --- ceph-client ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.558/0.558/0.558/0.000 ms cephu@cephadmin:~/my-cluster$ ceph-deploy install --rgw ceph-client [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /home/cephu/.local/bin/ceph-deploy install --rgw ceph-client [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] testing : None [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f61e87c4908\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] dev_commit : None [ceph_deploy.cli][INFO ] install_mds : False [ceph_deploy.cli][INFO ] stable : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] adjust_repos : True [ceph_deploy.cli][INFO ] func : \u0026lt;function install at 0x7f61e8e9b848\u0026gt; [ceph_deploy.cli][INFO ] install_mgr : False [ceph_deploy.cli][INFO ] install_all : False [ceph_deploy.cli][INFO ] repo : False [ceph_deploy.cli][INFO ] host : ['ceph-client'] [ceph_deploy.cli][INFO ] install_rgw : True [ceph_deploy.cli][INFO ] install_tests : False [ceph_deploy.cli][INFO ] repo_url : None [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] install_osd : False [ceph_deploy.cli][INFO ] version_kind : stable [ceph_deploy.cli][INFO ] install_common : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] dev : master [ceph_deploy.cli][INFO ] nogpgcheck : False [ceph_deploy.cli][INFO ] local_mirror : None [ceph_deploy.cli][INFO ] release : None [ceph_deploy.cli][INFO ] install_mon : False [ceph_deploy.cli][INFO ] gpg_url : None [ceph_deploy.install][DEBUG ] Installing stable version jewel on cluster ceph hosts ceph-client [ceph_deploy.install][DEBUG ] Detecting platform for host ceph-client ... [ceph-client][DEBUG ] connection detected need for sudo [ceph-client][DEBUG ] connected to host: ceph-client [ceph-client][DEBUG ] detect platform information from remote host [ceph-client][DEBUG ] detect machine type [ceph_deploy.install][INFO ] Distro info: Ubuntu 16.04 xenial [ceph-client][INFO ] installing Ceph on ceph-client [ceph-client][INFO ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q --no-install-recommends install ca-certificates apt-transport-https [ceph-client][DEBUG ] Reading package lists... [ceph-client][DEBUG ] Building dependency tree... [ceph-client][DEBUG ] Reading state information... [ceph-client][DEBUG ] apt-transport-https is already the newest version (1.2.24). [ceph-client][DEBUG ] ca-certificates is already the newest version (20170717~16.04.1). [ceph-client][DEBUG ] The following packages were automatically installed and are no longer required: [ceph-client][DEBUG ] libboost-program-options1.58.0 libboost-random1.58.0 libboost-regex1.58.0 [ceph-client][DEBUG ] libcephfs1 libfcgi0ldbl libllvm3.8 libmircommon5 linux-headers-4.4.0-31 [ceph-client][DEBUG ] linux-headers-4.4.0-31-generic linux-image-4.4.0-31-generic [ceph-client][DEBUG ] linux-image-extra-4.4.0-31-generic [ceph-client][DEBUG ] Use 'sudo apt autoremove' to remove them. [ceph-client][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded. [ceph-client][INFO ] Running command: sudo wget -O release.asc https://download.ceph.com/keys/release.asc [ceph-client][WARNIN] --2017-10-25 14:45:28-- https://download.ceph.com/keys/release.asc [ceph-client][WARNIN] Resolving download.ceph.com (download.ceph.com)... 158.69.68.124, 2607:5300:201:2000::3:58a1 [ceph-client][WARNIN] Connecting to download.ceph.com (download.ceph.com)|158.69.68.124|:443... connected. [ceph-client][WARNIN] HTTP request sent, awaiting response... 200 OK [ceph-client][WARNIN] Length: 1645 (1.6K) [application/octet-stream] [ceph-client][WARNIN] Saving to: ‘release.asc’ [ceph-client][WARNIN] [ceph-client][WARNIN] 0K . 100% 233M=0s [ceph-client][WARNIN] [ceph-client][WARNIN] 2017-10-25 14:45:35 (233 MB/s) - ‘release.asc’ saved [1645/1645] [ceph-client][WARNIN] [ceph-client][INFO ] Running command: sudo apt-key add release.asc [ceph-client][DEBUG ] OK [ceph-client][DEBUG ] add deb repo to /etc/apt/sources.list.d/ [ceph-client][INFO ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q update [ceph-client][DEBUG ] Hit:1 http://cn.archive.ubuntu.com/ubuntu xenial InRelease [ceph-client][DEBUG ] Hit:2 http://cn.archive.ubuntu.com/ubuntu xenial-updates InRelease [ceph-client][DEBUG ] Hit:3 http://cn.archive.ubuntu.com/ubuntu xenial-backports InRelease [ceph-client][DEBUG ] Hit:4 http://www.rabbitmq.com/debian testing InRelease [ceph-client][DEBUG ] Get:5 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB] [ceph-client][DEBUG ] Hit:6 https://download.docker.com/linux/ubuntu xenial InRelease [ceph-client][DEBUG ] Get:7 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [7,472 B] [ceph-client][DEBUG ] Get:8 http://security.ubuntu.com/ubuntu xenial-security/restricted i386 Packages [7,472 B] [ceph-client][DEBUG ] Get:9 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [3,208 B] [ceph-client][DEBUG ] Get:10 http://security.ubuntu.com/ubuntu xenial-security/multiverse i386 Packages [3,384 B] [ceph-client][DEBUG ] Hit:11 https://download.ceph.com/debian-jewel xenial InRelease [ceph-client][DEBUG ] Fetched 124 kB in 7s (16.8 kB/s) [ceph-client][DEBUG ] Reading package lists... [ceph-client][INFO ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q --no-install-recommends install -o Dpkg::Options::=--force-confnew radosgw [ceph-client][DEBUG ] Reading package lists... [ceph-client][DEBUG ] Building dependency tree... [ceph-client][DEBUG ] Reading state information... [ceph-client][DEBUG ] radosgw is already the newest version (12.2.1-1xenial). [ceph-client][DEBUG ] The following packages were automatically installed and are no longer required: [ceph-client][DEBUG ] libboost-program-options1.58.0 libboost-random1.58.0 libboost-regex1.58.0 [ceph-client][DEBUG ] libcephfs1 libfcgi0ldbl libllvm3.8 libmircommon5 linux-headers-4.4.0-31 [ceph-client][DEBUG ] linux-headers-4.4.0-31-generic linux-image-4.4.0-31-generic [ceph-client][DEBUG ] linux-image-extra-4.4.0-31-generic [ceph-client][DEBUG ] Use 'sudo apt autoremove' to remove them. [ceph-client][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded. [ceph-client][INFO ] Running command: sudo ceph --version [ceph-client][DEBUG ] ceph version 12.2.1 (3e7492b9ada8bdc9a5cd0feafd42fbca27f9c38e) luminous (stable) cephu@cephadmin:~/my-cluster$  看状态\ncephu@cephadmin:~/my-cluster$ ceph -s cluster: id: d0aa5af1-4f8e-4953-9448-7f1b2448b8a5 health: HEALTH_OK services: mon: 3 daemons, quorum cephfsn2,mon1,cephfsn3 mgr: mon1(active), standbys: node2, node3 mds: cephfs-jlch-1/1/1 up {0=node1=up:active} osd: 3 osds: 3 up, 3 in rgw: 1 daemon active data: pools: 8 pools, 64 pgs objects: 296 objects, 134 MB usage: 4286 MB used, 79378 MB / 83664 MB avail pgs: 64 active+clean cephu@cephadmin:~/my-cluster$  CREATING THE CEPH OBJECT GATEWAY INSTANCE admin:\ncephu@cephadmin:~/my-cluster$ ceph-deploy rgw create ceph-client [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /home/cephu/.local/bin/ceph-deploy rgw create ceph-client [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] rgw : [('ceph-client', 'rgw.ceph-client')] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1dc4631bd8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function rgw at 0x7f1dc4c7e140\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph-client:rgw.ceph-client [ceph-client][DEBUG ] connection detected need for sudo [ceph-client][DEBUG ] connected to host: ceph-client [ceph-client][DEBUG ] detect platform information from remote host [ceph-client][DEBUG ] detect machine type [ceph_deploy.rgw][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.rgw][DEBUG ] remote host will use systemd [ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph-client [ceph-client][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph_deploy.rgw][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite [ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs cephu@cephadmin:~/my-cluster$ ceph-deploy --overwrite-conf rgw create ceph-client [ceph_deploy.conf][DEBUG ] found configuration file at: /home/cephu/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): /home/cephu/.local/bin/ceph-deploy --overwrite-conf rgw create ceph-client [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] rgw : [('ceph-client', 'rgw.ceph-client')] [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : \u0026lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb62d844bd8\u0026gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : \u0026lt;function rgw at 0x7fb62de91140\u0026gt; [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts ceph-client:rgw.ceph-client [ceph-client][DEBUG ] connection detected need for sudo [ceph-client][DEBUG ] connected to host: ceph-client [ceph-client][DEBUG ] detect platform information from remote host [ceph-client][DEBUG ] detect machine type [ceph_deploy.rgw][INFO ] Distro info: Ubuntu 16.04 xenial [ceph_deploy.rgw][DEBUG ] remote host will use systemd [ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to ceph-client [ceph-client][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf [ceph-client][WARNIN] rgw keyring does not exist yet, creating one [ceph-client][DEBUG ] create a keyring file [ceph-client][DEBUG ] create path recursively if it doesn't exist [ceph-client][INFO ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.ceph-client osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.ceph-client/keyring [ceph-client][INFO ] Running command: sudo systemctl enable ceph-radosgw@rgw.ceph-client [ceph-client][WARNIN] Created symlink from /etc/systemd/system/ceph-radosgw.target.wants/ceph-radosgw@rgw.ceph-client.service to /lib/systemd/system/ceph-radosgw@.service. [ceph-client][INFO ] Running command: sudo systemctl start ceph-radosgw@rgw.ceph-client [ceph-client][INFO ] Running command: sudo systemctl enable ceph.target [ceph_deploy.rgw][INFO ] The Ceph Object Gateway (RGW) is now running on host ceph-client and default port 7480 cephu@cephadmin:~/my-cluster$  CONFIGURING THE CEPH OBJECT GATEWAY INSTANCE 这里是配置web端口成 80 .\n这里我就不做了，我没必要。修改也简单，看一下就明白了。\n我的 ceph-client 的IP是 192.168.31.172，则： 我就直接到浏览器下打开 http://192.168.31.172:7480/\n输出大体如下：\nThis XML file does not appear to have any style information associated with it. The document tree is shown below. \u0026lt;ListAllMyBucketsResult xmlns=\u0026quot;http://s3.amazonaws.com/doc/2006-03-01/\u0026quot;\u0026gt; \u0026lt;Owner\u0026gt; \u0026lt;ID\u0026gt;anonymous\u0026lt;/ID\u0026gt; \u0026lt;DisplayName/\u0026gt; \u0026lt;/Owner\u0026gt; \u0026lt;Buckets/\u0026gt; \u0026lt;/ListAllMyBucketsResult\u0026gt;  好了，这一小节就到这里了。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-make.html",
	"title": "cephfs-k8s 中的 make",
	"tags": ["ceph", "cephfs", "kubernetes", "make"],
	"description": "",
	"content": "下载 make ，报错了。\nroot@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful# cd external-storage/ceph/cephfs/ root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# ls cephfs_provisioner cephfs-provisioner.go ceph-secret-admin.yaml CHANGELOG.md claim.yaml class.yaml configmap.yaml deployment.yaml Dockerfile local-start.sh Makefile OWNERS README.md test-pod.yaml root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# make CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags \u0026quot;-static\u0026quot;' -o cephfs-provisioner cephfs-provisioner.go cephfs-provisioner.go:28:2: cannot find package \u0026quot;github.com/golang/glog\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/golang/glog (from $GOROOT) /root/go/src/github.com/golang/glog (from $GOPATH) cephfs-provisioner.go:29:2: cannot find package \u0026quot;github.com/kubernetes-incubator/external-storage/lib/controller\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/kubernetes-incubator/external-storage/lib/controller (from $GOROOT) /root/go/src/github.com/kubernetes-incubator/external-storage/lib/controller (from $GOPATH) cephfs-provisioner.go:30:2: cannot find package \u0026quot;k8s.io/api/core/v1\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/api/core/v1 (from $GOROOT) /root/go/src/k8s.io/api/core/v1 (from $GOPATH) cephfs-provisioner.go:31:2: cannot find package \u0026quot;k8s.io/apimachinery/pkg/apis/meta/v1\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/apimachinery/pkg/apis/meta/v1 (from $GOROOT) /root/go/src/k8s.io/apimachinery/pkg/apis/meta/v1 (from $GOPATH) cephfs-provisioner.go:32:2: cannot find package \u0026quot;k8s.io/apimachinery/pkg/util/uuid\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/apimachinery/pkg/util/uuid (from $GOROOT) /root/go/src/k8s.io/apimachinery/pkg/util/uuid (from $GOPATH) cephfs-provisioner.go:33:2: cannot find package \u0026quot;k8s.io/apimachinery/pkg/util/wait\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/apimachinery/pkg/util/wait (from $GOROOT) /root/go/src/k8s.io/apimachinery/pkg/util/wait (from $GOPATH) cephfs-provisioner.go:34:2: cannot find package \u0026quot;k8s.io/client-go/kubernetes\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/client-go/kubernetes (from $GOROOT) /root/go/src/k8s.io/client-go/kubernetes (from $GOPATH) cephfs-provisioner.go:35:2: cannot find package \u0026quot;k8s.io/client-go/rest\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/client-go/rest (from $GOROOT) /root/go/src/k8s.io/client-go/rest (from $GOPATH) cephfs-provisioner.go:36:2: cannot find package \u0026quot;k8s.io/client-go/tools/clientcmd\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/client-go/tools/clientcmd (from $GOROOT) /root/go/src/k8s.io/client-go/tools/clientcmd (from $GOPATH) cephfs-provisioner.go:37:2: cannot find package \u0026quot;k8s.io/kubernetes/pkg/api/v1/helper\u0026quot; in any of: /usr/lib/go-1.8/src/k8s.io/kubernetes/pkg/api/v1/helper (from $GOROOT) /root/go/src/k8s.io/kubernetes/pkg/api/v1/helper (from $GOPATH) Makefile:27: recipe for target 'all' failed make: *** [all] Error 1 root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs#  少了包呀。\n查一下，有没有go, GOPATH\nroot@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# which go /usr/bin/go root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# echo $GOPATH root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs#  没有设置，那好了，设置成我们之前用过的地址。\n先看一下，我们之前的go包：\nroot@km:~# cd kubernetes root@km:~/kubernetes# ls api BUILD.bazel cluster code-of-conduct.md docs federation hack LICENSE Makefile OWNERS pkg README.md SUPPORT.md third_party Vagrantfile WORKSPACE build CHANGELOG.md cmd CONTRIBUTING.md examples Godeps labels.yaml logo Makefile.generated_files OWNERS_ALIASES plugin staging test translations vendor root@km:~/kubernetes#  随便查一个，上面没有的包吧，如 client-go:\nroot@km:~/kubernetes# ls -lR \u0026gt; ls-lr root@km:~/kubernetes# cat ls-lr | grep client-go drwxr-xr-x 17 root root 4096 Aug 29 18:47 client-go drwxr-xr-x 5 root root 4096 Aug 29 18:47 client-go ... ... ./staging/src/k8s.io/client-go: ./staging/src/k8s.io/client-go/discovery: ./staging/src/k8s.io/client-go/discovery/cached: ./staging/src/k8s.io/client-go/discovery/fake: ./staging/src/k8s.io/client-go/dynamic: ./staging/src/k8s.io/client-go/dynamic/fake: ./staging/src/k8s.io/client-go/examples: ... ... lrwxrwxrwx 1 root root 34 Aug 29 18:47 client-go -\u0026gt; ../../staging/src/k8s.io/client-go root@km:~/kubernetes#  有呀，这样就不用重复下载了。\nroot@km:~/kubernetes# cd staging/ root@km:~/kubernetes/staging# ls BUILD godeps-json-updater.go OWNERS pkg prime-apimachinery.sh README.md src root@km:~/kubernetes/staging# cd src root@km:~/kubernetes/staging/src# ls github.com golang.org gopkg.in k8s.io root@km:~/kubernetes/staging/src# cd k8s.io/ root@km:~/kubernetes/staging/src/k8s.io# ls api apiextensions-apiserver apimachinery apiserver client-go code-generator kube-aggregator kube-openapi kubernetes metrics sample-apiserver root@km:~/kubernetes/staging/src/k8s.io# pwd /root/kubernetes/staging/src/k8s.io root@km:~/kubernetes/staging/src/k8s.io#  设置一下 GOPATH\nroot@km:~/kubernetes/staging# export GOPATH=/root/kubernetes/staging root@km:~/kubernetes/staging# echo $GOPATH /root/kubernetes/staging root@km:~/kubernetes/staging#  重新来一下，并且 go get\nroot@km:~/kubernetes/staging# cd ~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# make CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags \u0026quot;-static\u0026quot;' -o cephfs-provisioner cephfs-provisioner.go /root/kubernetes/staging/src/k8s.io/client-go/discovery/discovery_client.go:26:2: cannot find package \u0026quot;github.com/emicklei/go-restful-swagger12\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/emicklei/go-restful-swagger12 (from $GOROOT) /root/kubernetes/staging/src/github.com/emicklei/go-restful-swagger12 (from $GOPATH) /root/kubernetes/staging/src/k8s.io/client-go/discovery/discovery_client.go:27:2: cannot find package \u0026quot;github.com/golang/protobuf/proto\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/golang/protobuf/proto (from $GOROOT) /root/kubernetes/staging/src/github.com/golang/protobuf/proto (from $GOPATH) /root/kubernetes/staging/src/k8s.io/client-go/discovery/discovery_client.go:28:2: cannot find package \u0026quot;github.com/googleapis/gnostic/OpenAPIv2\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/googleapis/gnostic/OpenAPIv2 (from $GOROOT) /root/kubernetes/staging/src/github.com/googleapis/gnostic/OpenAPIv2 (from $GOPATH) /root/kubernetes/staging/src/k8s.io/client-go/tools/clientcmd/auth_loaders.go:26:2: cannot find package \u0026quot;github.com/howeyc/gopass\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/howeyc/gopass (from $GOROOT) /root/kubernetes/staging/src/github.com/howeyc/gopass (from $GOPATH) /root/kubernetes/staging/src/k8s.io/client-go/tools/clientcmd/client_config.go:28:2: cannot find package \u0026quot;github.com/imdario/mergo\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/imdario/mergo (from $GOROOT) /root/kubernetes/staging/src/github.com/imdario/mergo (from $GOPATH) /root/kubernetes/staging/src/k8s.io/client-go/util/flowcontrol/throttle.go:22:2: cannot find package \u0026quot;github.com/juju/ratelimit\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/juju/ratelimit (from $GOROOT) /root/kubernetes/staging/src/github.com/juju/ratelimit (from $GOPATH) cephfs-provisioner.go:29:2: cannot find package \u0026quot;github.com/kubernetes-incubator/external-storage/lib/controller\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/kubernetes-incubator/external-storage/lib/controller (from $GOROOT) /root/kubernetes/staging/src/github.com/kubernetes-incubator/external-storage/lib/controller (from $GOPATH) /root/kubernetes/staging/src/k8s.io/apimachinery/pkg/util/uuid/uuid.go:22:2: cannot find package \u0026quot;github.com/pborman/uuid\u0026quot; in any of: /usr/lib/go-1.8/src/github.com/pborman/uuid (from $GOROOT) /root/kubernetes/staging/src/github.com/pborman/uuid (from $GOPATH) Makefile:27: recipe for target 'all' failed make: *** [all] Error 1 root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# go get github.com/emicklei/go-restful-swagger12 root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# go get github.com/golang/protobuf/proto root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# go get github.com/googleapis/gnostic/OpenAPIv2 root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# go get github.com/howeyc/gopass package golang.org/x/crypto/ssh/terminal: unrecognized import path \u0026quot;golang.org/x/crypto/ssh/terminal\u0026quot; (https fetch: Get https://golang.org/x/crypto/ssh/terminal?go-get=1: dial tcp 216.239.37.1:443: i/o timeout) root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs#  呀，这里要去 https://golang.org/x/crypto/ssh/terminal 这要FQ的呀，怎么办？\n农总来了。\n打开浏览器，github.com, 搜索，crypto, 语言选择 go, 找到 golang/crypto, 打开，复制 url,\n打开 另一个 terminal, 然后，从之前知道 GOPATH 是 root/kubernetes/staging ,那进去。\nroot@km:~# root@km:~# cd kubernetes/staging/ root@km:~/kubernetes/staging# ls BUILD godeps-json-updater.go OWNERS pkg prime-apimachinery.sh README.md src root@km:~/kubernetes/staging# cd src root@km:~/kubernetes/staging/src# ls github.com golang.org gopkg.in k8s.io root@km:~/kubernetes/staging/src# cd golang.org/ root@km:~/kubernetes/staging/src/golang.org# ls x root@km:~/kubernetes/staging/src/golang.org# cd x root@km:~/kubernetes/staging/src/golang.org/x# ls net text root@km:~/kubernetes/staging/src/golang.org/x#  好了，到这里看到了，确实是没有 crypto, 下载 golang 在 github.com 下的官方镜像吧。\nroot@km:~/kubernetes/staging/src/golang.org/x# git clone https://github.com/golang/crypto.git Cloning into 'crypto'... remote: Counting objects: 3889, done. remote: Compressing objects: 100% (22/22), done. remote: Total 3889 (delta 6), reused 18 (delta 4), pack-reused 3863 Receiving objects: 100% (3889/3889), 2.82 MiB | 44.00 KiB/s, done. Resolving deltas: 100% (2469/2469), done. Checking connectivity... done. root@km:~/kubernetes/staging/src/golang.org/x# ls crypto net text root@km:~/kubernetes/staging/src/golang.org/x#  好了，现在有了。\n如果后续还有其它的 golang 的包，也这么处理吧。\n回到之前的 terminal 吧。 接着 go get\nroot@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# go get github.com/kubernetes-incubator/external-storage/lib/controller root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs# make CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags \u0026quot;-static\u0026quot;' -o cephfs-provisioner cephfs-provisioner.go # command-line-arguments ./cephfs-provisioner.go:65: cannot use cephFSProvisioner literal (type *cephFSProvisioner) as type controller.Provisioner in return argument: *cephFSProvisioner does not implement controller.Provisioner (wrong type for Delete method) have Delete(*\u0026quot;k8s.io/api/core/v1\u0026quot;.PersistentVolume) error want Delete(*\u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/api/core/v1\u0026quot;.PersistentVolume) error ./cephfs-provisioner.go:69: cannot use cephFSProvisioner literal (type *cephFSProvisioner) as type controller.Provisioner in assignment: *cephFSProvisioner does not implement controller.Provisioner (wrong type for Delete method) have Delete(*\u0026quot;k8s.io/api/core/v1\u0026quot;.PersistentVolume) error want Delete(*\u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/api/core/v1\u0026quot;.PersistentVolume) error ./cephfs-provisioner.go:134: cannot use options.PersistentVolumeReclaimPolicy (type \u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/api/core/v1\u0026quot;.PersistentVolumeReclaimPolicy) as type \u0026quot;k8s.io /api/core/v1\u0026quot;.PersistentVolumeReclaimPolicy in field value ./cephfs-provisioner.go:135: cannot use options.PVC.Spec.AccessModes (type []\u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/api/core/v1\u0026quot;.PersistentVolumeAccessMode) as type []\u0026quot;k8s.io/api/cor e/v1\u0026quot;.PersistentVolumeAccessMode in field value ./cephfs-provisioner.go:137: cannot use \u0026quot;k8s.io/api/core/v1\u0026quot;.ResourceName(\u0026quot;k8s.io/api/core/v1\u0026quot;.ResourceStorage) (type \u0026quot;k8s.io/api/core/v1\u0026quot;.ResourceName) as type \u0026quot;github.com/kubernetes-incubator/external-stor age/vendor/k8s.io/api/core/v1\u0026quot;.ResourceName in map index ./cephfs-provisioner.go:137: cannot use options.PVC.Spec.Resources.Requests[\u0026quot;k8s.io/api/core/v1\u0026quot;.ResourceName(\u0026quot;k8s.io/api/core/v1\u0026quot;.ResourceStorage)] (type \u0026quot;github.com/kubernetes-incubator/external-storage/ve ndor/k8s.io/apimachinery/pkg/api/resource\u0026quot;.Quantity) as type \u0026quot;k8s.io/apimachinery/pkg/api/resource\u0026quot;.Quantity in map value ./cephfs-provisioner.go:147: cannot use \u0026quot;k8s.io/api/core/v1\u0026quot;.CephFSVolumeSource literal (type *\u0026quot;k8s.io/api/core/v1\u0026quot;.CephFSVolumeSource) as type *\u0026quot;k8s.io/api/core/v1\u0026quot;.CephFSPersistentVolumeSource in field val ue ./cephfs-provisioner.go:318: cannot use clientset (type *\u0026quot;k8s.io/client-go/kubernetes\u0026quot;.Clientset) as type \u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/client-go/kubernetes\u0026quot;.Interface in ar gument to controller.NewProvisionController: *\u0026quot;k8s.io/client-go/kubernetes\u0026quot;.Clientset does not implement \u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/client-go/kubernetes\u0026quot;.Interface (wrong type for Admissionregistration metho d) have Admissionregistration() \u0026quot;k8s.io/client-go/kubernetes/typed/admissionregistration/v1alpha1\u0026quot;.AdmissionregistrationV1alpha1Interface want Admissionregistration() \u0026quot;github.com/kubernetes-incubator/external-storage/vendor/k8s.io/client-go/kubernetes/typed/admissionregistration/v1alpha1\u0026quot;.AdmissionregistrationV1alpha1Interface Makefile:27: recipe for target 'all' failed make: *** [all] Error 2 root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs#  又报错。\n这个好像是说冲突了嘛。。。\n农总来了。\nroot@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage# ln -s ~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/lib build/src/github.com/kubernetes-incubator/external-storage/ root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage# make ceph/cephfs cd ceph/cephfs; \\ make container make[1]: Entering directory '/root/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs' CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags \u0026quot;-static\u0026quot;' -o cephfs-provisioner cephfs-provisioner.go docker build -t quay.io/external_storage/cephfs-provisioner:latest . Sending build context to Docker daemon 36.23MB Step 1/6 : FROM centos:7 7: Pulling from library/centos d9aaf4d82f24: Pull complete Digest: sha256:eba772bac22c86d7d6e72421b4700c3f894ab6e35475a34014ff8de74c10872e Status: Downloaded newer image for centos:7 ---\u0026gt; 196e0ce0c9fb Step 2/6 : ENV CEPH_VERSION \u0026quot;jewel\u0026quot; ---\u0026gt; Running in c48e286ca165 ---\u0026gt; e9689ae3f521 Removing intermediate container c48e286ca165 Step 3/6 : RUN rpm -Uvh https://download.ceph.com/rpm-$CEPH_VERSION/el7/noarch/ceph-release-1-1.el7.noarch.rpm \u0026amp;\u0026amp; yum install -y epel-release \u0026amp;\u0026amp; yum install -y ceph-common python-cephfs ---\u0026gt; Running in 69640c268019 warning: /var/tmp/rpm-tmp.6mAWB0: Header V4 RSA/SHA256 Signature, key ID 460f3994: NOKEY Retrieving https://download.ceph.com/rpm-jewel/el7/noarch/ceph-release-1-1.el7.noarch.rpm Preparing... ######################################## Updating / installing... ceph-release-1-1.el7 ######################################## Loaded plugins: fastestmirror, ovl Determining fastest mirrors * base: mirrors.cn99.com * extras: mirrors.cn99.com * updates: mirrors.cn99.com userspace-rcu.x86_64 0:0.7.16-1.el7 .... ... ... # 好长的一断时间，大约半个小时后 Complete! ---\u0026gt; 21cae91539c0 Removing intermediate container b1c88201e72b Step 4/6 : COPY cephfs-provisioner /usr/local/bin/cephfs-provisioner ---\u0026gt; 73664d0eca7a Removing intermediate container c076e6de19f0 Step 5/6 : COPY cephfs_provisioner/cephfs_provisioner.py /usr/local/bin/cephfs_provisioner ---\u0026gt; 25bc4c6da1d1 Removing intermediate container 0eba40388f99 Step 6/6 : CMD chmod o+x /usr/local/bin/cephfs_provisioner ---\u0026gt; Running in 5bf6e5fbc6e1 ---\u0026gt; 262cba7e52ed Removing intermediate container 5bf6e5fbc6e1 Successfully built 262cba7e52ed Successfully tagged quay.io/external_storage/cephfs-provisioner:latest docker tag quay.io/external_storage/cephfs-provisioner:latest quay.io/external_storage/cephfs-provisioner:latest make[1]: Leaving directory '/root/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs' root@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage#  成功了，看一下 docker image 是不是多了一个 quay.io/external_storage/cephfs-provisioner:latest\nroot@km:~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage# docker images REPOSITORY TAG IMAGE ID CREATED SIZE quay.io/external_storage/cephfs-provisioner latest 262cba7e52ed 5 minutes ago 485MB gcr.io/google-samples/hello-frontend 1.0 d8ca9fb857d9 3 weeks ago 183MB  果然有了。\n这样，make 算是完成了。\n后来发现 docker image 的文件不对。\nvi Dockerfile\nroot@km:~/cephfs# cat ~/kubernetes.io/TUTORIALS/Stateful-Applications/cephfs-stateful/external-storage/ceph/cephfs/Dockerfile # Copyright 2017 The Kubernetes Authors. # # Licensed under the Apache License, Version 2.0 (the \u0026quot;License\u0026quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. FROM centos:7 ENV CEPH_VERSION \u0026quot;jewel\u0026quot; RUN rpm -Uvh https://download.ceph.com/rpm-$CEPH_VERSION/el7/noarch/ceph-release-1-1.el7.noarch.rpm \u0026amp;\u0026amp; \\ yum install -y epel-release \u0026amp;\u0026amp; \\ yum install -y ceph-common python-cephfs COPY cephfs-provisioner /usr/local/bin/cephfs-provisioner COPY cephfs_provisioner/cephfs_provisioner.py /usr/local/bin/cephfs_provisioner CMD [\u0026quot;chmod\u0026quot;, \u0026quot;o+x\u0026quot;, \u0026quot;/usr/local/bin/cephfs_provisioner\u0026quot;] root@km:~/cephfs#  这个地方的 ENV CEPH_VERSION \u0026ldquo;jewel\u0026rdquo; 应该修改成 ENV CEPH_VERSION \u0026ldquo;luminous\u0026rdquo;\n然后再 make\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-install-v183.html",
	"title": "kubeadm v1.8.3 安装",
	"tags": ["kubernetes", "install"],
	"description": "",
	"content": " https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\nenv 192.168.31.120 km master 192.168.31.119 kn1 node 192.168.31.118 kn2 node  Initializing your master kubeadm init --pod-network-cidr=10.244.0.0/16  如果遇到类似下面错误\n- [preflight] Some fatal errors occurred: :: Port 10250 is in use /etc/kubernetes/manifests is not empty /var/lib/kubelet is not empty  则，参考 https://github.com/kubernetes/kubernetes/issues/37063 运行下面命令：\nkubeadm reset systemctl start kubelet.service  之后，再次运行\nkubeadm init --pod-network-cidr=10.244.0.0/16  被墙了，出不去，我了个去，怎么办？\nhttps://mritd.me/2016/10/29/set-up-kubernetes-cluster-by-kubeadm/#21安装包从哪来\n好吧，那就去 hub.docker.com 中配置吧\n找到所有要配置的 image 找 etc/kubernetes/manifests root@km:~# cd /etc/kubernetes/manifests/ root@km:/etc/kubernetes/manifests# ls etcd.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml root@km:/etc/kubernetes/manifests# root@km:/etc/kubernetes/manifests# cat *.yaml | grep image image: gcr.io/google_containers/etcd-amd64:3.0.17 image: gcr.io/google_containers/kube-apiserver-amd64:v1.8.3 image: gcr.io/google_containers/kube-controller-manager-amd64:v1.8.3 image: gcr.io/google_containers/kube-scheduler-amd64:v1.8.3 root@km:/etc/kubernetes/manifests#  找源码 https://github.com/kubernetes/kubernetes/tree/master/cmd/kubeadm\nroot@km:~/kubernetes.20171116/cmd/kubeadm# git clone https://github.com/kubernetes/kubernetes kubernetes.20171116 root@km:~# cd kubernetes.20171116 root@km:~/kubernetes.20171116# cd cmd/kubeadm/ root@km:~/kubernetes.20171116/cmd/kubeadm# grep gcr.io -r ./ ./app/apis/kubeadm/v1alpha1/defaults.go: DefaultImageRepository = \u0026quot;gcr.io/google_containers\u0026quot; ./app/phases/selfhosting/selfhosting_test.go: image: gcr.io/google_containers/kube-apiserver-amd64:v1.7.4 ./app/phases/selfhosting/selfhosting_test.go: image: gcr.io/google_containers/kube-apiserver-amd64:v1.7.4 ./app/phases/selfhosting/selfhosting_test.go: image: gcr.io/google_containers/kube-controller-manager-amd64:v1.7.4 ./app/phases/selfhosting/selfhosting_test.go: image: gcr.io/google_containers/kube-controller-manager-amd64:v1.7.4 ./app/phases/selfhosting/selfhosting_test.go: image: gcr.io/google_containers/kube-scheduler-amd64:v1.7.4 ./app/phases/selfhosting/selfhosting_test.go: image: gcr.io/google_containers/kube-scheduler-amd64:v1.7.4 ./app/phases/selfhosting/selfhosting_test.go: - image: gcr.io/google_containers/busybox ./app/phases/selfhosting/selfhosting_test.go: \u0026quot;image\u0026quot;: \u0026quot;gcr.io/google_containers/busybox\u0026quot; ./app/phases/selfhosting/selfhosting_test.go: - image: gcr.io/google_containers/busybox ./app/phases/upgrade/staticpods_test.go:imageRepository: gcr.io/google_containers ./app/util/template_test.go: validTmplOut = \u0026quot;image: gcr.io/google_containers/pause-amd64:3.0\u0026quot; ./app/util/template_test.go: doNothing = \u0026quot;image: gcr.io/google_containers/pause-amd64:3.0\u0026quot; ./app/util/template_test.go: ImageRepository: \u0026quot;gcr.io/google_containers\u0026quot;, ./app/util/template_test.go: ImageRepository: \u0026quot;gcr.io/google_containers\u0026quot;, ./app/images/images_test.go: gcrPrefix = \u0026quot;gcr.io/google_containers\u0026quot; ./app/constants/constants.go: DefaultCIImageRepository = \u0026quot;gcr.io/kubernetes-ci-images\u0026quot; root@km:~/kubernetes.20171116/cmd/kubeadm#  最后，居然什么也没有找到。哎呀。好吧。\n回到 https://gitee.com/tomt/tom%5Fdocker%5Fregistry%5Fpush%5Fpull.git ，看了一下，也就是这4个需要更新一下。\ngcr.io/google_containers/kube-apiserver-amd64:v1.8.3 gcr.io/google_containers/kube-proxy-amd64:v1.8.3 gcr.io/google_containers/kube-scheduler-amd64:v1.8.3 gcr.io/google_containers/kube-controller-manager-amd64:v1.8.3  好了。明确了image, 那就做吧。\ngithub hub.docker.io 配置 image 注意，在 hub.docker.io 下，自动构建仓库，时，取 github的仓库，对这个仓库名称有限制\n 不能大于3个 “-” 号 长度不能太长  这样呢，gcr.io/google_containers/kube-controller-manager-amd64:v1.8.3，在 github上本来要创建名称为 dockerlibraryk8s-kube-controller-manager-amd64 ，那这个不符合要求的。 怎么办？改个名称咯。 我把它修改成 dockerlibraryk8s-kube-cm-amd64了。 记得最后，pull 下来的时候，docker tag 一下。\nroot@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# ls dockerlibraryk8s.sh k8s-v1.8.3.txt root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# cat dockerlibraryk8s.sh #images=(heapster-influxdb-amd64:v1.3.3 heapster-amd64:v1.4.0 heapster-grafana-amd64:v4.4.3) #images=(heapster-grafana-amd64:v4.4.3) for imageName in `cat k8s-v1.8.3.txt`; do echo $imageName echo ${imageName%:*} echo ${imageName#*:} imageNamelast=dockerlibraryk8s-${imageName%:*} echo docker pull tomtsang/$imageNamelast docker pull tomtsang/$imageNamelast echo docker tag tomtsang/$imageNamelast gcr.io/google_containers/$imageName docker tag tomtsang/$imageNamelast gcr.io/google_containers/$imageName echo docker rmi tomtsang/$imageNamelast docker rmi tomtsang/$imageNamelast done echo \u0026quot;game over\u0026quot; root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# docker pull tomtsang/dockerlibraryk8s-kube-cm-amd64 Using default tag: latest latest: Pulling from tomtsang/dockerlibraryk8s-kube-cm-amd64 0ffadd58f2a6: Already exists 18c5c31a1ebe: Pull complete Digest: sha256:4e738f80a607772c205ca597c1d5874ee50ac40f0a5e88ab85084fd45b684ac0 Status: Downloaded newer image for tomtsang/dockerlibraryk8s-kube-cm-amd64:latest root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# docker tag tomtsang/dockerlibraryk8s-kube-cm-amd64 gcr.io/google_containers/dockerlibraryk8s-kube-cm-amd64:v1.8.3 root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# docker tag gcr.io/google_containers/dockerlibraryk8s-kube-cm-amd64:v1.8.3 gcr.io/google_containers/kube-controller-manager-amd64:v1.8.3 root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# docker rmi tomtsang/dockerlibraryk8s-kube-cm-amd64 Untagged: tomtsang/dockerlibraryk8s-kube-cm-amd64:latest Untagged: tomtsang/dockerlibraryk8s-kube-cm-amd64@sha256:4e738f80a607772c205ca597c1d5874ee50ac40f0a5e88ab85084fd45b684ac0 root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3#  使用 http://git.oschina.net/tomt/tom%5Fk8s%5Fkubernetes%5Finstall 这个仓库吧。\nroot@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# git remote -v origin http://git.oschina.net/tomt/tom_k8s_kubernetes_install (fetch) origin http://git.oschina.net/tomt/tom_k8s_kubernetes_install (push) root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# ls dockerlibraryk8s.sh k8s-v1.8.3.txt root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# pwd /root/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3 root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# ls dockerlibraryk8s.sh k8s-v1.8.3.txt root@km:~/tom_k8s_kubernetes_install/k8/docker-library-k8s-v1.8.3# ./dockerlibraryk8s.sh  到现在为止，应该 4 个 image都成功pull 到了 master节点了。\ndocker registry push 因为我们后面要在 node 节点上使用，所以干脆就直接 push 到 docker registry 去吧。\nkubeadm-init-use-local-image 参看 kubeadm-init-use-local-image.rst 文件。\n好像没成功\nkubeadm init root@km:~# export ... declare -x http_proxy=\u0026quot;http://192.168.31.239:8118/\u0026quot; declare -x https_proxy=\u0026quot;http://192.168.31.239:8118/\u0026quot; declare -x no_proxy=\u0026quot;localhost,127.0.0.1,192.168.31.120,10.96.0.10,github.com,ubuntu.com\u0026quot;  root@km:~# kubeadm init --pod-network-cidr=10.244.0.0/16 --skip-preflight-checks .... .... .... To start using your cluster, you need to run (as a regular user): mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026quot;kubectl apply -f [podnetwork].yaml\u0026quot; with one of the options listed at: http://kubernetes.io/docs/admin/addons/ You can now join any number of machines by running the following on each node as root: kubeadm join --token ce4253.8322cc2590378260 192.168.31.120:6443 --discovery-token-ca-cert-hash sha256:bb0b9ef27e5ffef06776ca10a87ed548cefedc703ddaf904316c87d4a7f3655d  有image, 而不能启动docker container.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-5-notes.html",
	"title": "Spacemacs Rocks Day 5, Find, Search and replace",
	"tags": ["emacs", "spacemacs", "search"],
	"description": "",
	"content": " Evil search  Use / and * to start search. Use n \u0026amp; N to search forward and backward  进入 iedit 批量修改  * e\n 修改的时候，按S则删除原单词，修改完成后，按ESC，2次，退出iedit模式回到Normal模式。\n选择匹配范围。 多次按 r 切换匹配区域（当前buffer, 当前屏幕，当前函数）\n * r\n 按 e 进入编辑模式，按 f 进入函数区域，按S开始修改。\n清除搜索下的高亮：evil-search-clear-highlight  SPC s c\n Swiper  C-s to start search.  搜索到结果后，C-j, C-k, C-n, C-p 可以跳转\n C-c C-o to enter ivy-occur  可以把当前的搜索项，罗列在另一个buffer中。\nHelm-swoop SPC s s/S to search search C-c C-e to enter edit mode SPC h l(helm-resume)\n直接搜索光标处的单词  SPC s S\n 批量修改  搜索后，C-c C-e\n 只是打开另一个buffer, 没有做到 批量修改，至于后面提到的 C-x C-s 保存修改结果，更无从谈起了。\n正确的是什么方式？\n开启上一次搜索项目，查询上一次搜索结果 修正：\nSPC h l runs the command ivy-spacemacs-help-layers, 查询layers help文档。不是视 频说的：开启上一次搜索项目，查询上一次搜索结果。\nHelm-imenu-or-semantic To search structured word. SPC s l\nOccur to search and multiple editing M-s o to use occur and e to enter edit mode. C-c to finish editing. Edit search result one by one. Edit search result with iedit and multiple cursor.\nHelm -ag F3 to save search result, SPC s L to open last save search buffer.\n这里的 F3 to save search result, SPC s L to open last save search buffer. 没有做到,谁知道呀？\nSPC s p to search project wide C-c c-e\nSPC s f to search for files and certain suffix files. 指定搜索某单个文件  SPC s f 选择某文件\n 指定搜索某类型文件  SPC u SPC s f 选择某文件夹，选择某文件类型\n SPC s b to search all the open buffer SPC n f to narrow to function, SPC n w to restore After narrowing, you could use :%s/old/new/g to replace\n方法1 标记搜索内容后，搜索buffer\n SPC s E\n 再按 F ,缩小到只有当前函数。再按S,进行编辑。\n方法2  SPC n f\n  替换1   %s/A/B/g\n  替换1   光标处，* e S, 编辑完成后，ESC ESC，返回到 normal 模式\n 替换完成后，\n SPC n w\n "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-cephfs-faq.html",
	"title": "k8s 与 cephfs 相关的FAQ",
	"tags": ["ceph", "cephfs", "kubernetes", "faq"],
	"description": "",
	"content": " Input/output error cephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$ ll kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/ ls: reading directory 'kubernetes-dynamic-pvc-a2c667ad-d0c7-11e7-b656-0a580af40148/': Input/output error total 0 drwxr-xr-x 1 root root 0 Nov 24 11:36 ./ drwxr-xr-x 1 root root 0 Nov 24 11:29 ../ cephu@ceph-client:/mnt/mycephfs/volumes/kubernetes$  这个问题，看了一下，https://github.com/kubernetes-incubator/external-storage/issues/345，\n最后，有用户是这样回复的\nI tried to update my ubuntu kernel from 4.4.0 to 4.10.0 (sudo apt install linux-image-4.10.0-28-generic) and after a reboot, the error is gone, everything works fine from now on :)  所以就是升级内核了。升级去吧。 升级一下，果然成功了。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-init-use-local-image.html",
	"title": "使用本地镜像进行kubeadm init",
	"tags": ["kubernetes", "install", "image"],
	"description": "",
	"content": " 因为 kubeadm 安装 要提前下载好docker images, 并使用 这些个 docker images. 但是，我们公司的网络FQ的下载速度太慢，时不时会断了。所以，我们考虑使用本地下载好的这些 images。\n要使用 local images, 那就要去修改 kubeadm 的代码，并重新build。好吧，我们build 吧。\nenv 192.168.31.120 km master 192.168.31.119 kn1 node 192.168.31.118 kn2 node  kubeadm-build 见 kubeadm-build 部分\n加代理 root@km:/etc/kubernetes/manifests# export declare -x HOME=\u0026quot;/root\u0026quot; declare -x LANG=\u0026quot;en_US.UTF-8\u0026quot; declare -x LANGUAGE=\u0026quot;en_US:en\u0026quot; declare -x LESSCLOSE=\u0026quot;/usr/bin/lesspipe %s %s\u0026quot; declare -x LESSOPEN=\u0026quot;| /usr/bin/lesspipe %s\u0026quot; declare -x LOGNAME=\u0026quot;root\u0026quot; declare -x LS_COLORS=\u0026quot;rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\u0026quot; declare -x MAIL=\u0026quot;/var/mail/root\u0026quot; declare -x NO_PROXY=\u0026quot;localhost,127.0.0.1/8,192.168.31.1/24\u0026quot; declare -x OLDPWD=\u0026quot;/etc/kubernetes\u0026quot; declare -x PATH=\u0026quot;/home/jlch/.ana/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\u0026quot; declare -x PWD=\u0026quot;/etc/kubernetes/manifests\u0026quot; declare -x SHELL=\u0026quot;/bin/bash\u0026quot; declare -x SHLVL=\u0026quot;1\u0026quot; declare -x SUDO_COMMAND=\u0026quot;/bin/su\u0026quot; declare -x SUDO_GID=\u0026quot;1000\u0026quot; declare -x SUDO_UID=\u0026quot;1000\u0026quot; declare -x SUDO_USER=\u0026quot;jlch\u0026quot; declare -x TERM=\u0026quot;xterm\u0026quot; declare -x USER=\u0026quot;root\u0026quot; declare -x USERNAME=\u0026quot;root\u0026quot; declare -x http_proxy=\u0026quot;http://192.168.31.10:1080\u0026quot; declare -x https_proxy=\u0026quot;http://192.168.31.10:1080\u0026quot; declare -x no_proxy=\u0026quot;localhost,127.0.0.1,192.168.31.120,192.168.0.0/16,10.96.0.0/16,github.com\u0026quot;  kubeadm init 把这个 kubeadm 放到 km 下\nroot@km:/etc/kubernetes/manifests# chmod a+rx /usr/bin/kubeadm root@km:/etc/kubernetes/manifests# kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;8+\u0026quot;, GitVersion:\u0026quot;v1.8.3-dirty\u0026quot;, GitCommit:\u0026quot;f0efb3cb883751c5ffdbe6d515f3cb4fbe7b7acd\u0026quot;, GitTreeState:\u0026quot;dirty\u0026quot;, BuildDate:\u0026quot;2017-11-20T07:05:42Z\u0026quot;, GoVersion:\u0026quot;go1.9.2\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} root@km:/etc/kubernetes/manifests# root@km:/etc/kubernetes/manifests# kubeadm init --pod-network-cidr=10.244.0.0/16 --skip-preflight-checks [kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters. unable to get URL \u0026quot;https://dl.k8s.io/release/stable-1.8.txt\u0026quot;: Get https://dl.k8s.io/release/stable-1.8.txt: net/http: TLS handshake timeout root@km:/etc/kubernetes/manifests#  不成功呀。连接上了代理，还是会 pull image\n其它测试 root@km:/etc/kubernetes/manifests# kubeadm alpha phase etcd local unable to get URL \u0026quot;https://dl.k8s.io/release/stable-1.8.txt\u0026quot;: Get https://dl.k8s.io/release/stable-1.8.txt: net/http: TLS handshake timeout root@km:/etc/kubernetes/manifests#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-6-notes.html",
	"title": "Spacemacs Rocks Day 6, Org-mode as a blogging engine",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " youku\nStart to blogging any place and any time. Press F1 to launch a menu and type blog to choose. Navigation all the blog posts\nhttps://github.com/CodeFalling/blog-admin\n这里的配置，主要是针对 hexo\nPress W to new post Enter the title of your new post\n快速生成一个draft blog\n下面这个在另一篇博文中已经提过。  C-c t h\n 使用 yasnippet 模板，快速生成一个draft hugo 文章信息模板\nStart writing You could use all the Org syntax here. But org table is not well supported.\n Headings. Insert links. Insert Images Insert Code(We can even execute the code in the documents, oh my!)  Insert links: zilongshanren/insert-chrome-current-tab-url  C-c l\n Insert Images 截图  M-x zilongshanren/capture-screenshot\n 这里，子龙山人的操作，使得截图自动生成 ，其中图片名格式 为：日期-博文名-图片名.png, 且放置在了博客的一个图片文件夹中。 再通过一个 zilongshanren/octopress-upimg 函数，把这个图片上传到七牛云存储中，这 时回车，就可以通过浏览器访问到此图片。\n这2步，他是怎么做到的呢？\nInsert Code  C-c i s\n runs the command zilongshanren/org-insert-src-block ，插入完成后， 然后可以直接执行这一段代码。这个功能，还是蛮好的。\n怎么执行的呢？\n按 `C-c` 后，还按了什么键，出现了 `Evaluate this C++ code block on your system? (y or n)`\n就是没有找到按的是什么键\n但是我发现，只要把光标，移动到 `#+BEGIN_SRC`这个地方，minibuffer处，会自动提示出 `:results :exports :tangle` 这些，然后，直接回车，就是上面这个询问。\necho \u0026quot;hello world\u0026quot;  Preview and publish Preview runs the command prodigy to preview  SPC a S\n 然后按 s 启动 hugo server 就可以了。\n s 开启服务 S 关闭服务 r 重启服务  prodigy的快捷键，参考这里  https://segmentfault.com/a/1190000000452049 https://github.com/rejeep/prodigy.el  这里的前提是配置了hugo server 相关的 prodigy 参考 - https://www.shanesveller.com/blog/2018/02/13/blogging-with-org-mode-and-ox-hugo/ 或者子龙的hexo的配置就可以了。我的配置如下：\n(prodigy-define-service :name \u0026quot;Hugo Server beautifulhugo\u0026quot; :command \u0026quot;/usr/local/bin/hugo\u0026quot; :args '(\u0026quot;server\u0026quot; \u0026quot;-D\u0026quot; \u0026quot;--navigateToChanged\u0026quot; \u0026quot;-t\u0026quot; \u0026quot;beautifulhugo\u0026quot;) :cwd \u0026quot;~/******jc-hugo\u0026quot; :tags '(hugo server) :stop-signal 'sigkill :init (lambda () (browse-url \u0026quot;http://localhost:1313\u0026quot;)) :kill-process-buffer-on-stop t) (prodigy-define-service :name \u0026quot;Hugo Server\u0026quot; :command \u0026quot;hugo\u0026quot; :args '(\u0026quot;server\u0026quot;) :cwd \u0026quot;~/******jc-hugo\u0026quot; :tags '(hugo server) :kill-signal 'sigkill :kill-process-buffer-on-stop t)  这里的 args 参数里的内容，可以自己先在 shell 下尝试，并了解清楚含义。比如 -t beautifulhugo指 的是theme主题名为beautifulhugo\n➜ hugo git:(master) ✗ /usr/local/bin/hugo server -D --navigateToChanged -t beautifulhugo | EN +------------------|-----+ Pages | 930 Paginator pages | 66 Non-page files | 0 Static files | 28 Processed images | 0 Aliases | 314 Sitemaps | 1 Cleaned | 0 Total in 632 ms  deploy "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubeadm-build.html",
	"title": "kubeadm build",
	"tags": ["kubernetes", "install", "build"],
	"description": "",
	"content": " build kubeadm 修改 Kubeadm 使得 etc/kubernetes/manifests 下的 *.yaml 文件带有 imagePullPolicy: IfNotPresent\nenv 192.168.31.114 jlch\ngopath cd ~/gopath/src/github.com/kubernetes/ git clone https://github.com/kubernetes/kubernetes.git cd kubernetes  修改吧 jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes$ git status Not currently on any branch. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: cmd/kubeadm/app/phases/controlplane/manifests.go modified: cmd/kubeadm/app/phases/etcd/local.go no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes$ git diff cmd/kubeadm/app/phases/controlplane/manifests.go diff --git a/cmd/kubeadm/app/phases/controlplane/manifests.go b/cmd/kubeadm/app/phases/controlplane/manifests.go index 7d2784d..5b2833f 100644 --- a/cmd/kubeadm/app/phases/controlplane/manifests.go +++ b/cmd/kubeadm/app/phases/controlplane/manifests.go @@ -75,6 +75,7 @@ func GetStaticPodSpecs(cfg *kubeadmapi.MasterConfiguration, k8sVersion *version. kubeadmconstants.KubeAPIServer: staticpodutil.ComponentPod(v1.Container{ Name: kubeadmconstants.KubeAPIServer, Image: images.GetCoreImage(kubeadmconstants.KubeAPIServer, cfg.GetControlPlaneImageRepository(), cfg.KubernetesVersion, cfg.UnifiedControlPlaneImage), + ImagePullPolicy: v1.PullIfNotPresent, Command: getAPIServerCommand(cfg, k8sVersion), VolumeMounts: mounts.GetVolumeMounts(kubeadmconstants.KubeAPIServer), LivenessProbe: staticpodutil.ComponentProbe(int(cfg.API.BindPort), \u0026quot;/healthz\u0026quot;, v1.URISchemeHTTPS), @@ -84,6 +85,7 @@ func GetStaticPodSpecs(cfg *kubeadmapi.MasterConfiguration, k8sVersion *version. kubeadmconstants.KubeControllerManager: staticpodutil.ComponentPod(v1.Container{ Name: kubeadmconstants.KubeControllerManager, Image: images.GetCoreImage(kubeadmconstants.KubeControllerManager, cfg.GetControlPlaneImageRepository(), cfg.KubernetesVersion, cfg.UnifiedControlPlaneImage), + ImagePullPolicy: v1.PullIfNotPresent, Command: getControllerManagerCommand(cfg, k8sVersion), VolumeMounts: mounts.GetVolumeMounts(kubeadmconstants.KubeControllerManager), LivenessProbe: staticpodutil.ComponentProbe(10252, \u0026quot;/healthz\u0026quot;, v1.URISchemeHTTP), @@ -93,6 +95,7 @@ func GetStaticPodSpecs(cfg *kubeadmapi.MasterConfiguration, k8sVersion *version. kubeadmconstants.KubeScheduler: staticpodutil.ComponentPod(v1.Container{ Name: kubeadmconstants.KubeScheduler, Image: images.GetCoreImage(kubeadmconstants.KubeScheduler, cfg.GetControlPlaneImageRepository(), cfg.KubernetesVersion, cfg.UnifiedControlPlaneImage), + ImagePullPolicy: v1.PullIfNotPresent, Command: getSchedulerCommand(cfg), VolumeMounts: mounts.GetVolumeMounts(kubeadmconstants.KubeScheduler), LivenessProbe: staticpodutil.ComponentProbe(10251, \u0026quot;/healthz\u0026quot;, v1.URISchemeHTTP), jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes$ git diff cmd/kubeadm/app/phases/etcd/local.go diff --git a/cmd/kubeadm/app/phases/etcd/local.go b/cmd/kubeadm/app/phases/etcd/local.go index e947794..8cc609a 100644 --- a/cmd/kubeadm/app/phases/etcd/local.go +++ b/cmd/kubeadm/app/phases/etcd/local.go @@ -54,6 +54,7 @@ func GetEtcdPodSpec(cfg *kubeadmapi.MasterConfiguration) v1.Pod { Name: kubeadmconstants.Etcd, Command: getEtcdCommand(cfg), Image: images.GetCoreImage(kubeadmconstants.Etcd, cfg.ImageRepository, \u0026quot;\u0026quot;, cfg.Etcd.Image), + ImagePullPolicy: v1.PullIfNotPresent, // Mount the etcd datadir path read-write so etcd can store data in a more persistent manner VolumeMounts: []v1.VolumeMount{staticpodutil.NewVolumeMount(etcdVolumeName, cfg.Etcd.DataDir, false)}, LivenessProbe: staticpodutil.ComponentProbe(2379, \u0026quot;/health\u0026quot;, v1.URISchemeHTTP), jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes$  make jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes$ make jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes$ cd _output/ jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes/_output$ ls bin local jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes/_output$ cd bin/ jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes/_output/bin$ ls apiextensions-apiserver conversion-gen defaulter-gen e2e.test genfeddocs genman genyaml gke-certificates-controller hyperkube kube-aggregator kube-controller-manager kubefed kubemark kube-scheduler openapi-gen cloud-controller-manager deepcopy-gen e2e_node.test gendocs genkubedocs genswaggertypedocs ginkgo go-bindata kubeadm kube-apiserver kubectl kubelet kube-proxy linkcheck teststale jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes/_output/bin$ ./kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;8+\u0026quot;, GitVersion:\u0026quot;v1.8.3-dirty\u0026quot;, GitCommit:\u0026quot;f0efb3cb883751c5ffdbe6d515f3cb4fbe7b7acd\u0026quot;, GitTreeState:\u0026quot;dirty\u0026quot;, BuildDate:\u0026quot;2017-11-20T07:05:42Z\u0026quot;, GoVersion:\u0026quot;go1.9.2\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} jlch@mon1:~/gopath/src/github.com/kubernetes/kubernetes/_output/bin$  好了，现在我们要的就是 kubeadm 文件。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-7-notes.html",
	"title": "Spacemacs Rocks Day 7, Spacemacs buffer, file, project and layout management",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " youku\nSPC f \u0026mdash;\u0026gt; file related operations SPC f f --\u0026gt; helm-find-file SPC f r --\u0026gt; open recent file SPC f R --\u0026gt; rename file SPC f c --\u0026gt; copy file SPC f j --\u0026gt; jump to dired SPC f t --\u0026gt; open neo tree SPC f o --\u0026gt; open in external application  在 SPC f f的时候，可以通过 TAB 和 C-h 补充和回退文件夹名。\nSPC b \u0026mdash;\u0026gt; buffer related operations SPC b b \u0026amp; SPC b B(i) SPC b h (spacemacs home buffer) SPC b s (scratch buffer) SPC b f (reveal in finder) SPC b w in dired buffer. SPC b n/p (previous or next buffer) SPC b TAB to switch back and forth.  SPC b w in dired buffer.从而实现对文件名的修改, 多行编辑等操作。\nSPC p \u0026mdash;\u0026gt; project related operations SPC p f and SPC p b  SPC l \u0026mdash;\u0026gt; layout replated operations SPC l o --\u0026gt; custom layout SPC l L/s --\u0026gt; load or save layout SPC l l --\u0026gt; switch bewteen layout SPC l TAB --\u0026gt; quick way to switch SPC l ? --\u0026gt; open up the help. SPC p l --\u0026gt; switch to project and create a layout  dired related operations new file/delete file/rename file new folder/delete folder/rename folder  `+`号,新建文件夹。 在文件夹上，f 新建文件。\n标记并删除 在 dired 模式下，m 标记，D 删除。\nRanger SPC a r h l to navigate folder j k to preview file  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock.html",
	"title": "stock",
	"tags": [],
	"description": "stock",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-delete-node.html",
	"title": "kubernetes delete node",
	"tags": ["kubernetes", "install", "delete"],
	"description": "",
	"content": "clear cat k8.export.sh export KUBECONFIG=$HOME/admin.conf ls k get node kubectl drain kn1 --delete-local-data --force --ignore-daemonsets kubectl delete node kn1 kubectl drain kn2 --delete-local-data --force --ignore-daemonsets kubectl delete node kn2 k get node clear kubectl drain km --delete-local-data --force --ignore-daemonsets kubeadm reset k get pod --all-namespaces docker ps  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-8-notes.html",
	"title": "Spacemacs Rocks Day 8, Spacemacs as a JavaScript/Node.js IDE",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " Autocompletion  company-etags vs company-tern hippie-expand   M-x hippie-expand\n 或者\n M-/\n Jump to definition  SPC s l to jump to function definitions. ctags. SPC m g d/ etags-select SPC s p / SPC o s to search keywords SPC m g g if use tern.js  jump to function definitions. ctags\u0026gt; SPC s l 已经失效了\netags-select etags, 基于正则表达式的补全 \u0026gt; SPC m g d 和 \u0026gt; , g d 相同\ntern 精确补全 \u0026gt; SPC m g g 也就是 \u0026gt; , g g\nSyntax check  flycheck with jshint / eslint js2-mode checking  开启语法检查  SPC t s\n 查看语法错误信息  SPC e l\n REPL  jscomint  jscomint has better ES6 support. But the keybinding are not perfect\n nodejs repl  ES6 support is not good, but has better keybinding.\nnodejs repl 开启\n M-x nodejs-repl\n 关闭 nodejs-repl\n .exit\n 去 nodejs-repl buffer执行当前行\n , e d\n 已修改成\n , s d\n 具体其它命令，可以搜索文档\n C-h o nodejs-repl-command\n 然后，查看 nodejs-repl-mode 文档\nFormat code  js beautify   , =\n 运行前，需要先安装 js-beautify\n$ npm install -g js-beautify  其中js-beautify的配置文件是 `~/.jsbeautifyrc`.\n如果不想安装，则使用：\n SPC j =\n runs the command spacemacs/indent-region-or-buffer.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-9-notes.html",
	"title": "Spacemacs Rocks Day 9, spacemacs as a life style",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " spacemacs as a life style 视频中的命令，还没有找到\n进入不同的项目，使用layer切换：\n SPC l l\n 一般先进入 @org 查看当天的任务\n只有单你，确切地需要功能时，才去写elisp函数，实现自动化。\nTODO 在 day 周期下，如何把任务设置成 done? TODO 开启ERC 在 SPC f e d 中安装 erc layer.\nTODO 通过 ispell 语法检查 experience\nosx-dictionary 英英翻译 光标处翻译 比如，我们现在有ball这个单词，把光标放在ball上（b,l上都可以）,然后\n M-x osx-dictionary-search-word-at-point\n 或者\n SPC x w d\n 然后，就给出了英文翻译，这时在这个临时buffer中有 s, o, r, q 提示，我们按r就有发音了。\n翻译一个输入的单词  M-x osx-dictionary-search-input\n "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-10-notes.html",
	"title": "Spacemacs Rocks Day 10, spacemacs tutor",
	"tags": ["emacs", "spacemacs", "tutor"],
	"description": "",
	"content": " youku spacemacs tutor\n安装 各文件夹功能 core 方便加载layer的配置\n使用 proxychains4 打开 emacs $ proxychains4 open /Applications/Emacs.app  这样的话，就会让emacs翻墙，这样下载melpa.org中的packages就会比较快。\n介绍 spacemacs home page change-log Evil tutor  SPC h T\n universal arguments  SPC u\n 配置启动全屏 在buffer中快速跳转  M-x jump-in-buffer\n 现在有2种\n M-x helm-jump-in-buffer\n 和\n M-x counsel-jump-in-buffer\n 不需要安装layer，只单独安装某package 在 ~/.spacemacs.d/init.el 中的\ndotspacemacs-additional-packages 中添加packages名就可以了。\n行号  SPC t n\n 相对行号\n SPC t r\n 这时，向下跳转9行，则只要：\n 9 j 或者 \u0026gt; C-u 9 j\n 同理，向上跳转9行，则只要：\n 9 k 或者 \u0026gt; C-u 9 k\n 中文输入法，chinese layer 启动或退出（第一次运行时，要选择输入法）\n C-\\\n 切换输入法\n M-x set-input-method\n 查询输入法\n M-x list-input-method\n 跳转至 中文 文中有 “东西” 2字，此时，想跳转到这里，则：\n M-x ace-pinyin-jump-word RTN dx RTN\n 创建layer  SPC : configuration-layer/create-layer\n 会选择一个目录地址，比如layer名为abc, 那直接回车，则会在\n~/.spacemacs.d/layers/abc/ 下 自动生成 packages.el 文件\n跳转到 layer 的文档或其中的某个package 视频中的\n SPC f e h\n 修改成：\n SPC h SPC\n layer中配置package 下以配置 zilongshanren-misc/packages.el 中的 helm-github-stats 为例子。\n(defun zilongshanren-misc/init-helm-github-stars () (use-package helm-github-stars :commands (helm-github-stars) :init （progn (setq helm-github-stars-username \u0026quot;secretrobots\u0026quot;) (evil-leader/set-key \u0026quot;og\u0026quot; 'helm-github-stars) ） ))  其中，包括介绍了绑定leader-key。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-11-notes.html",
	"title": "Spacemacs Rocks Day 11, spacemacs use daily",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " youku spacemacs\n开启 org-pomodoro  M-x org-pomodoro\n 或者\n , C p\n 插入chrome tab 且有title 无title可以使用\n C-c l\n 但是视频中的是有title的，命令\n C-c G c\n 已经失效。\n记笔记主要用 deft 代码跳转至定义  , g\n 返回到跳转前\n C-o\n python 语法检查错误列表  SPC e L\n 查看函数文件  , h h\n REPL环境 打开  , s i\n 发送选中区块代码至 REPL环境  , s r\n 在emacs中直接调用搜索引擎进行搜索  SPC a /\n 输入 bing 就是bing搜索，google就是google搜索\nlispy 这一小节的具体内容，还是直接看 spacemacs-rocks season2 的第17节视频吧\n代码块内部跳转 跳转至开头\n M-a\n 向下跳转\n M-f\n hotspots  M-x helm-hotspots 或者 SPC o o\n 这里的 github 指的是 github.com上的star的仓库，选中，回车，浏览器就会打开这个仓 库。\nmarkdown markdown-toc 自动生成文档目录\n M-x markdown-toc-generate-toc 或者 , i t\n 但是，发现有问题：\n 有时生成出来的toc有时层级不对。 preview的时候，要去除前后两行删除行。  emacs中启动markdown preview zilongshanren/markdown-to-html 开启\n , p\n 使用 grip 程序preview markdown-to-html 文件。子龙说，这里的预览效果与 github上的md文件的效果是一模一样的。\ngrip安装 https://github.com/joeyespo/grip\nbrew install grip  Ref  https://emacs-china.org/t/topic/1549/17  打开PDF文件 dired buffer 下\n \u0026amp; RTN\n 2048 game 播放音乐 magit Untrack\n S-k\n 建议  使用spacemacs的develop分支，而不是master分支，因为master分支bug很多 对使用的Layer下的packages的文档，应当了解，查看。从而把没有必要的package exclude掉，从而加速emacs, dotspacemacs/config 函数是所有启动后，最后一个被调用的。但是，依然不建议这么做， 而是新建立一个自己的layer. QQ群 59134186(已失效)  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor.html",
	"title": "qor",
	"tags": [],
	"description": "qor",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/saleor.html",
	"title": "saleor",
	"tags": [],
	"description": "saleor",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/emacs-markdown-preview.html",
	"title": "emacs中启动markdown preview",
	"tags": ["emacs", "spacemacs", "preview"],
	"description": "",
	"content": " zilongshanren/markdown-to-html 开启\n , p\n 使用 grip 程序preview markdown-to-html 文件。子龙说，这里的预览效果与 github上的md文件的效果是一模一样的。\ngrip安装 https://github.com/joeyespo/grip\nbrew install grip  Ref  https://emacs-china.org/t/topic/1549/17  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/learn-hugo.html",
	"title": "Learn-Hugo",
	"tags": [],
	"description": "介绍Hugo学习笔记的基本资料和访问方式",
	"content": " 内容介绍 Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。\nHugo以速度快著称，号称是世界上最快的网站生成框架。\nThe world’s fastest framework for building websites\n访问方式 这是个人学习Hugo的笔记，请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。托管于腾讯云香港节点，速度快，偶尔抽风 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/others.html",
	"title": "others",
	"tags": [],
	"description": "others",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tools.html",
	"title": "tools",
	"tags": [],
	"description": "tools",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about.html",
	"title": "about",
	"tags": [],
	"description": "about non tech",
	"content": "关于我与其它\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/chedan.html",
	"title": "chedan",
	"tags": [],
	"description": "blog",
	"content": " 内容介绍 这是个人博客, 主要包括一些学习笔记\n访问方式 请点击下面的链接阅读:\n 在线阅读：hugo格式，界面清爽。 @github：源码托管于github，如有谬误或需讨论，请提issue，欢迎提交PR  版权申明 本笔记内容可以任意转载，但请注明来源并提供链接，请勿用于商业出版。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/docker.html",
	"title": "Docker",
	"tags": ["docker", "command"],
	"description": "",
	"content": " docker 删除所有容器，镜像，数据卷 #以下，按需求开启 #停止容器 docker stop $(docker ps -a -q) #删除容器 docker rm $(docker ps -a -q) #删除镜像 docker image rm $(docker image ls -a -q) #删除数据卷： #docker volume rm $(docker volume ls -q) #删除 network： #docker network rm $(docker network ls -q) #---------------------------------------------------------------------------- #最直接并全面清理的的就是以下命令 #$docker stop $(docker ps -a -q) \u0026amp;\u0026amp; docker system prune --all --force  ref  https://blog.csdn.net/qq_34924407/article/details/82777691  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/remove-mysql-mariadb-from-ubuntu.html",
	"title": "To Completly remove Mysql from Ubuntu",
	"tags": ["mysql"],
	"description": "",
	"content": " To Completly remove Mysql from Ubuntu\nenv  os: ubuntu mysql: 5.7 mariadb: 10.3  step sudo apt-get remove --purge mysql-server mysql-client mysql-common sudo apt-get autoremove sudo apt-get autoclean  如果有安装过 mariadb\nsudo apt-get remove --purge mariadb* sudo apt-get autoremove sudo apt-get autoclean  after this, if you are having issues with re installing, Try to remove Mysql files in :\nsudo rm -rf /var/lib/mysql  ref  https://stackoverflow.com/questions/25244606/completely-remove-mysql-ubuntu-14-04-lts  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/cannot-setup-mysql-root-password-during-installation.html",
	"title": "Unable to set password for the MariaDB ‘root’ user",
	"tags": ["mysql"],
	"description": "",
	"content": " env 在安装 mysql 或者 mariadb 过程中，设置完 root 密码后，报出类似下面错误：\nUnable to set password for the MariaDB \u0026quot;root\u0026quot; user An error occurred while setting the password for the MariaDB administrative user. This may have happened because the account already has a password, or because of a communication problem with the MariaDB server. You should check the account's password after the package installation. Please read the /usr/share/doc/mariadb-server-10.2/README.Debian file for more information.  step 说明，之前的安装，没有 completly remove。怎么remove, 看 这里\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-usage.html",
	"title": "mysql 常用用法",
	"tags": ["mysql"],
	"description": "",
	"content": " mysql 常用用法\n修改mysql用户密码 select User,Password from mysql.user; set password for keystone@localhost = password('324dcdc2318be07d0300');  mysql timestamp 在建立表时,优先使用ON UPDATE CURRENT_TIMESTAMP, 也就是说, 优先使用下面的\n`create_date` timestamp NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间', `update_date` timestamp NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',  而不是使用这下面的\n`create_date` timestamp NULL DEFAULT NULL COMMENT '创建时间', `update_date` timestamp NULL DEFAULT NULL COMMENT '更新时间',  如果表已经建立好了,则通过 navicat ,选中字段后,点击,默认:根据当前时间戳更新, 就可以更改了.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/windows-tools.html",
	"title": "Windows下效率必备软件",
	"tags": ["tools", "windows"],
	"description": "",
	"content": " Windows下效率必备软件\nenv os: win10\nstep 工欲善其事，必先利其器！ 工欲善其事，必先利其器！ 工欲善其事，必先利其器！重而说三。\n当你第一次接触windows，并准备在其上开发时，请先安装 package-manager-for-windows , 并用它来安装下面的软件。\n工具 AutoHotKey: 神器！神器！神器！当然也得看使用者咯(^__^) 嘻嘻……详情请参看：Win下最爱效率神器:AutoHotKey。\n[Listary]()： 本地搜索神器，当然还有别的作用，More\u0026amp;More。\nLaunchy : 快速启动安装的应用程序，老而弥坚，有丝Mac下Spotlight之风；\n http://www.launchy.net/ https://www.iplaysoft.com/launchy.html  Wox ： Windows下一款最接近 Alfred 的软件启动/文件搜索利器；可参见Listary Everything Wox Launch。\nChrome: Web世界里的神，的神，神。偏爱ing；如虎添翼，效率必备：Vimium~让您的Chrome起飞。\nSublimeText3： 编码垒字的神器，还能览图/文件对比/…,偏爱ing；自荐笔者总结一文： 如何优雅地使用Sublime Text\nPicasa3: 图片查看器中的佼佼者，偏爱ing。姑姑出品，必属精品！\nClover： 在Win下必备，谁让Win资源管理器太…QT，TotalCommand太重(⊙o⊙)…\nEverything： 本来必备神器，无奈我移情别恋了–Listary。不过是不会忘了你。\nFoxmail： 对比体验不多，不做评判，必备；反正不用win自带的。\nEvernote: 纪录/收藏你想保存的文｜图｜网页;为知笔记～功能同丰满,身材更骨感😄。\nBeyond Compare : 文件比较器; 此款为所接触中最佳。\nCmder: windows下cmd的替换工具,支持PowerShell;同比还有PowerShell，ConEmu 等。自荐笔者总结的：Win下必备神器之Cmder。\n作业部落客户端: 开启卓越写作之旅,支持全平台＋离线使用，一键发布文稿，社交化批注。身材苗条，面容姣好，免费Markdown书写平台的魅力战斗机。\n夜神模拟器: 经历了BlueStacks,海马，一遇这夜神,认你乃最佳！ 之后体验过程也没那么好，兼用海马(都不经常)。\n网易云音乐: 初遇QQ音乐,处过天天动听,恋过酷狗，上过酷我，一夜情过千千静听,移情过虾米，和豆瓣FM好过，同百度随心听约过,最后，发现音乐的世界,还得是你～网易云音乐。\n[Update: 2016-03-09 ~ 2016-03-10]\nAtom: 新一代编码写文神器；虽还在发展，却已惊艳。自荐笔者一文：新编码神器Atom使用纪要。\nGit for Windows : 打包好了，直接使用；Git 一族必备。\nNodejs: 可以辅助让Sublime编译Js；可以做Web开发，REST开发**，Web聊天室/爬虫，Web博客(Hexo)，Web论坛等等，可参见分享十五个NodeJS应用场景；还可以利用Nodejs的包管理器Npm 安装Gulp Webpack等屌炸天工具～做大多你可以想到的东东；Web端必备。\nGoodSync: 文件同步好帮手。可以同步 本地文件 P2P 云(Dropbox,Google,OnDrive,FTP/SFTP等等)，还可以同步应用程序 以及各设备；强大且不失简洁。比如：SFTP同步，用过SublimeText的SFTP(最方便，却老弹框)，WinSCP(F5即可同步，设计却不人性化)，Gulp的SFTP(只是需要率先Watch)，Xftp4(老牌了，都是手动点来点去，额)。\nTotal Commander: 资源管理器集大成者，只是快捷键太繁琐，用她需要花费些时间了解她先；个人还是用 Clover(虽然她很容易发脾气，简单就好)。\nShareX: 截图、注释、上传，复制 URL 一条龙服务；免费，强大而简洁；自动存储；支持双屏；支持录制；还有给力有用的工具集…大有相见恨晚之感 (☆_☆)(唯一没中不足是：安装时需率先安装Steam桌面应用，不过无妨)。\nnvm-windows: 管理 nodejs\ngvm: 管理 golang\nZeal - 离线 API 文档查找阅读工具。\nzotero : 一款自由及开放源代码的文献管理软件，管理书目信息（如作者、标题、出版社、摘要、阅读笔记等）及相关材料（如PDF文件等)。\nbabun\npowershell: cmd.exe的官方替代品，一般系统自带\n20190315\nhttps://mp.weixin.qq.com/s/3e6gk3K3tLZXFegUc3O0pA\ncapslock+:\ncapslock++ : 与上一个不是同一个东西。没有尝试，看起来不错。\nFeem : 不同设备传文件。\nQuickLook: Bring macOS “Quick Look” feature to Windows\nvscode-leetcode: 在 vscode 中刷 leetcode\nTweeten: 刷推特，我认为 Tweeten 是最好的选择\nWindows-Auto-Night-Mode: 按当地时间自动切换应用模式，并单独设置应用、系统、Edge 浏览器主题颜色。\nEarTrumpet: 每个软件单独设置音量. 可以在 Microsoft Store 免费获取 EarTrumpet。\n还有几个我没有安装，但是，看起来不错的软件：\nGlassWire, Process Lasso, Dism++, Geek Uninstaller, SpaceSniffer\n20190316\ngitnote: git笔记, 可以结合github私有库\nRunZ: 类似 ALTRun 的专业快速启动工具。\nfastwindowswitcher: A fast window switcher for Windows using the keyboard.\nPower Keys: 系统全局快捷键\n20190620\nSnipaste : 图片\nPicGo : 图床\nref  https://www.jeffjade.com/2015/10/19/2015-10-18-Efficacious-win-software/ https://github.com/Awesome-Windows/Awesome http://finalhome.org/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E4%BC%98%E9%9B%85%E7%9A%84windows%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/ https://mp.weixin.qq.com/s/3e6gk3K3tLZXFegUc3O0pA  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/autohotkey-usage.html",
	"title": "autohotkey 用法",
	"tags": ["autohotkey"],
	"description": "",
	"content": " autohotkey 用法\nenv  os: win10 autohotkey: Version 1.1.30.01  step 最好的方法是直接看官网\nhttps://autohotkey.com/docs/Tutorial.htm\n对应点击en,会出现zh，也就是中文版本\nhttps://wyagd001.github.io/zh-cn/docs/Tutorial.htm\nscript https://zhuanlan.zhihu.com/p/19754204\nref  https://autohotkey.com/docs/Tutorial.htm https://wyagd001.github.io/zh-cn/docs/Tutorial.htm https://blog.csdn.net/weixin_37834999/article/details/79542638 https://blog.csdn.net/ChinarCSDN/article/details/82914429 https://blog.lovejade.cn/2016/03/12/share-autohotkey-script.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/emacs-install-with-win10.html",
	"title": "在win10上安装emacs",
	"tags": ["emacs"],
	"description": "",
	"content": " 在win10上安装emacs\nenv  os: win10 emacs: 26.1  step 官网下载 emacs 包 官网 https://www.gnu.org/software/emacs/\n下载地址 http://mirrors.nju.edu.cn/gnu/emacs/windows/emacs-26/emacs-26.1-x86_64.zip\n放到程序相应位置 解压后得到 emacs-26.1-x86_64 文件夹，剪切至程序安装目录 C:\\Program Files\\emacs-26.1-x86_64\n设置环境变量 设置系统环境变量\n declare a environment variable named HOME pointing to your user directory C:\\Users\u0026lt;username\u0026gt;   path中增加emacs\\bin。  检查 win-r输入cmd\nC:\\Users\\DELL\u0026gt;emacs --version GNU Emacs 26.1 Copyright (C) 2018 Free Software Foundation, Inc. GNU Emacs comes with ABSOLUTELY NO WARRANTY. You may redistribute copies of GNU Emacs under the terms of the GNU General Public License. For more information about these matters, see the file named COPYING. C:\\Users\\DELL\u0026gt;  表示安装成功，happy!\n安装效果 最后在cmd中运行emacs -nw，查看安装效果。\n-nw No window模式，以字符界面打开。 -Q 快速启动。  ref  https://www.douban.com/note/511848652/ http://ftp.gnu.org/gnu/emacs/windows/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-install-with-win10.html",
	"title": "在win10上安装spacemacs",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " 在win10上安装spacemacs\nenv  os: win10 emacs: 26.1 spacemacs: develop分支  step 安装 emacs 参考这里\n备份 cd ~ mv .emacs.d .emacs.d.bak mv .emacs .emacs.bak  官网下载 spacemacs 包 git clone https://github.com/syl20bnr/spacemacs -b develop ~/.emacs.d  Launch Emacs Spacemacs will automatically install the packages it requires. If you get an error regarding package downloads then you may try to disable the HTTPS protocol by starting Emacs with\nemacs --insecure  第一次运行，请选择默认选择项目（1. vim; 2. 推荐）\n设置private配置 备份或删除原有配置文件：\nmv\ngit clone https://github.com/$yourAccount/spacemacs-private ~/.spacemacs.d  如果愿意，可以使用我的配置\ngit clone https://github.com/eiuapp/spacemacs-private-win10-tl ~/.spacemacs.d  检查 最后在cmd中运行emacs，查看安装效果。\n-nw No window模式，以字符界面打开。 -Q 快速启动。  快捷方式 打开emacs安装地址（比如：C:\\Program Files\\emacs-26.1-x86_64\\bin）, 找到，runemacs.exe （不是emacs.exe）设置 快捷方式 到桌面\nref  https://www.douban.com/note/511848652/ http://ftp.gnu.org/gnu/emacs/windows/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-install-faq-with-win10.html",
	"title": "在win10上安装spacemacs的常见问题",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": " 在win10上安装spacemacs后，出现的问题\nWarning 提示如下： Error (use-package): Cannot load highlight-global Warning (magit): Magit no longer uses Magit-Popup. It now uses Transient. See https://emacsair.me/2019/02/14/transient-0.1. However your configuration and/or some third-party package that you use still depends on the `magit-popup' package. But because `magit' no longer depends on that, `package' has removed it from your system. If some package that you use still depends on `magit-popup' but does not declare it as a dependency, then please contact its maintainer about that and install `magit-popup' explicitly. If you yourself use functions that are defined in `magit-popup' in your configuration, then the next step depends on what you use that for. * If you use `magit-popup' to define your own popups but do not modify any of Magit's old popups, then you have to install `magit-popup' explicitly. (You can also migrate to Transient, but there is no need to rush that.) * If you add additional arguments and/or actions to Magit's popups, then you have to port that to modify the new \u0026quot;transients\u0026quot; instead. See https://github.com/magit/magit/wiki/Converting-popup-modifications-to-transient-modifications  打开 spaemacs 后，首页提示如下： Errors: - An error occurred while installing font-lock+ (error: (error Invalid version syntax: ‘Command ’(git submodule sync --recursive)’ exited with non-zero status 128: Fetching origin HEAD is now at f2c1ddc no summary available fatal: 'submodule' appears to be a git command, but we were not able to execute it. Maybe git-submodule is broken? ’ (must start with a number))) - An error occurred while installing counsel-css (error: (error Invalid version syntax: ‘Command ’(git submodule sync --recursive)’ exited with non-zero status 128: Fetching origin HEAD is now at f2c1ddc no summary available fatal: 'submodule' appears to be a git command, but we were not able to execute it. Maybe git-submodule is broken? Fetching origin HEAD is now at 0536af0 v1.0.5 bump fatal: 'submodule' appears to be a git command, but we were not able to execute it. Maybe git-submodule is broken? ’ (must start with a number))) Warnings: - Cannot find any of the specified fonts (Source Code Pro)! Font settings may not be correct. - More than one init function found for package ac-ispell. Previous owner was auto-completion, replacing it with layer zilongshanren-tomtsang. - More than one init function found for package flycheck. Previous owner was syntax-checking, replacing it with layer zilongshanren-tomtsang. - More than one init function found for package ox-hugo. Previous owner was org, replacing it with layer zilongshanren-tomtsang.  按道理，应该一个一个把这些报错信息，处理一下。\nref    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/mkfs-xfs-command-not-found.html",
	"title": "mkfs.xfs command not found",
	"tags": ["linux", "mkfs"],
	"description": "",
	"content": " 如果 mkfs.xfs /dev/sdb1 出现 mkfs.xfs command not found , 则运行下面命令安装 mkfs.xfs\napt-get install xfsprogs  ref  http://blog.51cto.com/yangzhiming/2117942  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/org/org-mode-set-org-directory.html",
	"title": "org-mode-set-org-directory",
	"tags": ["org"],
	"description": "",
	"content": " 做 软连接 这个方法比较方便，不需要另外再去修改spacemacs或emacs配置。\n➜ tomtsang-rootsongjc-hugo git:(master) ✗ echo `pwd`/org /Users/tomtsang/bitbucket/qqbb/tomtsang-rootsongjc-hugo/org ➜ tomtsang-rootsongjc-hugo git:(master) ✗ ln -s `pwd`/org/ ~/org ➜ tomtsang-rootsongjc-hugo git:(master) ✗ l ~/org lrwxr-xr-x 1 tomtsang 60 Nov 13 14:55 /Users/tomtsang/org -\u0026gt; /Users/tomtsang/bitbucket/qqbb/tomtsang-rootsongjc-hugo/org/ ➜ tomtsang-rootsongjc-hugo git:(master) ✗ l ~/org/ total 48K drwxr-xr-x 13 tomtsang 416 Nov 13 14:53 . drwxr-xr-x 24 tomtsang 768 Nov 12 01:56 .. -rw-r--r-- 1 tomtsang 1.5K Nov 13 14:52 all-posts.org -rw-r--r-- 1 tomtsang 758 Nov 13 00:27 emacs-install-base-ubuntu.org ➜ tomtsang-rootsongjc-hugo git:(master) ✗  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/emacs-install-base-ubuntu.html",
	"title": "ubuntu安装最新emacs",
	"tags": [],
	"description": "",
	"content": " Env  os: ubuntu  Step $sudo add-apt-repository ppa:ubuntu-elisp/ppa $sudo apt update $sudo apt install emacs-snapshot emacs-snapshot-el $emacs --version #查看emacs版本  REF ubuntu安装最新emacs\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-emacs.html",
	"title": "emacs下使用hugo写文档",
	"tags": [],
	"description": "",
	"content": " emacs下使用hugo写文档, 主要有以下几种方式\n无论是写哪种文档，都建议使用easy-mode创建,管理文档\n写org文档 用ox-hugo写org文档 安装 使用 用org-mode写org文档 TODO 直接用easy-mode创建新的.org文档，header不正常 看了一下代码，好像是源码里写死，没有使用到 archetype/default.org文件呀。\n 直接用easy-mode preview\n可以看到，\nTODO 避免删除后重新安装\n这样子的信息。\n  导出成markdown 发现写成org文档后，导出成markdown，会有content-table,这样，会有2个大纲，且，文章的时间不对。\n直接导出成html 这时，没有大纲。但是，其它都还正常。\nTODO Orgmode利用ox-pandoc导出成markdown Orgmode利用ox-pandoc导出hugo博客的workflow\n写markdown文档 用markdown-mode写markdown文档 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/env.html",
	"title": "关于配置",
	"tags": [],
	"description": "",
	"content": " 因为我不希望总是去重复写我的配置，所以，我集中地把配置信息放在这里。\nEnv  os: mac Emacs: 26.1 Spacemacs: 0.300.0 Org: 9.1.2 Hugo: v0.41 ox-hugo: 20181106.2350 prodigy: 20180511.938  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/ox-hugo-quickly-create-a-draft-post.html",
	"title": "quickly create a new draft post",
	"tags": ["org", "ox-hugo"],
	"description": "",
	"content": " Of course I’m using a handy capture template, as provided by the ox-hugo docs. This lets me type `C-c c h` to quickly create a new draft post.\n(with-eval-after-load 'org-capture (defun org-hugo-new-subtree-post-capture-template () \u0026quot;Returns `org-capture' template string for new Hugo post. See `org-capture-templates' for more information.\u0026quot; (let* ((title (read-from-minibuffer \u0026quot;Post Title: \u0026quot;)) ;Prompt to enter the post title (fname (org-hugo-slug title))) (mapconcat #'identity `( ,(concat \u0026quot;* TODO \u0026quot; title) \u0026quot;:PROPERTIES:\u0026quot; ,(concat \u0026quot;:EXPORT_FILE_NAME: \u0026quot; fname) \u0026quot;:END:\u0026quot; \u0026quot;%?\\n\u0026quot;) ;Place the cursor here finally \u0026quot;\\n\u0026quot;))) (add-to-list 'org-capture-templates '(\u0026quot;h\u0026quot; ;`org-capture' binding + h \u0026quot;Hugo post\u0026quot; entry ;; It is assumed that below file is present in `org-directory' ;; and that it has a \u0026quot;Blog Ideas\u0026quot; heading. It can even be a ;; symlink pointing to the actual location of all-posts.org! (file+olp \u0026quot;all-posts.org\u0026quot; \u0026quot;Blog Ideas\u0026quot;) (function org-hugo-new-subtree-post-capture-template)))) )))  如果直接使用上面的配置，则运行之前，有2个条件：\n 在 `org-directory` 中有个 名为 all-posts.org 的文件 此文件中 有一个一级标题，为\u0026rdquo;Blog Ideas\u0026rdquo;  要先查`org-directory`在哪里（SPC h d v），默认为~/org。如果想设置成其它文件夹，请看org-mode-set-org-directory\n➜ hugo git:(master) ✗ head ~/org/all-posts.org  我的all-posts.org的头是下面这样的：\n #+HUGO_BASE_DIR: /Users/tomtsang/bitbucket/qqbb/tomtsang-rootsongjc-hugo/ * Blog Ideas :PROPERTIES: # :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true :nocomment true :nodate true :nopaging true :noread true :EXPORT_HUGO_SECTION: posts :EXPORT_HUGO_WEIGHT: auto :END: ** TODO test-a-aritile-title :PROPERTIES: :EXPORT_FILE_NAME: test-a-file-name :END: This is a abc test!   Ref  https://www.baty.net/2018/lets-try-using-ox-hugo-again/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/org/org-blog-why.html",
	"title": "使用Org写Blog",
	"tags": ["blog"],
	"description": "",
	"content": " Env    Step why  http://ju.outofmemory.cn/entry/204743  Ref  http://ju.outofmemory.cn/entry/204743  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/emacs-melt-no-use.html",
	"title": "解决Mac下emacs中alt键不能使用问题",
	"tags": ["emacs", "mac"],
	"description": "",
	"content": " Env  os: mac  Step iTerm preferences-\u0026gt;Profiles\n找到Left option key acts as一栏 选中+Esc选项\nTerminal preferences-\u0026gt;Profiles-\u0026gt;keyboard\n在使用Option键作为Meta一栏上打钩\nRef  https://www.jianshu.com/p/7432c3bfcc99  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock/jaqs-lecture4.html",
	"title": "量化小学Lecture4的笔记",
	"tags": ["jaqs", "python"],
	"description": "",
	"content": " Env  os: mac  Step 尝试用python做个股票绘图软件，要用到 finance 库，于是开始导入：\nimport matplotlib.finance as mpf  结果执行的时候直接报错：\nModuleNotFoundError: No module named 'matplotlib.finance'  那么我们可以到 ipython 环境中去测试一下。\n➜ ~ ipython Python 3.7.0 (default, Jun 28 2018, 07:39:16) Type 'copyright', 'credits' or 'license' for more information IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from matplotlib.finance import candlestick_ohlc --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) \u0026lt;ipython-input-1-7ea83a59eaf3\u0026gt; in \u0026lt;module\u0026gt;() ----\u0026gt; 1 from matplotlib.finance import candlestick_ohlc ModuleNotFoundError: No module named 'matplotlib.finance'  去查看 matplotlib 的文档说明，在matplotlib2.2.2的API中有这么一段话：\nThe matplotlib.finance, mpl_toolkits.exceltools and mpl_toolkits.gtktools modules have been removed. matplotlib.finance remains available at https://github.com/matplotlib/mpl_finance.  finance这个模块竟然被删除了！！！并且就是从2.2.2版本开始。\n知道了原因，解决方法就简单了，在github中下载源代码，安装：\ngit clone https://github.com/matplotlib/mpl_finance \u0026amp;\u0026amp; cd mpl_finance python setup.py install  可以看到 mpl_finance 模块已经安装上了。\n验证 ➜ mpl_finance git:(master) ✗ ipython Python 3.7.0 (default, Jun 28 2018, 07:39:16) Type 'copyright', 'credits' or 'license' for more information IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from matplotlib.mpl_finance import candlestick_ohlc --------------------------------------------------------------------------- ModuleNotFoundError Traceback (most recent call last) \u0026lt;ipython-input-1-89e3069fc596\u0026gt; in \u0026lt;module\u0026gt;() ----\u0026gt; 1 from matplotlib.mpl_finance import candlestick_ohlc ModuleNotFoundError: No module named 'matplotlib.mpl_finance' In [2]: from mpl_finance import candlestick_ohlc In [3]: exit ➜ mpl_finance git:(master) ✗  Ref  http://www.classnotes.cn/3689.html https://github.com/matplotlib/mpl_finance  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-jaqs-install.html",
	"title": "Jaqs安装笔记",
	"tags": ["jaqs", "python"],
	"description": "",
	"content": " Env    Step ## 下载并安装 Anaconda chmod +x Anaconda3-5.3.0-MacOSX-x86_64.sh which sh sh ./Anaconda3-5.3.0-MacOSX-x86_64.sh ## 配置环境 cat /Users/tomtsang/.bash_profile source /Users/tomtsang/.bash_profile which python which python3 which python2 ## 这个还是原来的路径 python3 python which ipython ipython workon quant-py3 ## 验证，不影响其它环境 which python which python3 which python2 which deactivate deactivate ## 退出 virtualenv ## 安装依赖 snappy brew install snappy CPPFLAGS=\u0026quot;-I/usr/local/include -L/usr/local/lib\u0026quot; pip install python-snappy pip install PyHamcrest ## 安装 jaqs pip install jaqs ## 验证 ipython ## 输入 import jaqs ##  Ref  https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ https://jaqs.readthedocs.io/zh_CN/latest/install.html https://github.com/quantOS-org/JAQS https://github.com/andrix/python-snappy#frequently-asked-questions  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-env-virtualenv.html",
	"title": "python搭建多个互不干扰的开发环境",
	"tags": ["python"],
	"description": "",
	"content": " Env  os: mac  Step 安装 python3 Mac安装Python2和Python3、pip2和pip3、ipython2和ipython3\n一、Homebrew的安装及使用  Homebrew的安装 Homebrew的使用  安装软件：brew install 软件名，例：brew install wget 搜索软件：brew search 软件名，例：brew search wget 卸载软件：brew uninstall 软件名，例：brew uninstall wget 更新所有软件：brew update ⚠️通过 update 可以把包信息更新到最新，不过包更新是通过git命令，所以要先通过 brew install git 命令安装git。 安装git 更新具体软件：brew upgrade 软件名 ，例：brew upgrade git 显示已安装软件：brew list 查看软件信息：brew info／home 软件名 ，例：brew info git ／ brew home git ⚠️brew home指令是用浏览器打开官方网页查看软件信息 查看那些已安装的程序需要更新： brew outdated 显示包依赖：brew reps  二、安装Python3和pip3  安装Python3\n  brew install python   测试  安装pip2\nMac电脑本身自带Python2但是不带pip2，所以通过再次用brew安装Python2之后自然就携带pip2\n 安装Python2  brew install python@2   测试  三、安装ipython2和ipython3 (可不安装) 通过pip安装\n 安装ipython3  pip3 install ipython   测试ipython3是否安装成功  ipython3   安装ipython2  pip install ipython   测试ipython2是否安装成功  ipython  使用 python3 安装 virtualenvs which python3 which pip3 vi .zshrc ## 具体添加的内容见下文 source .zshrc pip3 install virtualenv virtualenvwrapper ## 建立python3环境 mkvirtualenv -p /usr/local/bin/python3 quant-py3 ## 建立python2环境 mkvirtualenv -p /usr/local/bin/python2 quant-py2  tail .zshrc ## python virtualenvs export VIRTUALENVWRAPPER_PYTHON=\u0026quot;$(command \\which python3)\u0026quot; export WORKON_HOME=$HOME/.virtualenvs export PROJECT_HOME=$HOME/workspace source /usr/local/bin/virtualenvwrapper.sh  虚拟环境使用方法 mkvirtualenv zqxt：创建运行环境zqxt\nworkon zqxt: 工作在 zqxt 环境 或 从其它环境切换到 zqxt 环境\ndeactivate: 退出终端环境\n其它的：\nrmvirtualenv ENV：删除运行环境ENV\nmkproject mic：创建mic项目和运行环境mic\nmktmpenv：创建临时运行环境\nlsvirtualenv: 列出可用的运行环境\nlssitepackages: 列出当前环境安装了的包\n创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。\n示例 python2 ➜ ~ mkvirtualenv quant New python executable in /Users/tomtsang/.virtualenvs/quant/bin/python2.7 Also creating executable in /Users/tomtsang/.virtualenvs/quant/bin/python Installing setuptools, pip, wheel...done. virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant/bin/preactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant/bin/postactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant/bin/get_env_details (quant) ➜ ~ python Python 2.7.15 (default, Oct 2 2018, 11:47:18) [GCC 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.2)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; (quant) ➜ ~ which python /Users/tomtsang/.virtualenvs/quant/bin/python (quant) ➜ ~ which python2 /Users/tomtsang/.virtualenvs/quant/bin/python2 (quant) ➜ ~ which python3 /usr/local/bin/python3 (quant) ➜ ~ python3 Python 3.7.0 (default, Oct 2 2018, 09:20:07) [Clang 10.0.0 (clang-1000.11.45.2)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; (quant) ➜ ~ lsvirtualenv quant ===== (quant) ➜ ~ deactivate  python3 ➜ ~ mkvirtualenv -p /usr/local/bin/python3 quant-py3 Running virtualenv with interpreter /usr/local/bin/python3 Using base prefix '/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7' /usr/local/lib/python2.7/site-packages/virtualenv.py:1041: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses import imp New python executable in /Users/tomtsang/.virtualenvs/quant-py3/bin/python3.7 Also creating executable in /Users/tomtsang/.virtualenvs/quant-py3/bin/python Installing setuptools, pip, wheel...done. virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant-py3/bin/predeactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant-py3/bin/postdeactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant-py3/bin/preactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant-py3/bin/postactivate virtualenvwrapper.user_scripts creating /Users/tomtsang/.virtualenvs/quant-py3/bin/get_env_details (quant-py3) ➜ (quant-py3) ➜ ~ which python2 /usr/local/bin/python2 (quant-py3) ➜ ~ which python3 /Users/tomtsang/.virtualenvs/quant-py3/bin/python3 (quant-py3) ➜ ~ which python /Users/tomtsang/.virtualenvs/quant-py3/bin/python (quant-py3) ➜ ~ python Python 3.7.0 (default, Oct 2 2018, 09:20:07) [Clang 10.0.0 (clang-1000.11.45.2)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; (quant-py3) ➜ ~ python3 Python 3.7.0 (default, Oct 2 2018, 09:20:07) [Clang 10.0.0 (clang-1000.11.45.2)] on darwin Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; (quant-py3) ➜ ~ (quant-py3) ➜ ~ deactivate  Ref  Mac安装Python2和Python3、pip2和pip3、ipython2和ipython3 https://code.ziqiangxuetang.com/django/django-install.html https://blog.csdn.net/shile/article/details/78648587  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-sed.html",
	"title": "Mac Sed",
	"tags": ["mac", "sed"],
	"description": "",
	"content": " 由于Mac OS X自带的sed等命令行工具是基于BSD的，有一些缺陷和不足，比如sed不支持\\t来表示TAB\nEnv  os: mac  报错如下：\n➜ home git:(master) ✗ grep \u0026quot;finsoft.info\u0026quot; -rl ./CNAME ./CNAME ➜ home git:(master) ✗ ➜ home git:(master) ✗ grep \u0026quot;finsoft.info\u0026quot; -rl ./CNAME | xargs sed -i \u0026quot;s/finsoft.info/qqbb.app/g\u0026quot; sed: 1: \u0026quot;./CNAME\u0026quot;: invalid command code . ➜ home git:(master) ✗  Step ➜ ~ brew install coreutils ➜ ~ vi ~/.zshrc ➜ ~ source ~/.zshrc ➜ ~ tail ~/.zshrc ## coreutil export PATH=\u0026quot;$(brew --prefix coreutils)/libexec/gnubin:/usr/local/bin:$PATH\u0026quot; export MANPATH=\u0026quot;$(brew --prefix coreutils)/libexec/gnuman:$MANPATH\u0026quot; ➜ ~ brew install gnu-sed --with-default-names ➜ ~  Ref  https://blog.csdn.net/xicikkk/article/details/52559433  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-use-zilongshanren-spacemacs-private.html",
	"title": "Spacemacs Use Zilongshanren Spacemacs Private",
	"tags": ["spacemacs"],
	"description": "",
	"content": " 想直接使用，zilongshanren的 配置\nEnv  os: mac os 10.13.3 emacs: 26.1 spacemacs： 0.200.13@26.1  prepare 在使用前，我们可以安装一些软件\nbrew install emacs brew install ispell brew install trash brew tap caskroom/fonts \u0026amp;\u0026amp; brew cask install font-source-code-pro brew install ctags-exuberant  Step 现在直接就报了一个错误。见 https://github.com/zilongshanren/spacemacs-private/issues/180\n然后，这个时候，从各地方，获知，要用 spacemacs 源码的 devlop分支，而不是master分支。所以。要重新clone一下。\n➜ .emacs.d git:(develop) pwd /Users/tomtsang/.emacs.d ➜ .emacs.d git:(develop) git remote -v origin\thttps://github.com/syl20bnr/spacemacs.git (fetch) origin\thttps://github.com/syl20bnr/spacemacs.git (push) ➜ .emacs.d git:(develop) git branch -v * develop c122eb6a0 lsp-layer configuration and building blocks for derived layers. master c7a103a77 Fix line separation in README ➜ .emacs.d git:(develop)  当然，我们的 zilongshanren 的配置，也应该是 devlop 分支的。\n➜ .spacemacs.d git:(develop) ✗ pwd /Users/tomtsang/.spacemacs.d ➜ .spacemacs.d git:(develop) ✗ git remote -v origin\thttps://github.com/zilongshanren/spacemacs-private (fetch) origin\thttps://github.com/zilongshanren/spacemacs-private (push) ➜ .spacemacs.d git:(develop) ✗ git branch -v * develop ea09142 Merge branch 'windows' into develop ➜ .spacemacs.d git:(develop) ✗  这样，重新启动spacemacs, 就可以使用了。\nQA 问题1 Cannot find any of the specified fonts (Source Code Pro)! Font settings may not be correct.  https://github.com/syl20bnr/spacemacs/issues/7919\nhttps://github.com/adobe-fonts/source-code-pro\nbrew tap caskroom/fonts \u0026amp;\u0026amp; brew cask install font-source-code-pro  好像，这个问题，已经OK了。\nRef  https://github.com/zilongshanren/spacemacs-private/issues/180  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-qa-1.html",
	"title": "Spacemacs Qa 1",
	"tags": ["spacemacs", "emacs"],
	"description": "",
	"content": " Env  os: mac os 10.13.3 emacs: 26.1 spacemacs： 0.200.13@26.1  Step QA Q:\nDescription :octocat:\nError (use-package): org-projectile :config: Symbol's function definition is void: org-projectile-per-project  A:\n参考 https://github.com/syl20bnr/spacemacs/issues/9374 知道\nI also faced this issue today after updating all packages.\nfind ~/.emacs.d/elpa/org-projectile-20180601.242/ -name \u0026quot;*elc\u0026quot; -delete and restarting fixed it.\nRef  https://github.com/syl20bnr/spacemacs/issues/9374  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/emacs-flycheck-eslint.html",
	"title": "Emacs Flycheck Eslint",
	"tags": ["emacs", "flycheck", "eslint"],
	"description": "",
	"content": " Env  os: mac emacs: GNU Emacs 22.1.1  Step https://github.com/flycheck/flycheck/issues/1195\n遇到下面的情形，就按提示，把这些个包，一个一个地安装。\n➜ tmp git:(master) ✗ eslint -v v5.4.0 { ➜ tmp git:(master) ✗ ls test.js ➜ tmp git:(master) ✗ cat test.js var a=1; var b = 2; vardf c=a+b; function a(){ console.log(\u0026quot;hello world\u0026quot;) } ➜ tmp git:(master) ✗ eslint test.js Oops! Something went wrong! :( ESLint: 5.4.0. ESLint couldn't find the plugin \u0026quot;eslint-plugin-import\u0026quot;. This can happen for a couple different reasons: 1. If ESLint is installed globally, then make sure eslint-plugin-import is also installed globally. A globally-installed ESLint cannot find a locally-installed plugin. 2. If ESLint is installed locally, then it's likely that the plugin isn't installed correctly. Try reinstalling by running the following: npm i eslint-plugin-import@latest --save-dev Path to ESLint package: /usr/local/lib/node_modules/eslint If you still can't figure out the problem, please stop by https://gitter.im/eslint/eslint to chat with the team. ➜ tmp git:(master) ✗ npm i -g eslint-plugin-import npm WARN eslint-plugin-import@2.14.0 requires a peer of eslint@2.x - 5.x but none is installed. You must install peer dependencies yourself. + eslint-plugin-import@2.14.0 added 49 packages from 32 contributors in 15.936s ➜ tmp git:(master) ✗ eslint test.js Oops! Something went wrong! :( ESLint: 5.4.0. ESLint couldn't find the plugin \u0026quot;eslint-plugin-node\u0026quot;. This can happen for a couple different reasons: 1. If ESLint is installed globally, then make sure eslint-plugin-node is also installed globally. A globally-installed ESLint cannot find a locally-installed plugin. 2. If ESLint is installed locally, then it's likely that the plugin isn't installed correctly. Try reinstalling by running the following: npm i eslint-plugin-node@latest --save-dev Path to ESLint package: /usr/local/lib/node_modules/eslint If you still can't figure out the problem, please stop by https://gitter.im/eslint/eslint to chat with the team. ➜ tmp git:(master) ✗ npm i -g eslint-plugin-node npm WARN eslint-plugin-node@7.0.1 requires a peer of eslint@\u0026gt;=4.19.1 but none is installed. You must install peer dependencies yourself. npm WARN eslint-plugin-es@1.3.1 requires a peer of eslint@\u0026gt;=4.19.1 but none is installed. You must install peer dependencies yourself. + eslint-plugin-node@7.0.1 added 12 packages from 7 contributors in 6.891s ➜ tmp git:(master) ✗ eslint test.js Oops! Something went wrong! :( ESLint: 5.4.0. ESLint couldn't find the plugin \u0026quot;eslint-plugin-promise\u0026quot;. This can happen for a couple different reasons: 1. If ESLint is installed globally, then make sure eslint-plugin-promise is also installed globally. A globally-installed ESLint cannot find a locally-installed plugin. 2. If ESLint is installed locally, then it's likely that the plugin isn't installed correctly. Try reinstalling by running the following: npm i eslint-plugin-promise@latest --save-dev Path to ESLint package: /usr/local/lib/node_modules/eslint If you still can't figure out the problem, please stop by https://gitter.im/eslint/eslint to chat with the team. ➜ tmp git:(master) ✗ npm i -g eslint-plugin-promise + eslint-plugin-promise@4.0.0 added 1 package from 1 contributor in 1.618s ➜ tmp git:(master) ✗ eslint test.js Oops! Something went wrong! :( ESLint: 5.4.0. ESLint couldn't find the plugin \u0026quot;eslint-plugin-standard\u0026quot;. This can happen for a couple different reasons: 1. If ESLint is installed globally, then make sure eslint-plugin-standard is also installed globally. A globally-installed ESLint cannot find a locally-installed plugin. 2. If ESLint is installed locally, then it's likely that the plugin isn't installed correctly. Try reinstalling by running the following: npm i eslint-plugin-standard@latest --save-dev Path to ESLint package: /usr/local/lib/node_modules/eslint If you still can't figure out the problem, please stop by https://gitter.im/eslint/eslint to chat with the team. ➜ tmp git:(master) ✗ npm i -g eslint-plugin-standard npm WARN eslint-plugin-standard@3.1.0 requires a peer of eslint@\u0026gt;=3.19.0 but none is installed. You must install peer dependencies yourself. + eslint-plugin-standard@3.1.0 added 1 package from 1 contributor in 6.621s ➜ tmp git:(master) ✗ eslint test.js /Users/tomtsang/.emacs.d/test/tmp/test.js 10:7 error Parsing error: Unexpected token c ✖ 1 problem (1 error, 0 warnings) (node:82363) [ESLINT_LEGACY_OBJECT_REST_SPREAD] DeprecationWarning: The 'parserOptions.ecmaFeatures.experimentalObjectRestSpread' option is deprecated. Use 'parserOptions.ecmaVersion' instead. (found in \u0026quot;standard\u0026quot;) ➜ tmp git:(master) ✗  又如下面这个，也是一样的\n➜ test eslint test.js Cannot find module 'eslint-config-airbnb' Referenced from: /Users/tomtsang/.eslintrc.js Error: Cannot find module 'eslint-config-airbnb' Referenced from: /Users/tomtsang/.eslintrc.js at ModuleResolver.resolve (/usr/local/lib/node_modules/eslint/lib/util/module-resolver.js:72:19) at resolve (/usr/local/lib/node_modules/eslint/lib/config/config-file.js:484:28) at load (/usr/local/lib/node_modules/eslint/lib/config/config-file.js:556:26) { at configExtends.reduceRight (/usr/local/lib/node_modules/eslint/lib/config/config-file.js:430:36) at Array.reduceRight (\u0026lt;anonymous\u0026gt;) at applyExtends (/usr/local/lib/node_modules/eslint/lib/config/config-file.js:408:26) at loadFromDisk (/usr/local/lib/node_modules/eslint/lib/config/config-file.js:528:22) at Object.load (/usr/local/lib/node_modules/eslint/lib/config/config-file.js:564:20) at Config.getPersonalConfig (/usr/local/lib/node_modules/eslint/lib/config.js:154:37) at Config.getLocalConfigHierarchy (/usr/local/lib/node_modules/eslint/lib/config.js:248:41) ➜ test  Ref  https://github.com/flycheck/flycheck/issues/1195  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/proxy.html",
	"title": "Proxy",
	"tags": ["proxy", "network"],
	"description": "",
	"content": " 正确的设置代理\nEnv  os: linux  Step root@tom:~/proxy# cat ./proxy_on.sh #!/bin/sh # for terminal export proxyserveraddr=127.0.0.1 export proxyserverport=8118 export HTTP_PROXY=\u0026quot;http://$proxyserveraddr:$proxyserverport/\u0026quot; export HTTPS_PROXY=\u0026quot;https://$proxyserveraddr:$proxyserverport/\u0026quot; export FTP_PROXY=\u0026quot;ftp://$proxyserveraddr:$proxyserverport/\u0026quot; export SOCKS_PROXY=\u0026quot;socks://$proxyserveraddr:$proxyserverport/\u0026quot; export NO_PROXY=\u0026quot;localhost,127.0.0.1,localaddress,.localdomain.com,200.200..;11.11.0.0;\u0026quot; export http_proxy=\u0026quot;http://$proxyserveraddr:$proxyserverport/\u0026quot; export https_proxy=\u0026quot;https://$proxyserveraddr:$proxyserverport/\u0026quot; export ftp_proxy=\u0026quot;ftp://$proxyserveraddr:$proxyserverport/\u0026quot; export socks_proxy=\u0026quot;socks://$proxyserveraddr:$proxyserverport/\u0026quot; export no_proxy=\u0026quot;localhost,127.0.0.1,localaddress,.localdomain.com,200.200..;11.11.0.0,10.88..;\u0026quot; # for chrome,firefox gsettings set org.gnome.system.proxy ignore-hosts \u0026quot;['localhost', '11.11.0.0/16', '200.200.0.0/16', '*.localdomain.com', '10.88.0.0/16', '10.88.88.116' ]\u0026quot; # for apt-get cat \u0026lt;\u0026lt;-EOF| sudo tee /etc/apt/apt.conf Acquire::http::proxy \u0026quot;http://$proxyserveraddr:$proxyserverport/\u0026quot;; Acquire::https::proxy \u0026quot;https://$proxyserveraddr:$proxyserverport/\u0026quot;; Acquire::ftp::proxy \u0026quot;ftp://$proxyserveraddr:$proxyserverport/\u0026quot;; Acquire::socks::proxy \u0026quot;socks://$proxyserveraddr:$proxyserverport/\u0026quot;; EOF  root@tom:~/proxy# cat proxy_off.sh #!/bin/sh unset proxyserveraddr unset proxyserverport unset HTTP_PROXY unset HTTPS_PROXY unset FTP_PROXY unset SOCKS_PROXY unset NO_PROXY unset http_proxy unset https_proxy unset ftp_proxy unset socks_proxy unset no_proxy gsettings reset org.gnome.system.proxy ignore-hosts echo -n \u0026quot;\u0026quot;|sudo tee /etc/apt/apt.conf root@tom:~/proxy#  Ref  http://www.cnblogs.com/scue/p/3891879.html http://www.crazyfairy.cn/archives/257  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/google/gamil-mail-server-domain.html",
	"title": "Gamil Mail Server Domain",
	"tags": ["mail"],
	"description": "",
	"content": " Env    Step 因为我们 bitspace.link 的域名，注册国家为香港，因此您无法使用中国电话进行验证。\nowen 您好， 感谢您接听我的电话。很高兴与您取得联系。 我了解您无法完成手机验证。由于您注册国家为香港，因此您无法使用中国电话进行验证。 经调查，您可等待九天让系统自动删除帐户后再重新注册。或者您也可以通过以下所提供的CNAME纪录值来验证您的网域拥有权以让我协助您删除帐户： 将以下的CNAME 纪录值根据主机及指向所需的DNS纪录值添加至您的网域管理控制台： -主机: deleteGAPPSnotBefore20180809utc -目标/指向: case-16595399-for-bitspace.link-at.google.com -Time to live (TTL): 3600 如果您的网域代管商并非您的网域注册商，请确保您是透过网域代管商修改您的CNAME 记录值。更多关于建立CNAME记录值的步骤与相关资讯，请点阅支援中心文章： https://support.google.com/a/answer/47283?hl=zh-Hant 。若您在建立CNAME 记录值时需要协助，请联系您的网域代管商进一步协助进行操作。 一旦完成了以上的验证，请回信告知以便我可以验证您对于“bitspace.link” 的拥有权。 同时请您提供您无法使用电话号码验证的错误信息截图，之后我将协助进行删除帐户。之后我将协助进行删除帐户。 若您还有其他疑问，您可以回覆此邮件以让我知道。我很乐意继续为您提供协助。  与google沟通，需要在Domain Name中配置\n配置如下：\nRef    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/keyboard/keyboard-ubuntu.html",
	"title": "Keyboard Ubuntu",
	"tags": ["keyboard", "ubuntu", "xmodmap"],
	"description": "",
	"content": " 通过xmodmap修改ubuntu系统下的键盘布局\n因为某种需求，需要把 右ctrl与右alt 互换\nEnv  os: ubuntu desktop 16.04 target: swap Right Ctrl with Right Alt on my keyboard  xmodmap Installation tom@tom:~$ cat ~/.Xmodmap clear control clear mod1 keycode 105 = Alt_R Meta_R keycode 108 = Control_R add control = Control_L Control_R add mod1 = Alt_R Meta_R tom@tom:~$ tom@tom:~$ xmodmap ~/.Xmodmap tom@tom:~$  这样，成功了。\n然后放到.bashrc中，这个文件每次启动shell都会执行，但结果确是：每启动一次shell,Ctrl和CapLock就交换一次，意味着我不知道下一时刻,哪个是Ctrl键，哪个是CapLock键。\n最后发现，在~目录添加一个.bash_profile文件，并将xmodmap脚本的执行放入其中。问题就解决了。\ntom@tom:~$ cat .bash_profile xmodmap ~/.Xmodmap tom@tom:~$ source .bash_profile  gnome-tweak-tool(不成功) gnome-tweak-tool 可以方便地修改某些键盘，如：互换 左ctrl与CapsLock\n安装gnome-tweak-tool：\nsudo apt install gnome-tweak-tool -y  运行\ngnome-tweak-tool  定位到Typing - Ctrl key position，选中Swap Ctrl and Caps Lock。关闭窗口，然后测试去吧。\n但是，我们选择Right Alt as Right Ctrl, 没有生效。哭。\nXKB(未测试)) Ubuntu 14.04 下通过 XKB 修改键盘映射, 实现自定义按键\nXKB : 全称 X Keyboard Extension, 是 Liunx 下管理键盘输入的一套较为复杂的系统. Ubuntu 14.04 采用这套系统来支持图形界面下的键盘管理.\nhttps://github.com/Chunlin-Li/Chunlin-Li.github.io/blob/master/blogs/linux/ubuntu-xkb-keyboard-remap.md\nRef  https://askubuntu.com/questions/93624/how-do-i-swap-left-ctrl-with-left-alt-on-my-keyboard https://www.cnblogs.com/billin/archive/2011/12/22/2298376.html https://www.jianshu.com/p/9b08b032a222 https://traceflight.github.io/tech/modify-caps-lock-to-ctrl.html xmodmap使用手册(中文版) 在ubuntu和mac间无缝切换 https://github.com/Chunlin-Li/Chunlin-Li.github.io/blob/master/blogs/linux/ubuntu-xkb-keyboard-remap.md  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/keyboard/keyboard.html",
	"title": "Keyboard",
	"tags": ["keyboard"],
	"description": "",
	"content": " Step ubuntu  xmodmap gnome-tweak-tool  mac  Karabiner Elements  windows  autohotkey  Ref    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox/ubuntu-share-file-to-virtulbox-win7.html",
	"title": "Ubuntu Share File to Virtulbox Win7",
	"tags": ["ubuntu", "virtualbox", "win7"],
	"description": "",
	"content": " Env  宿主机: ubuntu desktop 16 虚拟机软件: virtualbox 虚拟机: win7  Step 思路1 因为虚拟机是win7,那就直接通过 ubuntu如何访问windows共享文件夹 完成就可以了。\n思路2  https://www.linuxidc.com/Linux/2012-11/74195p3.htm http://xylonwang.iteye.com/blog/2221475  上面的方法，尝试，没有成功。\nRef  https://www.linuxidc.com/Linux/2012-11/74195p3.htm http://xylonwang.iteye.com/blog/2221475  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/emacs.html",
	"title": "Emacs",
	"tags": ["emacs"],
	"description": "",
	"content": " Step  Emacs 快速指南 - 原生中文手册 怎样学习 Emacs？ ergoemacs.org popkit evil  已经看过的  spacemacs 快捷键 spacemacs快捷键2 Emacs中那些不常用的行操作命令 写给 Pythonist 的 Spacemacs 入门指北 Spacemacs 使用总结  21天学会Emacs  21天学会Emacs http://book.emacs-china.org/  spacemacs  Spacemacs 使用总结 Spacemacs 基础 spacemacs 系列\u0026ndash;安装和基础配置  Ref  https://sam217pa.github.io/2016/09/13/from-helm-to-ivy/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown/markdown-style-guide.html",
	"title": "Markdown Style Guide",
	"tags": ["markdown"],
	"description": "",
	"content": " Step http://einverne.github.io/markdown-style-guide/zh.html\nRef  http://einverne.github.io/markdown-style-guide/zh.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/privoxy-mac.html",
	"title": "Privoxy Mac",
	"tags": ["mac", "privoxy", "shadowsocks", "network"],
	"description": "",
	"content": " mac osx 下面通过 privoxy 把shadowsocks 转换成http代理\nEnv  os: mac  Step ➜ ~ brew install privoxy ... ... To have launchd start privoxy now and restart at login: brew services start privoxy Or, if you don't want/need a background service you can just run: privoxy /usr/local/etc/privoxy/config ==\u0026gt; Summary 🍺 /usr/local/Cellar/privoxy/3.0.26: 99 files, 2.2MB ==\u0026gt; Caveats ==\u0026gt; privoxy To have launchd start privoxy now and restart at login: brew services start privoxy Or, if you don't want/need a background service you can just run: privoxy /usr/local/etc/privoxy/config ➜ ~  修改配置文件/usr/local/etc/privoxy/config\n➜ ~ vi /usr/local/etc/privoxy/config ➜ ~ tail -1 /usr/local/etc/privoxy/config forward-socks5 / 127.0.0.1:1080 . ➜ ~  启动privoxy服务\n➜ ~ brew services start privoxy ==\u0026gt; Tapping homebrew/services Cloning into '/usr/local/Homebrew/Library/Taps/homebrew/homebrew-services'... remote: Counting objects: 14, done. remote: Compressing objects: 100% (10/10), done. remote: Total 14 (delta 0), reused 8 (delta 0), pack-reused 0 Unpacking objects: 100% (14/14), done. Tapped 1 command (43 files, 55.2KB). ==\u0026gt; Successfully started `privoxy` (label: homebrew.mxcl.privoxy) ➜ ~ which privoxy privoxy not found ➜ ~  重新启动privoxy服务\n➜ ~ brew services start privoxy Service `privoxy` already started, use `brew services restart privoxy` to restart. ➜ ~ brew services restart privoxy Stopping `privoxy`... (might take a while) ==\u0026gt; Successfully stopped `privoxy` (label: homebrew.mxcl.privoxy) ==\u0026gt; Successfully started `privoxy` (label: homebrew.mxcl.privoxy) ➜ ~  验证已启动\n➜ ~ ps aux | grep privoxy tomtsang 79888 0.1 0.0 4276968 896 s006 S+ 2:34PM 0:00.01 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn privoxy tomtsang 79524 0.0 0.0 4296096 1192 ?? S 2:20PM 0:00.03 /usr/local/Cellar/privoxy/3.0.26/sbin/privoxy --no-daemon /usr/local/etc/privoxy/config ➜ ~ netstat -an | grep 8118 tcp4 0 0 127.0.0.1.8118 *.* LISTEN ➜ ~ ➜ ~ telnet 127.0.0.1 8118 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. '^] telnet\u0026gt; quit Connection closed. ➜ ~  加入环境变量\n➜ ~ tail -17 ~/.zshrc ### proxy function proxy_off(){ unset HTTP_PROXY unset HTTPS_PROXY unset http_proxy unset https_proxy echo -e \u0026quot;已关闭代理\u0026quot; } function proxy_on() { HTTP_PROXY=http://127.0.0.1:8118 http_proxy=${HTTP_PROXY} HTTPS_PROXY=${HTTP_PROXY} https_proxy=${HTTP_PROXY} export HTTP_PROXY HTTPS_PROXY http_proxy https_proxy echo -e \u0026quot;已开启代理\u0026quot; } ➜ ~ source .zshrc ➜ ~  验证科学上网成功\n➜ ~ proxy_on 已开启代理 ➜ ~ export | grep proxy http_proxy=http://127.0.0.1:8118 https_proxy=http://127.0.0.1:8118 ➜ ~ gvm listall gvm gos (available) go1 go1.0.1 go1.0.2 go1.0.3 go1.1 go1.1r ... ➜ ~  关闭科学上网\n➜ ~ proxy_off 已关闭代理 ➜ ~ gvm listall gvm gos (available) fatal: unable to access 'https://go.googlesource.com/go/': Failed to connect to go.googlesource.com port 443: Operation timed out ➜ ~  Ref  https://www.privoxy.org/ http://www.fyhqy.com/post-383.html https://blog.csdn.net/KimBing/article/details/70943325 https://blog.csdn.net/biyongyao/article/details/78636505  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/golang-gvm.html",
	"title": "Golang Gvm",
	"tags": ["golang", "gvm"],
	"description": "",
	"content": " Go 语言多版本安装及管理利器 - GVM\nEnv  golang  Step \u0008### 安装指定版本 golang\n这里要科学上网\n通过 gvm 安装指定 go版本\n➜ ~ gvm install go1.10 Downloading Go source...  但是这个时候，没有指定你会使用哪个版本\n➜ ~ gvm list gvm gos (installed) go1.10 system ➜ ~  通过 gvm 指定 默认使用版本\n➜ ~ gvm use go1.10 --default Now using version go1.10 ➜ ~ gvm list gvm gos (installed) =\u0026gt; go1.10 system ➜ ~  看一下go的环境吧\n➜ ~ go env GOARCH=\u0026quot;amd64\u0026quot; GOBIN=\u0026quot;\u0026quot; GOCACHE=\u0026quot;/Users/tomtsang/Library/Caches/go-build\u0026quot; GOEXE=\u0026quot;\u0026quot; GOHOSTARCH=\u0026quot;amd64\u0026quot; GOHOSTOS=\u0026quot;darwin\u0026quot; GOOS=\u0026quot;darwin\u0026quot; GOPATH=\u0026quot;/Users/tomtsang/.gvm/pkgsets/go1.10/global\u0026quot; GORACE=\u0026quot;\u0026quot; GOROOT=\u0026quot;/Users/tomtsang/.gvm/gos/go1.10\u0026quot; GOTMPDIR=\u0026quot;\u0026quot; GOTOOLDIR=\u0026quot;/Users/tomtsang/.gvm/gos/go1.10/pkg/tool/darwin_amd64\u0026quot; GCCGO=\u0026quot;gccgo\u0026quot; CC=\u0026quot;clang\u0026quot; CXX=\u0026quot;clang++\u0026quot; CGO_ENABLED=\u0026quot;1\u0026quot; CGO_CFLAGS=\u0026quot;-g -O2\u0026quot; CGO_CPPFLAGS=\u0026quot;\u0026quot; CGO_CXXFLAGS=\u0026quot;-g -O2\u0026quot; CGO_FFLAGS=\u0026quot;-g -O2\u0026quot; CGO_LDFLAGS=\u0026quot;-g -O2\u0026quot; PKG_CONFIG=\u0026quot;pkg-config\u0026quot; GOGCCFLAGS=\u0026quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/pj/9t97fpn94r71_8631wx_x1hm0000gn/T/go-build321836390=/tmp/go-build -gno-record-gcc-switches -fno-common\u0026quot; ➜ ~  看，完美呀，基本的环境都自动设置好了。\n用gvm管理Go项目的workspace 创建项目的workspace 我们来新建一个项目，名字叫baozou。项目目录放在~/goproj/下。\nmkdir -p ~/goproj/baozou cd ~/goproj/baozou gvm pkgset create --local gvm pkgset use --local mkdir src  在上面的命令中，我们创建了baozou项目的目录，进入目录后，使用gvm pkgset create --local命令，将目录设为一个local的pkgset，然后通过gvm pkgset use --local来使用它，这时，当前的环境变量的GOPATH为:\n$HOME/goproj/baozou:$HOME/goproj/baozou/.gvm_local/pkgsets/system/local:$HOME/.gvm/pkgsets/system/global  可以看到，GOPATH已经被设置为baozou这个项目目录了，这时我们执行go get命令来下载第三方库的时候，会默认下载到$HOME/goproj/baozou/src目录下。\n接下来，我们来创建真正用于代码管理的目录：\nmkdir -p ~/goproj/baozou/src/baozou cd ~/goproj/baozou/src/baozou git init  这里，我们用git来管理项目的软件版本。现在，我们可以在~/goproj/baozou/src/baozou这个目录下来编写代码了。\nRef  https://bingohuang.com/go-gvm/ https://github.com/moovweb/gvm https://studygolang.com/articles/4788  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/golang-ide-gogland.html",
	"title": "Golang Ide Gogland",
	"tags": ["golang", "gogland", "ide"],
	"description": "",
	"content": " Jetbrains 家族利器之 Gogland 简明教程\nEnv  os: mac  Step 安装 gvm 参考 Go 语言多版本安装及管理利器 - GVM\n并 通过 gvm 安装指定 go版本\n安装 goland 略\n激活 gogland mac版本 从 GoLand注册码 找到 https://www.imsxm.com/jetbrains-license-server.html ，从而知道了 在 JetBrains 授权服务器(License Server):填入 http://www.activejetbrains.gq，即可完成激活。\nwin10 版本 尝试 https://blog.csdn.net/sunylat/article/details/55096944\n三、设置 Gogland 的 GOROOT 如果之前已安装 gvm 则，这里会自动识别出来。\n这里如果说没有自动找到之前 gvm 安装的go版本，要重启一下mac。\nRef  https://www.imsxm.com/jetbrains-license-server.html https://bingohuang.com/go-gvm/ https://gocn.vip/article/445  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/win10-share-files.html",
	"title": "Win10 Share Files",
	"tags": ["win10"],
	"description": "",
	"content": " 两台win10 电脑怎么共享文件夹\nEnv  os: win10  Step 两台win10 电脑怎么共享文件夹\nRef  https://jingyan.baidu.com/article/495ba841b42de438b20ede5e.html https://jingyan.baidu.com/article/358570f6633ba4ce4624fc48.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/u-shendu.html",
	"title": "U Shendu",
	"tags": ["win10"],
	"description": "",
	"content": " 当你忘记了密码，可以使用u深度重置用户密码\nEnv  os: win10  Step u深度u盘启动盘制作教程\nu深度重置用户密码\nRef  https://jingyan.baidu.com/article/6b97984da3b9851ca2b0bfec.html http://upzxt.win7qjb.com/upzxtjc/794.html https://jingyan.baidu.com/article/90808022f724c6fd91c80fa6.html https://jingyan.baidu.com/article/6b97984da3b9851ca2b0bfec.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-no-passwd-login.html",
	"title": "Linux No Passwd Login",
	"tags": ["linux"],
	"description": "",
	"content": " 关闭SSH传统密码登陆方式\nEnv  os: linux  Step 加入登录公钥 自己创建 或 从其它地方导入 .ssh/authorized_keys 文件\nroot@ubuntu:/home/ubuntu# mv ssh/ .ssh/ root@ubuntu:/home/ubuntu# chmod 600 .ssh/authorized_keys  修改SSH的配置文件/etc/ssh/sshd_config root@ubuntu:/home/ubuntu# vi /etc/ssh/sshd_config root@ubuntu:/home/ubuntu# grep PasswordAuthentication -rn /etc/ssh/sshd_config 52:#PasswordAuthentication yes 53:PasswordAuthentication no 83:# PasswordAuthentication. Depending on your PAM configuration, 87:# PAM authentication, then enable this but set PasswordAuthentication root@ubuntu:/home/ubuntu#  注意，这个地方，一定要把 .ssh 文件夹的属性设置正确，然后重启sshd服务，否则会有如下错误\nubuntu@ubuntu:~$ sudo systemctl status sshd ● ssh.service - OpenBSD Secure Shell server Loaded: loaded (/lib/systemd/system/ssh.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2018-07-16 19:51:44 CST; 34s ago Main PID: 1439 (sshd) Tasks: 3 Memory: 6.4M CPU: 58ms CGroup: /system.slice/ssh.service ├─1330 sshd: ubuntu [priv] ├─1331 sshd: ubuntu [net] └─1439 /usr/sbin/sshd -D Jul 16 19:52:02 ubuntu sshd[1445]: error: Received disconnect from 10.88.88.64 port 49464:0: [preauth] Jul 16 19:52:02 ubuntu sshd[1445]: Disconnected from 10.88.88.64 port 49464 [preauth] Jul 16 19:52:07 ubuntu sshd[1447]: Authentication refused: bad ownership or modes for directory /home/ubuntu/.ssh Jul 16 19:52:10 ubuntu sshd[1447]: Authentication refused: bad ownership or modes for directory /home/ubuntu/.ssh Jul 16 19:52:11 ubuntu sshd[1447]: Authentication refused: bad ownership or modes for directory /home/ubuntu/.ssh Jul 16 19:52:12 ubuntu sshd[1447]: error: maximum authentication attempts exceeded for ubuntu from 10.88.88.64 port 49481 ssh2 [preauth] Jul 16 19:52:12 ubuntu sshd[1447]: Disconnecting: Too many authentication failures [preauth] ubuntu@ubuntu:~$  下面2步不能少\nubuntu@ubuntu:~$ chown -R ubuntu:ubuntu .ssh/ ubuntu@ubuntu:~$ chmod 700 .ssh/ ubuntu@ubuntu:~$  重启sshd服务 ubuntu@ubuntu:~$ sudo systemctl restart sshd ubuntu@ubuntu:~$ sudo systemctl status sshd  Ref  http://www.cnblogs.com/tl542475736/p/7814097.html http://www.cnblogs.com/tintin1926/archive/2012/07/23/2604281.html https://superuser.com/questions/215504/permissions-on-private-key-in-ssh-folder  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-authority.html",
	"title": "Gitlab Authority",
	"tags": ["gitlab"],
	"description": "",
	"content": " Env  gitlab: 10.0.8  Step 公司切入Gitlab来管理代码已经有一年多了，其中遇到很多权限问题，如没有权限clone、没有权限提交代码等等，这里做个总结. 权限分为访问权限和行为权限两个层次.\n访问权限 – Visibility Level 这个是在建立项目时就需要选定的，主要用于决定哪些人可以访问此项目，包含3种\n Private – 私有，只有属于该项目成员才有原先查看 Internal – 内部，用个Gitlab账号的人都可以clone Public – 公开，任何人可以clone  行为权限 在满足行为权限之前，必须具备访问权限（如果没有访问权限，那就无所谓行为权限了），行为权限是指对该项目进行某些操作，比如提交、创建问题、创建新分支、删除分支、创建标签、删除标签等.\n角色 Gitlab定义了以下几个角色:\n Guest – 访客 Reporter – 报告者; 可以理解为测试员、产品经理等，一般负责提交issue等 Developer – 开发者; 负责开发 Master – 主人; 一般是组长，负责对Master分支进行维护 Owner – 拥有者; 一般是项目经理  权限 不同角色，拥有不同权限，下面列出Gitlab各角色权限\nRef  https://www.cnblogs.com/dzcWeb/p/8919970.html http://ju.outofmemory.cn/entry/273281  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vscode/vscode-change-file-eol.html",
	"title": "Vscode Change File Eol",
	"tags": ["vscode"],
	"description": "",
	"content": " vscode 编辑器如何在用户配置文件里修改 行尾序列\nEnv  vscode  Step 文件，首选项，设置，搜索“files.eol”，然后编辑，然后就保存在用户设置或者工作区设置。\n下次打开一个新的文件时，就是 LF(\\n)结尾的换行符了。\n对于已有的文件，想批量转换的，请使用：\n另外一个方法是使用git-windows自带有dos2unix.exe, 在git bash中执行 find . -type f -exec dos2unix {} \\;批量转换\nRef  https://segmentfault.com/q/1010000006886783/a-1020000006890519 https://segmentfault.com/q/1010000011799577  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/change-system-datetime-base-ubuntu.html",
	"title": "Change System Datetime Base Ubuntu",
	"tags": ["ubuntu"],
	"description": "",
	"content": " Env  os: ubuntu16  Step 原理 需要取消自动从互联网同步时间才可以的\ntimedatectl set-ntp 0  上面的命令可以关闭自动同步，然后你再设置就好了\n如果又要打开可以运行\ntimedatectl set-ntp 1  示例 ubuntu@ip-172-31-46-220:~$ date Wed Jul 11 02:08:35 UTC 2018 ubuntu@ip-172-31-46-220:~$ sudo su root@ip-172-31-46-220:/home/ubuntu# timedatectl set-ntp 0 root@ip-172-31-46-220:/home/ubuntu# date -s \u0026quot;2018-07-12 02:08\u0026quot; Thu Jul 12 02:08:00 UTC 2018 root@ip-172-31-46-220:/home/ubuntu# hwclock --systohc root@ip-172-31-46-220:/home/ubuntu# date Thu Jul 12 02:08:06 UTC 2018 root@ip-172-31-46-220:/home/ubuntu# date -s \u0026quot;2018-07-12 02:10\u0026quot; Thu Jul 12 02:10:00 UTC 2018 root@ip-172-31-46-220:/home/ubuntu#  修改成功了\n还原 root@ip-172-31-46-220:/home/ubuntu# sudo timedatectl set-ntp 1 root@ip-172-31-46-220:/home/ubuntu# date Wed Jul 11 02:22:39 UTC 2018 root@ip-172-31-46-220:/home/ubuntu#  Ref  https://segmentfault.com/q/1010000010279964  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-install-base-win10.html",
	"title": "Hugo Install Base Win10",
	"tags": ["hugo"],
	"description": "",
	"content": " win10中安装hugo\nEnv  os: win10 sh: bash  Step Chocolatey (Windows) If you are on a Windows machine and use Chocolatey for package management, you can install Hugo with the following one-liner:\nchoco install hugo -confirm  安装之后，很重要的一步，是重启 git shell或者是cmd\nRef  https://gohugo.io/getting-started/installing https://www.howtogeek.com/194041/how-to-open-the-command-prompt-as-administrator-in-windows-8.1/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-ci-step-by-step.html",
	"title": "Gitlab CI Step by Step",
	"tags": ["gitlab"],
	"description": "",
	"content": " gitlab-ci \u0008一步一步学\nEnv  os: ubuntu docker: 17.03.2 gitlab: 10.2.8(比特空间提供)\n gitlab-runner:\n  Step 理论 了解  用 GitLab CI 进行持续集成, 这篇文章是写得我认为最合适入门的。\n gitlab ci quick-start有一个对应的中文版本-GitLab CI/CD快速入门。\n  安装 gitlab 略\n安装 gitlab-runner  可以先直接看 一步一步完成GitLab Runner持续化自动部署 的前3大点，就是安装的过程，我也就是这么安装成功的。  从 https://docs.gitlab.com/runner/install/ 了解到 docker 安装 gitlab-runner\ndocker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:v11.0.0  registering-a-specific-runner 获取Gitlab项目的Token https://blog.csdn.net/u011215669/article/details/80458972\nregister https://docs.gitlab.com/ce/ci/runners/README.html#registering-a-specific-runner\n找到\nhttps://docs.gitlab.com/runner/register/#docker\n可以完成 register, 但是，真正操作，其实可以参考刚刚说过的前3点大点。\n\u0008例子 https://gitlab.com/gitlab-examples/nodejs\n这里有一个nodejs的例子，可以先看一下项目中的 .gitlab-ci.yml 差不多出就明白了。\n那怎么利用这个例子呢？来吧。 总体思路，把这个工程clone下，push到自己的gitlab的一个新项目中去，然后，修改.gitlab-ci.yml 中的 tag为我们自己gitlab-runner的tag，然后commit就可以了。\n具体命令如下。\n在 gitlab-runner 节点\nsudo docker run --name postgres-db --publish=5432:5432 -e POSTGRES_PASSWORD=123456 -e POSTGRES_USER=testuser -d postgres:9.5.0 ## 因为这个项目的README.md文件中说明了，要先启动这个container,所以我们就在 gitlab-runner节点上启动一个。 git clone https://gitlab.com/gitlab-examples/nodejs.git cd nodejs/ git remote add gitlab http://X.X.X.X/archive/nodejs-test-a.git git push gitlab master vi .gitlab-ci.yml ### 修改tag为 `my-tag` git status git add .gitlab-ci.yml git commit -m \u0026quot;fix .gitlab-ci.yml\u0026quot; git push gitlab master  然后回到 gitlab，就可以看到CI/CD中的流水线中的作业，在执行我们想\u0008要的命令。\n学习 yaml 文件 接下来，我们当然是要去学习.gitlab-ci.yml的写法了。 来看看 .gitlab-ci.yml 是怎么写的吧.\n官方文档\n对应地，中文翻译\n 有一个过时的中文翻译 过时翻译，加了一个目录 过时翻译，加了一个目录  另一个\u0008翻译\n 翻译  更多官方文档中文翻译\nRef  https://scarletsky.github.io/2016/07/29/use-gitlab-ci-for-continuous-integration/ https://docs.gitlab.com/ce/ci/yaml/README.html https://docs.gitlab.com/ce/ci/runners/README.html#registering-a-specific-runner  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/bitbucket/bitbucket-user-share-repo.html",
	"title": "Bitbucket User Share Repo",
	"tags": ["bitbucket"],
	"description": "",
	"content": " bitbucket组来实现不同用户间的共同管理某一个具体repo\nEnv 2个bitbucket\n R: repo, 仓库R G: 组 A: UserA, 拥有仓库R，拥有组G，要分享给用户B B：UserB, 接受分享，来管理R  Step 登录A用户，新建立一个分组G\n管理组G, 添加用户B\n登录bitbucket\u0026gt;进入仓库R\u0026gt;设置\u0026gt;用户和组的访问\u0026gt;用户组\u0026gt;选择一个组G\u0026gt;管理\u0026gt;添加\n退出登录\n登录B用户, 确认加入组G\ngit clone git@bitbucket.org:UserA/Repo.git\n这样就实现了不同用户间的共同管理某一个具体repo, 而且，如果不希望用户B继续管理repo,则只需要从 组G中把 用户B 删除就可以了。\nTODO 后续，真的是可以直接将gitee中的私有项目放到 bitbucket中\ngitee 只有一个优点，拉取速度还行，但是，这个好像没有什么用。 - 开放项目，没必要放上面，比不过github - 私有项目，限制多，而且功能没有bitbucket强\nRef    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-user-create.html",
	"title": "Mysql User Create",
	"tags": ["mysql"],
	"description": "",
	"content": " mysql创建用户\nEnv  mysql: 5.7  Step MariaDB [(none)]\u0026gt; create user 'root'@'%' IDENTIFIED BY 'password'; Query OK, 0 rows affected (0.00 sec) MariaDB [(none)]\u0026gt; grant all on *.* to 'root'@'%' identified by 'password'; Query OK, 0 rows affected (0.00 sec) MariaDB [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) MariaDB [(none)]\u0026gt;  Ref    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor-character-set-database-utf8.html",
	"title": "Qor Character Set Database Utf8",
	"tags": ["qor", "mysql"],
	"description": "",
	"content": " qor通过字符集解决输入中文报错\nEnv  os: ubuntu16 go: 1.10.2  Step 输入中文会有 Error 1366: Incorrect string value: '\\xE4\\xB8\\xAD' for column 'name' at row 1这样的报错。\n这个错误主要的原因，就是插入数据的时候，数据库不认这个数据。那我们第一个想到的就是字符集的问题了。（可以先手动 insert into 方式测试）\nmysql 查看字符集 新安装的mysql数据库, 默认字符集是 latin1.\nmysql\u0026gt; show collation like 'gbk%'; +----------------+---------+----+---------+----------+---------+ | Collation | Charset | Id | Default | Compiled | Sortlen | +----------------+---------+----+---------+----------+---------+ | gbk_chinese_ci | gbk | 28 | Yes | Yes | 1 | | gbk_bin | gbk | 87 | | Yes | 1 | +----------------+---------+----+---------+----------+---------+ 2 rows in set (0.00 sec) mysql\u0026gt; show variables like 'character_set_server'; +----------------------+--------+ | Variable_name | Value | +----------------------+--------+ | character_set_server | latin1 | +----------------------+--------+ 1 row in set (0.01 sec) mysql\u0026gt; show variables like 'character_set_database'; +------------------------+--------+ | Variable_name | Value | +------------------------+--------+ | character_set_database | latin1 | +------------------------+--------+ 1 row in set (0.00 sec) mysql\u0026gt; show variables like 'collation_database'; +--------------------+-------------------+ | Variable_name | Value | +--------------------+-------------------+ | collation_database | latin1_swedish_ci | +--------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt;  mysql create database 指定utf-8编码 如下脚本创建数据库yourdbname，并制定默认的字符集是utf8\nCREATE DATABASE IF NOT EXISTS yourdbname DEFAULT CHARSET utf8 COLLATE utf8_general_ci;  如果要创建默认gbk字符集的数据库可以用下面的sql:\ncreate database yourdb DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci;  先 drop database, 再 create\nmysql\u0026gt; drop database qor_test; Query OK, 9 rows affected (0.26 sec) mysql\u0026gt; CREATE DATABASE IF NOT EXISTS qor_test DEFAULT CHARSET utf8 COLLATE utf8_general_ci; Query OK, 1 row affected (0.00 sec) mysql\u0026gt;  再查看字符集 mysql\u0026gt; show variables like 'character_set_database'; +------------------------+--------+ | Variable_name | Value | +------------------------+--------+ | character_set_database | latin1 | +------------------------+--------+ 1 row in set (0.00 sec) mysql\u0026gt; use qor_test; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u0026gt; show variables like 'character_set_database'; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | character_set_database | utf8 | +------------------------+-------+ 1 row in set (0.00 sec) mysql\u0026gt;  确认 再启动项目并测试，成功了！\nRef  https://jingyan.baidu.com/article/fea4511a011e6bf7bb912518.html https://blog.csdn.net/qq_20480611/article/details/48132343  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor-admin-test-change-sidebar.html",
	"title": "Qor Admin Test Change Sidebar",
	"tags": ["qor"],
	"description": "",
	"content": " qor/admin 项目的个性化配置(sidebar)\n这里使用 qor/admin 项目的 test 文件夹中的用例，启动。\nEnv  os: ubuntu16 go: 1.10.2  Step 总共修改3个文件\n dummy/admin.go dummy/models.go main.go  tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ git status On branch master Your branch is up-to-date with 'origin/master'. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: dummy/admin.go modified: dummy/models.go modified: main.go no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$  修改 main.go  导入本地的 dummy 包 路由路径从 admin 到 wq  tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ git diff main.go diff --git a/tests/main.go b/tests/main.go index 3328196..bb38c65 100644 --- a/tests/main.go +++ b/tests/main.go @@ -5,7 +5,8 @@ import ( \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; - \u0026quot;github.com/qor/admin/tests/dummy\u0026quot; + // \u0026quot;github.com/qor/admin/tests/dummy\u0026quot; + \u0026quot;./dummy\u0026quot; \u0026quot;github.com/qor/qor/utils\u0026quot; ) @@ -19,6 +20,6 @@ func main() { mux := http.NewServeMux() mux.Handle(\u0026quot;/system/\u0026quot;, utils.FileServer(http.Dir(\u0026quot;public\u0026quot;))) - dummy.NewDummyAdmin(true).MountTo(\u0026quot;/admin\u0026quot;, mux) + dummy.NewDummyAdmin(true).MountTo(\u0026quot;/wq\u0026quot;, mux) http.ListenAndServe(fmt.Sprintf(\u0026quot;:%s\u0026quot;, port), mux) } tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ ### 修改 dummy/models.go `dummy/models.go` 对应的是 mysql 中的表与字段 加减字段  tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ git diff dummy/models.go diff \u0026ndash;git a/tests/dummy/models.go b/tests/dummy/models.go index 426eb24..55cf59a 100644 \u0026mdash; a/tests/dummy/models.go +++ b/tests/dummy/models.go @@ -16,6 +16,7 @@ type CreditCard struct { type Company struct { gorm.Model Name string + Annotation string }\ntype Address struct { @@ -27,7 +28,12 @@ type Address struct {\ntype Language struct { gorm.Model - Name string + Name string + Materials string + Sizes string + Price float32 + Number uint + Description string }\ntype User struct { tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$\n ### 修改 dummy/admin.go `dummy/admin.go` 中的 `Admin.AddResource` 代表了 sidebar 的内容 导入本地的 `admin`包。这一步，好像也不需要。哈哈！  tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ git diff dummy/admin.go diff \u0026ndash;git a/tests/dummy/admin.go b/tests/dummy/admin.go index ca39a7c..11ab1ee 100644 \u0026mdash; a/tests/dummy/admin.go +++ b/tests/dummy/admin.go @@ -1,9 +1,10 @@ package dummy\nimport ( - \u0026ldquo;fmt\u0026rdquo; + // \u0026ldquo;fmt\u0026rdquo; // 去除 users 时要注释\n \u0026ldquo;github.com/qor/admin\u0026rdquo; // \u0026ldquo;github.com/qor/admin\u0026rdquo; \u0026rdquo;../../../admin\u0026rdquo; \u0026ldquo;github.com/qor/media\u0026rdquo; \u0026ldquo;github.com/qor/qor\u0026rdquo; \u0026ldquo;github.com/qor/qor/test/utils\u0026rdquo; @@ -14,6 +15,7 @@ func NewDummyAdmin(keepData \u0026hellip;bool) *admin.Admin { var ( db = utils.TestDB() models = []interface{}{\u0026amp;User{}, \u0026amp;CreditCard{}, \u0026amp;Address{}, \u0026amp;Language{}, \u0026amp;Profile{}, \u0026amp;Phone{}, \u0026amp;Company{}} // Admin = admin.New(\u0026amp;qor.Config{DB: db, SiteName: \u0026ldquo;文强的店\u0026rdquo;}) Admin = admin.New(\u0026amp;qor.Config{DB: db}) )  @@ -26,8 +28,9 @@ func NewDummyAdmin(keepData \u0026hellip;bool) *admin.Admin { db.AutoMigrate(value) }\n Admin.AddResource(\u0026amp;Company{}) Admin.AddResource(\u0026amp;Language{}, \u0026amp;admin.Config{Name: \u0026ldquo;语种 \u0026amp; 语言\u0026rdquo;, Priority: -1}) // Admin.AddResource(\u0026amp;Company{}) Admin.AddResource(\u0026amp;Language{}, \u0026amp;admin.Config{Name: \u0026ldquo;材料\u0026rdquo;, Priority: -1}) /* // 去除 users 时要注释 user := Admin.AddResource(\u0026amp;User{}) user.Meta(\u0026amp;admin.Meta{ Name: \u0026ldquo;CreditCard\u0026rdquo;, @@ -45,6 +48,7 @@ func NewDummyAdmin(keepData \u0026hellip;bool) *admin.Admin { return }, }) */\nreturn Admin  } tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ ```\n  Command 命令汇总\ntom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ git status On branch master Your branch is up-to-date with 'origin/master'. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: dummy/admin.go modified: dummy/models.go modified: main.go Untracked files: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed) main no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ git diff diff --git a/tests/dummy/admin.go b/tests/dummy/admin.go index ca39a7c..11ab1ee 100644 --- a/tests/dummy/admin.go +++ b/tests/dummy/admin.go @@ -1,9 +1,10 @@ package dummy import ( - \u0026quot;fmt\u0026quot; + // \u0026quot;fmt\u0026quot; // 去除 users 时要注释 - \u0026quot;github.com/qor/admin\u0026quot; + // \u0026quot;github.com/qor/admin\u0026quot; + \u0026quot;../../../admin\u0026quot; \u0026quot;github.com/qor/media\u0026quot; \u0026quot;github.com/qor/qor\u0026quot; \u0026quot;github.com/qor/qor/test/utils\u0026quot; @@ -14,6 +15,7 @@ func NewDummyAdmin(keepData ...bool) *admin.Admin { var ( db = utils.TestDB() models = []interface{}{\u0026amp;User{}, \u0026amp;CreditCard{}, \u0026amp;Address{}, \u0026amp;Language{}, \u0026amp;Profile{}, \u0026amp;Phone{}, \u0026amp;Company{}} + // Admin = admin.New(\u0026amp;qor.Config{DB: db, SiteName: \u0026quot;文强的店\u0026quot;}) Admin = admin.New(\u0026amp;qor.Config{DB: db}) ) @@ -26,8 +28,9 @@ func NewDummyAdmin(keepData ...bool) *admin.Admin { db.AutoMigrate(value) } - Admin.AddResource(\u0026amp;Company{}) - Admin.AddResource(\u0026amp;Language{}, \u0026amp;admin.Config{Name: \u0026quot;语种 \u0026amp; 语言\u0026quot;, Priority: -1}) + // Admin.AddResource(\u0026amp;Company{}) + Admin.AddResource(\u0026amp;Language{}, \u0026amp;admin.Config{Name: \u0026quot;材料\u0026quot;, Priority: -1}) + /* // 去除 users 时要注释 user := Admin.AddResource(\u0026amp;User{}) user.Meta(\u0026amp;admin.Meta{ Name: \u0026quot;CreditCard\u0026quot;, @@ -45,6 +48,7 @@ func NewDummyAdmin(keepData ...bool) *admin.Admin { return }, }) + */ return Admin } diff --git a/tests/dummy/models.go b/tests/dummy/models.go index 426eb24..55cf59a 100644 --- a/tests/dummy/models.go +++ b/tests/dummy/models.go @@ -16,6 +16,7 @@ type CreditCard struct { type Company struct { gorm.Model Name string + Annotation string } type Address struct { @@ -27,7 +28,12 @@ type Address struct { type Language struct { gorm.Model - Name string + Name string + Materials string + Sizes string + Price float32 + Number uint + Description string } type User struct { diff --git a/tests/main.go b/tests/main.go index 3328196..bb38c65 100644 --- a/tests/main.go +++ b/tests/main.go @@ -5,7 +5,8 @@ import ( \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; - \u0026quot;github.com/qor/admin/tests/dummy\u0026quot; + // \u0026quot;github.com/qor/admin/tests/dummy\u0026quot; + \u0026quot;./dummy\u0026quot; \u0026quot;github.com/qor/qor/utils\u0026quot; ) @@ -19,6 +20,6 @@ func main() { mux := http.NewServeMux() mux.Handle(\u0026quot;/system/\u0026quot;, utils.FileServer(http.Dir(\u0026quot;public\u0026quot;))) - dummy.NewDummyAdmin(true).MountTo(\u0026quot;/admin\u0026quot;, mux) + dummy.NewDummyAdmin(true).MountTo(\u0026quot;/wq\u0026quot;, mux) http.ListenAndServe(fmt.Sprintf(\u0026quot;:%s\u0026quot;, port), mux) } tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$  Ref  https://github.com/qor/admin  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor-admin-test-change-title.html",
	"title": "Qor Admin Test Change Title",
	"tags": ["qor"],
	"description": "",
	"content": " qor/admin 项目的个性化配置(依赖包)\n这里使用 qor/admin 项目的 test 文件夹中的用例，启动。\nEnv  os: ubuntu16 go: 1.10.2  Step 现在我们启动项目后，会先安装依赖，再配置依赖包。\n安装依赖 查看 test文件夹下的文件，找出依赖包，整理一下，安装\ngo get github.com/qor/media go get github.com/jinzhu/gorm go get github.com/qor/admin go get github.com/qor/qor  个性化配置 找到go get文件 以我的代码习惯，go get文件放在了 $HOME/golang/lib 中\n所以qor/admin项目文件，就在 $HOME/golang/lib/src/github.com/qor/admin 中\ncd ~/golang/lib/src/github.com/qor/admin  配置logo logo 在 views/assets/images/logo.png 中，替换就可以了。\n配置左下角的 Powered by Powered by 在 views/shared/sidebar.tmpl\n配置标签页面的标题 标签页面的标题 在 views/layout.tmpl\nCommand ubuntu@VM-0-12-ubuntu:~/golang/lib/src/github.com/qor/admin$ git status On branch master Your branch is up-to-date with 'origin/master'. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: views/assets/images/logo.png modified: views/layout.tmpl modified: views/shared/sidebar.tmpl no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) ubuntu@VM-0-12-ubuntu:~/golang/lib/src/github.com/qor/admin$ git diff diff --git a/views/assets/images/logo.png b/views/assets/images/logo.png index 37da102..1201a78 100644 Binary files a/views/assets/images/logo.png and b/views/assets/images/logo.png differ diff --git a/views/layout.tmpl b/views/layout.tmpl index 6aa17ef..c68f759 100644 --- a/views/layout.tmpl +++ b/views/layout.tmpl @@ -10,7 +10,7 @@ --\u0026gt; \u0026lt;head\u0026gt; {{$title := page_title}} - \u0026lt;title\u0026gt;{{if $title}}{{$title}} - {{end}}{{if .Admin.SiteName}}{{t .Admin.SiteName}}{{else}}{{t \u0026quot;Qor Admin\u0026quot;}}{{end}}\u0026lt;/title\u0026gt; + \u0026lt;title\u0026gt;{{if $title}}{{$title}} - {{end}}{{if .Admin.SiteName}}{{t .Admin.SiteName}}{{else}}{{t \u0026quot;\u0026lt;E6\u0026gt;\u0026lt;96\u0026gt;\u0026lt;87\u0026gt;\u0026lt;E5\u0026gt;\u0026lt;BC\u0026gt;\u0026lt;BA\u0026gt;\u0026lt;E7\u0026gt;\u0026lt;9A\u0026gt;\u0026lt;84\u0026gt;\u0026lt;E5\u0026gt;\u0026lt;BA\u0026gt;\u0026lt;97\u0026gt;\u0026quot;}}{{end}}\u0026lt;/title\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;x-ua-compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1\u0026quot;\u0026gt; diff --git a/views/shared/sidebar.tmpl b/views/shared/sidebar.tmpl index 4a85658..8743614 100644 --- a/views/shared/sidebar.tmpl +++ b/views/shared/sidebar.tmpl @@ -22,6 +22,7 @@ \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;sidebar-footer\u0026quot;\u0026gt; - {{t \u0026quot;qor_admin.layout.powered_by\u0026quot; \u0026quot;Powered by \u0026lt;a href=\\\u0026quot;http://getqor.com\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;QOR\u0026lt;/a\u0026gt;\u0026quot;}} + \u0026lt;!-- {{t \u0026quot;qor_admin.layout.powered_by\u0026quot; \u0026quot;Powered by \u0026lt;a href=\\\u0026quot;http://getqor.com\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;QOR\u0026lt;/a\u0026gt;\u0026quot;}} --\u0026gt; + {{t \u0026quot;qor_admin.layout.powered_by\u0026quot; \u0026quot;Powered by \u0026lt;a href=\\\u0026quot;https://blog.finsoft.info\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;blog.finsoft.info\u0026lt;/a\u0026gt;\u0026quot;}} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ubuntu@VM-0-12-ubuntu:~/golang/lib/src/github.com/qor/admin$  Ref  https://github.com/qor/admin  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor-admin-test.html",
	"title": "Qor Admin Test",
	"tags": ["qor"],
	"description": "",
	"content": " qor/admin 项目的 test 文件夹中的用例\nEnv  os: ubuntu16 go: 1.10.2  Step 安装依赖 查看 test文件夹下的文件，找出依赖包，整理一下，安装\ngo get github.com/qor/media go get github.com/jinzhu/gorm go get github.com/qor/admin go get github.com/qor/qor  配置mysql tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ go run main.go Listening on: 3000 panic: Error 1045: Access denied for user 'qor'@'localhost' (using password: YES) goroutine 1 [running]: github.com/qor/qor/test/utils.TestDB(0x30) /home/tom/golang/lib/src/github.com/qor/qor/test/utils/test_db.go:36 +0x585 github.com/qor/admin/tests/dummy.NewDummyAdmin(0xc42031bf1f, 0x1, 0x1, 0xa791a0) /home/tom/golang/lib/src/github.com/qor/admin/tests/dummy/admin.go:15 +0x37 main.main() /home/tom/golang/qor/src/qor/tom/admin/admin/tests/main.go:22 +0x187 exit status 2 tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$  有报错了。报错，说明了，在我们的 go get github.com/qor/qor 中的 utils.TestDB 出错了，文件夹是在 /home/tom/golang/lib/src/github.com/qor/qor/test/utils/test_db.go. 那容易了，我们直接去grep一下。\ntom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ grep localhost -rn ./ tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ grep localhost -rn ./../../ tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ grep localhost -rn ./../../../../../../../lib/src/github.com/qor/qor/test/utils/ ./../../../../../../../lib/src/github.com/qor/qor/test/utils/test_db.go:27: db, err = gorm.Open(\u0026quot;postgres\u0026quot;, fmt.Sprintf(\u0026quot;postgres://%s:%s@localhost/%s?sslmode=disable\u0026quot;, dbuser, dbpwd, dbname)) ./../../../../../../../lib/src/github.com/qor/qor/test/utils/test_db.go:29: // CREATE USER 'qor'@'localhost' IDENTIFIED BY 'qor'; ./../../../../../../../lib/src/github.com/qor/qor/test/utils/test_db.go:31: // GRANT ALL ON qor_test.* TO 'qor'@'localhost'; tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$  果然是有的。 提示说了，// CREATE USER 'qor'@'localhost' IDENTIFIED BY 'qor';, // GRANT ALL ON qor_test.* TO 'qor'@'localhost';, 那我们先把这些创建好吧。\nmysql\u0026gt; CREATE USER 'qor'@'localhost' IDENTIFIED BY 'qor'; mysql\u0026gt; GRANT ALL ON qor_test.* TO 'qor'@'localhost';  再启动\ntom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ ls dummy logo.png main.go qor.png views tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ go run main.go Listening on: 3000 panic: Error 1049: Unknown database 'qor_test' goroutine 1 [running]: github.com/qor/qor/test/utils.TestDB(0x30) /home/tom/golang/lib/src/github.com/qor/qor/test/utils/test_db.go:36 +0x585 github.com/qor/admin/tests/dummy.NewDummyAdmin(0xc42033ff1f, 0x1, 0x1, 0xa791a0) /home/tom/golang/lib/src/github.com/qor/admin/tests/dummy/admin.go:15 +0x37 main.main() /home/tom/golang/qor/src/qor/tom/admin/admin/tests/main.go:22 +0x187 exit status 2 tom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$  好了，现在是另一个报错了，Unknown database 'qor_test'。那就去创建这个database吧。\nmysql\u0026gt; CREATE DATABASE IF NOT EXISTS qor_test DEFAULT CHARSET utf8 COLLATE utf8_general_ci;  注意，这里不能直接使用 mysql\u0026gt; CREATE DATABASE qor_test;因为这样会使用默认字符集latin1，导致中文无法输入，且会报错。\n再启动\ntom@tom-w10vbud16:~/golang/qor/src/qor/tom/admin/admin/tests$ go run main.go Listening on: 3000 2018/07/03 16:07:25 Finish [GET] /admin Took 18.91ms  成功了！\nRef  https://github.com/qor/admin  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/grep-exclude-many-file.html",
	"title": "Grep Exclude Many File",
	"tags": ["grep"],
	"description": "",
	"content": " grep 同时排除多个关键字,多个文件\nStep grep -v 排除文件 | grep -v 排除文件\ntom@tom-w10vbud16:~$ ifconfig | grep inet | grep -v inet6 | grep -v 127.0.0.1 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 inet addr:10.88.88.130 Bcast:10.88.88.255 Mask:255.255.255.0 inet addr:10.42.0.0 Bcast:0.0.0.0 Mask:255.255.255.255 tom@tom-w10vbud16:~$  Ref  https://blog.csdn.net/qq70945934/article/details/77573870  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor-doc-get-started.html",
	"title": "Qor Doc Get Started",
	"tags": ["qor", "learn"],
	"description": "",
	"content": " qor step by step\nQor Doc中的Get Started\nEnv  os: ubuntu16 go: 1.10.2  Step root@tom-w10vbud16:/home/tom/test# cd /home/tom/golang/ root@tom-w10vbud16:/home/tom/golang# mkdir qor/src -p root@tom-w10vbud16:/home/tom/golang# cd qor/src/ root@tom-w10vbud16:/home/tom/golang/qor/src# git clone https://github.com/qor/qor root@tom-w10vbud16:/home/tom/golang/qor/src# ls qor/ bower.json config.go context.go errors.go gulpfile.js LICENSE.txt package.json README.md resource test test_all.sh update_all_qor_repos.sh utils yarn.lock  get_started https://doc.getqor.com/get_started.html\n配置 GOPATH 把 /home/tom/golang/qor 加入 GOPATH\nroot@tom-w10vbud16:/home/tom/golang/qor/src# vi ~/.bashrc root@tom-w10vbud16:/home/tom/golang/qor/src# source ~/.bashrc root@tom-w10vbud16:/home/tom/golang/qor/src# export | grep go declare -x GOPATH=\u0026quot;/home/tom/golang/lib:/home/tom/golang/goc2p:/home/tom/ztom/project/github/ERP/goERP:/home/tom/golang/qor\u0026quot; declare -x GOROOT=\u0026quot;/usr/local/go\u0026quot; declare -x OLDPWD=\u0026quot;/home/tom/golang\u0026quot; declare -x PATH=\u0026quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/go/bin:/home/tom/golang/lib/bin:/usr/local/go/bin:/home/tom/golang/lib/bin\u0026quot; declare -x PWD=\u0026quot;/home/tom/golang/qor/src\u0026quot;  root@tom-w10vbud16:/home/tom/golang/qor/src# vi main.go root@tom-w10vbud16:/home/tom/golang/qor/src# chmod +x main.go  把 main.go 中涉及的包，安装一下 root@tom-w10vbud16:/home/tom/golang/qor/src# ls main.go qor root@tom-w10vbud16:/home/tom/golang/qor/src# go get github.com/qor/qor root@tom-w10vbud16:/home/tom/golang/qor/src# go get github.com/qor/admin root@tom-w10vbud16:/home/tom/golang/qor/src# go get github.com/jinzhu/gorm root@tom-w10vbud16:/home/tom/golang/qor/src# go get github.com/jinzhu/gorm/dialects/sqlite  run root@tom-w10vbud16:/home/tom/golang/qor/src# ls main.go qor root@tom-w10vbud16:/home/tom/golang/qor/src# go run main.go # command-line-arguments ./main.go:6:3: imported and not used: \u0026quot;github.com/qor/qor\u0026quot; root@tom-w10vbud16:/home/tom/golang/qor/src#  好像说github.com/qor/qor这个包没有用到，那先注释掉吧\nroot@tom-w10vbud16:/home/tom/golang/qor/src# pwd /home/tom/golang/qor/src root@tom-w10vbud16:/home/tom/golang/qor/src# ls main.go qor root@tom-w10vbud16:/home/tom/golang/qor/src# vi main.go root@tom-w10vbud16:/home/tom/golang/qor/src# go run main.go Listening on: 9000 2018/07/02 14:43:21 Finish [GET] /admin Took 4.04ms 2018/07/02 14:48:33 Finish [GET] /admin Took 2.25ms 2018/07/02 14:48:35 Finish [GET] /admin/users Took 6.25ms 2018/07/02 14:48:36 Finish [GET] /admin/products Took 7.03ms 2018/07/02 14:50:50 Finish [GET] /admin/products Took 5.62ms 2018/07/02 14:50:54 Finish [GET] /admin Took 2.21ms 2018/07/02 16:57:57 Finish [GET] /admin/users Took 15.72ms 2018/07/02 16:57:58 Finish [GET] /admin/products Took 4.41ms 2018/07/02 16:57:59 Finish [GET] /admin/users Took 12.21ms 2018/07/02 16:58:00 Finish [GET] /admin/products Took 4.65ms ^Csignal: interrupt root@tom-w10vbud16:/home/tom/golang/qor/src#  这个时候，会多出一个demo.db文件\nroot@tom-w10vbud16:/home/tom/golang/qor/src# ls demo.db main.go qor  成功了。虽然这个demo没有什么东西。\nRef  https://doc.getqor.com/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/erp-golang.html",
	"title": "Erp Golang",
	"tags": ["erp", "golang", "resource"],
	"description": "",
	"content": " Any ERP system written in Go\n非开源 https://www.obs2go.com/\nopen source https://golanglibs.com/search?q=erp\u0026amp;sort=top\n中英文 https://getqor.com/cn https://github.com/qor/qor https://github.com/reechou/erp\n中文版 https://github.com/hexiaoyun128/ERP.git https://www.ctolib.com/hexiaoyun128-ERP.html\nhexya 无中文 http://hexya.io/\n中文版 https://github.com/JoyiSystem/goerp\ngolang-erp https://github.com/odenktools/golang-erp\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor-example-install.html",
	"title": "Qor Example Install",
	"tags": ["qor", "ERP"],
	"description": "",
	"content": " qor-example 安装启动\nEnv  os: ubuntu16 go: 1.10.2  Step 设置 GOPATH 添加 /home/tom/golang/qor为GOPATH\nroot@tom-w10vbud16:/home/tom/ztom/bits/pem/aws/aws-account-b/pem# export | grep go declare -x GOPATH=\u0026quot;/home/tom/golang/lib:/home/tom/golang/goc2p:/home/tom/ztom/project/github/ERP/goERP:/home/tom/golang/qor\u0026quot; declare -x GOROOT=\u0026quot;/usr/local/go\u0026quot; declare -x PATH=\u0026quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/go/bin:/home/tom/golang/lib/bin\u0026quot; root@tom-w10vbud16:/home/tom/ztom/bits/pem/aws/aws-account-b/pem#  安装 # Get example app $ go get -u github.com/qor/qor-example # Setup database $ mysql -uroot -p mysql\u0026gt; CREATE DATABASE IF NOT EXISTS qor_example DEFAULT CHARSET utf8 COLLATE utf8_general_ci; # Run Application $ cd $GOPATH/src/github.com/qor/qor-example $ go run main.go  注意，这里不能直接使用 mysql\u0026gt; CREATE DATABASE qor_example;因为这样会使用默认字符集latin1，导致中文无法输入，且会报错。\n最后一步，报错了。\nroot@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example# go run main.go Failed to find configuration config/application.yml, using example file config/application.example.yml Failed to find configuration config/smtp.yml, using example file config/smtp.example.yml WARNING: AssetFS is used before overwrite it! goroutine 1 [running, locked to thread]: runtime/debug.Stack(0xc4200a6008, 0xc42036fd08, 0x1) /usr/local/go/src/runtime/debug/stack.go:24 +0xa7 runtime/debug.PrintStack() /usr/local/go/src/runtime/debug/stack.go:16 +0x22 github.com/qor/assetfs.SetAssetFS(0x7f46b008c0d0, 0x140e160) /home/tom/golang/lib/src/github.com/qor/assetfs/assetfs.go:33 +0xb0 github.com/qor/qor-example/config/bindatafs.init.0() /home/tom/golang/lib/src/github.com/qor/qor-example/config/bindatafs/bindatafs.go:26 +0x5d panic: Error 1045: Access denied for user 'root'@'localhost' (using password: NO) goroutine 1 [running]: github.com/qor/qor-example/config/db.init.0() /home/tom/golang/lib/src/github.com/qor/qor-example/config/db/db.go:49 +0x799 exit status 2 root@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example#  这个明显是mysql错误，首先要排除登录问题。\nroot@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example# mysql -uroot -h localhost -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 11 Server version: 5.7.22-0ubuntu0.16.04.1 (Ubuntu) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u0026gt;  说明本机 'root'@'localhost'用户是可以登录的。 那就是密码配置问题咯。\n配置mysql 找到配置文件，发现是在 config/database.example.yml 文件中配置的。那生成新配置文件，并添加密码吧。\nroot@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example# cp config/application.example.yml config/database.yml root@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example# vi config/database.yml root@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example# cat config/database.yml db: adapter: mysql name: qor_example user: root password: root root@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example#  gitter 再次 go run main.go 报Failed to find configuration config/application.yml, using example file config/application.example.yml\n然后去到了 qor的 gitter 中去找找相同经历。 果然找到了。\nnawikart @nawikart 4月 02 21:00 hi guys, anyone can help me about QOR Quick Started please.. I already do these: Get example app $ go get -u github.com/qor/qor-example Setup database $ mysql -uroot -p mysql\u0026gt; CREATE DATABASE qor_example; Run Application $ cd $GOPATH/src/github.com/qor/qor-example $ go run main.go but got result: Failed to find configuration config/application.yml, using example file config/application.example.yml is anyone would like to explain what happened please..... Thanateros @thanateros 4月 03 03:14 @nawikart you also need to have NodeJS installed, then install 'gulp' globally with npm and do npm install (in application root directory). Then pull go dependencies (go get -u ./... from application root directory) -- this part may take a while and gives no feedback until error or done, so you can throw a -v switch in there (go get -u -v ./... if you want feedback while it works). Do not forget to edit the database connection information (edit qor-example/config/config.go). Then run with go run main.go or go run -v main.go if you want some verbose output. I recall having to piece all of this together myself (except for the go get ./... part, that is actually there if you click the wiki link for the qor-example repo). You are almost there my fellow gopher.  总之，就是运行下面的命令\ncnpm i -g gulp cd $GOPATH/src/github/qor/qor-example go get -u ./... go run -v main.go  最后，我的效果如下\nroot@tom-w10vbud16:/home/tom/golang/lib/src/github.com/qor/qor-example# go run main.go Failed to find configuration config/application.yml, using example file config/application.example.yml Failed to find configuration config/smtp.yml, using example file config/smtp.example.yml WARNING: AssetFS is used before overwrite it! goroutine 1 [running, locked to thread]: runtime/debug.Stack(0xc42000e018, 0xc42038fd08, 0x1) /usr/local/go/src/runtime/debug/stack.go:24 +0xa7 runtime/debug.PrintStack() /usr/local/go/src/runtime/debug/stack.go:16 +0x22 github.com/qor/assetfs.SetAssetFS(0x7f3bb5e54000, 0x140e160) /home/tom/golang/lib/src/github.com/qor/assetfs/assetfs.go:33 +0xb0 github.com/qor/qor-example/config/bindatafs.init.0() /home/tom/golang/lib/src/github.com/qor/qor-example/config/bindatafs/bindatafs.go:26 +0x5d Failed to create unique index for translations key \u0026amp; locale, got: Error 1170: BLOB/TEXT column 'key' used in key specification without a key length (Error 1170: BLOB/TEXT column 'key' used in key specification without a key length) [2018-07-02 16:41:27] Enterprise features not enabled... Listening on: 7000  Ref  https://github.com/qor/qor-example https://gitter.im/qor/qor  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-role.html",
	"title": "Kubernetes Role",
	"tags": ["kubernetes"],
	"description": "",
	"content": " Env  kubernetes: 1.10  Step \u0026ldquo;我打你\u0026rdquo;,\n 动作执行对象是 我, 动作是 打 动作被执行对象是 你  在namespace级别：\nrole: 是`动作`与`动作被执行对象`的规则，比如：\u0026quot;打你\u0026quot; rolebing: 是绑定`动作`与`动作对象`，比如：指定 \u0026quot;我\u0026quot;与\u0026quot;打你\u0026quot; 相绑定。  在cluster级别：\nclusterrole clusterrolebing  Ref  https://live.vhall.com/829906699  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/mac.html",
	"title": "Mac",
	"tags": ["resource", "mac"],
	"description": "",
	"content": " Env    Step mysql  sequelpro  Karabiner Elements  https://pqrs.org/osx/karabiner/ Karabiner Elements 键位定制神器 https://www.jianshu.com/p/47d5de7f12bc https://github.com/tekezo/Karabiner-Elements https://note.wuze.me/liu-shui/macos-zhi-wai-jie-hhkb-jian-pan-karabiner-elements-pei-zhi  ###\n Manico, 一款快速启动及切换 Mac App 的工具 KeyCastr: 录屏好帮手，实时显示按键操作的小工具\n dash\n  Ref  https://zhuanlan.zhihu.com/p/29982257  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/rancher-add-worker.html",
	"title": "Rancher Add Worker",
	"tags": ["rancher"],
	"description": "",
	"content": " Env    Step QA 报 certificate has expired or is not yet valid 错误 Q: 希望新添加1个 worker， 报 certificate has expired or is not yet valid 错误，应该如何修正？ A:\nRef  https://www.cnblogs.com/xzkzzz/p/9106218.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/rancher-service-discovery.html",
	"title": "Rancher Service Discovery",
	"tags": ["rancher"],
	"description": "",
	"content": " rancher 中的 service discovery\nEnv  rancher: v2.0.2  Step service discovery对应于 k8s的service\n external IP addresses 相当于 DNS的A记录的解析 An external hostname 相当于 DNS的CNAME的域名转换 Alias of another DNS record\u0026rsquo;s value 相当于 指向另外一个DNS的记录 One or more workloads 指向其它的workloads The set of pods which match a selector 通过selector作转换, 实现内部的负载均衡，升级时就可使用。  Ref  http://live.vhall.com/209459630  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/rancher-node-driver-add-aliyun.html",
	"title": "Rancher Node Driver Add Aliyun",
	"tags": ["rancher"],
	"description": "",
	"content": " rancher添加node drivers(阿里云)\nEnv  rancher: v2.0.2  Step Global, Node Drivers, Add Node Drivers, 把下图填写完，OK了。\nRef  http://live.vhall.com/431874021  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-workflow.html",
	"title": "Gitlab Workflow",
	"tags": ["gitlab", "workflow"],
	"description": "",
	"content": " gitlab流程\nEnv    Step Ref  https://www.cnblogs.com/coderzl/p/7491143.html https://blog.csdn.net/liumiaocn/article/details/79256312  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yapi/yapi-install-base-ubuntu.html",
	"title": "Yapi Install Base Ubuntu",
	"tags": ["yapi"],
	"description": "",
	"content": " Env    Step  177 yum install -y mongodb-org 178 mongo -v 179 systemctl start mongod 180 /etc/init.d/mongod start 181 npm install -g yapi-cli --registry https://registry.npm.taobao.org 182 yapi server 183 ls 184 rm -rf my-yapi/ 185 clear 186 ls 187 node -v 188 mongo 189 git 190 yum install git 191 /etc/init.d/mongod restart 192 mongod -v 193 mongo 194 clear 195 npm install -g yapi-cli --registry https://registry.npm.taobao.org 196 yapi server 197 ls 198 node my-yapi/vendors/server/app.js 199 nohup node my-yapi/vendors/server/app.js \u0026amp; 200 node my-yapi/vendors/server/app.js 201 clear 202 ps -ef | grep node 203 kill -9 10314 204 ps -ef | grep node 205 ls 206 cd my-yapi/ 207 ls 208 cd vendors/ 209 ls 210 cd .. 211 node vendors/server/app.js 212 ls 213 cd my-yapi/ 214 ls 215 cd vendors/ 216 ls 217 cd .. 218 clear 219 ls 220 cd .. 221 netstat-ntpl 222 netstat -ntpl 223 ps -ef | grep node 224 kill -9 1314 225 ls 226 cd my-yapi/ 227 ls 228 cd vendors/ 229 ls 230 cd my-yapi/ 231 ls 232 cd vendors/ 233 ls 234 node server/app.js 235 ls 236 ps -ef | grep node 237 ls 238 cd .. 239 ls 240 nohup node vendors/server/app.js \u0026amp; 241 clear 242 ifconfig 243 history 244 clear 245 ls 778 nohup node /my-yapi/vendors/server/app.js \u0026amp; 779 history | grep nohup 780 ps -ef | grep app.js 781 ls 782 nohup node my-yapi/vendors/server/app.js \u0026amp; 783 exit 784 netstat -ntpl  Ref    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yapi/yapi-docker-transfer-data-install.html",
	"title": "Yapi Transfer Base Docker",
	"tags": ["yapi"],
	"description": "",
	"content": " 记一次yapi的迁移过程\nEnv 原来有一个docker安装在 192.168.168.162. 现在希望迁移至 192.168.168.137\n原来 docker 的安装方式,见, https://github.com/eiuapp/docker-yapi\n同时也可以参考一下 https://www.cnblogs.com/woshimrf/p/docker-install-yapi.html\nStep 安装文件与容器数据迁移 tar -zcvf yapi.tar.gz ./yapi/ tar zcvf ./data.opt.mongodb.data.tar.gz /data/opt/mongodb/data/ scp -P 2222 data.opt.mongodb.data.tar.gz yapi.tar.gz ubuntu@192.168.168.137:/home/ubuntu/  新机器安装docker网络与相关镜像 tar -zxvf yapi.tar.gz tar -zxvf data.opt.mongodb.data.tar.gz sudo mv data/opt/ /data/opt/ ls /data/opt/mongodb/data/ cd yapi/ cp index.sh rindex.sh vi rindex.sh  修改一下rindex.sh文件\nubuntu@utuntu:~/yapi$ cat rindex.sh #!/bin/bash #git clone https://github.com/Ryan-Miao/docker-yapi.git cd docker-yapi bash build.sh 1.5.10 bash start.sh init-network bash start.sh start-mongo #bash start.sh init-mongo #bash start.sh init-yapi #bash start.sh logs-yapi ubuntu@utuntu:~/yapi$ ./rindex.sh  验证一下, 这个环境可以了.\n docker images: mongo, yapi应该已准备好 docker network: 有 tools-net docker container: 有 mongod  ubuntu@utuntu:~/yapi$ docker images | grep mongo mongo 4 0fb47b43df19 2 weeks ago 411MB ubuntu@utuntu:~/yapi$ docker images | grep yapi yapi 1.5.10 ece770eae458 7 minutes ago 153MB yapi latest ece770eae458 7 minutes ago 153MB ubuntu@utuntu:~/yapi$ docker network ls | grep tools-net 6172fe3cf9c6 tools-net bridge local ubuntu@utuntu:~/yapi$ docker ps | grep mongo 104964ede6a7 mongo:4 \u0026quot;docker-entrypoint.s…\u0026quot; 10 minutes ago Up 10 minutes 0.0.0.0:27017-\u0026gt;27017/tcp mongod ubuntu@utuntu:~/yapi$  启动 yapi\nubuntu@utuntu:~/yapi/docker-yapi$ sudo docker run -d -p 3001:3001 --name yapi --net tools-net --ip 172.18.0.3 yapi 63a6152d324b9f5b5dfda40923cdf35dcf8580bc38090eed4b00ebfdf065a1e5 ubuntu@utuntu:~/yapi/docker-yapi$ sudo docker logs --tail 10 yapi log: 服务已启动，请打开下面链接访问: http://127.0.0.1:3001/ log: mongodb load success... ubuntu@utuntu:~/yapi/docker-yapi$  开启防火墙, 应该就可以访问了.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn/svn-remove-user-name-passwd.html",
	"title": "Svn Remove User Name Passwd",
	"tags": ["svn", "TortoiseSVN"],
	"description": "",
	"content": " TortoiseSVN如何去掉记住的用户名密码\nEnv  svn: 1.9.7 os: win10  Step 直接看 https://jingyan.baidu.com/article/a17d5285cc80cf8099c8f25a.html\nRef  https://jingyan.baidu.com/article/a17d5285cc80cf8099c8f25a.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn/svn-authorization-failed.html",
	"title": "Svn Authorization Failed",
	"tags": ["svn"],
	"description": "",
	"content": " 如何解决svn Authorization failed错误\nEnv  svn: 1.9.7  Step 出现这种问题肯定是\n SVN服务器 清除一下svn的缓存  SVN服务器 SVN服务器出现了问题，需要修改其三个配置文件：\n1、svnserve.conf:\n[general] anon-access = read auth-access = write password-db = passwd authz-db = authz  2、passwd:\n[users] admin=123  3、authz:\n[groups] [/] admin= rw  出现authorization failed异常，一般都是authz文件或者svnserve.conf里，用户组或者用户权限没有配置好，只要设置[/]就可以，代表根目录下所有的资源，如果要限定资源，可以加上 子目录即可。\n清除一下svn的缓存 右击桌面，找到TortoiseSVN下面的Settings，Saved data, Authentication data点击clear\n注意：这里不要全部清除，清除你刚才输入的那个svn地址的缓存，然后确定退出。\nRef  https://blog.csdn.net/qq_26291823/article/details/70846732 https://blog.csdn.net/zhouchenxuan/article/details/71249655  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn/svn-add-projects.html",
	"title": "Svn Add Projects",
	"tags": ["svn"],
	"description": "",
	"content": " svn增加工程\nEnv  os: ubuntu16 svn: 1.9.7  Step 下面以 ValueAddedChain 工程为例\n加工程 [root@vachain ~]# svnadmin create /application/svndata/ValueAddedChain [root@vachain ~]# cd /application/svndata/ [root@vachain svndata]# ls ValueAddedChain [root@vachain svndata]#  改配置 配置交由全局配置文件\n[root@vachain svndata]# pwd /application/svndata/ [root@vachain svndata]# vi ValueAddedChain/conf/  这里面修改的内容是\n[general] anon-access = none auth-access = write password-db = /application/svnpasswd/passwd authz-db = /application/svnpasswd/authz  这里的 password-db, authz-db可以是从其它地方copy过来，后，修改\ncd /application/svndata/sadoc/ cp authz passwd /application/svnpasswd/ cd svnpasswd/  当然，你可以直接把已经配置好的文件，copy过来就行了\n[root@vachain svndata]# cp doc/conf/svnserve.conf ValueAddedChain/conf/ cp: overwrite `ValueAddedChain/conf/svnserve.conf'? y [root@vachain svndata]#  配置完了，要重启 [root@vachain svndata]# netstat -tlpn | grep svn tcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 22584/svnserve [root@vachain svndata]# kill 22584 [root@vachain svndata]# svnserve -d -r /application/svndata/ [root@vachain svndata]# netstat -tlpn | grep svn tcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 22703/svnserve [root@vachain svndata]#  Ref "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn/svn-permission-configuration.html",
	"title": "Svn Permission Configuration",
	"tags": ["svn"],
	"description": "",
	"content": " svn 修改权限\nEnv  os: ubuntu16 svn: 1.9.7 目录： /application/  Step 修改权限文件 authz\n[root@vachain application]# pwd /application [root@vachain application]# vi svnpasswd/authz  配置组及组员\n[groups] # harry_and_sally = harry,sally # harry_sally_and_joe = harry,sally,\u0026amp;joe # [/foo/bar] # harry = rw # \u0026amp;joe = r # * = vachain=zhaoguofen,yangqing,wutao,zengxianwen,gaojunying,liujiansen,liruizhang,huangyanya,aichao admin1=zengyunlong,liuchao,hezhengwen chainexchange=gaojunying chaintrack=zhaoguofen chainvac=yangqing,liujiansen chainpaper=zengxianwen  配置项目的权限(以ripple-1.0为例)\n[ripple-1.0:/] @admin1=rw @vachain=rw liuchao=rw zhouxiaoming=rw liujiansen=rw  配置完了，要重启哟。\n[root@vachain svndata]# netstat -tlpn | grep svn tcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 22584/svnserve [root@vachain svndata]# kill 22584 [root@vachain svndata]# svnserve -d -r /application/svndata/ [root@vachain svndata]# netstat -tlpn | grep svn tcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 22703/svnserve [root@vachain svndata]#  Ref "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-add-format-mount-harddisk.html",
	"title": "Linux Add Format Mount Harddisk",
	"tags": ["linux", "ubuntu"],
	"description": "",
	"content": " 替 Linux 新增硬碟（磁碟分割、格式化與掛載）\n最近要替我的 Linux Server 增加一顆硬碟，一般若是在安裝 Linux 時就將硬碟裝上去的話，就可以直接在安裝時設定好硬碟的格式化與掛載，但若是後來要加掛新的硬碟，就要自己動手設定了。\n這裡示範在 Ubuntu Linux 下面新增加硬碟的做法，首先當然是買一顆新硬碟囉。\nEnv  os: ubuntu16 新硬盘: sdb  Step 查看 root@ubuntu:~# fdisk -l Disk /dev/sda: 111.8 GiB, 120034123776 bytes, 234441648 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 846C81DB-5DB9-4853-94E9-CC1192592FC9 Device Start End Sectors Size Type /dev/sda1 2048 1050623 1048576 512M EFI System /dev/sda2 1050624 2050047 999424 488M Linux filesystem /dev/sda3 2050048 234440703 232390656 110.8G Linux LVM Disk /dev/sdb: 931.5 GiB, 1000204886016 bytes, 1953525168 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: dos Disk identifier: 0x00c57ca5 Device Boot Start End Sectors Size Id Type /dev/sdb1 2048 1953523711 1953521664 931.5G f W95 Ext'd (LBA) /dev/sdb5 4096 629151743 629147648 300G 7 HPFS/NTFS/exFAT /dev/sdb6 629153792 1291855871 662702080 316G 7 HPFS/NTFS/exFAT /dev/sdb7 1291857920 1953523711 661665792 315.5G 7 HPFS/NTFS/exFAT Disk /dev/mapper/ubuntu--vg-root: 109.9 GiB, 117952217088 bytes, 230375424 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/ubuntu--vg-swap_1: 980 MiB, 1027604480 bytes, 2007040 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes root@ubuntu:~# fdisk -l /dev/sdb Disk /dev/sdb: 931.5 GiB, 1000204886016 bytes, 1953525168 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: dos Disk identifier: 0x00c57ca5 Device Boot Start End Sectors Size Id Type /dev/sdb1 2048 1953523711 1953521664 931.5G f W95 Ext'd (LBA) /dev/sdb5 4096 629151743 629147648 300G 7 HPFS/NTFS/exFAT /dev/sdb6 629153792 1291855871 662702080 316G 7 HPFS/NTFS/exFAT /dev/sdb7 1291857920 1953523711 661665792 315.5G 7 HPFS/NTFS/exFAT root@ubuntu:~#  可以看到，这不是全新的，应该是之前有人用过的硬盘，被分过区。\n删除原来的分区 root@ubuntu:~# fdisk /dev/sdb Welcome to fdisk (util-linux 2.27.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/sdb: 931.5 GiB, 1000204886016 bytes, 1953525168 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: dos Disk identifier: 0x00c57ca5 Device Boot Start End Sectors Size Id Type /dev/sdb1 2048 1953523711 1953521664 931.5G f W95 Ext'd (LBA) /dev/sdb5 4096 629151743 629147648 300G 7 HPFS/NTFS/exFAT /dev/sdb6 629153792 1291855871 662702080 316G 7 HPFS/NTFS/exFAT /dev/sdb7 1291857920 1953523711 661665792 315.5G 7 HPFS/NTFS/exFAT Command (m for help): d Partition number (1,5-7, default 7): Partition 7 has been deleted. Command (m for help): d Partition number (1,5,6, default 6): Partition 6 has been deleted. Command (m for help): d Partition number (1,5, default 5): Partition 5 has been deleted. Command (m for help): w The partition table has been altered. qCalling ioctl() to re-read partition table. Syncing disks. root@ubuntu:~# fdisk -l /dev/sdb Disk /dev/sdb: 931.5 GiB, 1000204886016 bytes, 1953525168 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: dos Disk identifier: 0x00c57ca5 Device Boot Start End Sectors Size Id Type /dev/sdb1 2048 1953523711 1953521664 931.5G f W95 Ext'd (LBA) root@ubuntu:~#  好了，已删除，把它当成一块新硬盘吧。\n新建立一个逻辑分区吧 root@ubuntu:~# mkfs -t ext4 /dev/sdb1 mke2fs 1.42.13 (17-May-2015) Found a dos partition table in /dev/sdb1 Proceed anyway? (y,n) y mkfs.ext4: inode_size (128) * inodes_count (0) too big for a filesystem with 0 blocks, specify higher inode_ratio (-i) or lower inode count (-N). root@ubuntu:~# which mkfs.ext4 /sbin/mkfs.ext4 root@ubuntu:~# mkfs.ext4 /dev/sdb1 mke2fs 1.42.13 (17-May-2015) Found a dos partition table in /dev/sdb1 Proceed anyway? (y,n) y mkfs.ext4: inode_size (128) * inodes_count (0) too big for a filesystem with 0 blocks, specify higher inode_ratio (-i) or lower inode count (-N). root@ubuntu:~#  好吧，因为不是逻辑分区，所以，挂载失败了。 新建立一个逻辑分区吧\nroot@ubuntu:~# fdisk /dev/sdb Welcome to fdisk (util-linux 2.27.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n All space for primary partitions is in use. Adding logical partition 5 First sector (4096-1953523711, default 4096): Last sector, +sectors or +size{K,M,G,T,P} (4096-1953523711, default 1953523711): Created a new partition 5 of type 'Linux' and of size 931.5 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. root@ubuntu:~# root@ubuntu:~# fdisk -l /dev/sdb Disk /dev/sdb: 931.5 GiB, 1000204886016 bytes, 1953525168 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: dos Disk identifier: 0x00c57ca5 Device Boot Start End Sectors Size Id Type /dev/sdb1 2048 1953523711 1953521664 931.5G f W95 Ext'd (LBA) /dev/sdb5 4096 1953523711 1953519616 931.5G 83 Linux root@ubuntu:~#  查看一下块信息 root@ubuntu:~# blkid /dev/sda1: UUID=\u0026quot;BED7-5A24\u0026quot; TYPE=\u0026quot;vfat\u0026quot; PARTUUID=\u0026quot;cfc28357-02bf-4471-b8df-a6a6583fdbd3\u0026quot; /dev/sda2: UUID=\u0026quot;2729da44-8e4e-4f0c-ae39-97e2b0feb31e\u0026quot; TYPE=\u0026quot;ext2\u0026quot; PARTUUID=\u0026quot;8f7353d4-83d3-4196-80e9-d0e01fb7ed7f\u0026quot; /dev/sda3: UUID=\u0026quot;7hQ9xw-bLp9-3XSb-ngFg-hCBF-O2vO-djLqei\u0026quot; TYPE=\u0026quot;LVM2_member\u0026quot; PARTUUID=\u0026quot;59163f66-90e5-466d-9d48-b40fe2ee367e\u0026quot; /dev/mapper/ubuntu--vg-root: UUID=\u0026quot;32e5d6dd-a435-48f7-9604-ab426300f93d\u0026quot; TYPE=\u0026quot;ext4\u0026quot; /dev/mapper/ubuntu--vg-swap_1: UUID=\u0026quot;a1551b61-32df-4853-ba8e-55dea76aa580\u0026quot; TYPE=\u0026quot;swap\u0026quot; /dev/sdb5: UUID=\u0026quot;114dc4e0-32e1-4e0c-bcbd-12812e67b5d6\u0026quot; TYPE=\u0026quot;ext4\u0026quot; PARTUUID=\u0026quot;00c57ca5-05\u0026quot; root@ubuntu:~# cat /etc/fstab # /etc/fstab: static file system information. # # Use 'blkid' to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # \u0026lt;file system\u0026gt; \u0026lt;mount point\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; /dev/mapper/ubuntu--vg-root / ext4 errors=remount-ro 0 1 # /boot was on /dev/sda2 during installation UUID=2729da44-8e4e-4f0c-ae39-97e2b0feb31e /boot ext2 defaults 0 2 # /boot/efi was on /dev/sda1 during installation UUID=BED7-5A24 /boot/efi vfat umask=0077 0 1 /dev/mapper/ubuntu--vg-swap_1 none swap sw 0 0 root@ubuntu:~#  mount 注意，mount的写法，block信息写前，mount地址写后。\nroot@ubuntu:~# mount -t ext4 /mnt/sdb/ /dev/sdb5 mount: /mnt/sdb is not a block device root@ubuntu:~# mount -t ext4 /dev/sdb5 /mnt/sdb root@ubuntu:~# ls /mnt/sdb/ lost+found root@ubuntu:~#  确认 root@ubuntu:~# blkid /dev/sda1: UUID=\u0026quot;BED7-5A24\u0026quot; TYPE=\u0026quot;vfat\u0026quot; PARTUUID=\u0026quot;cfc28357-02bf-4471-b8df-a6a6583fdbd3\u0026quot; /dev/sda2: UUID=\u0026quot;2729da44-8e4e-4f0c-ae39-97e2b0feb31e\u0026quot; TYPE=\u0026quot;ext2\u0026quot; PARTUUID=\u0026quot;8f7353d4-83d3-4196-80e9-d0e01fb7ed7f\u0026quot; /dev/sda3: UUID=\u0026quot;7hQ9xw-bLp9-3XSb-ngFg-hCBF-O2vO-djLqei\u0026quot; TYPE=\u0026quot;LVM2_member\u0026quot; PARTUUID=\u0026quot;59163f66-90e5-466d-9d48-b40fe2ee367e\u0026quot; /dev/mapper/ubuntu--vg-root: UUID=\u0026quot;32e5d6dd-a435-48f7-9604-ab426300f93d\u0026quot; TYPE=\u0026quot;ext4\u0026quot; /dev/mapper/ubuntu--vg-swap_1: UUID=\u0026quot;a1551b61-32df-4853-ba8e-55dea76aa580\u0026quot; TYPE=\u0026quot;swap\u0026quot; /dev/sdb5: UUID=\u0026quot;114dc4e0-32e1-4e0c-bcbd-12812e67b5d6\u0026quot; TYPE=\u0026quot;ext4\u0026quot; PARTUUID=\u0026quot;00c57ca5-05\u0026quot; root@ubuntu:~# df -h Filesystem Size Used Avail Use% Mounted on udev 3.9G 0 3.9G 0% /dev tmpfs 788M 18M 771M 3% /run /dev/mapper/ubuntu--vg-root 109G 1.8G 101G 2% / tmpfs 3.9G 0 3.9G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/sda2 473M 66M 384M 15% /boot /dev/sda1 511M 3.4M 508M 1% /boot/efi tmpfs 788M 0 788M 0% /run/user/1000 /dev/sdb5 917G 72M 871G 1% /mnt/sdb root@ubuntu:~#  OK了。 新硬盘已经可以使用了。\nRef  https://blog.gtwang.org/linux/linux-add-format-mount-harddisk/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-install-faq-a.html",
	"title": "Ubuntu Install Faq A",
	"tags": ["ubuntu", "install"],
	"description": "",
	"content": " U盘安装Ubuntu16.04 server版 提示无法挂载cd-rom数据的解决办法\nStep 错误：\n使用类似ultraiso的刻录软件会出现这个错误 Failed to copy files from CD-ROM, retry?\n解决：\n解决的办法是使用win32diskimager制作U盘安装程序，就可以正常安装Ubuntu 16.04 Server。\n下载地址win32diskimager\n文本框用来输入文件完整地址，后面的文件夹图标是浏览窗口，默认只能识别img文件。 只需要将iso文件全路径输入在Image File中。 填好镜像的完整地址后右边有个下拉列表用来选择移动设备，千万别选错了！\n建议只插一个U盘，以免误操作。之后点击Wirte按钮就开始写入。写入后就能够使用U盘安装了。\nRef  http://blog.51cto.com/gentle/1743114 https://blog.csdn.net/w_ww_w/article/details/18219911 https://sourceforge.net/projects/win32diskimager/?source=typ_redirect  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-servername.html",
	"title": "Nginx Servername",
	"tags": ["nginx"],
	"description": "",
	"content": " nginx中servername的作用\nEnv  os: ubuntu16 外网ip: 13.209.68.247 domain name: link.devs1.xsl.ph  Step 当配置了servername后，只能通过 servername 访问被代理URL\n看配置\nroot@ip-172-31-21-164:/etc/nginx/sites-enabled# cat links server{ listen 80; server_name link.devs1.xsl.ph; client_max_body_size 80m; location /spider { proxy_pass http://127.0.0.1:9003/spider; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; } } root@ip-172-31-21-164:/etc/nginx/sites-enabled# /etc/init.d/nginx restart [ ok ] Restarting nginx (via systemctl): nginx.service root@ip-172-31-21-164:/etc/nginx/sites-enabled#  请求\nroot@ip-172-31-21-164:/etc/nginx/sites-enabled# curl link.devs1.xsl.ph/spider/news/hello hello,null.server.port==9003spring.profiles.active==testspring.datasource.url==jdbc:mysql://localhost:3306/link?useUnicode=true\u0026amp;characterEncoding=utf-8 root@ip-172-31-21-164:/etc/nginx/sites-enabled#  但是通过其它都不行。127.0.0.1,localhost,外网IP13.209.68.247都不可以的。都会返回404错误。\nroot@ip-172-31-21-164:/etc/nginx/sites-enabled# curl 13.209.68.247/spider/news/hello \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026quot;white\u0026quot;\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.10.3 (Ubuntu)\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; root@ip-172-31-21-164:/etc/nginx/sites-enabled# curl localhost/spider/news/hello \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026quot;white\u0026quot;\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.10.3 (Ubuntu)\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; root@ip-172-31-21-164:/etc/nginx/sites-enabled# curl 127.0.0.1:80/spider/news/hello \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026quot;white\u0026quot;\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.10.3 (Ubuntu)\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; root@ip-172-31-21-164:/etc/nginx/sites-enabled#  当然，如果想从外网访问，请配置domain name: link.devs1.xsl.ph的DNS管理，把domain name: link.devs1.xsl.ph指向本机的外网IP13.209.68.247。 然后通过浏览器就可以拿到结果了。\nRef "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/life/mastercard-icard-tapngo-registry.html",
	"title": "Mastercard Icard Tapngo Registry",
	"tags": ["icard", "mastercard"],
	"description": "",
	"content": " 注册拍住赏TAP\u0026amp;GO免费获得一张虚拟卡\n原以为拍住赏TAP\u0026amp;GO是一种实体的预付卡，但事实证明我Too young too simple了。原来拍住赏是一种电子钱包，有手机和护照或者港澳通行证就可以使用，这个电子钱包有个功能叫 i.Card，是一张虚拟卡，有卡号，有效日期及cvc2验证码，在线消费时和实体卡一样使用，非常方便。注册成功即可获得一张虚拟卡，甚至不需要充值。\n拍住赏的官方介绍如下\n拍住赏是一种全新付款方式，将手机变成电子钱包。客户只要使用指定的iPhone或Android制式智能手机下载拍住赏手机钱包， 配合商户的MasterCard® 终端机(包括MasterCard® 感应式支付终端机)或拍住赏付款终端机， 便可拍卡或于网上消费。\n你不需要去淘宝买卡，也不需要人肉去香港，你只需要拿出你的手机，下载一个app，在手机上完成以下操作就可以了。\nEnv  iphone  Step 下载App 掏出你的手机，如果是iPhone，打开App Store，搜索 tap \u0026amp; go 注意中间要有空格，如图：\n注册拍住赏帐号 安装这个电子钱包，然后打开，选择 中国（+86），输入你的手机号码，并点“新帐户”进行注册\n拍住赏会发一条短信验证码给你，输入验证码并点”确定”\n然后创建一个密码（一定要记好这个密码），以后都是用这个密码来登录，要查看 i.Card或者进行其他一行重要操作，都需要输入这个密码。\n接下来就要上传身份证明文件，对于大陆的朋友，可以使用护照或者港澳通行证。\n我的护照寄出去办签证了，只好使用港澳通行证。上传了证件以后，拍住赏就注册成功了。\n不用等待资料审核完成，进入主界面，点击侧边栏的 “卡资料” 选项，往下拉选取 “提取 i.Card”，输入密码，就能获取到 Tap\u0026amp;Go 给你分配的虚拟卡号，还有 CVV2验证码、有效日期等信息。\n获得虚拟卡号 在菜单上的”卡资料”这个选项里，可以查看余额，提取你的i.Card虚拟卡号，如图：\n点下面的 Mastercard, 里面就是iCard 信息，需要输入之前注册时的密码。\n如何充值 因为目前卡内无余额，目前暂时还不能做为 Apple ID 付款方式. 所以如果你是这个时候在申请Apple ID,会提示 你的卡 无效。但是不要紧张，充值吧少年。\n充值方式 现在你的钱包里是没有钱的，但是你可以\n 让朋友通过PayBuddy功能转钱给你，PayBuddy功能和支付宝的转帐功能是一样的。 中国银行(香港)在线实时充值 银行转帐 现金 可以是招行一卡通转账、 去香港便利店和 淘宝JS  可以通过以下方法充值，如图：\n可以通过中国银行(香港)在线实时充值，也可以通过银行转帐，现金等方式充值。\n充值示例，不需要的同志可以直接忽略了\n淘宝JS 本穷B选择的是最后一种方式，90rmb -\u0026gt; 100 hkd，算逑，无商不奸，为了自由皆可抛。链接在此, 店主麻烦给我广告费。哈哈哈哈\u0026hellip;.\n淘宝买完后，把手机号码和收款二维码给\u0008老板就可以了。\n如果是英文版本的话，点击 top-up \u0026gt; cash, 把这个 二维码 给老板，他会直接帮你充的。\ntopngo转帐 朋友用拍住赏有段时间了，他的拍住赏里有钱，我让他通过PayBuddy功能转了50港币给我做测试。如图：\n输入收款人的手机号码，接着输入转帐金额，确认以后，钱就转过去了，无手续费。\nRef  https://www.vpsdawanjia.com/489.html https://pi9.me/post/change-appleid-religion-by-tapgo http://www.bochk.com/creditcard/pdf/chi/spec/Clpform.pdf  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/apple/apple-id-register-hongkong.html",
	"title": "Apple Id Register Hongkong",
	"tags": ["apple"],
	"description": "",
	"content": " 因为苹果ios系统升级的原因，之前的注册香港苹果ID的方法不再有效。本教程介绍一种新的注册香港苹果ID的方法。\nEnv  电脑 iphone 香港信用卡虚拟卡  适应人群：不想淘宝买，想拥有属于自己的香港苹果ID的伙伴；需要经常使用非大陆苹果ID下载或者更新相关软件的伙伴。\n注意事项：\n 1）本教程中的手机端完善时需要科学上网，电脑端注册时最好也是科学上网，PC+手机都科学上网可以提高注册成功的概率。 2）本方法相对于以前稍微复杂一些，不一定100%能注册成功 3）本人在实操时，使用的是英文版。  Step 本教程分为三部分：\n 注册拍住赏TAP\u0026amp;GO免费获得一张香港信用卡虚拟卡 电脑端注册账号 退出原有APPLE ID 手机端完善账号  \u0008注册拍住赏TAP\u0026amp;GO免费获得一张香港信用卡虚拟卡 直接参考这里\n电脑端注册账号（最好科学上网） 1，百度苹果官网，点击进入\n2，进入官网后\n3, 下滑到页面最底部，点击右下角【中国】\n4, 选择【HongKong】\n注意，这里必须点击英文Hong Kong, 而不是中文香港。\n5, 申请ID页面\n点击后，会有新页面，https://appleid.apple.com/#!\u0026amp;page=signin ，下滑到最下方，点击Create your Apple ID\n6，资料填写\n这时我们到了 https://appleid.apple.com/account#!\u0026amp;page=create\n7，输入邮箱收到的验证码\n8，输入上面验证码后，页面自动跳到登录页面，输入账号密码，如果能登录表示注册成功。\n退出原有APPLE ID 打开手机，设置 \u0026gt; Apple ID \u0026gt; 退出（sign out)\n手机端完善账号（需要科学上网） 1，手机设置中退出原来apple id之后，打开Apple Store，点击右侧蓝色头像\n2，输入自己在电脑端注册的账号和密码\n3, 点击【检查】\n4, 同意协议，点击下一页\n5，选取先生或者女士，点击下一页\n6，付款方式选择信用卡/记账卡，姓名可以随便编写，街道可以写女人街，电话可以输入默认的号码。当然，你还可以通过百度地图，进入香港，在地图中选择一个地址和电话（区号是852)。如果完之后，点击下一页。\n7，出现下图，表示大功告成，注册成功！\n确认 退出科学上网（只有退出了，才能证明哈），退出网络，连接网络。\n进APP Store可以搜一下\n KMB，能搜出来App1993 - KMB*LWB mytv, 能搜出来myTV或者myTV SUPER  表示你已经拥有了属于自己的香港Apple id了。\nApp Store 如何转换美国商店和中国商店 可能，你会换成其它地区的APP Store, 请登陆相应区的apple id就可以了。\n当然，如果是只有一个apple id,不建议你这么做了。但是，如果说，你一定要这么做， 直接点击这里，第一个回答是你想要的。\nRef  https://appleid.apple.com/ https://www.vpsdawanjia.com/489.html https://pi9.me/post/change-appleid-religion-by-tapgo http://www.bochk.com/creditcard/pdf/chi/spec/Clpform.pdf http://www.imspender.com/articles/shi-ce-you-xiao-shou-cang-ban https://www.zhihu.com/question/20763260  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-swap.html",
	"title": "Linux Swap",
	"tags": ["linux"],
	"description": "",
	"content": " Env  os: linux  Step 有时运行大量的进程后swap大量占用，达到30%的话机器会变得很慢\n可以用以下两个命令清除刷新swap\nswapoff -a swapon -a  这样swap就还原到初始状态\nRef  http://blog.163.com/zhao_jw/blog/static/18058736620121027102932108/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-registry-mirrors-base-ubuntu.html",
	"title": "Docker Registry Mirrors Base Ubuntu",
	"tags": ["docker", "mirrors"],
	"description": "",
	"content": " 如何配置镜像加速器\nEnv  docker: 17.03.2+ os: ubuntu16.04  Step 打开 https://cr.console.aliyun.com/#/imageList 找到 镜像加速器\n可以根据自己OS选择，下面的是ubuntu, registry-mirrors中的内容已失效，请替换成您自己的。\n针对Docker客户端版本大于1.10.0的用户 您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器：\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF' { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://0d6wdn2yzz.mirror.aliyuncs.com\u0026quot;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker  Ref  https://cr.console.aliyun.com/?spm=a2c4e.11153940.blogcont29941.9.520269d6m3p5Xn\u0026amp;accounttraceid=1843b6a4-8ded-4ec5-bdd5-fc17fcffbf8f\u0026amp;accounttraceid=93aba21f-da4b-41b2-ba82-c692f6d5c65f#/accelerator https://cr.console.aliyun.com/#/imageList  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/update-kernel-base-centos.html",
	"title": "Update Kernel Base Centos",
	"tags": ["centos", "kernel"],
	"description": "",
	"content": " 如何在 CentOS 7 中安装或升级最新的内核\n请直接看 https://linux.cn/article-8310-1.html\n下文只是记录\nEnv  os: centos7  Step 虽然有些人使用 Linux 来表示整个操作系统，但要注意的是，严格地来说，Linux 只是个内核。另一方面，发行版是一个完整功能的系统，它建立在内核之上，具有各种各样的应用程序工具和库。\n在正常操作期间，内核负责执行两个重要任务：\n 作为硬件和系统上运行的软件之间的接口。 尽可能高效地管理系统资源。  为此，内核通过内置的驱动程序或以后可作为模块安装的驱动程序与硬件通信。\n例如，当你计算机上运行的程序想要连接到无线网络时，它会将该请求提交给内核，后者又会使用正确的驱动程序连接到网络。\n建议阅读： 如何在 Ubuntu 中升级内核\n随着新的设备和技术定期出来，如果我们想充分利用它们，保持最新的内核就很重要。此外，更新内核将帮助我们利用新的内核函数，并保护自己免受先前版本中发现的漏洞的攻击。\n准备好了在 CentOS 7 或其衍生产品（如 RHEL 7和 Fedora）上更新内核了么？如果是这样，请继续阅读！\n步骤 1：检查已安装的内核版本 让我们安装了一个发行版，它包含了一个特定版本的内核。为了展示当前系统中已安装的版本，我们可以：\n# uname -sr  如果我们现在进入 https://www.kernel.org/，在撰写本文时，我们看到最新的内核版本是4.10.1（其他版本可以从同一网站获得）。\n还要考虑的一个重要的事情是内核版本的生命周期 - 如果你当前使用的版本接近它的生命周期结束，那么在该日期后将不会提供更多的 bug 修复。关于更多信息，请参阅内核发布页。\n步骤 2：在 CentOS 7 中升级内核 大多数现代发行版提供了一种使用 yum 等包管理系统和官方支持的仓库升级内核的方法。\n但是，这只会升级内核到仓库中可用的最新版本 - 而不是在 https://www.kernel.org/ 中可用的最新版本。不幸的是，Red Hat 只允许使用前者升级内核。\n与 Red Hat 不同，CentOS 允许使用 ELRepo，这是一个第三方仓库，可以将内核升级到最新版本。\n要在 CentOS 7 上启用 ELRepo 仓库，请运行：\n# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org # rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm  仓库启用后，你可以使用下面的命令列出可用的内核相关包：\n# yum --disablerepo=\u0026quot;*\u0026quot; --enablerepo=\u0026quot;elrepo-kernel\u0026quot; list available  接下来，安装最新的主线稳定内核：\n# yum --enablerepo=elrepo-kernel install kernel-ml  最后，重启机器并应用最新内核，接着运行下面的命令检查最新内核版本：\nuname -sr  步骤 3：设置 GRUB 默认的内核版本 为了让新安装的内核成为默认启动选项，你需要如下修改 GRUB 配置：\n打开并编辑 /etc/default/grub 并设置 GRUB_DEFAULT=0。意思是 GRUB 初始化页面的第一个内核将作为默认内核。\nGRUB_TIMEOUT=5 GRUB_DEFAULT=0 GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=\u0026quot;console\u0026quot; GRUB_CMDLINE_LINUX=\u0026quot;rd.lvm.lv=centos/root rd.lvm.lv=centos/swap crashkernel=auto rhgb quiet\u0026quot; GRUB_DISABLE_RECOVERY=\u0026quot;true\u0026quot;  接下来运行下面的命令来重新创建内核配置。\n# grub2-mkconfig -o /boot/grub2/grub.cfg  重启并验证最新的内核已作为默认内核。\n恭喜你！你已经在 CentOS 7 中升级内核了！\n总结 在本文中，我们解释了如何轻松升级系统上的 Linux 内核。我们还没讲到另外一个方法，因为它涉及从源代码编译内核，这可以写成一本书，并且不推荐在生产系统上这么做。\n虽然它是最好的学习体验之一，并且允许细粒度配置内核，但是你可能会让你的系统不可用，并且可能必须从头重新安装它。\n如果你仍然有兴趣构建内核作为学习经验，你可以在 Kernel Newbies页面中获得指导。\n一如既往，如果你对本文有任何问题或意见，请随时使用下面的评论栏。\nRef  http://www.tecmint.com/install-upgrade-kernel-version-in-centos-7/ https://linux.cn/article-8310-1.html https://linux.cn/article-8284-1.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/how-to-install-certificates-for-command-line.html",
	"title": "How to Install Certificates for Command Line",
	"tags": ["CA", "ubuntu", "download"],
	"description": "",
	"content": " 当你有一个 CA.crt 文件时，怎么安装它，然后使用呢？我遇到了这个问题。\nEnv  os: ubuntu16 192.168.31.120  Step 尝试直接 apt install\njlch@km:~$ sudo apt install ./CA.crt [sudo] password for jlch: Reading package lists... Done E: Unsupported file ./CA.crt given on commandline jlch@km:~$  不行，那尝试一下\njlch@km:~$ dpkg-query -L ca-certificates /. /etc /etc/ssl /etc/ssl/certs /etc/ca-certificates /etc/ca-certificates/update.d /usr /usr/sbin /usr/sbin/update-ca-certificates /usr/share /usr/share/ca-certificates /usr/share/ca-certificates/mozilla ... # 看到了好多 mozilla 的证书相关信息呀。 /usr/share/ca-certificates/mozilla/DigiCert_Global_Root_CA.crt /usr/share/doc /usr/share/doc/ca-certificates /usr/share/doc/ca-certificates/examples ... # 好多 examples /usr/share/doc/ca-certificates/examples/ca-certificates-local/README /usr/share/doc/ca-certificates/changelog.gz /usr/share/doc/ca-certificates/copyright /usr/share/doc/ca-certificates/README.Debian /usr/share/doc/ca-certificates/NEWS.Debian.gz /usr/share/man /usr/share/man/man8 /usr/share/man/man8/update-ca-certificates.8.gz jlch@km:~$  那查一下 update-ca-certificates\njlch@km:~$ which update-ca-certificates jlch@km:~$ sudo which update-ca-certificates [sudo] password for jlch: /usr/sbin/update-ca-certificates jlch@km:~$  好了, 根据 https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line 来更新吧\njlch@km:~$ cd /usr/sbin/update-ca-certificates jlch@km:/usr/share/ca-certificates/xxnet$ sudo cp /home/jlch/CA.crt . jlch@km:/usr/share/ca-certificates/xxnet$ sudo /usr/sbin/update-ca-certificates Updating certificates in /etc/ssl/certs... 0 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d... done. jlch@km:/usr/share/ca-certificates/xxnet$  好了，CA证书已经更新成功了。\n测试 jlch@km:~$ export http_proxy=http://192.168.31.10:8087 jlch@km:~$ curl -sSL https://dl.k8s.io/release/stable.txt jlch@km:~$  看吧，通过这个 CA.crt 文件，从指定的网站 https://dl.k8s.io/release/stable.txt 下载了这个 stable.txt 文件哟。\nRef  https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/how-to-install-certificates-for-command-line.html",
	"title": "How to Install Certificates for Command Line",
	"tags": ["CA", "ubuntu", "download"],
	"description": "",
	"content": " 当你有一个 CA.crt 文件时，怎么安装它，然后使用呢？我遇到了这个问题。\nEnv  os: ubuntu16 192.168.31.120  Step 尝试直接 apt install\njlch@km:~$ sudo apt install ./CA.crt [sudo] password for jlch: Reading package lists... Done E: Unsupported file ./CA.crt given on commandline jlch@km:~$  不行，那尝试一下\njlch@km:~$ dpkg-query -L ca-certificates /. /etc /etc/ssl /etc/ssl/certs /etc/ca-certificates /etc/ca-certificates/update.d /usr /usr/sbin /usr/sbin/update-ca-certificates /usr/share /usr/share/ca-certificates /usr/share/ca-certificates/mozilla ... # 看到了好多 mozilla 的证书相关信息呀。 /usr/share/ca-certificates/mozilla/DigiCert_Global_Root_CA.crt /usr/share/doc /usr/share/doc/ca-certificates /usr/share/doc/ca-certificates/examples ... # 好多 examples /usr/share/doc/ca-certificates/examples/ca-certificates-local/README /usr/share/doc/ca-certificates/changelog.gz /usr/share/doc/ca-certificates/copyright /usr/share/doc/ca-certificates/README.Debian /usr/share/doc/ca-certificates/NEWS.Debian.gz /usr/share/man /usr/share/man/man8 /usr/share/man/man8/update-ca-certificates.8.gz jlch@km:~$  那查一下 update-ca-certificates\njlch@km:~$ which update-ca-certificates jlch@km:~$ sudo which update-ca-certificates [sudo] password for jlch: /usr/sbin/update-ca-certificates jlch@km:~$  好了, 根据 https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line 来更新吧\njlch@km:~$ cd /usr/sbin/update-ca-certificates jlch@km:/usr/share/ca-certificates/xxnet$ sudo cp /home/jlch/CA.crt . jlch@km:/usr/share/ca-certificates/xxnet$ sudo /usr/sbin/update-ca-certificates Updating certificates in /etc/ssl/certs... 0 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d... done. jlch@km:/usr/share/ca-certificates/xxnet$  好了，CA证书已经更新成功了。\n测试 jlch@km:~$ export http_proxy=http://192.168.31.10:8087 jlch@km:~$ curl -sSL https://dl.k8s.io/release/stable.txt jlch@km:~$  看吧，通过这个 CA.crt 文件，从指定的网站 https://dl.k8s.io/release/stable.txt 下载了这个 stable.txt 文件哟。\nRef  https://askubuntu.com/questions/645818/how-to-install-certificates-for-command-line  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown/convert-rst-to-gfm-document-style.html",
	"title": "Convert Rst to Gfm Document Style",
	"tags": ["rst", "markdown", "gfm", "pandoc"],
	"description": "",
	"content": " RST(reStructuredText) 转换为 MD(Markdown)\nEnv  os: ubuntu16.04 ip: 192.168.31.199  Step 准备\n安装 restbuilder https://pythonhosted.org/sphinxcontrib-restbuilder/\npip install sphinxcontrib-restbuilder  安装 pandoc https://pandoc.org/installing.html https://github.com/jgm/pandoc/releases/latest\n我这里选择二进制安装包\nwget https://github.com/jgm/pandoc/releases/download/2.2.1/pandoc-2.2.1-1-amd64.deb dpkg -i ./pandoc-2.2.1-1-amd64.deb  操作 生成 rst 文件：\nmake -e SPHINXOPTS=\u0026quot;-D language='zh_CN'\u0026quot; rst  转换 rst 到 gfm或markdown 文件, 写成一个脚本。\nroot@ud-b:~# cat convert-doc-style.sh #!/usr/bin/env bash export pandoc=\u0026quot;pandoc +RTS -V0 -RTS\u0026quot; cd $1 FILES=\u0026quot;*.rst\u0026quot; for f in $FILES do filename=\u0026quot;${f%.*}\u0026quot; echo \u0026quot;Converting '$f' to '$filename.md'\u0026quot; $pandoc \u0026quot;$f\u0026quot; -f rst -t gfm -o \u0026quot;$filename.md\u0026quot; #$pandoc \u0026quot;$f\u0026quot; -f rst -t markdown -o \u0026quot;$filename.md\u0026quot; done root@ud-b:~#  Ref  翻译 RST(reStructuredText) 和转换为 MD(Markdown) github/markup https://help.github.com/categories/writing-on-github/ Github Flavored Markdown介绍 附录：轻量级标记语言 GFM(GitHub Flavored Markdown)与标准Markdown的语法区别 文档格式转化神器pandoc  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/update-kernel-base-ubuntu.html",
	"title": "Update Kernel Base Ubuntu",
	"tags": ["ubuntu", "kernel"],
	"description": "",
	"content": " ubuntu16.04 update-kernel\nEnv  os: ubuntu16.04 ip: 192.168.31.118  Step 浏览器打开 http://kernel.ubuntu.com/~kernel-ppa/mainline/\n找到适合的 内核版本（这时v4.12), 进入，\n找到合适的内核文件(linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb)\nwget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.12/linux-image-4.12.0-041200-generic_4.12.0-041200.201707022031_amd64.deb  然后安装就可以了。\nRef  http://kernel.ubuntu.com/~kernel-ppa/mainline/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/security/host-protection.html",
	"title": "Host Protection",
	"tags": ["protection"],
	"description": "",
	"content": " Step 所以啊，主机防护还是很重要的！不要小看了！提供几个方向给大家思考看看吧：\n建立完善的登入密码规则限制； 完善的主机权限设定； 设定自动升级与修补软件漏洞、及移除危险软件； 在每项系统服务的设定当中，强化安全设定的项目； 利用 iptables, TCP_Wrappers 强化网络防火墙； 利用主机监控软件如 MRTG 与 logwatch 来分析主机状况与登录文件；  Ref    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tools/teamviewer-install-base-ubuntu.html",
	"title": "Teamviewer Install Base Ubuntu",
	"tags": ["ubuntu", "teamviewer"],
	"description": "",
	"content": " Ubuntu16.04 安装 Teamviewer\n有时需要远程控制ubuntu系统的电脑，Teamviewer在linux下也可以进行安装，而且Teamviewer远程控制的流畅性一直不错，就选择安装Teamviewer。\nEnv  os: ubuntu16.04 teamviewer: 13.1  Step 下面给出具体的安装步骤：\n首先到 https://www.teamviewer.com/zhcn/download/linux/ 下载相应linux版本的Teamviewer，版主选择的是ubuntu版本，下载完成之后，在你的下载路径中会有软件安装包teamviewer_12.0.85001_i386.deb。\n安装依赖包，ternimal终端进入到下载路径中，执行命令：(博主是64位系统没有执行这个命令也成功，假如是32位的系统则需要执行)\nsudo apt-get install libjpeg62:i386 libxinerama1:i386 libxrandr2:i386 libxtst6:i386 ca-certificates -y  安装deb软件包，执行命令：\nsudo dpkg -i teamviewer_12.0.76279_i386.deb  安装成功之后在dash输入Teamviewer就可以打开了。\n注意：在执行第三步安装deb包的时候，可能会遇到下面的问题：\nwanglaotou@wanglaotou95:~/softwares/software-package$ sudo dpkg -i teamviewer_12.0.85001_i386.deb (正在读取数据库 ... 系统当前共安装有 215790 个文件和目录。) 正准备解包 teamviewer_12.0.85001_i386.deb ... 正在将 teamviewer:i386 (12.0.85001) 解包到 (12.0.85001) 上 ... dpkg: 依赖关系问题使得 teamviewer:i386 的配置工作不能继续： teamviewer:i386 依赖于 libasound2. teamviewer:i386 依赖于 libdbus-1-3. teamviewer:i386 依赖于 libexpat1. teamviewer:i386 依赖于 libfontconfig1. teamviewer:i386 依赖于 libfreetype6. teamviewer:i386 依赖于 libsm6. teamviewer:i386 依赖于 libxdamage1. teamviewer:i386 依赖于 libxfixes3. teamviewer:i386 依赖于 zlib1g. dpkg: 处理软件包 teamviewer:i386 (--install)时出错： 依赖关系问题 - 仍未被配置 正在处理用于 gnome-menus (3.13.3-6ubuntu3.1) 的触发器 ... 正在处理用于 desktop-file-utils (0.22-1ubuntu5.1) 的触发器 ... 正在处理用于 bamfdaemon (0.5.3~bzr0+16.04.20160824-0ubuntu1) 的触发器 ... Rebuilding /usr/share/applications/bamf-2.index... 正在处理用于 mime-support (3.59ubuntu1) 的触发器 ... 正在处理用于 hicolor-icon-theme (0.15-0ubuntu1) 的触发器 ... 在处理时有错误发生： teamviewer:i386  下面这个命令是修复依赖关系（depends）的命令，就是假如你的系统上有某个package不满足依赖条件，这个命令就会自动修复，安装那个package依赖的package.\n这个时候需要执行命令：\nsudo apt-get install -f  选择 ‘Y’，回车等待修复结束后继续执行第三步。\n我的实操\ntom@ud-b:~/Downloads$ sudo dpkg -i teamviewer_13.1.8286_amd64.deb [sudo] password for tom: Selecting previously unselected package teamviewer. (Reading database ... 276613 files and directories currently installed.) Preparing to unpack teamviewer_13.1.8286_amd64.deb ... Unpacking teamviewer (13.1.8286) ... dpkg: dependency problems prevent configuration of teamviewer: teamviewer depends on libqt5x11extras5 (\u0026gt;= 5.2); however: Package libqt5x11extras5 is not installed. teamviewer depends on qtdeclarative5-controls-plugin (\u0026gt;= 5.2) | qml-module-qtquick-controls (\u0026gt;= 5.2); however: Package qtdeclarative5-controls-plugin is not installed. Package qml-module-qtquick-controls is not installed. teamviewer depends on qtdeclarative5-dialogs-plugin (\u0026gt;= 5.2) | qml-module-qtquick-dialogs (\u0026gt;= 5.2); however: Package qtdeclarative5-dialogs-plugin is not installed. Package qml-module-qtquick-dialogs is not installed. dpkg: error processing package teamviewer (--install): dependency problems - leaving unconfigured Processing triggers for bamfdaemon (0.5.3~bzr0+16.04.20180209-0ubuntu1) ... Rebuilding /usr/share/applications/bamf-2.index... Processing triggers for desktop-file-utils (0.22-1ubuntu5.1) ... Processing triggers for gnome-menus (3.13.3-6ubuntu3.1) ... Processing triggers for mime-support (3.59ubuntu1) ... Processing triggers for hicolor-icon-theme (0.15-0ubuntu1) ... Errors were encountered while processing: teamviewer tom@ud-b:~/Downloads$ sudo apt install -f Reading package lists... Done Building dependency tree Reading state information... Done Correcting dependencies... Done The following packages were automatically installed and are no longer required: linux-headers-4.4.0-122 linux-headers-4.4.0-122-generic linux-image-4.4.0-122-generic linux-image-extra-4.4.0-122-generic linux-signed-image-4.4.0-122-generic Use 'sudo apt autoremove' to remove them. The following additional packages will be installed: libqt5x11extras5 qml-module-qtquick-controls qml-module-qtquick-dialogs qml-module-qtquick-privatewidgets qtdeclarative5-controls-plugin qtdeclarative5-dialogs-plugin The following NEW packages will be installed: libqt5x11extras5 qml-module-qtquick-controls qml-module-qtquick-dialogs qml-module-qtquick-privatewidgets qtdeclarative5-controls-plugin qtdeclarative5-dialogs-plugin 0 upgraded, 6 newly installed, 0 to remove and 24 not upgraded. 1 not fully installed or removed. Need to get 787 kB of archives. After this operation, 3,511 kB of additional disk space will be used. Do you want to continue? [Y/n] y Get:1 http://cn.archive.ubuntu.com/ubuntu xenial/universe amd64 libqt5x11extras5 amd64 5.5.1-3build1 [7,876 B] Get:2 http://cn.archive.ubuntu.com/ubuntu xenial/main amd64 qml-module-qtquick-controls amd64 5.5.1-1ubuntu1 [643 kB] Get:3 http://cn.archive.ubuntu.com/ubuntu xenial/universe amd64 qtdeclarative5-controls-plugin all 5.5.1-1ubuntu1 [4,032 B] Get:4 http://cn.archive.ubuntu.com/ubuntu xenial/main amd64 qml-module-qtquick-privatewidgets amd64 5.5.1-1ubuntu1 [38.9 kB] Get:5 http://cn.archive.ubuntu.com/ubuntu xenial/main amd64 qml-module-qtquick-dialogs amd64 5.5.1-1ubuntu1 [89.0 kB] Get:6 http://cn.archive.ubuntu.com/ubuntu xenial/universe amd64 qtdeclarative5-dialogs-plugin amd64 5.5.1-1ubuntu1 [4,044 B] Fetched 787 kB in 2s (362 kB/s) Selecting previously unselected package libqt5x11extras5:amd64. (Reading database ... 276722 files and directories currently installed.) Preparing to unpack .../libqt5x11extras5_5.5.1-3build1_amd64.deb ... Unpacking libqt5x11extras5:amd64 (5.5.1-3build1) ... Selecting previously unselected package qml-module-qtquick-controls:amd64. Preparing to unpack .../qml-module-qtquick-controls_5.5.1-1ubuntu1_amd64.deb ... Unpacking qml-module-qtquick-controls:amd64 (5.5.1-1ubuntu1) ... Selecting previously unselected package qtdeclarative5-controls-plugin. Preparing to unpack .../qtdeclarative5-controls-plugin_5.5.1-1ubuntu1_all.deb ... Unpacking qtdeclarative5-controls-plugin (5.5.1-1ubuntu1) ... Selecting previously unselected package qml-module-qtquick-privatewidgets:amd64. Preparing to unpack .../qml-module-qtquick-privatewidgets_5.5.1-1ubuntu1_amd64.deb ... Unpacking qml-module-qtquick-privatewidgets:amd64 (5.5.1-1ubuntu1) ... Selecting previously unselected package qml-module-qtquick-dialogs:amd64. Preparing to unpack .../qml-module-qtquick-dialogs_5.5.1-1ubuntu1_amd64.deb ... Unpacking qml-module-qtquick-dialogs:amd64 (5.5.1-1ubuntu1) ... Selecting previously unselected package qtdeclarative5-dialogs-plugin:amd64. Preparing to unpack .../qtdeclarative5-dialogs-plugin_5.5.1-1ubuntu1_amd64.deb ... Unpacking qtdeclarative5-dialogs-plugin:amd64 (5.5.1-1ubuntu1) ... Processing triggers for libc-bin (2.23-0ubuntu10) ... Setting up libqt5x11extras5:amd64 (5.5.1-3build1) ... Setting up qml-module-qtquick-controls:amd64 (5.5.1-1ubuntu1) ... Setting up qtdeclarative5-controls-plugin (5.5.1-1ubuntu1) ... Setting up qml-module-qtquick-privatewidgets:amd64 (5.5.1-1ubuntu1) ... Setting up qml-module-qtquick-dialogs:amd64 (5.5.1-1ubuntu1) ... Setting up qtdeclarative5-dialogs-plugin:amd64 (5.5.1-1ubuntu1) ... Setting up teamviewer (13.1.8286) ... Processing triggers for libc-bin (2.23-0ubuntu10) ... tom@ud-b:~/Downloads$ sudo dpkg -i teamviewer_13.1.8286_amd64.deb (Reading database ... 276928 files and directories currently installed.) Preparing to unpack teamviewer_13.1.8286_amd64.deb ... Removed symlink /etc/systemd/system/multi-user.target.wants/teamviewerd.service. Unpacking teamviewer (13.1.8286) over (13.1.8286) ... Setting up teamviewer (13.1.8286) ... Processing triggers for bamfdaemon (0.5.3~bzr0+16.04.20180209-0ubuntu1) ... Rebuilding /usr/share/applications/bamf-2.index... Processing triggers for desktop-file-utils (0.22-1ubuntu5.1) ... Processing triggers for gnome-menus (3.13.3-6ubuntu3.1) ... Processing triggers for mime-support (3.59ubuntu1) ... Processing triggers for hicolor-icon-theme (0.15-0ubuntu1) ... tom@ud-b:~/Downloads$  Ref  https://www.cnblogs.com/wmr95/p/7574615.html https://www.linuxidc.com/Linux/2017-12/149279.htm  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/ddos.html",
	"title": "Ddos",
	"tags": ["resource", "ddos"],
	"description": "",
	"content": " 公司被另一家公司给抄袭了。老板很生气。\nEnv 比特空间 site\n http://www.bitspace.link/ http://bitone.cc/#/  抄袭者 site\n http://www.vac-china.com/ https://vacc.vip/  IP\n 104.18.42.57 47.90.52.55 香港特别行政区 阿里云  Step 为了防止我们被攻击，要做实验了。\nping攻击 无效。\nDDos攻击 zanyarjamal的github 还真有一点干货。\n先用xerxes\nRef  xerxes  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-kill-tty.html",
	"title": "Linux Kill Tty",
	"tags": ["linux", "tty"],
	"description": "",
	"content": " linux 如何杀掉 tty终端\nStep 1、用w -s命令可以得到终端名 root@bitzone:~# w 17:37:05 up 164 days, 1:13, 2 users, load average: 1.47, 0.83, 0.66 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 121.34.147.224 17:36 0.00s 0.02s 0.00s w root pts/2 121.34.147.224 11:58 5:37m 0.04s 0.04s -bash root@bitzone:~# w -s 17:38:38 up 164 days, 1:15, 2 users, load average: 0.65, 0.69, 0.62 USER TTY FROM IDLE WHAT root pts/0 121.34.147.224 2.00s w -s root pts/2 121.34.147.224 5:39m -bash root@bitzone:~#  2、用ps -t 命令可以得到终端的进程号 root@bitzone:~# ps -t /dev/pts/2 PID TTY TIME CMD 14188 pts/2 00:00:00 bash root@bitzone:~#  3、用kill -9命令 可以将进程杀掉，以关闭终端。 s前提：kill命令的执行者必须是超级用户或对tty1的进程有操作权限，否则，命令会报错：Operation not permitted，如：\nroot@bitzone:~# ps -t /dev/pts/2 PID TTY TIME CMD 14188 pts/2 00:00:00 bash root@bitzone:~# kill -9 14188 root@bitzone:~# w 17:39:06 up 164 days, 1:15, 1 user, load average: 0.54, 0.66, 0.61 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 121.34.147.224 17:36 2.00s 0.04s 0.00s w root@bitzone:~#  命令汇总 root@bitzone:~# w 17:37:05 up 164 days, 1:13, 2 users, load average: 1.47, 0.83, 0.66 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 121.34.147.224 17:36 0.00s 0.02s 0.00s w root pts/2 121.34.147.224 11:58 5:37m 0.04s 0.04s -bash root@bitzone:~# w -s 17:38:38 up 164 days, 1:15, 2 users, load average: 0.65, 0.69, 0.62 USER TTY FROM IDLE WHAT root pts/0 121.34.147.224 2.00s w -s root pts/2 121.34.147.224 5:39m -bash root@bitzone:~# ps -t /dev/pts/2 PID TTY TIME CMD 14188 pts/2 00:00:00 bash root@bitzone:~# kill -9 14188 root@bitzone:~# w 17:39:06 up 164 days, 1:15, 1 user, load average: 0.54, 0.66, 0.61 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 121.34.147.224 17:36 2.00s 0.04s 0.00s w root@bitzone:~#  Ref  https://blog.csdn.net/r13929847477/article/details/77979146  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/backup-rancher.html",
	"title": "Backup Rancher",
	"tags": ["rancher"],
	"description": "",
	"content": " Single Node Backup And Restoration\nEnv    Step backup rancher server\nroot@bitzone:~/.tom# docker stop e3655bea211c^C root@bitzone:~/.tom# docker create --volumes-from e3655bea211c --name rancher-backup-v2.0.2 rancher/rancher:v2.0.2 464fd997687abe4cbc43fa39b30f4c246e620b6c33c8f032f32fdafebcd29c61 root@bitzone:~/.tom#  查看所有正在运行容器的hash-id\nroot@bitzone:~/.tom# docker ps -q 2211913af199 3cb7184995a4 5e50622bcc06 9e2549352d17 0287433011b0 2f7f9a341fcb 6b80dcdacaf5 d22d8ef3b283 a321ebd4941c 9c7e75ce47b3 0ea90d1c532f 1aec7af587f1 970a46ba0b57 698b46a9e3fb fc9270fe5d50 d41ae6d7fa22 aab01d4e1556 95d8b9f51555 7a07fd5c94ce a93266250acf 7b5c63b5de0e dfda4227277f 84804443cd2c e3655bea211c root@bitzone:~/.tom#  重启rancher及容器\ndocker start 2211913af199 docker start 3cb7184995a4 docker start 5e50622bcc06 docker start 9e2549352d17 docker start 0287433011b0 docker start 2f7f9a341fcb docker start 6b80dcdacaf5 docker start d22d8ef3b283 docker start a321ebd4941c docker start 9c7e75ce47b3 docker start 0ea90d1c532f docker start 1aec7af587f1 docker start 970a46ba0b57 docker start 698b46a9e3fb docker start fc9270fe5d50 docker start d41ae6d7fa22 docker start aab01d4e1556 docker start 95d8b9f51555 docker start 7a07fd5c94ce docker start a93266250acf docker start 7b5c63b5de0e docker start dfda4227277f docker start 84804443cd2c docker start e3655bea211c  docker 正常运行时\nroot@bitzone:~/.tom# docker ps | wc -l 29 root@bitzone:~/.tom# root@bitzone:~/.tom# netstat tlpn | wc -l 416 root@bitzone:~/.tom# netstat -tlpn | wc -l 29 root@bitzone:~/.tom# netstat -tlpn Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:10248 0.0.0.0:* LISTEN 5587/kubelet tcp 0 0 127.0.0.1:10249 0.0.0.0:* LISTEN 5567/kube-proxy tcp 0 0 127.0.0.1:5001 0.0.0.0:* LISTEN 23113/trackabled tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN 5525/mysqld tcp 0 0 172.31.158.93:56235 0.0.0.0:* LISTEN 23113/trackabled tcp 0 0 0.0.0.0:110 0.0.0.0:* LISTEN 23861/dovecot tcp 0 0 0.0.0.0:143 0.0.0.0:* LISTEN 23861/dovecot tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 9551/apache2 tcp 0 0 127.0.0.1:6001 0.0.0.0:* LISTEN 23113/trackabled tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 940/sshd tcp 0 0 0.0.0.0:25 0.0.0.0:* LISTEN 24447/master tcp 0 0 0.0.0.0:1024 0.0.0.0:* LISTEN 14836/python tcp6 0 0 :::10250 :::* LISTEN 5587/kubelet tcp6 0 0 :::9099 :::* LISTEN 7335/calico-felix tcp6 0 0 :::10251 :::* LISTEN 5483/kube-scheduler tcp6 0 0 :::6443 :::* LISTEN 5420/kube-apiserver tcp6 0 0 :::2379 :::* LISTEN 5446/etcd tcp6 0 0 :::10252 :::* LISTEN 5378/kube-controlle tcp6 0 0 :::2380 :::* LISTEN 5446/etcd tcp6 0 0 :::9900 :::* LISTEN 25464/index.js tcp6 0 0 :::110 :::* LISTEN 23861/dovecot tcp6 0 0 :::143 :::* LISTEN 23861/dovecot tcp6 0 0 :::10256 :::* LISTEN 5567/kube-proxy tcp6 0 0 :::8088 :::* LISTEN 5600/docker-proxy tcp6 0 0 :::25 :::* LISTEN 24447/master tcp6 0 0 :::4443 :::* LISTEN 5619/docker-proxy tcp6 0 0 :::31102 :::* LISTEN 5567/kube-proxy root@bitzone:~/.tom# root@bitzone:~/.tom# docker ps | wc -l 29 root@bitzone:~/.tom# netstat -tlnp | wc -l 29 root@bitzone:~/.tom# ps -ef | wc -l 244 root@bitzone:~/.tom# ps -au | wc -l 11 root@bitzone:~/.tom# ps -ax | wc -l 244 root@bitzone:~/.tom#  现在stop docker\nroot@bitzone:~/.tom# systemctl stop docker root@bitzone:~/.tom# netstat tlpn | wc -l 149 root@bitzone:~/.tom# root@bitzone:~/.tom# netstat -tlpn | wc -l 16 root@bitzone:~/.tom# ps -ax | wc -l 174 root@bitzone:~/.tom# ps -ef | wc -l 174 root@bitzone:~/.tom# docker ps | wc -l Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 0 root@bitzone:~/.tom#  前后看得出，还是开了有很多进程的。\nRef  https://rancher.com/docs/rancher/v2.x/en/installation/backups-and-restoration/single-node-backup-and-restoration/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-pull-with-proxy.html",
	"title": "Docker Pull With Proxy",
	"tags": ["docker", "proxy"],
	"description": "",
	"content": " 透过proxy进行docker pull\nEnv  os: ubuntu16 os: centos  Step  对于Ubuntu 系统  sudo vi /etc/default/docker   对于Centos 系统  sudo vi /etc/sysconfig/docker  把下面的内容加到尾部\nHTTP_PROXY=http://192.168.31.112:8118 http_proxy=${HTTP_PROXY} HTTPS_PROXY=${HTTP_PROXY} https_proxy=${HTTP_PROXY} export HTTP_PROXY HTTPS_PROXY http_proxy https_proxy  重启docker\nsudo systemctl restart docker sudo systemctl status docker  然后再进行相关的 docker pull 操作就可以了。\nRef  https://blog.csdn.net/u011563903/article/details/52161648  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/rancher-single-node-install.html",
	"title": "Rancher Single Node Install",
	"tags": ["rancher", "kubernetes"],
	"description": "",
	"content": " rancher2.0单节点安装kubernetes\nEnv 无论哪个环境\n 硬盘容量\n 空闲 \u0026gt; 20G 空闲 \u0026gt; 20%  有网络\n  Env-1(成功)  cloud: aws os: ubuntu16.04 rancher: v2.0.2 docker: docker-ce=17.03.2~ce-0~ubuntu-xenial post: 8088, 4443  实际上，我是直接把\n ufw: disable  Env-2(没有成功)可略过。 实验环境\n4台vm，配置为2C，4G，100G 一台安装Rancher 一台作为Kubernets cted \u0026amp; control 两台作为Kubernets worker\n os: ubuntu16.04 rancher: v2.0.2  IP  ip: 192.168.31.189 rancher, win10（192.168.31.102）下的virtualbox ip: 192.168.31.188 k8s-etcd, ud-ssd（192.168.31.199）下的virtualbox ip: 192.168.31.187 k8s-worker, ud-ssd（192.168.31.199）下的virtualbox ip: 192.168.31.186 k8s-worker, ud-putong（192.168.31.112）下的virtualbox  后来发现，192.168.31.186-188 ping不通192.168.31.189。(我三台宿主机全用桥接分配到的IP, 怎么会出现这个情况？） 所以，调整IP如下。\n ip: 192.168.31.199 rancher, win10（192.168.31.102）下的virtualbox ip: 192.168.31.199 k8s-etcd, ud-ssd（192.168.31.199） ip: 192.168.31.112 k8s-worker, ud-ssd（192.168.31.199）下的virtualbox ip: 192.168.31.112 k8s-worker, ud-putong（192.168.31.112）下的virtualbox  Env-3(成功)  cloud: 无 os: ubuntu16.04 rancher: v2.0.2 docker: docker-ce=17.03.2~ce-0~ubuntu-xenial post: 8088, 4443 单硬盘，裸机 ip: 192.168.31.199  实际上，我是直接把\n ufw: disable  Step 网络互通 所有节点相互之间连通。\n科学上网 aws下载镜像很快，所以不需要设置。\n参考 透过proxy进行docker pull\nroot@uda:/home/tom# tail /etc/default/docker #export http_proxy=\u0026quot;http://127.0.0.1:3128/\u0026quot; # This is also a handy place to tweak where Docker's temporary files go. #export DOCKER_TMPDIR=\u0026quot;/mnt/bigdrive/docker-tmp\u0026quot; HTTP_PROXY=http://192.168.31.112:8118 http_proxy=${HTTP_PROXY} HTTPS_PROXY=${HTTP_PROXY} https_proxy=${HTTP_PROXY} export HTTP_PROXY HTTPS_PROXY http_proxy https_proxy root@uda:/home/tom#  所有节点都安装了docker mkdir .tom cd .tom/ vi docker.sh chmod +x docker.sh ./docker.sh  \u0008具体 docker.sh 内容见下方。\nroot@ripple01:~# cat .tom/docker.sh #!/bin/bash lsb_release -a sudo apt-get install apt-transport-https ca-certificates curl software-properties-common -y curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-key fingerprint 0EBFCD88 sudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026quot; sudo apt-get update apt-cache madison docker-ce sudo apt-get install docker-ce=17.03.2~ce-0~ubuntu-xenial -y sudo docker run hello-world root@ripple01:~#  准备基础镜像 这里只是为了加快安装速度，如果你觉得速度没问题，可跳过\n当然，如果是rancher版本不是2.0.2，而是其它，这里肯定有些镜像的版本就不是这个了。\n所以，如果不是安装2.0.2, 则不要提前准备下面镜像（因为版本不一定是这些嘛），让系统自动下载，只是时间久一点。\nrancher-server节点 docker pull nginx:latest docker pull rancher/rancher-agent:v2.0.2 docker pull rancher/rancher:v2.0.2 docker pull rancher/rke-tools:v0.1.8 docker pull rancher/rancher-agent:v2.0.0 docker pull rancher/rancher:v2.0.0 docker pull rancher/hyperkube:v1.10.1-rancher2 docker pull rancher/rke-tools:v0.1.4 docker pull rancher/nginx-ingress-controller:0.10.2-rancher3 docker pull rancher/calico-node:v3.1.1 docker pull rancher/calico-cni:v3.1.1 docker pull hello-world:latest docker pull rancher/coreos-etcd:v3.1.12 docker pull rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8 docker pull rancher/k8s-dns-sidecar-amd64:1.14.8 docker pull rancher/k8s-dns-kube-dns-amd64:1.14.8 docker pull rancher/pause-amd64:3.1 docker pull rancher/coreos-flannel:v0.9.1 docker pull rancher/nginx-ingress-controller-defaultbackend:1.4 docker pull rancher/cluster-proportional-autoscaler-amd64:1.0.0  如果不想安装这么多，那就至少把rancher server安装ectd, worker之前的镜像（下面这些）安装完吧。\ndocker pull nginx:latest docker pull rancher/hyperkube:v1.10.1-rancher2 docker pull rancher/coreos-etcd:v3.1.12 docker pull rancher/rancher:v2.0.2 docker pull rancher/rancher-agent:v2.0.2 docker pull rancher/rke-tools:v0.1.8  如果是racher2.0.0则准备把相应镜像的版本号替换下，成下面基础镜像\ndocker pull nginx:latest docker pull rancher/hyperkube:v1.10.1-rancher2 docker pull rancher/coreos-etcd:v3.1.12 docker pull rancher/rancher:v2.0.0 docker pull rancher/rancher-agent:v2.0.0 docker pull rancher/rke-tools:v0.1.4  worker节点 docker pull nginx:latest docker pull rancher/rancher-agent:v2.0.2 docker pull rancher/pause-amd64:3.1 docker pull rancher/rke-tools:v0.1.8 docker pull rancher/hyperkube:v1.10.1-rancher2  运行rancher-server节点 docker run -d --restart=unless-stopped \\ -p 80:80 -p 443:443 \\ -v /host/rancher:/var/lib/rancher \\ rancher/rancher:v2.0.2  示例如下\nroot@bogon:~# docker run -d --restart=unless-stopped -p 80:80 -p 443:443 -v /host/rancher:/var/lib/rancher rancher/rancher:v2.0.2 3aa4d8b39e61a178840196dcd8e05031a0cef56dbcc56b6a72117b7316d19918 root@bogon:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3aa4d8b39e61 rancher/rancher:v2.0.2 \u0026quot;rancher --http-li...\u0026quot; 3 seconds ago Up 2 seconds 0.0.0.0:80-\u0026gt;80/tcp, 0.0.0.0:443-\u0026gt;443/tcp distracted_stallman root@bogon:~# sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.0.2 --server https://192.168.31.104 --token qt6xd2jg4mvx4qs94q8bqlfdqcdgr6p794cwzj5vhld2l62ds6l9lw --ca-checksum 1d2d1038b6e78cd0c4925bd5931629e6e6e0d9c97699cdbabe9eb59448154f85 --etcd --controlplane --worker Unable to find image 'rancher/rancher-agent:v2.0.2' locally v2.0.2: Pulling from rancher/rancher-agent a48c500ed24e: Already exists 1e1de00ff7e1: Already exists 0330ca45a200: Already exists 471db38bcfbf: Already exists 0b4aba487617: Already exists b0300e97030b: Downloading [========\u0026gt; ] 2.87 MB/17.59 MB 64b8ae7ae0d5: Download complete 73facef3793d: Downloading [=============\u0026gt; ] 3.521 MB/12.97 MB 649b24d0dfef: Downloading [=================\u0026gt; ] 3.8 MB/10.86 MB  浏览器设置 设置密码，拿到docker命令\nrancher-server, etcd, control, worker节点运行container 注意：\n 这里，每个人的 IP, port, token, 启动项目类型不同，\u0008\u0008以浏览器内容为准，不要复制下面的。 如果后续要加work, 记得不要再启动 etcd, controlplane  基本流程就是这样了。\n命令汇总 下面可以看一下，我自己的实际操作的命令汇总吧。\n在 aws 环境下，成功安装了rancher，命令汇总如下\n查看一下基本信息，知道的，可以忽略 sudo -i ufw status which docker lsb_release -a top cat /proc/cpuinfo df -h  安装docker mkdir .tom cd .tom/ vi docker.sh chmod +x docker.sh ./docker.sh  安装准备镜像 docker pull nginx:latest docker pull rancher/hyperkube:v1.10.1-rancher2 docker pull rancher/coreos-etcd:v3.1.12 docker pull rancher/rancher:v2.0.2 docker pull rancher/rancher-agent:v2.0.2 docker pull rancher/rke-tools:v0.1.8 ## 如果不安装v2.0.0\u0008则不需要下面2行 # docker pull rancher/rancher:v2.0.0 # docker pull rancher/rke-tools:v0.1.4  备注：\n这个操作是只有这么几个镜像？实际上应该如下面这样的。但是，aws网络实在是好，其它的，都它自己下载了。\ndocker pull nginx:latest docker pull rancher/rancher-agent:v2.0.2 docker pull rancher/rancher:v2.0.2 docker pull rancher/rke-tools:v0.1.8 docker pull rancher/rancher-agent:v2.0.0 docker pull rancher/rancher:v2.0.0 docker pull rancher/hyperkube:v1.10.1-rancher2 docker pull rancher/rke-tools:v0.1.4 docker pull rancher/nginx-ingress-controller:0.10.2-rancher3 docker pull rancher/calico-node:v3.1.1 docker pull rancher/calico-cni:v3.1.1 docker pull hello-world:latest docker pull rancher/coreos-etcd:v3.1.12 docker pull rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8 docker pull rancher/k8s-dns-sidecar-amd64:1.14.8 docker pull rancher/k8s-dns-kube-dns-amd64:1.14.8 docker pull rancher/pause-amd64:3.1 docker pull rancher/coreos-flannel:v0.9.1 docker pull rancher/nginx-ingress-controller-defaultbackend:1.4 docker pull rancher/cluster-proportional-autoscaler-amd64:1.0.0  启动rancher-server 把rancher-server持久化到本机 /host/rancher。\n注意设置port\ndocker run -d --restart=unless-stopped -p 8088:80 -p 4443:443 -v /host/rancher:/var/lib/rancher rancher/rancher:v2.0.2 docker ps  打开浏览器 设置admin密码，并拿到docker命令\n启动，etcd，controlplane，worker 注意：\n 这里，每个人的 IP, port, token, 启动项目类型不同，\u0008\u0008以浏览器内容为准，不要复制下面的。 如果后续要加work, 记得不要再启动 etcd, controlplane  docker images sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.0.2 --server https://yourIP:4443 --token d82dc2g4qbhvxwssm95sf6mtl2plxgk4jmmx4xnj6zd2thsnjt9sq9 --ca-checksum c160ff8a67d540af15c3cf7299e65a81b99f476b9e06526d39ada649afbd1f67 --etcd --controlplane --worker docker ps  回浏览器查看\n cluster状态: Active node状态: Active node下的Disk Space，Disk Pressure，Memory Pressure，Kubelet：绿色，打勾 cluster下Launch kubectl正常可打开，且，运行kubectl get all返回正常  至此，就知道了,所有成功了,完成了。\nFAQ cni config uninitialized Q: Env-2环境下，这个时候，会出现 https://github.com/rancher/rancher/issues/13484 的报错信息 A: 这个问题，因为在Env-1(aws)环境下，没有出现，也就意味着，很可能是网络下载环节出了问题（可能是下载cni相关镜像出错了，比如网络连接中断） \u0008\ndocker images Q: 准备阶段，为什么是那些镜像呢？\nA: 我这里主要是依据，在 aws 成功安装rancher server 并启动一个kubernetes后, 通过查看 docker images 得到。\nroot@ripple01:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest cd5239a0906a 12 days ago 109 MB rancher/rancher-agent v2.0.2 df087865517d 3 weeks ago 228 MB rancher/rancher v2.0.2 88526c7bea4e 3 weeks ago 521 MB rancher/rke-tools v0.1.8 5df9ccc4e588 4 weeks ago 136 MB rancher/rancher-agent v2.0.0 8cfec7659f1d 6 weeks ago 248 MB rancher/rancher v2.0.0 3141e5c66ee8 6 weeks ago 535 MB rancher/hyperkube v1.10.1-rancher2 3e3f2ccada54 7 weeks ago 967 MB rancher/rke-tools v0.1.4 d1a7302844b3 7 weeks ago 56.9 MB rancher/nginx-ingress-controller 0.10.2-rancher3 66e10c24a484 7 weeks ago 203 MB rancher/calico-node v3.1.1 d94b64ac210d 8 weeks ago 248 MB rancher/calico-cni v3.1.1 482f47df27e2 8 weeks ago 68.8 MB hello-world latest e38bc07ac18e 2 months ago 1.85 kB rancher/coreos-etcd v3.1.12 02f30926cd60 3 months ago 34.8 MB rancher/k8s-dns-dnsmasq-nanny-amd64 1.14.8 c2ce1ffb51ed 5 months ago 41 MB rancher/k8s-dns-sidecar-amd64 1.14.8 6f7f2dc7fab5 5 months ago 42.2 MB rancher/k8s-dns-kube-dns-amd64 1.14.8 80cc5ea4b547 5 months ago 50.5 MB rancher/pause-amd64 3.1 da86e6ba6ca1 5 months ago 742 kB rancher/coreos-flannel v0.9.1 2b736d06ca4c 7 months ago 51.3 MB rancher/nginx-ingress-controller-defaultbackend 1.4 846921f0fe0e 7 months ago 4.84 MB rancher/cluster-proportional-autoscaler-amd64 1.0.0 e183460c484d 19 months ago 48.2 MB root@ripple01:~#  可知，我们真正要下载的images 有 下面这些images\ndocker pull nginx:latest docker pull rancher/rancher-agent:v2.0.2 docker pull rancher/rancher:v2.0.2 docker pull rancher/rke-tools:v0.1.8 docker pull rancher/rancher-agent:v2.0.0 docker pull rancher/rancher:v2.0.0 docker pull rancher/hyperkube:v1.10.1-rancher2 docker pull rancher/rke-tools:v0.1.4 docker pull rancher/nginx-ingress-controller:0.10.2-rancher3 docker pull rancher/calico-node:v3.1.1 docker pull rancher/calico-cni:v3.1.1 docker pull hello-world:latest docker pull rancher/coreos-etcd:v3.1.12 docker pull rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8 docker pull rancher/k8s-dns-sidecar-amd64:1.14.8 docker pull rancher/k8s-dns-kube-dns-amd64:1.14.8 docker pull rancher/pause-amd64:3.1 docker pull rancher/coreos-flannel:v0.9.1 docker pull rancher/nginx-ingress-controller-defaultbackend:1.4 docker pull rancher/cluster-proportional-autoscaler-amd64:1.0.0  当然，如果是rancher版本不是2.0.2，而是其它，这里肯定有些镜像的版本就不是这个了。\n所以，如果不是安装2.0.2, 则，不提前准备镜像，让系统，自动下载，只是时间久一点。\n安装完成后 Q: 安装完成v2.0.2后，安装etcd, controlplane, worker, 共下载多少镜像？共启动多少container?\nA: 看下面\nroot@ud-b:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE rancher/rancher-agent v2.0.2 df087865517d 3 weeks ago 228 MB rancher/rancher v2.0.2 88526c7bea4e 3 weeks ago 521 MB rancher/rke-tools v0.1.8 5df9ccc4e588 4 weeks ago 136 MB rancher/hyperkube v1.10.1-rancher2 3e3f2ccada54 7 weeks ago 967 MB rancher/nginx-ingress-controller 0.10.2-rancher3 66e10c24a484 7 weeks ago 203 MB rancher/calico-node v3.1.1 d94b64ac210d 2 months ago 248 MB rancher/calico-cni v3.1.1 482f47df27e2 2 months ago 68.8 MB rancher/coreos-etcd v3.1.12 02f30926cd60 3 months ago 34.8 MB rancher/k8s-dns-dnsmasq-nanny-amd64 1.14.8 c2ce1ffb51ed 5 months ago 41 MB rancher/k8s-dns-sidecar-amd64 1.14.8 6f7f2dc7fab5 5 months ago 42.2 MB rancher/k8s-dns-kube-dns-amd64 1.14.8 80cc5ea4b547 5 months ago 50.5 MB rancher/pause-amd64 3.1 da86e6ba6ca1 6 months ago 742 kB rancher/coreos-flannel v0.9.1 2b736d06ca4c 7 months ago 51.3 MB rancher/nginx-ingress-controller-defaultbackend 1.4 846921f0fe0e 7 months ago 4.84 MB rancher/cluster-proportional-autoscaler-amd64 1.0.0 e183460c484d 19 months ago 48.2 MB root@ud-b:~# docker images | wc -l 16 root@ud-b:~# docker ps | wc -l 26 root@ud-b:~#  所以，共下载16个镜像，启动26个容器。\nkubectl get pods \u0026ndash;all-namespaces Q: 为什么kubectl get pods --all-namespaces中的ingress-nginx是CrashLoopBackOff状态，具体如下？\n# Run kubectl commands inside here # e.g. kubectl get all \u0026gt; kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE cattle-system cattle-cluster-agent-8d7c4cf9b-7f6jb 1/1 Running 1 4h cattle-system cattle-node-agent-r29z4 1/1 Running 0 4h ingress-nginx default-http-backend-564b9b6c5b-4k2x6 1/1 Running 0 4h ingress-nginx nginx-ingress-controller-jlcbt 0/1 CrashLoopBackOff 60 4h kube-system canal-2k7qn 3/3 Running 0 4h kube-system kube-dns-5ccb66df65-d8qrb 3/3 Running 0 4h kube-system kube-dns-autoscaler-6c4b786f5-xj7nj 1/1 Running 0 4h \u0026gt;  A: 这个谁知道的？求留言。\nnode出现Disk Pressure Q: 出现Disk Pressure, 是什么问题？\nA: 硬盘空间不\u0008够。最少要有20G或者总硬盘空间的20%。\n我有一次就是在\u0008硬盘空间这里卡住了，导致没有继续往下安装。\n安装时可以使用加速器么？ Q: 安装时可以使用加速器么？\nA: 可以使用，且建议使用。\n具体如何使用，可以参考 https://yq.aliyun.com/articles/29941\n删除rancher Q: 如何删除rancher?\nA: 其实就是删除所有相关容器，那么直接参考高人的sh就行了。\nroot@uda:~# cat clean-up.sh #!/bin/sh docker rm -f $(docker ps -qa) docker volume rm $(docker volume ls -q) cleanupdirs=\u0026quot;/var/lib/etcd /etc/kubernetes /etc/cni /opt/cni /var/lib/cni /var/run/calico\u0026quot; for dir in $cleanupdirs; do echo \u0026quot;Removing $dir\u0026quot; rm -rf $dir done root@uda:~#  运行上面这个clean-up.sh\n如果要连rancher的持久化数据也删除，则把当时创建的持久化数据文件 /host/rancher/也删除吧。\nRef  https://github.com/rancher/rancher/issues/13484 https://gist.github.com/superseb/2cf186726807a012af59a027cb41270d https://rancher.com/docs/rancher/v2.x/en/quick-start-guide/ https://rancher.com/docs/rancher/v2.x/en/installation/single-node-install/ https://yq.aliyun.com/articles/29941 https://www.cnblogs.com/xzkzzz/p/9106218.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown/markdown-comments.html",
	"title": "Markdown Comments",
	"tags": ["markdown"],
	"description": "",
	"content": " 概述 下面是我整理的在Markdown中写注释的几种方法，供自己开发时参考，相信对其他人也有用。\nStep html标签 既然Markdown内嵌html语法，那么就可以用可以用隐藏的html标签。\n注意：需要在前面空一行\n\u0026lt;div style='display: none'\u0026gt; 哈哈我是注释，不会在浏览器中显示。 我也是注释。 \u0026lt;/div\u0026gt;  html注释 既然支持html语法，那也支持html注释。\n\u0026lt;!--哈哈我是注释，不会在浏览器中显示。--\u0026gt; \u0026lt;!-- 哈哈我是多段 注释， 不会在浏览器中显示。 --\u0026gt;  hack方法 hack方法就是利用markdown的解析原理来实现注释的。\n一般有的markdown解析器不支持上面的注释方法，这个时候就可以用hack方法。\nhack方法比上面2种方法稳定得多，但是语义化太差。\n[comment]: \u0026lt;\u0026gt; (哈哈我是注释，不会在浏览器中显示。) [comment]: \u0026lt;\u0026gt; (哈哈我是注释，不会在浏览器中显示。) [comment]: \u0026lt;\u0026gt; (哈哈我是注释，不会在浏览器中显示。) [//]: \u0026lt;\u0026gt; (哈哈我是注释，不会在浏览器中显示。) [//]: # (哈哈我是注释，不会在浏览器中显示。)  其中，这种方法最稳定，适用性最强：\n[//]: # (哈哈我是注释，不会在浏览器中显示。)  这种最可爱，超级无敌萌啊：\n[^_^]: # (哈哈我是注释，不会在浏览器中显示。)  更为关键的是，这种方法最强，支持多行注释，\n[^_^]: commentted-out contents should be shift to right by four spaces (`\u0026gt;\u0026gt;`).  示例测试 1.html标签（你如果看不到下面的注释说明已经成功注释）\n2.html注释（你如果看不到下面的注释说明已经成功注释）\n3.hack注释（你如果看不到下面的注释说明已经成功注释）\nRef  https://www.jianshu.com/p/9be87e7e15bf http://www.cnblogs.com/yangzhou33/p/8438461.html https://stackoverflow.com/questions/4823468/comments-in-markdown  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/static-ip-ubuntu18.html",
	"title": "Static Ip Ubuntu18",
	"tags": ["ubuntu", "ip"],
	"description": "",
	"content": " ubuntu18设置固态IP\nEnv  os: ubuntu18  Step ubuntu16 ubuntu16是在/etc/network/interfaces 文件中设置固态IP 设置的方式类似下面\nsource /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface auto ens160 #iface ens160 inet dhcp iface ens160 inet static address 192.168.31.120 gateway 192.168.31.1 #这个地址你要确认下 网关是不是这个地址 netmask 255.255.255.0 network 192.168.31.0 broadcast 192.168.31.255 dns-nameservers 202.96.134.133  ubuntu17及以上 但是，ubuntu17起，改成了etc/netplan/*.yaml来配置。\n配置方式类似下面\ntom@tom:~$ cat /etc/netplan/50-cloud-init.yaml # This file is generated from information provided by # the datasource. Changes to it will not persist across an instance. # To disable cloud-init's network configuration capabilities, write a file # /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following: # network: {config: disabled} network: version: 2 ethernets: enp0s3: dhcp4: no dhcp6: no addresses: [192.168.31.103/24, '2001:1::2/64'] gateway4: 192.168.31.1 nameservers: addresses: [192.168.31.1] tom@tom:~$  配置完成后，运行\nsudo netplan apply  此时，固态IP配置完成。\nRef  https://websiteforstudents.com/configuring-static-ips-ubuntu-17-10-servers/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/php/php-install-base-ubuntu.html",
	"title": "Php Install Base Ubuntu",
	"tags": ["ubuntu", "php"],
	"description": "",
	"content": " Env  os: ubuntu  Step sudo apt-get install -y language-pack-en-base sudo LC_ALL=en_US.UTF-8 add-apt-repository ppa:ondrej/php sudo add-apt-repository ppa:ondrej/php sudo apt-get update sudo apt search php5 # 这个地方，会返回具体的版本号，不同的时间可能返回不同，比如20180616返回的是5.6，所以安装php5.6而不是php5.5 sudo apt-get install php5.6-common sudo apt-get install libapache2-mod-php5.6  Ref  https://www.zhihu.com/question/45999546/answer/100165171  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-command-not-found.html",
	"title": "Ubuntu Command Not Found",
	"tags": ["ubuntu"],
	"description": "",
	"content": " add-apt-repository: command not found When I run:\nsudo add-apt-repository ppa:ubuntu-wine/ppa  Log here:\nsudo: add-apt-repository: command not found  solved I tried to run:\nsudo apt-get install software-properties-common  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/google-chrome-setup.html",
	"title": "Google Chrome Setup",
	"tags": ["google", "chrome"],
	"description": "",
	"content": " 通过这个小小的设置，能让我的mac不再那么热，不再那么响，说明优化chrome是一件值得做的事情。\n11 Chrome Settings You Should Change Now! 看视频吧\n 设置已不存在。 打开chrome://flags/ Show Saved Copy Button,选择Enabled:Primary Parallel downloading设置成 Enabled 设置已不存在。 设置已不存在。 Omnibox UI Show Suggestion Favicons,设置成Enabled Automatic tab discarding，设置成Enabled Tab audio muting UI control =》 Disabled, 无需修改 Fast tab/window close =》 Disabled, 无需修改 Scroll Anchoring，设置成Enabled  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/google-chrome-helper.html",
	"title": "Google Chrome Helper",
	"tags": ["google", "chrome"],
	"description": "",
	"content": " google chrome helper占用超多CPU资源\nEnv  os: mac  看视频的同学要先做到科学上网\nStep 2014年前的chrome 如果能看视频的朋友，点这里\n有一篇文章提过这个问题，这里面提到的解决方案如下\nFirst, shut down all your Chrome windows without quitting the program. In the Chrome menu, go to “Preferences,” scroll all the way down in the menu, and click on “Show advanced settings…” The first item in the expanded advanced settings list will be “Privacy,” and click on the “Content Settings” button right under that. About halfway down the content settings list is a “Plug-ins” entry, which will likely be set to “Run automatically.” Instead, select “Click to play.”  2017年后的chrome 但是，现在这个Plug-ins已经不在这个位置了，所以，现在不知道怎么去禁用google chrome helper了。\n所以，我现在还是每发现一次就直接找到对应的进程，kill掉。\nRef  https://www.wired.com/2014/10/google-chrome-helper/ https://www.youtube.com/watch?v=jD7y4R6VNXU  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/charts.html",
	"title": "Charts",
	"tags": ["charts"],
	"description": "",
	"content": " tradingview，一个免费股票，数字货币图表网站 tradingview-cn  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git-faq-a.html",
	"title": "Git Faq A",
	"tags": ["git"],
	"description": "",
	"content": " git 报错 Updates were rejected because the tip of your current branch is behind\nEnv ➜ public git:(master) git push -u origin master To bitbucket.org:tomtsang/blog_tomtsang_hugo_html.git ! [rejected] master -\u0026gt; master (non-fast-forward) error: failed to push some refs to 'git@bitbucket.org:tomtsang/blog_tomtsang_hugo_html.git' hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.  Step 查看大部分资料，只有这个有用\nhttp://www.cnblogs.com/xwdreamer/archive/2012/05/29/2523958.html\n勾选强制覆盖已有的分支（可能会丢失改动），再点击上传，上传成功。\n只有这句是核心，所以，本人就略微想了一下\ngit push -u origin master -f\n至此，搞定问题\n➜ public git:(master) git push -u origin master -f Counting objects: 1832, done. Delta compression using up to 4 threads. Compressing objects: 100% (891/891), done. Writing objects: 100% (1832/1832), 1.58 MiB | 7.23 MiB/s, done. Total 1832 (delta 868), reused 723 (delta 283) remote: Resolving deltas: 100% (868/868), done. To bitbucket.org:tomtsang/blog_tomtsang_hugo_html.git + c0059fb...1eb30ee master -\u0026gt; master (forced update) Branch 'master' set up to track remote branch 'master' from 'origin'. ➜ public git:(master)  Ref  https://blog.csdn.net/shiren1118/article/details/7761203  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/iterm2-hotkey.html",
	"title": "Iterm2 Hotkey",
	"tags": ["iterm2", "hotkey"],
	"description": "",
	"content": " Env  os: macOS  Content 标签 新建标签：command + t 关闭标签：command + w 切换标签：command + 数字 command + 左右方向键 切换全屏：command + enter 查找：command + f  分屏 垂直分屏：command + d 水平分屏：command + shift + d 切换屏幕：command + option + 方向键 command + [ 或 command + ] 查看历史命令：command + ; 查看剪贴板历史：command + shift + h  其他 清除当前行：ctrl + u 到行首：ctrl + a 到行尾：ctrl + e 前进后退：ctrl + f/b (相当于左右方向键) 上一条命令：ctrl + p 搜索命令历史：ctrl + r 删除当前光标的字符：ctrl + d 删除光标之前的字符：ctrl + h 删除光标之前的单词：ctrl + w 删除到文本末尾：ctrl + k 交换光标处文本：ctrl + t 清屏1：command + r 清屏2：ctrl + l  自带有哪些很实用的功能/快捷键 ⌘ + 数字在各 tab 标签直接来回切换 选择即复制 + 鼠标中键粘贴，这个很实用 ⌘ + f 所查找的内容会被自动复制 ⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏 ⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏 ctrl + u 清空当前行，无论光标在什么位置 输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令 ⌘ + shift + h 会列出剪切板历史 可以在 Preferences \u0026gt; keys 设置全局快捷键调出 iterm，这个也可以用过 Alfred 实现  常用的一些快捷键 ⌘ + 1 / 2 左右 tab 之间来回切换，这个在 前面 已经介绍过了 ⌘← / ⌘→ 到一行命令最左边/最右边 ，这个功能同 C+a / C+e ⌥← / ⌥→ 按单词前移/后移，相当与 C+f / C+b，其实这个功能在Iterm中已经预定义好了，⌥f / ⌥b，看个人习惯了 好像就这几个 设置方法如下 当然除了这些可以自定义的也不能忘了 linux 下那些好用的组合 C+a / C+e 这个几乎在哪都可以使用 C+p / !! 上一条命令 C+k 从光标处删至命令行尾 (本来 C+u 是删至命令行首，但iterm中是删掉整行) C+w A+d 从光标处删至字首/尾 C+h C+d 删掉光标前后的自负 C+y 粘贴至光标后 C+r 搜索命令历史，这个较常用  选中即复制 iterm2 有 2 种好用的选中即复制模式。\n 一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。  另一种是无鼠标模式，command+f,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之后，输入 tab，查找窗口将自动变化内容，并将其复制。如果输入的是 shift+tab，则自动将查找内容的左边选中并复制。\n自动完成 输入打头几个字母，然后输入 command+; iterm2 将自动列出之前输入过的类似命令。   剪切历史 输入 command+shift+h，iterm2 将自动列出剪切板的历史记录。如果需要将剪切板的历史记录保存到磁盘，在 Preferences \u0026gt; General \u0026gt; Save copy/paste history to disk 中设置。\n设置快捷键 这一步很简单，定位到 [Preferences - Keys - Hotkey]，这里有两个选项 - 第一个为设置全局快捷键，在 iTerm 启动的前提下，使用该快捷键（比如，这里我设置为F12）可显示或隐藏窗口。 - 第二个指定新窗口使用哪个 Profile，这里就指定为在 Step1 中设置了 WIndow 的那个即可，勾选这个选项能获得显示／隐藏窗口时淡入淡出的技能。\nRef  https://cnbin.github.io/blog/2015/06/20/iterm2-kuai-jie-jian-da-quan/ https://blog.csdn.net/thinkdiff/article/details/25075047  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/blockchain/learn-blockchain.html",
	"title": "Blockchain",
	"tags": ["blockchain", "learn"],
	"description": "",
	"content": " 记录我的blockchain学习过程\n区块链浏览器  区块链学习笔记-如何使用区块链浏览器 三分钟了解区块链浏览器 区块链浏览器是什么？  常识  浏览器都可以挖矿  实操 未操作  fabric中简单搭建区块链浏览器  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-install-pip-with-get-pip-py.html",
	"title": "Python Install Pip With Get Pip Py",
	"tags": ["python", "install", "pip"],
	"description": "",
	"content": " 通过 get-pip.py 安装 pip\nEnv  os: ubuntu16  Step curl https://bootstrap.pypa.io/get-pip.py | sudo python  Ref  https://pip.pypa.io/en/stable/installing/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-faq-openssl.html",
	"title": "Python Faq Openssl",
	"tags": ["linux", "python", "openssl", "faq"],
	"description": "",
	"content": " Env  os: ubuntu16  出错 /alg -Iscrypt-1.2.1/libcperciva/util -Iscrypt-1.2.1/libcperciva/crypto -I/usr/local/include -I/usr/include -I/usr/include/python2.7 -c scrypt-1.2.1/libcperciva/crypto/crypto_aes.c -o build/temp.linux-x86_64-2.7/scrypt-1.2.1/libcperciva/crypto/crypto_aes.o -O2 scrypt-1.2.1/libcperciva/crypto/crypto_aes.c:6:25: fatal error: openssl/aes.h: No such file or directory compilation terminated. error: command 'x86_64-linux-gnu-gcc' failed with exit status 1 ---------------------------------------- Command \u0026quot;/usr/bin/python -u -c \u0026quot;import setuptools, tokenize;__file__='/tmp/pip-install-qN0XHo/scrypt/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\u0026quot; install --record /tmp/pip-record-8LxwEK/install-record.txt --single-version-externally-managed --compile\u0026quot; failed with error code 1 in /tmp/pip-install-qN0XHo/scrypt/ root@ip-172-31-23-102:/home/ubuntu/rpc#  Step 看错误。这里看的错误，不应该是error: command 'x86_64-linux-gnu-gcc' failed with exit status 1,而应该是fatal error: openssl/aes.h: No such file or directory。（之前就是犯了这个错误，而弄错了查错方向）\n如果你在编译时遇到这个错误，这可能是下面的原因：你尝试编译的程序使用OpenSSL，但是需要和OpenSSL链接的文件（库和头文件）在你Linux平台上缺少。（译注：其它类似的错误也可以照此处理）\n要解决这个问题，你需要安装OpenSSL 开发包，这在所有的现代Linux发行版的标准软件仓库中都有。\n要在Debian、Ubuntu或者其他衍生版上安装OpenSSL：\nsudo apt-get install libssl-dev  要在Fedora、CentOS或者RHEL上安装OpenSSL开发包：\nsudo yum install openssl-devel  安装完后，尝试重新编译程序。\nRef  Linux 有问必答：如何修复“fatal error: openssl/aes.h: No such file or directory http://ask.xmodulo.com/fix-fatal-error-openssl.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/java/tomcat-install-base-ubuntu.html",
	"title": "Tomcat Install Base Ubuntu",
	"tags": ["ubuntu", "install", "tomcat"],
	"description": "",
	"content": " Env  os: ubuntu16 java:  root@ip-172-31-28-68:/home/ubuntu/java/sotre_app# java -version openjdk version \u0026quot;1.8.0_171\u0026quot; OpenJDK Runtime Environment (build 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11) OpenJDK 64-Bit Server VM (build 25.171-b11, mixed mode) root@ip-172-31-28-68:/home/ubuntu/java/sotre_app#  nodejs: v8.11.2 tomcat: apache-tomcat-8.5.31 java-jre: openjdk-8-jdk  Step wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.31/bin/apache-tomcat-8.5.31.tar.gz ls tar zxvf apache-tomcat-8.5.31.tar.gz sudo mv apache-tomcat-8.5.31 /opt/ sudo ln -s /opt/apache-tomcat-8.5.31/ /opt/tomcat8 /opt/tomcat8/bin/startup.sh curl http://127.0.0.1:8080/  Ref  https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.31/bin/ https://www.cnblogs.com/EasonJim/p/7202844.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-config-server_name.html",
	"title": "Nginx Config Server_name",
	"tags": ["nginx", "godaddy", "DNS"],
	"description": "",
	"content": " nginx 配合 godaddy 完成 3级域名\n原理：godaddy, 配置3级域名解析，转到nginx配置中的 server_name\nEnv  os: ubuntu16 nginx: nginx/1.10.3 (Ubuntu) 2级域名: bitzone.space 3级域名: store1.bitzone.space godaddy  Step 配置nginx 在 nginx 的 sites-enabled 中配置\nroot@ip-172-31-28-68:~# cat sites-enabled/store1 server { listen 80; server_name store1.bitzone.space; client_max_body_size 80m; location / { index index.html; root /home/ubuntu/html/code_commit_vac_competition/APP; #root /home/dev/completition/code_commit_competition/code_commit_competition_food_blockChainCheck; } }  配置godaddy 打开相应地址(2级域名: bitzone.space)的DNS管理\n增加\nA\tstore1\t52.78.79.111\t600 秒  确认 浏览器访问http://store1.bitzone.space/index.html 就访问到了 http://52.78.79.111:80 , 根据nginx配置就知道， 拿到了 52.78.79.111:/home/ubuntu/html/code_commit_vac_competition/APP/index.html这里的资源\n新加记录 同理，我们可以增加 store2, 成 http://store2.bitzone.space/index.html\nnginx\nroot@ip-172-31-28-68:~# cat sites-enabled/store2 server { listen 80; server_name store2.bitzone.space; client_max_body_size 80m; location / { index index.html; root /home/ubuntu/html/code_commit_vac_competition/competitionA; } } root@ip-172-31-28-68:~#  godaddy 增加\nA\tstore2\t52.78.79.111\t600 秒  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-rar-unrar.html",
	"title": "Mac Rar Unrar",
	"tags": ["mac", "rar"],
	"description": "",
	"content": " Mac上rar文件命令解压和压缩\nEnv  os: macOS  Step rar和unrar命令需要自己安装\n可以直接通过brew安装，如果不清楚brew安装命令，可以查看《mac上安装类似 apt-get 的软件包管理器 \u0026ndash; Homebrew》\n下面说下另外一种简单安装方式\n1.下载mac上对应rar版本\nhttp://www.rarlab.com/download.htm\n2.利用tar名解压下载的rarosx-5.4.0.tar.gz，版本可能会更新\ntar xzvf arosx-5.4.0.tar.gz . #解压到当前目录  3.安装rar和unrar命令\nsudo install -c -o $USER rar /usr/local/bin/ ＃安装rar sudo install -c -o $USER unrar /usr/local/bin ＃安装unrar  如果安装失败可以看看/usr/local/bin 目录是不是存在rar或unrar的软链接\n4.利用rar和unrar压缩和解压文件\nrar和unrar文件的参数也很多，就不在一一介绍了，直接在Ternimal执行对应命令就能看到所有参数选项，下面列举几个常用的\n解压文件：unrar x test.rar 压缩文件A和B：rar a 压缩后.rar A B\nRef  http://www.rarlab.com/download.htm https://blog.csdn.net/yin1031468524/article/details/68955194?locationNum=12\u0026amp;fps=1  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-iterm2-ohmyzsh-install.html",
	"title": "Mac Iterm2 Ohmyzsh Install",
	"tags": ["mac", "iterm2", "zsh"],
	"description": "",
	"content": " Mac下如何安装iTerm2并使用zsh iTerm2\nEnv  os: macOS  Step 安装iterm2 安装iterm2只需要下载，解压安装就可以了。\n安装zsh 方式1 brew install zsh zsh-completions  无brew的请先安装Homebrew，mac上的一个包管理工具，很有必要安装，省去安装软件的麻烦。\n方式2 直接上官网查看安装方式\nzsh --version  配置zsh 创建一个zsh的配置文件 注意:如果你已经有一个~/.zshrc文件的话，建议你先做备份。使用以下命令\ncp ~/.zshrc ~/.zshrc.orig  然后开始创建zsh的配置文件\ncp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc  设置zsh为你的默认的shell chsh -s /bin/zsh  然后退出iterm2，再重启就ok。\n期间报的问题不要管直接按照步骤来就行了。\nRef  http://www.jianshu.com/p/77a4349bf67b https://blog.csdn.net/sufubo/article/details/54988457  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/network-proxy-shadowsocks-server.html",
	"title": "Network Proxy Shadowsocks Server",
	"tags": ["network", "proxy", "shadowssocks"],
	"description": "",
	"content": " Env  cloud: aws os: ubuntu16 ip: 美国IP  Ref 直接看下面文章就可以了 - https://github.com/flyzy2005/ss-fly - https://www.flyzy2005.com/fan-qiang/shadowsocks/install-shadowsocks-in-one-command/#shadowsocks\nStep git clone https://github.com/Flyzy2005/ss-fly ss-fly/ss-fly.sh -i password 1024 ping www.youtube.com  修改配置文件：vim /etc/shadowsocks.json 停止ss服务：ssserver -c /etc/shadowsocks.json -d stop 启动ss服务：ssserver -c /etc/shadowsocks.json -d start 重启ss服务：ssserver -c /etc/shadowsocks.json -d restart  卸载ss服务\nss-fly/ss-fly.sh -uninstall  Article 注意：在特殊时期，一般是大会期间，即使是设置好了 SS,但是还是不能科学上网。 比如，我就遇到了一次，在 上合组织峰会第十八次峰会-青岛峰会（2018年6月9日到10日）之后的，2018-06-11号，就出现了（大佬们，有没有哪位，和我类似）情况：\n 美国IP 不能科学上网 香港IP 能科学上网  还有一种可能性，IP段中的其他同志的IP搞歪东西，把我\u0008给扯到了。 GXB直接封的IP段，这个时候，IP段中的新机器也不行。\n一键脚本搭建SS/搭建SSR服务并开启BBR加速\nRef  https://blog.csdn.net/ZhangAdo/article/details/50663527 https://blog.csdn.net/f59130/article/details/74014415 https://blog.csdn.net/amoscn/article/details/79364599  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-shadowsock-server.html",
	"title": "Ubuntu Network Proxy Shadowsocks Server",
	"tags": ["network", "proxy", "shadowssocks"],
	"description": "",
	"content": " Env  os: ubuntu16 ip: 192.168.168.137  Ref cd sudo pip install shadowsocks which sslocal sudo vi /etc/shadowsocks.json sslocal -c /etc/shadowsocks.json start sslocal -c /etc/shadowsocks.json sslocal -c /etc/shadowsocks.json -d start vi /usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py sslocal -c /etc/shadowsocks.json -d start sslocal -c /etc/shadowsocks.json -d stop sslocal -c /etc/shadowsocks.json -d start netstat -tlpnu vi /etc/shadowsocks.json cat /etc/shadowsocks.json sslocal -c /etc/shadowsocks.json -d stop sslocal -c /etc/shadowsocks.json -d start sudo vim /etc/systemd/system/shadowsocks.service sudo systemctl enable /etc/systemd/system/shadowsocks.service  但是,发现,这个 shadowssocks.service 并不生效,\nubuntu@utuntu:~$ sudo systemctl status shadowsocks ● shadowsocks.service - Shadowsocks Client Service Loaded: loaded (/etc/systemd/system/shadowsocks.service; enabled; vendor preset: enabled) Active: inactive (dead) since Thu 2019-06-13 15:34:15 CST; 4min 19s ago Process: 15037 ExecStart=/usr/local/bin/sslocal -c /etc/shadowsocks.json -d start (code=exited, status=0/SUCCESS) Main PID: 15037 (code=exited, status=0/SUCCESS) Jun 13 15:34:15 utuntu systemd[1]: Started Shadowsocks Client Service. Jun 13 15:34:15 utuntu sslocal[15037]: INFO: loading config from /etc/shadowsocks.json Jun 13 15:34:15 utuntu sslocal[15037]: 2019-06-13 15:34:15 INFO loading libcrypto from libcrypto.so.1.1 ubuntu@utuntu:~$  而且,只能通过root用户,运行\nroot@utuntu:/home/ubuntu# /usr/bin/python /usr/local/bin/sslocal -c /etc/shadowsocks.json -d start  才能成功.这个是为什么呢? 是shadowsocks.service文件写得不对吗?\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/macos-apple-id-america.html",
	"title": "Macos Apple Id America",
	"tags": ["mac", "apple"],
	"description": "",
	"content": " 申请美国apple id\nEnv  os: macOS cloud: aws  Step Ref  https://zhuanlan.zhihu.com/p/36574047 https://www.zhihu.com/question/20422874/answer/413390698 https://blog.csdn.net/amoscn/article/details/79364599 https://zhuanlan.zhihu.com/p/33150135  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-install-software.html",
	"title": "Mac Install Software",
	"tags": ["tom", "mac"],
	"description": "",
	"content": " 记录mac-pro安装软件\n安装截图 安装  git (直接输入git version) 这个时候，会自动安装Xcode的组件，请保持网络稳定且快速。 搜狗五笔拼音 homebrew [telnet]() brew install telnet Visual Studio Code hugo  这个时候，你需要的是科学上网\n shadowsocks chrome(美国版)，这里一定不要是google.cn下载的中文版。  无需科学上网\n [百度网盘](https://pan.baidu.com/download#pan） iterm2, 下载，解压，安装就行了，不是brew安装的 oh my zsh安装 RARLAB-osx用于解压rar文件  设置 \u0008\u0008mac输入法切换快捷键设置\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/network-proxy-win10.html",
	"title": "Network Proxy Win10",
	"tags": ["network", "proxy", "windows"],
	"description": "",
	"content": " 通过win10实现FQ\nEnv  os: win10  Step 先配置Shadowsocks privoxy or not 方法1 不配置 privoxy 其实可以不配置privoxy,而使得socks5生效。\n具体步骤如下：\n配置的过程中，可以通过一个pac 文件过滤url,这个地方，怎么设置的呢？看下图\n方法2 配置 privoxy "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/aws/aws-get-access-key-secret-key.html",
	"title": "Aws Get Access Key Secret Key",
	"tags": ["aws"],
	"description": "",
	"content": " 教你如何找到AWS Access Key ID and Secret Access Key\nEnv  aws  Step 按照 教你如何找到AWS Access Key ID and Secret Access Key 完成 1-5\nStep 1. Visit the Amazon Web Services web console. Step 2. Click My Account/Console at the top right corner of the web page. In this case User Name is Alexander. Step 3. In the drop-down list click the “Security Credentials” option. Step 4. Then you will be redirected to the “Your Security Credentials” page and see the following pop-up window: Step 5. Click on the “Access Keys (Access Key ID and Secret Access Key)” to extend the list of keys.  然后 点击 Create New Access Key, 然后弹框后一定要看完内容，然后 Download 到本地，这个文件中就是你想要的 Access Key ID 和 Secret Access Key。\n 一定要下载 一定要下载 一定要下载  Ref  https://www.multcloud.com/tutorials/s3-key.html http://blog.iyunker.com/%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0aws-access-key-id-and-secret-access-key/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/realtek-shengyin.html",
	"title": "Realtek Shengyin",
	"tags": ["realtek"],
	"description": "",
	"content": " Realtek高清晰音频管理器使耳机能听到声音\nenv  os: win10  step 总以为是声卡类驱动没有安装成功，哈哈！～～\n直接看图操作吧\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/rancher2-install-base-aws-ubuntu.html",
	"title": "Rancher2 Install Base Aws Ubuntu",
	"tags": ["rancher", "install", "aws", "ubuntu"],
	"description": "",
	"content": " aws中ubuntu安装rancher2.0\nEnv Env-a  cloud: aws os: ubuntu 16.04 docker: 17.03.2-ce  Env-b  cloud: aws os: Amazon Linux AMI 2018.03 docker: 17.12.1-ce  这里的env-b可以不看, 因为效果与env-a相同\nRancher versions:\nrancher/server or rancher/rancher: rancher/server 2.0.2\n**Docker version: 17.03.2-ce\n**Operating system and kernel:\n ubuntu 16.04 Linux ip-172-31-12-229 4.4.0-1060-aws #69-Ubuntu SMP Sun May 20 13:42:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux  **Type/provider of hosts: AWS\n**Setup details: single node rancher\n**Environment Template: Kubernetes\nSteps to Reproduce:\nsudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher docker logs e95 -f  Results:\nenv-a报错情况 root@ip-172-31-12-229:/home/ubuntu# docker logs e95 -f 2018/06/06 11:45:16 [INFO] Listening on /tmp/log.sock 2018/06/06 11:45:16 [INFO] [certificates] Generating CA kubernetes certificates 2018/06/06 11:45:17 [INFO] [certificates] Generating Kubernetes API server certificates *** *** *** 2018/06/06 11:45:32 [INFO] uploading digitaloceanConfig to node schema 2018/06/06 11:45:32 [INFO] uploading vmwarevsphereConfig to node schema 2018/06/06 11:45:32 [INFO] uploading vmwarevsphereConfig to node schema E0606 11:45:38.982324 1 core.go:70] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail. E0606 11:45:39.156222 1 certificates.go:48] Failed to start certificate controller: error reading CA cert file \u0026quot;/etc/kubernetes/ca/ca.pem\u0026quot;: open /etc/kubernetes/ca/ca.pem: no such file or directory 2018/06/06 11:45:54 [INFO] traversing files and generating templates 2018/06/06 11:45:54 [INFO] Updating catalog library 2018/06/06 11:45:54 [INFO] Creating template library-prometheus 2018/06/06 11:45:55 [INFO] Creating template library-redis 2018/06/06 11:45:55 [INFO] Creating template library-longhorn 2018/06/06 11:45:55 [INFO] Creating template library-memcached 2018/06/06 11:45:55 [INFO] Creating template library-mongodb-replicaset 2018/06/06 11:45:55 [INFO] Creating template library-mysql 2018/06/06 11:45:55 [INFO] Creating template library-mariadb 2018/06/06 11:45:55 [INFO] Creating template library-mongodb 2018/06/06 11:45:55 [INFO] Creating template library-wordpress 2018/06/06 11:45:55 [INFO] Creating template library-nfs-provisioner 2018/06/06 11:45:55 [INFO] Creating template library-etcd-operator 2018/06/06 11:45:55 [INFO] Creating template library-grafana 2018/06/06 11:45:55 [INFO] Creating template library-magento 2018-06-06 11:55:19.631773 I | mvcc: store.index: compact 1198 2018-06-06 11:55:19.633173 I | mvcc: finished scheduled compaction at 1198 (took 920.507µs) *** *** 2018/06/06 23:45:31 [INFO] Running cluster events cleanup 2018/06/06 23:45:31 [INFO] Done running cluster events cleanup 2018-06-06 23:50:20.099819 I | mvcc: store.index: compact 65618 2018-06-06 23:50:20.100893 I | mvcc: finished scheduled compaction at 65618 (took 633.146µs) 2018-06-06 23:55:20.103352 I | mvcc: store.index: compact 66068 2018-06-06 23:55:20.104455 I | mvcc: finished scheduled compaction at 66068 (took 698.482µs) 2018-06-07 00:00:20.107535 I | mvcc: store.index: compact 66519 2018-06-07 00:00:20.108586 I | mvcc: finished scheduled compaction at 66519 (took 648.45µs) 2018-06-07 00:05:20.112088 I | mvcc: store.index: compact 66970 2018-06-07 00:05:20.113204 I | mvcc: finished scheduled compaction at 66970 (took 721.359µs) 2018-06-07 00:10:20.115164 I | mvcc: store.index: compact 67419 2018-06-07 00:10:20.116207 I | mvcc: finished scheduled compaction at 67419 (took 697.953µs) 2018-06-07 00:15:20.118671 I | mvcc: store.index: compact 67870 2018-06-07 00:15:20.119770 I | mvcc: finished scheduled compaction at 67870 (took 696.612µs) 2018-06-07 00:20:20.121399 I | mvcc: store.index: compact 68321 2018-06-07 00:20:20.122572 I | mvcc: finished scheduled compaction at 68321 (took 694.312µs) 2018-06-07 00:25:20.125420 I | mvcc: store.index: compact 68771 2018-06-07 00:25:20.127133 I | mvcc: finished scheduled compaction at 68771 (took 1.167633ms) 2018-06-07 00:30:20.129448 I | mvcc: store.index: compact 69220 2018-06-07 00:30:20.130575 I | mvcc: finished scheduled compaction at 69220 (took 676.794µs) 2018-06-07 00:35:20.132825 I | mvcc: store.index: compact 69671 2018-06-07 00:35:20.133879 I | mvcc: finished scheduled compaction at 69671 (took 642.16µs) 2018-06-07 00:40:20.136230 I | mvcc: store.index: compact 70122 2018-06-07 00:40:20.137384 I | mvcc: finished scheduled compaction at 70122 (took 740.249µs) 2018-06-07 00:45:20.139217 I | mvcc: store.index: compact 70573 2018-06-07 00:45:20.140354 I | mvcc: finished scheduled compaction at 70573 (took 732.96µs) 2018/06/07 00:45:31 [INFO] Running cluster events cleanup 2018/06/07 00:45:31 [INFO] Done running cluster events cleanup  env-b报错情况 [root@ip-172-31-32-161 ec2-user]# docker logs 626 -f E0606 07:39:56.323409 1 garbagecollector.go:113] failed to sync all monitors: [couldn't look up resource {\u0026quot;management.cattle.io\u0026quot; \u0026quot;v3\u0026quot; \u0026quot;nodes\u0026quot;}: no matches for {management.cattle.io v3 nodes}, couldn't look up resource {\u0026quot;management.cattle.io\u0026quot; \u0026quot;v3\u0026quot; \u0026quot;globalroles\u0026quot;}: no matches for {management.cattle.io v3 globalroles}, couldn't look up resource {\u0026quot;management.cattle.io\u0026quot; \u0026quot;v3\u0026quot; \u0026quot;groupmembers\u0026quot;}: no matches for {management.cattle.io v3 groupmembers}, couldn't look up resource {\u0026quot;management.cattle.io\u0026quot; \u0026quot;v3\u0026quot; \u0026quot;listenconfigs\u0026quot;}: no matches for {management.cattle.io v3 listenconfigs}, couldn't look up resource {\u0026quot;management.cattle.io\u0026quot; \u0026quot;v3\u0026quot; \u0026quot;groups\u0026quot;}: no matches for {management.cattle.io v3 groups}] E0606 07:40:01.279595 1 streamwatcher.go:109] Unable to decode an event from the watch stream: json: cannot unmarshal string into Go struct field dynamicEvent.Object of type v3.ProjectStatus E0606 07:40:01.280050 1 streamwatcher.go:109] Unable to decode an event from the watch stream: json: cannot unmarshal string into Go struct field dynamicEvent.Object of type v3.NodeDriverStatus E0606 07:40:01.281077 1 streamwatcher.go:109] Unable to decode an event from the watch stream: json: cannot unmarshal string into Go struct field dynamicEvent.Object of type v3.DynamicSchemaStatus E0606 07:40:01.283896 1 streamwatcher.go:109] Unable to decode an event from the watch stream: json: cannot unmarshal string into Go struct field dynamicEvent.Object of type v3.SourceCodeCredentialStatus E0606 07:48:06.259413 1 streamwatcher.go:109] Unable to decode an event from the watch stream: json: cannot unmarshal string into Go struct field dynamicEvent.Object of type v3.ClusterPipelineStatus 2018-06-06 07:49:49.076333 I | mvcc: store.index: compact 1198 2018-06-06 07:49:49.077697 I | mvcc: finished scheduled compaction at 1198 (took 892.715µs) 2018-06-06 07:54:49.079381 I | mvcc: store.index: compact 1650 2018-06-06 07:54:49.080456 I | mvcc: finished scheduled compaction at 1650 (took 622.642µs) 2018-06-06 07:57:51.244337 N | pkg/osutil: received terminated signal, shutting down... 2018/06/06 07:57:51 [INFO] Shutting down ProjectRoleTemplateBindingController controller 2018/06/06 07:57:51 [INFO] Shutting down ClusterRoleTemplateBindingController controller 2018/06/06 07:57:51 [INFO] Shutting down UserController controller 2018/06/06 07:57:51 [INFO] Shutting down NodeController controller 2018/06/06 07:57:51 [INFO] Shutting down NodeController controller 2018/06/06 07:57:51 [INFO] Shutting down ClusterController controller 2018/06/06 07:57:51 [INFO] Shutting down SecretController controller 2018/06/06 07:57:51 [INFO] Shutting down ClusterRegistrationTokenController controller 2018/06/06 07:57:51 [FATAL] context canceled 2018/06/06 07:57:51 [ERROR] server on [::]:443 returned err: accept tcp [::]:443: use of closed network connection tail: cannot open ‘25’ for reading: No such file or directory  Step 这里的输出，目前好像是不影响rancher server的使用。\n但是，请在 aws中打开 443端口（只打开80是不够的，最后还是会转向443）。\n当时，我就是没有把443端口打开，导致，一直怀疑是下面几个方面：\n 配置了vpc docker版本过高  事后看，与这些怀疑点无关。\nRef  YouTube的Creating a Rancher 2.0-alpha Server in AWS EC2 https://rancher.com/docs/rancher/v2.x/en/quick-start-guide/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/mount-ntfs-base-centos.html",
	"title": "Mount Ntfs Base Centos",
	"tags": ["centos", "mount"],
	"description": "",
	"content": " centos挂载ntfs硬盘\nEnv  os: centos6.9  当前状态\n[root@bitspace ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk ├─sda1 8:1 0 220G 0 part ├─sda2 8:2 0 238G 0 part ├─sda3 8:3 0 237G 0 part └─sda4 8:4 0 236.5G 0 part sdb 8:16 0 111.8G 0 disk ├─sdb1 8:17 0 500M 0 part /boot └─sdb2 8:18 0 111.3G 0 part ├─vg_bitspace-lv_root (dm-0) 253:0 0 50G 0 lvm / ├─vg_bitspace-lv_swap (dm-1) 253:1 0 7.7G 0 lvm [SWAP] └─vg_bitspace-lv_home (dm-2) 253:2 0 53.6G 0 lvm /home [root@bitspace ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/vg_bitspace-lv_root 50G 3.1G 44G 7% / tmpfs 3.8G 0 3.8G 0% /dev/shm /dev/sdb1 477M 41M 411M 9% /boot /dev/mapper/vg_bitspace-lv_home 53G 53M 50G 1% /home [root@bitspace ~]# fdisk -l WARNING: GPT (GUID Partition Table) detected on '/dev/sda'! The util fdisk doesn't support GPT. Use GNU Parted. Disk /dev/sda: 1000.2 GB, 1000204886016 bytes 256 heads, 63 sectors/track, 121126 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk identifier: 0x0f544158 Device Boot Start End Blocks Id System /dev/sda1 1 266306 2147483647+ ee GPT Partition 1 does not start on physical sector boundary. Disk /dev/sdb: 120.0 GB, 120034123776 bytes 255 heads, 63 sectors/track, 14593 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x0bd932d6 Device Boot Start End Blocks Id System /dev/sdb1 * 1 64 512000 83 Linux Partition 1 does not end on cylinder boundary. /dev/sdb2 64 14594 116707328 8e Linux LVM Disk /dev/mapper/vg_bitspace-lv_root: 53.7 GB, 53687091200 bytes 255 heads, 63 sectors/track, 6527 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 Disk /dev/mapper/vg_bitspace-lv_swap: 8271 MB, 8271167488 bytes 255 heads, 63 sectors/track, 1005 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 Disk /dev/mapper/vg_bitspace-lv_home: 57.5 GB, 57545850880 bytes 255 heads, 63 sectors/track, 6996 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x00000000 [root@bitspace ~]#  Step [root@bitspace ~]# mount /dev/sda1 /mnt/sda1 mount: unknown filesystem type 'ntfs' [root@bitspace ~]# mount -t ntfs /dev/sda1 /mnt/sda1 mount: unknown filesystem type 'ntfs'  没有mount.ntfs类型啊\n注意：mount是一个root命令，归属于/sbin/mount*而不是/bin/mount*\n[root@bitspace ~]# which mount /bin/mount [root@bitspace ~]# ls /sbin/moun* /sbin/mount.cifs /sbin/mount.nfs /sbin/mount.nfs4 /sbin/mount.tmpfs [root@bitspace ~]#  说明没有相关的mount类型呀\n[root@bitspace ntfs-3g_ntfsprogs-2017.3.23]# mount -t ntfs /dev/sda1 /mnt/sda1 mount: unknown filesystem type 'ntfs'  没成功\n解决办法：\n通过使用 ntfs-3g 来解决。 打开ntfs-3g的下载点http://www.tuxera.com/community/ntfs-3g-download/ ，将最新稳定(当前最新版本为ntfs-3g_ntfsprogs-2017.3.23）下载到CentOS，执行以下命令安装：\n编译安装 ntfs-3g # tar zxvf ntfs-3g_ntfsprogs-2017.3.23.tgz # cd ntfs-3g_ntfsprogs-2017.3.23 #./configure # make # make install  在网上找了，方法一样安上 还是不能挂载，最后在官方站 找到方法了，如下：\nmount -t ntfs-3g /dev/sda5 /mnt/windows  这样就可以挂载了, 试一下\n[root@bitspace ntfs-3g_ntfsprogs-2017.3.23]# ls /sbin/moun* /sbin/mount.cifs /sbin/mount.lowntfs-3g /sbin/mount.nfs /sbin/mount.nfs4 /sbin/mount.ntfs-3g /sbin/mount.tmpfs [root@bitspace ntfs-3g_ntfsprogs-2017.3.23]# mount -t ntfs-3g /dev/sda1 /mnt/sda1 The disk contains an unclean file system (0, 0). Metadata kept in Windows cache, refused to mount. Falling back to read-only mount because the NTFS partition is in an unsafe state. Please resume and shutdown Windows fully (no hibernation or fast restarting.) [root@bitspace ntfs-3g_ntfsprogs-2017.3.23]#  看到这条信息，不要紧张，实际上就是已经挂载成功了。哈哈，但是这个信息，给人的感觉是没有成功。\n[root@bitspace ~]# ls /mnt/sda1/ $RECYCLE.BIN System Volume Information [root@bitspace ~]# ls /mnt/sda1/System\\ Volume\\ Information/ IndexerVolumeGuid tracking.log  其它几个类似\n[root@bitspace ~]# ls /mnt/sda2/ $RECYCLE.BIN System Volume Information [root@bitspace ~]# ls /mnt/sda3/ $RECYCLE.BIN System Volume Information [root@bitspace ~]# ls /mnt/sda4/ $RECYCLE.BIN System Volume Information  查看一下所有硬盘\n[root@bitspace ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/vg_bitspace-lv_root 50G 3.2G 44G 7% / tmpfs 3.8G 0 3.8G 0% /dev/shm /dev/sdb1 477M 41M 411M 9% /boot /dev/mapper/vg_bitspace-lv_home 53G 53M 50G 1% /home /dev/sda1 221G 120M 220G 1% /mnt/sda1 /dev/sda2 239G 121M 238G 1% /mnt/sda2 /dev/sda3 238G 121M 237G 1% /mnt/sda3 /dev/sda4 237G 121M 237G 1% /mnt/sda4 [root@bitspace ~]#  Ref  http://blog.51cto.com/luyafei/496788 https://www.tuxera.com/community/open-source-ntfs-3g/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-install-base-ubuntu.html",
	"title": "Docker Install Base Ubuntu",
	"tags": ["ubuntu", "docker", "install"],
	"description": "",
	"content": " ubuntu中安装docker-ce\nEnv  os: ubuntu16 ip: ... docker: 17.03.2~ce-0~ubuntu-xenial  Step 查看已安装 sudo docker version  如果有已安装，请卸载，给个示例\nsudo apt remove docker* -y  安装 lsb_release -a sudo apt-get install apt-transport-https ca-certificates curl software-properties-common -y curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-key fingerprint 0EBFCD88 sudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026quot; sudo apt-get update apt-cache madison docker-ce  查看后，选择我们需要的指定版本, 我这里选择17.03.2.\nsudo apt-get install docker-ce=17.03.2~ce-0~ubuntu-xenial -y sudo docker run hello-world  Ref  https://docs.docker.com/install/linux/docker-ce/ubuntu/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-pip-install-virtualenv.html",
	"title": "Python Pip Install Virtualenv",
	"tags": ["python"],
	"description": "",
	"content": " python源码安装pip后，安装virtualenv环境\nStep 源码安装pip后, pip会在 /usr/local/python27/bin/ 下，且由pip安装的模块下的命令文件（如下文中的virtualenvwrapper.sh)，也会在这里哟。\n环境变量加 pip which pip\n[root@bitspace ~]# tail -1 ~/.bashrc export PATH=$PATH:/usr/local/python27/bin [root@bitspace ~]# which pip /usr/local/python27/bin/pip [root@bitspace ~]#  环境变量加 virtualenvwrapper.sh which virtualenvwrapper.sh\n[root@bitspace ~]# which virtualenvwrapper.sh /usr/local/python27/bin/virtualenvwrapper.sh [root@bitspace ~]#  加环境变量\n[root@bitspace ~]# tail -3 ~/.bashrc export WORKON_HOME=$HOME/.virtualenvs export PROJECT_HOME=$HOME/workspace source /usr/local/python27/bin/virtualenvwrapper.sh [root@bitspace ~]#  这个时候，已经可以使用mkvirtualenv,workon等下列命令了（但是which会不成功的，一定要注意了）。\nmkvirtualenv zqxt：创建运行环境zqxt workon zqxt: 工作在 zqxt 环境 或 从其它环境切换到 zqxt 环境 deactivate: 退出终端环境 其它的： rmvirtualenv ENV：删除运行环境ENV mkproject mic：创建mic项目和运行环境mic mktmpenv：创建临时运行环境 lsvirtualenv: 列出可用的运行环境 lssitepackages: 列出当前环境安装了的包  创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。\n[root@bitspace ~]# which mkvirtualenv /usr/bin/which: no mkvirtualenv in (/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/local/python27/bin) [root@bitspace ~]# mkvirtualenv aone New python executable in /root/.virtualenvs/aone/bin/python Installing setuptools, pip, wheel...done. (aone) [root@bitspace ~]#  Ref  https://code.ziqiangxuetang.com/django/django-install.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-pip-install-ssl-module-not-available.html",
	"title": "Python Pip Install Ssl Module Not Available",
	"tags": ["python", "pip"],
	"description": "",
	"content": " 先看报错\n[root@bitspace pip-10.0.1]# python -m pip install virtualenv virtualenvwrapper pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. Collecting virtualenv Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)': /simple/virtualenv/ Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)': /simple/virtualenv/ Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)': /simple/virtualenv/ Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)': /simple/virtualenv/ Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)': /simple/virtualenv/ Could not fetch URL https://pypi.org/simple/virtualenv/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/virtualenv/ (Caused by SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)) - skipping Could not find a version that satisfies the requirement virtualenv (from versions: ) No matching distribution found for virtualenv pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(\u0026quot;Can't connect to HTTPS URL because the SSL module is not available.\u0026quot;,)) - skipping [root@bitspace pip-10.0.1]#  Env  os: centos6.9 python: 2.7.9 pip: 1.10.1  Step 原理：系统安装 openssl, 并重编译python\nyum install openssl openssl-devel -y  python重新编译\ncd ~/python/Python-2.7.9/ ./configure --prefix=/usr/local/python27 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install cd ~/python/setuptools/setuptools-0.6c11/ python setup.py build \u0026amp;\u0026amp; python setup.py install cd ~/python/pip-10.0.1/ python setup.py build \u0026amp;\u0026amp; python setup.py install  再安装virtualenv\npython -m pip install virtualenv virtualenvwrapper  Ref  https://jingyan.baidu.com/article/cbf0e500475c042eab289362.html https://www.cnblogs.com/allan-king/p/5445879.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-install-setuptools.html",
	"title": "Python Install Setuptools",
	"tags": ["python"],
	"description": "",
	"content": " 源码安装 pip 时，出错，并提示ImportError: No module named setuptools解决方法\nEnv  python: 2.7.9  Step 安装过程详见这篇博客： http://www.ttlsa.com/python/how-to-install-and-use-pip-ttlsa/\n安装后运行到：python setup.py install出现错误，错误图片如下所示：\n[root@localhost pip-1.5.4]# python setup.py install Traceback (most recent call last): File “setup.py”, line 6, in from setuptools import setup, find_packages ImportError: No module named setuptools  解决方法\nwget http://pypi.python.org/packages/source/s/setuptools/setuptools-0.6c11.tar.gz tar zxvf setuptools-0.6c11.tar.gz cd setuptools-0.6c11 python setup.py build python setup.py install  之后就可以开心的使用pip了\nRef  https://blog.csdn.net/yangbodong22011/article/details/52456581  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-zlib-module-missing.html",
	"title": "Python Zlib Module Missing",
	"tags": ["python"],
	"description": "",
	"content": "  Traceback (most recent call last): File \u0026quot;setup.py\u0026quot;, line 94, in \u0026lt;module\u0026gt; scripts = scripts, File \u0026quot;/usr/local/lib/python2.7/distutils/core.py\u0026quot;, line 152, in setup dist.run_commands() File \u0026quot;/usr/local/lib/python2.7/distutils/dist.py\u0026quot;, line 953, in run_commands self.run_command(cmd) File \u0026quot;/usr/local/lib/python2.7/distutils/dist.py\u0026quot;, line 972, in run_command cmd_obj.run() File \u0026quot;/home/rohan/setuptools-0.6c11/setuptools/command/install.py\u0026quot;, line 76, in run self.do_egg_install() File \u0026quot;/home/rohan/setuptools-0.6c11/setuptools/command/install.py\u0026quot;, line 96, in do_egg_install self.run_command('bdist_egg') File \u0026quot;/usr/local/lib/python2.7/distutils/cmd.py\u0026quot;, line 326, in run_command self.distribution.run_command(command) File \u0026quot;/usr/local/lib/python2.7/distutils/dist.py\u0026quot;, line 972, in run_command cmd_obj.run() File \u0026quot;/home/rohan/setuptools-0.6c11/setuptools/command/bdist_egg.py\u0026quot;, line 236, in run dry_run=self.dry_run, mode=self.gen_header()) File \u0026quot;/home/rohan/setuptools-0.6c11/setuptools/command/bdist_egg.py\u0026quot;, line 527, in make_zipfile z = zipfile.ZipFile(zip_filename, mode, compression=compression) File \u0026quot;/usr/local/lib/python2.7/zipfile.py\u0026quot;, line 651, in __init__ \u0026quot;Compression requires the (missing) zlib module\u0026quot; RuntimeError: Compression requires the (missing) zlib module  Env  os: centos6.9 python: 2.7.9  Step first install the companents with the following command\nyum install -y zlib zlib-devel  then remake python\nmake \u0026amp;\u0026amp; make install  Ref  https://stackoverflow.com/questions/3905615/zlib-module-missing  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-install-pip.html",
	"title": "Python Install Pip",
	"tags": ["python", "pip"],
	"description": "",
	"content": " Env  os: centos6.9 python: 2.7.9  step 首先安装Python 我安装了两个版本:\n　Python-2.7.10.tgz\n首先看一下系统自带的Python版本：\n[root@zk src]# python -V Python 2.6.6  安装Python2.7版本：\n参考 在centos中python从2.6升级到2.7\n开始安装pip 打开 https://pypi.org/search/?q=pip, 点击 pip 10.0.1， 点击 Download files, 右键Copy link address\n下载pip [root@zk src]# wget \u0026quot;https://files.pythonhosted.org/packages/ae/e8/2340d46ecadb1692a1e455f13f75e596d4eab3d11a57446f08259dee8f02/pip-10.0.1.tar.gz\u0026quot; [root@zk src]# tar -zxvf pip-1.5.4.tar.gz [root@zk src]# cd pip-1.5.4 [root@zk pip-1.5.4]# python setup.py install  如果出现下面错误\n[root@zk pip-1.5.4]# python setup.py install Traceback (most recent call last): File \u0026quot;setup.py\u0026quot;, line 6, in \u0026lt;module\u0026gt; from setuptools import setup, find_packages ImportError: No module named setuptools  看到ImportError: No module named setuptools，缺少setuptools模块\n安装 setuptools 参考python源码安装setuptools, 下载安装setuptools模块：\n[root@zk src]# wget --no-check-certificate https://pypi.python.org/packages/source/s/setuptools/setuptools-12.0.3.tar.gz#md5=f07e4b0f4c1c9368fcd980d888b29a65 [root@zk src]# tar zxvf setuptools-12.0.3.tar.gz [root@zk setuptools-12.0.3]# python setup.py build [root@zk setuptools-12.0.3]# python setup.py install *** z = zipfile.ZipFile(zip_filename, mode, compression=compression) File \u0026quot;/usr/local/python27/lib/python2.7/zipfile.py\u0026quot;, line 736, in __init__ \u0026quot;Compression requires the (missing) zlib module\u0026quot; RuntimeError: Compression requires the (missing) zlib module  看到缺少zlib模块,\n安装 zlib 解决方法：\n[root@zk setuptools-12.0.3]# yum install zlib zlib-devel  重新编译 安装完成之后需要重新编译Python2.7和3.5：\n[root@zk setuptools-12.0.3]# cd ../Python-2.7.10 [root@zk Python-2.7.10]# ./configure --prefix=/usr/local/python27/ [root@zk Python-2.7.10]# make \u0026amp;\u0026amp; make install [root@zk Python-2.7.10]# rm -rf /usr/bin/python [root@zk Python-2.7.10]# rm -rf /usr/bin/python3 [root@zk Python-2.7.10]# ln -s /usr/local/python27/bin/python /usr/bin/python [root@zk Python-2.7.10]# cd ../setuptools-12.0.3 [root@zk setuptools-12.0.3]# python setup.py build running build running build_py [root@zk setuptools-12.0.3]# python setup.py install *** Processing dependencies for setuptools==12.0.3 Finished processing dependencies for setuptools==12.0.3  重新安装之后成功了！但是现在只是把setuptools安装好了，在重新安装pip：\n[root@zk pip-1.5.4]# python setup.py install Installed /usr/local/python27/lib/python2.7/site-packages/pip-1.5.4-py2.7.egg Processing dependencies for pip==1.5.4 Finished processing dependencies for pip==1.5.4 [root@zk pip-1.5.4]# python -m pip install a /usr/bin/python: cannot import name HTTPSHandler; 'pip' is a package and cannot be directly executed  根据上面提示又是缺少HTTPSHandler模块，安装：\n安装 openssl与openssl-devel [root@zk ~]# yum install openssl openssl-devel -y  然后再重新安装编译Python，安装完成时候在重新安装pip：\n查看一下pip版本 [root@bitspace pip-10.0.1]# python -m pip --version pip 10.0.1 from /usr/local/python27/lib/python2.7/site-packages/pip-10.0.1-py2.7.egg/pip (python 2.7) [root@bitspace pip-10.0.1]#  安装virtualenv 模块 [root@zk ~]# python Python 2.7.10 (default, Apr 29 2016, 11:43:29) [GCC 4.4.7 20120313 (Red Hat 4.4.7-16)] on linux2 Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; import virtualenv Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; ImportError: No module named virtualenv \u0026gt;\u0026gt;\u0026gt; exit() [root@zk ~]# python -m pip install virtualenv Downloading/unpacking virtualenv Downloading virtualenv-15.0.1-py2.py3-none-any.whl (1.8MB): 1.8MB downloaded Installing collected packages: virtualenv Successfully installed virtualenv Cleaning up... [root@zk ~]# python Python 2.7.10 (default, Apr 29 2016, 11:43:29) [GCC 4.4.7 20120313 (Red Hat 4.4.7-16)] on linux2 Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; import virtualenv \u0026gt;\u0026gt;\u0026gt;  ~ok,已经成功了！\n如果安装的时候不出问题是最好的，所以在安装软件的时候一点要先把依赖包安装好！\nRef  https://www.cnblogs.com/allan-king/p/5445879.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-upgrade-version-base-on-centos.html",
	"title": "Python Upgrade Version Base on Centos",
	"tags": ["python", "centos"],
	"description": "",
	"content": " 概要\nCentOS 6.9中预安装了Python-2.6.6，其比较新的Python-2.7.9(CentOS 7预装版本)主要区别在于新版本的Python导入了更丰富的模块功能。对于初学者而言这一般不会有太大的影响，相对而言这些新模块在某些特定的编译环境下却是不可或缺的。例如：使用Devstack all-in-one模式进行安装OpenStack开发调试平台，需要Python-2.7及以上的支持，这样可以省去很多缺失模块的麻烦。\nEnv  os: centos6.9 python: 2.6.6 =\u0026gt; 2.7.9  step 1.查看当前系统的Python Version\n[root@jmilk ~]# python --version Python 2.6.6  2.下载Python-2.7.9\nwget https://www.python.org/ftp/python/2.7.9/Python-2.7.9.tar.xz  3.安装Python\na. 解压\ntar -Jxvf Python-2.7.9.tar.xz -C /usr/src/  b. 安装\nmkdir /usr/local/python27 cd /usr/src/Python-2.7.9/ ./configure --prefix=/usr/local/python27 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install  c. 将系统python指令默认指向Python-2.7.9版本\nCentOS6.9中YUM需要Python-2.6.6支持，所以不建议卸载老版本。\nmv /usr/bin/python /usr/bin/python266 ln -s /usr/local/python27/bin/python2.7 /usr/bin/python python --version  解决YUM与Python2.7.9的兼容问题 因为YUM需要python-2.6.6的支持，CentOS 6.9中YUM却不兼容Python-2.7，导致YUM不可用。\n[root@bitspace ~]# yum install python-pip -y There was a problem importing one of the Python modules required to run yum. The error leading to this problem was: No module named yum Please install a package which provides this module, or verify that the module is installed correctly. It's possible that the above module doesn't match the current version of Python, which is: 2.7.9 (default, Jun 4 2018, 18:00:05) [GCC 4.4.7 20120313 (Red Hat 4.4.7-18)] If you cannot solve this problem yourself, please go to the yum faq at: http://yum.baseurl.org/wiki/Faq  需要在YUM的配置文件中，重新使YUM指向Python-2.6.6的执行程序(即CentOS 6.9 原始的/usr/bin/python程序)\nvim /usr/bin/yum  将原来的：\n#！/usr/bin/python  改为：\n#!/usr/bin/python266  如下\n[root@bitspace ~]# ls /usr/bin/python* /usr/bin/python /usr/bin/python2 /usr/bin/python2.6 /usr/bin/python266 [root@bitspace ~]# vi /usr/bin/yum [root@bitspace ~]# yum install python-pip -y  一般来说这样就可以恢复使用YUM，同理所有在CentOS 6.5中对Python-2.7不兼容的软件都可以使用上面的方法来解决。\n如果上述步骤执行完后仍不能有效的执行YUN指令，可以尝试下面的解决方法。 将CentOS 6.9的安装光盘或ISO文件中的以下rpm包(版本根据个人情况)拷贝到系统目录中。\nmount /dev/cdrom /mnt/cdrom cd /mnt/cdrom/Packages cp yum-3.2.29-40.el6.centos.noarch.rpm \\ python-2.6.6-51.el6.x86_64.rpm \\ python-urlgrabber-3.9.1-9.el6.noarch.rpm \\ python-devel-2.6.6-51.el6.x86_64.rpm \\ python-libs-2.6.6-51.el6.x86_64.rpm /usr/local/python27 cd /usr/local/python27 rpm -Uvh --replacepkgs *.rpm  将上面的依赖包都安装完，或许可以解决这个问题。\n至此，Python升级完成。\nRef  http://www.jb51.net/article/103967.htm https://www.cnblogs.com/allan-king/p/5445879.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tools/vsftp-add-user.html",
	"title": "Vsftp Add User",
	"tags": ["vsftp", "ftp"],
	"description": "",
	"content": " env  os: centos6.9 ftp: vsftpd ip: 10.88.88.22  step 加用户 加用户，为安全，禁止用户登录\n[root@bitspace vsftpd]# useradd liuchao [root@bitspace vsftpd]# passwd liuchao Changing password for user liuchao. New password: [root@bitspace vsftpd]# passwd liuchao Changing password for user liuchao. New password: BAD PASSWORD: it is WAY too short BAD PASSWORD: is too simple Retype new password: passwd: all authentication tokens updated successfully. [root@bitspace vsftpd]# vi /etc/passwd [root@bitspace vsftpd]# tail -1 /etc/passwd liuchao:x:507:507::/home/liuchao:/sbin/nologin [root@bitspace vsftpd]# su - liuchao This account is currently not available. [root@bitspace vsftpd]#  把用户名加入chroot_list文件 [root@bitspace vsftpd]# pwd /etc/vsftpd [root@bitspace vsftpd]# [root@bitspace vsftpd]# vi chroot_list [root@bitspace vsftpd]# cat chroot_list liuchao ftpuser hello ftp [root@bitspace vsftpd]# ls chroot_list ftpusers user_list vsftpd.conf vsftpd_conf_migrate.sh [root@bitspace vsftpd]#  重启 vsftpd\n[root@bitspace vsftpd]# service vsftpd restart Shutting down vsftpd: [ OK ] Starting vsftpd for vsftpd: [ OK ]  测试 [root@bitspace vsftpd]# ls /home/ ftp hello jack liuchao lost+found [root@bitspace vsftpd]# echo \u0026quot;dfadfds\u0026quot; \u0026gt;\u0026gt; /home/liuchao/123.txt  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/chrome/ftp-cannot-chrome-file-access.html",
	"title": "Ftp Cannot Chrome File Access",
	"tags": ["ftp", "centos"],
	"description": "",
	"content": " 为何客户端软件可以而浏览器则不能连接FTP服务器\nenv  centos6.9 ftp: vsftpd  step 这里主要的点就是理解主动模式与被动模式。\n主动模式对服务器端有利，被动模式对客户端有利。但是服务器端既然要提供FTP服务，应该在服务器端设置防火墙规则，提供被动模式服务，而不能要求所有的客户端都设置防火墙规则以适应主动服务模式。当然服务器端在提供被动模式服务时，出于安全考虑，应该设置客户端可发起数据连接的端口范围，这就是下面配置文件中的\npasv_min_port=61001 pasv_max_port=62000  即，告诉客户端可以向61001与62000之间的端口发起数据连接。\n[root@bitspace ~]# tail /etc/vsftpd/vsftpd.conf # sockets, you must run two copies of vsftpd with two configuration files. # Make sure, that one of the listen options is commented !! #listen_ipv6=YES pam_service_name=vsftpd userlist_enable=YES tcp_wrappers=YES pasv_min_port=61001 pasv_max_port=62000 [root@bitspace ~]#  Ref  https://blog.csdn.net/zilong00007/article/details/7663152 https://my.oschina.net/iyinghui/blog/1605801 http://www.cnblogs.com/qytan36/archive/2010/05/15/1736270.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos6-install-ftp.html",
	"title": "Centos6 Install Ftp",
	"tags": ["centos", "install", "ftp"],
	"description": "",
	"content": " CentOS6上ftp服务器搭建实战\nenv  centos6.9 IP: 10.88.88.22 IP: 172.16.55.6  step 1.安装程序包 [root@node1 ~]$ yum install -y vsftpd [root@node1 ~]$ yum install -y lftp # 安装测试软件  2.启动vsftpd服务 [root@node1 ~]$ setenforce 0　#关闭selinux setenforce: SELinux is disabled　[root@node1 ~]$ service iptables stop　#关闭防火墙　[root@node1 ~]$ service vsftpd start　# 启动服务 为 vsftpd 启动 vsftpd： [确定] [root@node1 ~]$ service vsftpd status vsftpd (pid 6473) 正在运行... [root@node1 ~]$ ss -tnl | grep 21　#默认监听21号端口 LISTEN 0 32 *:21 *:* [root@bitspace ~]# service vsftpd start Starting vsftpd for vsftpd: [ OK ] [root@bitspace ~]# netstat -anltp | grep 21 tcp 0 0 0.0.0.0:21 0.0.0.0:* LISTEN 4411/vsftpd tcp 0 0 10.88.88.22:60614 183.61.241.214:80 TIME_WAIT - tcp 0 0 10.88.88.22:40278 121.9.244.94:80 TIME_WAIT - tcp 0 0 10.88.88.22:51054 121.9.244.91:80 TIME_WAIT - [root@bitspace ~]#  3.访问vsftpd服务器 然后把相应端口（21）打开。让其它机器可访问。\n在本机或者其他主机，在其他主机上测试，需要先确认两台主机能进行网络通信ping，telnet\n在linux上访问测试\n[root@localhost ~]#lftp 172.16.55.6 lftp 172.16.55.6:~\u0026gt; ls drwxr-xr-x 2 0 0 4096 May 11 2016 pub lftp 172.16.55.6:/\u0026gt;  windows上访问测试\nC:\\Users\\Vathe\u0026gt;ftp 172.16.55.6 #连接 Connected to 172.16.55.6.　(vsFTPd 2.2.2) Always in UTF8 mode. User (172.16.55.6:(none)): ftp　#输入用户名 Please specify the password. Password:　#密码为空 Login successful. ftp\u0026gt; ls　#显示文件　PORT command successful. Consider using PASV. Here comes the directory listing. pub Directory send OK. ftp: 8 bytes received in 0.00Seconds 8000.00Kbytes/sec. ftp\u0026gt; pwd　#显示当前目录 \u0026quot;/\u0026quot; ftp\u0026gt; cd pub Directory successfully changed.  4.创建本地用户admin [root@node1 vsftpd]$ useradd admin [root@node1 vsftpd]$ echo \u0026quot;admin\u0026quot; | passwd --stdin admin 更改用户 admin 的密码 。 passwd： 所有的身份验证令牌已经成功更新。  5.修改配置文件vsftpf.conf [root@node1 vsftpd]$ cp vsftp.conf{,.bak}　#备份操作 [root@node1 vsftpd]$ vim vsftpd.conf chroot_local_user=YES #禁锢所有本地用户至家目录 chroot_list_enable=YES #指定需要禁锢的本地用户 chroot_list_file=/etc/vsftpd/chroot_list #禁锢的用户文件 [root@node1 vsftpd]$ pwd /etc/vsftpd [root@node1 vsftpd]$ vim chroot_list #添加admin用户 admin [root@node1 vsftpd]$ !ser #重启vsftpd服务 service vsftpd reload 关闭 vsftpd： [确定] 为 vsftpd 启动 vsftpd： [确定]  6.添加白名单 [root@node1 vsftpd]$ cd /etc/pam.d/ [root@node1 pam.d]$ vim vsftpd #修改pam的配置文件为白名单 auth required pam_listfile.so item=user sense=allow file=/etc/vsftpd/ftpusers onerr=succeed [root@node1 vsftpd]$ cp ftpusers{,.bak} #备份 [root@node1 vsftpd]$ vim ftpusers #修改白名单列表 # Users that are not allowed to login via ftp admin ftp  注：也可以使用vsftpd自身的配置文件/etc/vsftpd/user_list进行配置\n测试登录用户 [root@localhost ~]#ftp 172.16.55.6 # 连接 Connected to 172.16.55.6 (172.16.55.6). (vsFTPd 2.2.2) Name (172.16.55.6:root): ftp　# ftp用户登录成功 Please specify the password. Password: # 不需要密码登录 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u0026gt; exit Goodbye. [root@localhost ~]#ftp 172.16.55.6 Connected to 172.16.55.6 (172.16.55.6). (vsFTPd 2.2.2) Name (172.16.55.6:root): vathe # 其他用户（非白名单用户）登录 Please specify the password. Password: Login incorrect. Login failed. # 登录失败 ftp\u0026gt;  vstfpd服务常见文件目录 [root@node1 ~]$ rpm -ql vsftpd #查看程序包相关文件 /etc/logrotate.d/vsftpd　/etc/pam.d/vsftpd /etc/rc.d/init.d/vsftpd #主程序文件 /etc/vsftpd/ftpusers #pam模块默认的黑名单配置文件 /etc/vsftpd/user_list #黑名单或白名单配置文件 /etc/vsftpd/vsftpd.conf #主配置文件 ... /usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE #示例文档 2.2.2/EXAMPLE/INTERNET_SITE/vsftpd.xinetd /usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD /usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/README /usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/README.configuration /usr/share/doc/vsftpd-2.2.2/EXAMPLE/INTERNET_SITE_NOINETD/vsftpd.conf /usr/share/doc/vsftpd-2.2.2/EXAMPLE/PER_IP_CONFIG/hosts.allow /usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/vsftpd.conf /usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS_2 /usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS_2/README /usr/share/doc/vsftpd-2.2.2/FAQ ... /usr/share/man/man8/vsftpd.8.gz /var/ftp #匿名用户共享资源路径 /var/ftp/pub  Ref  https://www.cnblogs.com/vathe/p/6950325.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos-iptable-open-port-21.html",
	"title": "Centos Iptable Open Port 21",
	"tags": ["centos", "iptables"],
	"description": "",
	"content": " centos6.9开放ftp(vsftpd)的21端口\nenv  centos6.9  [root@bitspace ~]# /etc/rc.d/init.d/iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] [root@bitspace ~]# service iptables restart iptables: Setting chains to policy ACCEPT: filter [ OK ] iptables: Flushing firewall rules: [ OK ] iptables: Unloading modules: [ OK ] iptables: Applying firewall rules: [ OK ] [root@bitspace ~]# vim /etc/sysconfig/iptables [root@bitspace ~]# cat /etc/sysconfig/iptables # Generated by iptables-save v1.4.7 on Tue May 29 18:27:18 2018 *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [53:4182] -A INPUT -p tcp -m tcp --dport 21 -j ACCEPT -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A INPUT -p tcp -m state --state NEW -m tcp --dport 21 -j ACCEPT -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT # Completed on Tue May 29 18:27:18 2018 [root@bitspace ~]# [root@bitspace ~]# /sbin/iptables -I INPUT -p tcp --dport 21 -j ACCEPT [root@bitspace ~]# /etc/rc.d/init.d/iptables save iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] [root@bitspace ~]# /etc/rc.d/init.d/iptables restart iptables: Setting chains to policy ACCEPT: filter [ OK ] iptables: Flushing firewall rules: [ OK ] iptables: Unloading modules: [ OK ] iptables: Applying firewall rules: [ OK ] [root@bitspace ~]# telnet 127.0.0.1 21 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is '^]'. 220 (vsFTPd 2.2.2) ^] telnet\u0026gt; quit Connection closed. [root@bitspace ~]#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos-release.html",
	"title": "Centos Release",
	"tags": ["centos", "version"],
	"description": "",
	"content": " 前言\n记下CentOS 7查看系统版本及查看机器位数x86-64的方法，由于不经常使用Linux，每当使用的时候就是安装软件，安装软件的时候就要选择安装包平台，是32位的还是64位的。这时候突然发现不知道怎么查，于是百度。虽然轻而易举百度出来，但仍旧没有自己的笔记看起来舒服。所以，还是记录下来。\n辨识标准 首先要清楚什么样标识是32位的，什么样的是64位的。\nPC server X86 系列\n I386\u0026ndash;I686 都是32位 x86_64 是 64位  查看位数命令 命令实在是不要太多，为了防止选择性障碍，一致选择第一种方式，后面的仅作为补充。\n方法1： [root@linuxidc ~]# uname -a Linux linuxidc 3.10.0-327.18.2.el7.x86_64 #1 SMP Thu May 12 11:03:55 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux  方法2：显示系统程序信息 [root@linuxidc ~]# file /bin/ls /bin/ls: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=aa7ff68f13de25936a098016243ce57c3c982e06, stripped  方法3： [root@linuxidc ~]# cat /proc/version Linux version 3.10.0-327.18.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC) ) #1 SMP Thu May 12 11:03:55 UTC 2016  方法4： （32位的系统中int类型和long类型一般都是4字节，64位的系统中int类型还是4字节的，但是long已变成了8字节inux系统中可用\u0026rdquo;getconf WORD_BIT\u0026rdquo;和 \u0026ldquo;getconf LONG_BIT\u0026rdquo;获得word和long的位数。64位系统中应该分别得到32和64。）\n[root@linuxidc ~]# getconf LONG_BIT 64  查看系统版本 方法1： [root@linuxidc ~]# lsb_release -a LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch Distributor ID: CentOS Description: CentOS Linux release 7.2.1511 (Core) Release: 7.2.1511 Codename: Core  方法2： [root@linuxidc ~]# cat /etc/os-release NAME=\u0026quot;CentOS Linux\u0026quot; VERSION=\u0026quot;7 (Core)\u0026quot; ID=\u0026quot;centos\u0026quot; ID_LIKE=\u0026quot;rhel Fedora\u0026quot; VERSION_ID=\u0026quot;7\u0026quot; PRETTY_NAME=\u0026quot;CentOS Linux 7 (Core)\u0026quot; ANSI_COLOR=\u0026quot;0;31\u0026quot; CPE_NAME=\u0026quot;cpe:/o:centos:centos:7\u0026quot; HOME_URL=\u0026quot;https://www.centos.org/\u0026quot; BUG_REPORT_URL=\u0026quot;https://bugs.centos.org/\u0026quot; CENTOS_MANTISBT_PROJECT=\u0026quot;CentOS-7\u0026quot; CENTOS_MANTISBT_PROJECT_VERSION=\u0026quot;7\u0026quot; RedHat_SUPPORT_PRODUCT=\u0026quot;centos\u0026quot; REDHAT_SUPPORT_PRODUCT_VERSION=\u0026quot;7\u0026quot;  方法3： [root@linuxidc ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core)  方法4： [root@linuxidc ~]# rpm -q centos-release centos-release-7-2.1511.el7.centos.2.10.x86_64  查看内核版本 方法1： [root@linuxidc ~]# cat /proc/version Linux version 3.10.0-327.18.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC) ) #1 SMP Thu May 12 11:03:55 UTC 2016  方法2： [root@linuxidc ~]# uname -a Linux linuxidc 3.10.0-327.18.2.el7.x86_64 #1 SMP Thu May 12 11:03:55 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux  Ref  https://www.linuxidc.com/Linux/2016-11/137550.htm  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/network-proxy-iphone.html",
	"title": "Network Proxy Iphone",
	"tags": ["network", "proxy", "iphone"],
	"description": "",
	"content": " 通过手机实现FQ\nenv 国外安装了代理网络的服务器一台\n ip: ... port: 443 passwd: ********  iphone一台\n APP安装：ShadowBroken  step 先保证在windows中能够使用Shadowsocks客户端实现科学上网\n打开 ShadowBroken，把配置写入，然后，连接。现在可以KXSW了。\ntodo 在 超哥 提供的jumper机器上，实现一个科学上网吧。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/ssh-login.html",
	"title": "Ssh Login",
	"tags": ["ssh"],
	"description": "",
	"content": " faq 报错：Too many authentication failures\ntom@tom-w10vbud16:~/ztom/bits/pem$ ssh -i vachain_competition.pem ubuntu@ec2-13-125-197-97.ap-northeast-2.compute.amazonaws.com Received disconnect from 13.125.197.97 port 22:2: Too many authentication failures Connection to ec2-13-125-197-97.ap-northeast-2.compute.amazonaws.com closed by remote host. Connection to ec2-13-125-197-97.ap-northeast-2.compute.amazonaws.com closed. tom@tom-w10vbud16:~/ztom/bits/pem$  If you are not using any ssh hosts configuration, you have to explicitly specify the correct key in the ssh command like so:\nssh -i some_id_rsa -o 'IdentitiesOnly yes' them@there:/path/  Note: the \u0026lsquo;IdentitiesOnly yes\u0026rsquo; parameter needed to be between quotes.\nor\nssh -i some_id_rsa -o IdentitiesOnly=yes them@there:/path/  那好吧，我们试一下，果然登录成功了\ntom@tom-w10vbud16:~/ztom/bits/pem$ ssh -i vachain_competition.pem -o 'IdentitiesOnly yes' ubuntu@ec2-13-125-197-97.ap-northeast-2.compute.amazonaws.com Welcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.4.0-1052-aws x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 0 packages can be updated. 0 updates are security updates. *** System restart required *** Last login: Thu May 24 07:18:32 2018 from 121.34.145.43 ubuntu@ip-172-31-5-249:~$  Ref  https://www.cnblogs.com/xueweihan/p/6346804.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox/virtualbox-share-pasteboard.html",
	"title": "Virtualbox Share Pasteboard",
	"tags": ["virtualbox"],
	"description": "",
	"content": " virtubox 共享剪切板\nenv  host: win10 vbox-os: ubuntu18-desktop  step M1, OK 等我们启动虚拟机进入虚拟机后，在虚拟机的运行框的功能栏部分，如图所示点击设备，然后分别可以配置共享粘贴板和拖拽选项，也是可以配置功能的执行方向\nM2, not OK 我们可以在不启动虚拟机实例的进行设置，先鼠标左键点击选择一个创建好的实例，然后点击功能栏的设置图标，进入到设置的总体页面中,然后我们选择常规选项中的高级一栏，鼠标左键点击进入，我们可以看到有共享粘贴板和拖放两个配置项，其中每一个都可以进行单独设置，如图所示，分别可以设置从虚拟机到物理机，或者相反操作，或者双向操作，这里一般推荐设置双向操作，这样我们的虚拟机和物理机就可以无障碍的进行交互了\nref  https://jingyan.baidu.com/article/4dc40848645918c8d846f14b.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox/virtualbox-share-file.html",
	"title": "Virtualbox Share File",
	"tags": ["virtualbox"],
	"description": "",
	"content": " Virtualbox Ubuntu 共享文件夹（通过mount方式）\nenv  host: win10 vbox-os: ubuntu18-desktop  step  win10  ref  分享Virtualbox Ubuntu 共享文件夹、自动挂载的一些问题  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-http-proxy.html",
	"title": "Linux Http Proxy",
	"tags": ["linux", "proxy"],
	"description": "",
	"content": " linux-proxy 相关\nproxy FQ root@km:~# cat proxy.sh #!/bin/bash NO_PROXY=localhost,127.0.0.1/8,192.168.31.1/24 export NO_PROXY export http_proxy=http://192.168.31.10:1080/ export https_proxy=http://192.168.31.10:1080/ root@km:~#  这个问题，可以参考 https://blog.finsoft.info/posts/ubuntu-apt-http-proxy/#%E5%8F%96%E6%B6%88apt%E4%BB%A3%E7%90%86\n终端： [tom@mpro Desktop]$ export http_proxy=http://192.168.31.10:8031 # 这个 http://192.168.31.10:8031 是在 192.168.31.10的机器提供出来的 地址。 192.168.31.10的机器 是代理服务器。 [tom@mpro Desktop]$ export https_proxy=http://192.168.31.10:8031 [tom@mpro Desktop]$ ping www.google.com.hk # 代理后，ping 依然是不行的。呵呵 PING www.google.com.hk (93.46.8.89) 56(84) bytes of data. ^C --- www.google.com.hk ping statistics --- 6 packets transmitted, 0 received, 100% packet loss, time 4999ms [tom@mpro Desktop]$ wget www.google.com # 但是wget 是可以的。 --2016-07-22 11:18:25-- http://www.google.com/ Connecting to 192.168.31.10:8031... connected. Proxy request sent, awaiting response... 200 OK Length: unspecified [text/html] Saving to: ‘index.html’ [ \u0026lt;=\u0026gt; ] 10,466 11.5KB/s in 0.9s 2016-07-22 11:18:26 (11.5 KB/s) - ‘index.html’ saved [10466] [tom@mpro Desktop]$ vi index.html [tom@mpro Desktop]$  取消 http_proxy 运行： unset http_proxy\ntom@adata:~$ unset http_proxy tom@adata:~$ export declare -x CLUTTER_IM_MODULE=\u0026quot;xim\u0026quot; declare -x COLORTERM=\u0026quot;gnome-terminal\u0026quot; declare -x ... ... ...  查看一下 export ，知道，已经没有 http_proxy 了。\nchrome 先disable(去除)与网络代理相关的插件\n设置，network, network proxy, Manual,\nHTTP Proxy: 192.168.31.10 8031\nfirefox 先disable(去除)与网络代理相关的插件\npreferences, Advanced, Network, Settings,\nManual Proxy configuration:\nHTTP Proxy: 192.168.31.10 8031\nref  http://bbs.51cto.com/thread-1138093-1.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-wgetrc-wget-proxy.html",
	"title": "Linux Wgetrc Wget Proxy",
	"tags": ["linux", "wget", "proxy"],
	"description": "",
	"content": " wgetrc打开 wget 的代理\nenv  centos  step 通过 /etc/wgetrc 打开 wget 的代理\n[root@www ~]# vim /etc/wgetrc #http_proxy = http://proxy.yoyodyne.com:18023/ \u0026lt;==找到底下这几行，大约在 78 行 #ftp_proxy = http://proxy.yoyodyne.com:18023/ #use_proxy = on # 将他改成类似底下的模样，记得，你必须要有可接受的 proxy 主机才行！ http_proxy = http://192.168.31.10:8031/ use_proxy = on # use_proxy=off ## 关闭 [root@www ~]#  ref  http://cn.linux.vbird.org/linux_server/0140networkcommand.php#wget  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/xshell-ubuntu-transmitter-file.html",
	"title": "Xshell Ubuntu Transmitter File",
	"tags": ["ubunut", "xshell"],
	"description": "",
	"content": " xshell + ubuntu 直接拖拽完成传输\nenv  win10-xshell ubuntu  step ubunut 安装lrzsz软件\nubuntu@ip-172-31-17-102:~$ sudo apt install lrzsz Reading package lists... Done Building dependency tree Reading state information... Done lrzsz is already the newest version (0.12.21-8). 0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded. ubuntu@ip-172-31-17-102:~$  如果第一次没有成功，则，直接再把上面的命令运行一次\n传输完成了，会显示如下内容\nubuntu@ip-172-31-17-102:~$ rz -E rz waiting to receive. ubuntu@ip-172-31-17-102:~$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-apt-http-proxy.html",
	"title": "Ubuntu Apt Http Proxy",
	"tags": ["ubuntu", "proxy"],
	"description": "",
	"content": " Ubuntu的更改apt-get代理，设置与取消\napt代理的设置 方法1 这是一种临时的手段，如果您仅仅是暂时需要通过http代理使用apt-get，您可以使用这种方式。\n在使用apt-get之前，在终端中输入以下命令（根据您的实际情况替换yourproxyaddress和proxyport）。\nexport http_proxy=http://yourproxyaddress:proxyport  方法2 这种方法要用到/etc/apt/文件夹下的apt.conf文件。如果您希望apt-get（而不是其他应用程序）一直使用http代理，您可以使用这种方式。\n注意：某些情况下，系统安装过程中没有建立apt配置文件。下面的操作将视情况修改现有的配置文件或者新建配置文件。\nsudo gedit /etc/apt/apt.conf在您的apt.conf文件中加入下面这行（根据你的实际情况替换yourproxyaddress和proxyport）。\nAcquire::http::Proxy \u0026quot;http://yourproxyaddress:proxyport\u0026quot;  保存apt.conf文件。\n方法3 这种方法会在您的主目录下的.bashrc文件中添加两行。如果您希望apt-get和其他应用程序如wget等都使用http代理，您可以使用这种方式。\ngedit ~/.bashrc在您的.bashrc文件末尾添加如下内容（根据你的实际情况替换yourproxyaddress和proxyport）。\nhttp_proxy=http://yourproxyaddress:proxyport  export http_proxy保存文件。关闭当前终端，然後打开另一个终端。\n使用apt-get update或者任何您想用的网络工具测试代理。我使用firestarter查看活动的网络连接。\n如果您为了纠正错误而再次修改了配置文件，记得关闭终端并重新打开，否自新的设置不会生效。\n方法4 另外，apt-get也有一个“-o”选项，直接跟apt-get的设置变量，就不用指定配置文件了，比如\nsudo apt-get -o Acquire::http::proxy=\u0026quot;http://127.0.0.1:1080/”  取消apt代理 今天想装个软件(wine)，使用 sudo apt-get update 命令时，发现给出很多Ign 语句，总出现 Connecting to proxy.http://10.0.126.1:13128 的字样，发现这个代理是已经废弃掉的。接着想去取消使用该代理： 1、 查看/etc/apt/apt.conf，发现存在： http_proxy=\u0026quot;http://10.0.126.1:13128/\u0026quot; https_proxy=\u0026quot;https://10.0.126.1:13128/\u0026quot; ftp_proxy=\u0026quot;ftp://10.0.126.1:13128/\u0026quot; socks_proxy=\u0026quot;socks://10.0.126.1:13128/\u0026quot; 直接删除该文件，重启电脑，发现问题还是没解决； 2、百度一下，命令行执行：export http_proxy=\u0026quot;\u0026quot; 发现问题未解； 执行 unset http_proxy 问题还是存在； 3、查看~/.bashrc，未发现存在http_proxy之类设置; 4、env | grep proxy 发现依然存在 http 代理； 5、根目录查找一把： sudo grep -r -i http_proxy=http://10.0.126.168:13128/ ./ 看到控制台有输出: /etc/enviroment : http_proxy ..... 6、查看一下：cat /etc/enviroment，发现有配置： http_proxy=\u0026quot;http://10.0.126.1:13128/\u0026quot; https_proxy=\u0026quot;https://10.0.126.1:13128/\u0026quot; tp_proxy=\u0026quot;ftp://10.0.126.1:13128/\u0026quot; socks_proxy=\u0026quot;socks://10.0.126.1:13128/\u0026quot; 7、vi /etc/environment 将配置删掉； 8、至此终于搞定然后 sudo apt-get UPDATE,出现n多更新。 记录一下。  ref  https://blog.csdn.net/yctccg/article/details/52218066 https://blog.csdn.net/huangkq1989/article/details/9314749 https://www.iyunv.com/thread-206089-1-1.html https://blog.csdn.net/huangkq1989/article/details/9314749  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-install-wubipinyin.html",
	"title": "Ubuntu Install Wubipinyin",
	"tags": ["ubuntu", "install", "wubipinyin"],
	"description": "",
	"content": " ubuntu安装 五笔拼音输入法\nenv  Ubuntu Desktop 16.04  step 方法1 https://www.linuxdashen.com/ubuntu-16-04-%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85fcitx%E4%BA%94%E7%AC%94%E6%8B%BC%E9%9F%B3%E8%BE%93%E5%85%A5%E6%B3%95\n方法2 sudo add-apt-repository ppa:fcitx-team/nightly sudo apt update -y sudo apt -y install fcitx sudo apt -y install fcitx-table-wbpy  System Setting/Language Support/Keyboard input method system/ =\u0026gt; fcitx\n打开System Setting系统设置\u0026gt;Text Entry\n记得重启哟！\nref  https://www.linuxdashen.com/ubuntu-16-04-%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85fcitx%E4%BA%94%E7%AC%94%E6%8B%BC%E9%9F%B3%E8%BE%93%E5%85%A5%E6%B3%95 https://blog.csdn.net/zzqlivecn/article/details/25018203 https://blog.csdn.net/hamigua0208/article/details/51421117 https://blog.csdn.net/e421083458/article/details/37738805  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ngrok/ngrok-ssh.html",
	"title": "Ngrok Ssh",
	"tags": ["ngrok", "ssh"],
	"description": "",
	"content": " 远程登录家里的Ubuntu电脑(命令行模式)\nenv 服务端  机器: 腾讯云主机一台 IP: 111.230.153.251 OS: ubuntu server 16.04.1\n客户端 机器: 腾讯云主机一台\n IP: 192.168.31.106\n OS: ubuntu desktop 16.04.3\n  step 服务端建立一个 ngrokd服务,开通 4445 tunnel 我这里写成一个服务了的.\nubuntu@VM-0-12-ubuntu:~$ cat /etc/systemd/system/ngrok-83-84-45.service [Unit] Description=ngrok After=network.target [Service] ExecStart=/home/ubuntu/ngrok/ngrok-e/ngrok/bin/ngrokd -tlsKey=/home/ubuntu/ngrok/ngrok-e/ngrok/server.key -tlsCrt=/home/ubuntu/ngrok/ngrok-e/ngrok/server.crt -domain=\u0026quot;hkshop.club\u0026quot; -httpAddr=\u0026quot;:8083\u0026quot; -httpsAddr=\u0026quot;:8084\u0026quot; -tunnelAddr=\u0026quot;:4445\u0026quot; [Install] WantedBy=multi-user.target ubuntu@VM-0-12-ubuntu:~$ ubuntu@VM-0-12-ubuntu:~$ sudo systemctl status ngrok-83-84-45.service ● ngrok-83-84-45.service - ngrok Loaded: loaded (/etc/systemd/system/ngrok-83-84-45.service; disabled; vendor preset: enabled) Active: active (running) since Sun 2018-04-22 09:05:30 CST; 24h ago Main PID: 20599 (ngrokd) Tasks: 5 Memory: 2.3M CPU: 5.452s CGroup: /system.slice/ngrok-83-84-45.service └─20599 /home/ubuntu/ngrok/ngrok-e/ngrok/bin/ngrokd -tlsKey=/home/ubuntu/ngrok/ngrok-e/ngrok/server.key -tlsCrt=/home/ubuntu/ngrok/ngrok-e/ngrok/server.crt -domain=hkshop.club -httpAddr=:8083 - Apr 23 09:40:00 VM-0-12-ubuntu ngrokd[20599]: [09:40:00 CST 2018/04/23] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [metrics] Reporting: {\u0026quot;bytesIn.count\u0026quot;:20501,\u0026quot;bytesOut.count\u0026quot;:16763,\u0026quot;connMeter.count\u0026quot;:6,\u0026quot;c Apr 23 09:40:04 VM-0-12-ubuntu ngrokd[20599]: [09:40:04 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Reading message with length: 28 Apr 23 09:40:04 VM-0-12-ubuntu ngrokd[20599]: [09:40:04 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Read message {\u0026quot;Type\u0026quot;:\u0026quot;Ping\u0026quot;,\u0026quot;Payload\u0026quot;: Apr 23 09:40:04 VM-0-12-ubuntu ngrokd[20599]: [09:40:04 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Waiting to read message Apr 23 09:40:04 VM-0-12-ubuntu ngrokd[20599]: [09:40:04 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Writing message: {\u0026quot;Type\u0026quot;:\u0026quot;Pong\u0026quot;,\u0026quot;Paylo Apr 23 09:40:25 VM-0-12-ubuntu ngrokd[20599]: [09:40:25 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Reading message with length: 28 Apr 23 09:40:25 VM-0-12-ubuntu ngrokd[20599]: [09:40:25 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Read message {\u0026quot;Type\u0026quot;:\u0026quot;Ping\u0026quot;,\u0026quot;Payload\u0026quot;: Apr 23 09:40:25 VM-0-12-ubuntu ngrokd[20599]: [09:40:25 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Waiting to read message Apr 23 09:40:25 VM-0-12-ubuntu ngrokd[20599]: [09:40:25 CST 2018/04/23] [DEBG] (ngrok/log.(*PrefixLogger).Debug:79) [ctl:15ddd954] [753e7631548709e9649360ad9c3eb401] Writing message: {\u0026quot;Type\u0026quot;:\u0026quot;Pong\u0026quot;,\u0026quot;Paylo Apr 23 09:40:30 VM-0-12-ubuntu ngrokd[20599]: [09:40:30 CST 2018/04/23] [INFO] (ngrok/log.(*PrefixLogger).Info:83) [metrics] Reporting: {\u0026quot;bytesIn.count\u0026quot;:20501,\u0026quot;bytesOut.count\u0026quot;:16763,\u0026quot;connMeter.count\u0026quot;:6,\u0026quot;c lines 1-20/20 (END)  客户端 重点看一下 ngrok-4445-ssh-start.cfg 的配置\n server_addr 为 domain name:tunnelAddr remote_port 为 将来在外网连接时的 端口 tcp 为客户端 ssh IP和端口, 如: \u0026ldquo;127.0.0.1:22\u0026rdquo;  tom@udvbud-ngrokd-c:~/ngrok-cli$ pwd /home/tom/ngrok-cli tom@udvbud-ngrokd-c:~/ngrok-cli$ ls ngrok ngrok-4445-ssh.cfg ngrok-4445-ssh-start.cfg ngrok.cfg ngrok.cfg.origin ngrok-gitlab-111.cfg nohup.out README.md tom@udvbud-ngrokd-c:~/ngrok-cli$ cat ngrok-4445-ssh-start.cfg server_addr: \u0026quot;hkshop.club:4445\u0026quot; trust_host_root_certs: false tunnels: ssh: remote_port: 51001 proto: tcp: \u0026quot;127.0.0.1:22\u0026quot; tom@udvbud-ngrokd-c:~/ngrok-cli$  启动\ntom@udvbud-ngrokd-c:~/ngrok-cli$ /home/tom/ngrok-cli/ngrok -config=ngrok-4445-ssh-start.cfg start ssh  服务端测试 通过 ssh 客户端user@服务端IP -p客户端remeote_port 的方式进行连接\nubuntu@VM-0-12-ubuntu:~/ngrok$ ssh tom@127.0.0.1 -p51001 tom@127.0.0.1's password: Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.13.0-38-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage 206 packages can be updated. 0 updates are security updates. Last login: Mon Apr 23 09:35:25 2018 from 127.0.0.1 tom@udvbud-ngrokd-c:~$  连接成功了\nref  Ngrok远程桌面及ssh配置 如何远程登录家里的Ubuntu电脑(命令行模式)  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ngrok/ngrok-multi-user-tunnel.html",
	"title": "Ngrok Multi User Tunnel",
	"tags": ["ngrok"],
	"description": "",
	"content": " 一个 ngrokd 服务配置多个协议\nenv 服务端  机器: 腾讯云主机一台 IP: 111.230.153.251 OS: ubuntu server 16.04.1  客户端  机器: 腾讯云主机一台 IP: 192.168.31.106 OS: ubuntu desktop 16.04.3  step 服务端 ubuntu@VM-0-12-ubuntu:~$ cat /etc/systemd/system/ngrok-e.service [Unit] Description=ngrok After=network.target [Service] #/home/ubuntu/ngrok/ngrok-e/ngrok=/home/ubuntu/ngrok/ngrok-e/ngrok ExecStart=/home/ubuntu/ngrok/ngrok-e/ngrok/bin/ngrokd -tlsKey=/home/ubuntu/ngrok/ngrok-e/ngrok/server.key -tlsCrt=/home/ubuntu/ngrok/ngrok-e/ngrok/server.crt -domain=\u0026quot;hkshop.club\u0026quot; -httpAddr=\u0026quot;:8081\u0026quot; -httpsAddr=\u0026quot;:8082\u0026quot; [Install] WantedBy=multi-user.target ubuntu@VM-0-12-ubuntu:~$ sudo systemctl status ngrok-e.service ● ngrok-e.service - ngrok Loaded: loaded (/etc/systemd/system/ngrok-e.service; disabled; vendor preset: enabled) Active: active (running) since Sat 2018-04-21 08:34:20 CST; 2 days ago Main PID: 19755 (ngrokd) Tasks: 5 Memory: 2.6M CPU: 8.780s CGroup: /system.slice/ngrok-e.service └─19755 /home/ubuntu/ngrok/ngrok-e/ngrok/bin/ngrokd -tlsKey=/home/ubuntu/ngrok/ngrok-e/ngrok/server.key -tlsCrt=/home/ubuntu/ngrok/ngrok-e/ngrok/server.crt -domain=hkshop.club -httpAddr=:8081 - Apr 23 10:01:21 VM-0-12-ubuntu ngrokd[19755]  客户端 配置 yaml 文件 配置ngrok.cfg, 它是一个 yaml 文件\n可以放到 YAML在线格式化校验工具测试一下, 经过格式化后,再粘贴到 ngrok.cfg 文件中\ntom@udvbud-ngrokd-c:~/ngrok-cli$ cat ngrok.cfg server_addr: \u0026quot;hkshop.club:4443\u0026quot; trust_host_root_certs: false tunnels: ssh: remote_port: 50022 proto: tcp: \u0026quot;127.0.0.1:22\u0026quot; mstsc: remote_port: 53389 proto: tcp: \u0026quot;127.0.0.1:3389\u0026quot; web: subdomain: \u0026quot;gitlab\u0026quot; proto: http: 8081 tom@udvbud-ngrokd-c:~/ngrok-cli$  启动\ntom@udvbud-ngrokd-c:~/ngrok-cli$ ./ngrok -config=ngrok.cfg start ssh web  服务端连接测试 ubuntu@VM-0-12-ubuntu:~$ ssh tom@127.0.0.1 -p50022 tom@127.0.0.1's password: Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.13.0-38-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage 206 packages can be updated. 0 updates are security updates. Last login: Mon Apr 23 09:59:56 2018 from 127.0.0.1 tom@udvbud-ngrokd-c:~$  同时, 测试 http://gitlab.hkshop.club:8081/\n可以正常打开\n完成了一个 tunnelAdrr 下,同时做到ssh和http.\nref  Ngrok远程桌面及ssh配置 YAML在线格式化校验工具 ngrok在Windows上内网穿透（网站+远程桌面连接）配置  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ngrok/ngrok-server-install.html",
	"title": "Ngrok Server Install(搭建自己的ngrok服务器)",
	"tags": ["ngrok", "install", "network"],
	"description": "",
	"content": " 搭建自己的ngrok服务器\nenv 服务端  机器: 腾讯云主机一台 IP: 111.230.153.251 OS: ubuntu server 16.04.1\n客户端 机器: 腾讯云主机一台\n IP: 192.168.31.106\n OS: ubuntu desktop 16.04.3\n  step 主要就是参考了 搭建 ngrok 服务实现内网穿透 一文\n编译 ngrok 编译我是在服务端完成的\n首先装必要的工具：\nsudo apt-get install build-essential golang mercurial git  获取 ngrok 源码：\ngit clone https://github.com/inconshreveable/ngrok.git ngrok ### 请使用下面的地址，修复了无法访问的包地址 git clone https://github.com/tutumcloud/ngrok.git ngrok cd ngrok  生成并替换源码里默认的证书，注意域名修改为你自己的。（之后编译出来的服务端客户端会基于这个证书来加密通讯，保证了安全性）\nNGROK_DOMAIN=\u0026quot;hkshop.club\u0026quot; openssl genrsa -out base.key 2048 openssl req -new -x509 -nodes -key base.key -days 10000 -subj \u0026quot;/CN=$NGROK_DOMAIN\u0026quot; -out base.pem openssl genrsa -out server.key 2048 openssl req -new -key server.key -subj \u0026quot;/CN=$NGROK_DOMAIN\u0026quot; -out server.csr openssl x509 -req -in server.csr -CA base.pem -CAkey base.key -CAcreateserial -days 10000 -out server.crt cp base.pem assets/client/tls/ngrokroot.crt  开始编译：\nsudo make release-server release-client  如果一切正常，ngrok/bin 目录下应该有 ngrok、ngrokd 两个可执行文件。\n服务端 前面生成的 ngrokd 就是服务端程序了，指定证书、域名和端口启动它（证书就是前面生成的，注意修改域名）：\nsudo ./bin/ngrokd -tlsKey=server.key -tlsCrt=server.crt -domain=\u0026quot;hkshop.club\u0026quot; -httpAddr=\u0026quot;:8081\u0026quot; -httpsAddr=\u0026quot;:8082\u0026quot;  到这一步，ngrok 服务已经跑起来了，可以通过屏幕上显示的日志查看更多信息。httpAddr、httpsAddr 分别是 ngrok 用来转发 http、https 服务的端口，可以随意指定。ngrokd 还会开一个 4443 端口用来跟客户端通讯（可通过 -tunnelAddr=\u0026rdquo;:xxx\u0026rdquo; 指定），如果你配置了 iptables 规则，需要放行这三个端口上的 TCP 协议。\n现在，通过 https://hkshop.club:8081 和 https://hkshop.club:8082 就可以访问到 ngrok 提供的转发服务。为了使用方便，建议把域名泛解析到 VPS 上，这样能方便地使用不同子域转发不同的本地服务。\n域名配置泛解析 可以通过 ping 来检测\n➜ ~ ping hkshop.club PING hkshop.club (111.230.153.251): 56 data bytes 64 bytes from 111.230.153.251: icmp_seq=0 ttl=53 time=12.250 ms ^C --- hkshop.club ping statistics --- 1 packets transmitted, 1 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 12.250/12.250/12.250/0.000 ms ➜ ~ ping pub.hkshop.club PING pub.hkshop.club (111.230.153.251): 56 data bytes 64 bytes from 111.230.153.251: icmp_seq=0 ttl=53 time=11.128 ms 64 bytes from 111.230.153.251: icmp_seq=1 ttl=53 time=12.798 ms ^C --- pub.hkshop.club ping statistics --- 2 packets transmitted, 2 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 11.128/11.963/12.798/0.835 ms ➜ ~ ping abc.hkshop.club PING abc.hkshop.club (111.230.153.251): 56 data bytes 64 bytes from 111.230.153.251: icmp_seq=0 ttl=53 time=12.531 ms 64 bytes from 111.230.153.251: icmp_seq=1 ttl=53 time=11.356 ms ^C --- abc.hkshop.club ping statistics --- 2 packets transmitted, 2 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 11.356/11.944/12.531/0.587 ms ➜ ~  ping 出来都是同一个IP, 说明泛解析配置成功.\n我给 hkshop.club 做了泛解析，随便访问一个子域，如：http://pub.hkshop.club:8081，可以看到这样一行提示：\nTunnel pub.hkshop.club:8081 not found 这说明万事俱备，只差客户端来连了。\n客户端 因为我的客户端也是 ubuntu 所以, 我这里直接使用之前编译的 ngrok 文件就可以了.\n 如果要把 linux 上的服务映射出去，客户端就是前面生成的 ngrok 文件。但我用的是 Mac，需要指定环境变量再编一次：\n\u0026gt; sudo GOOS=darwin GOARCH=amd64 make release-server release-client \u0026gt; ``` \u0026gt; 这样在 ngrok/bin 目录下会多出来一个 darwin_amd64 目录，这里的 ngrok 文件就可以拷到 Mac 系统用了。  tom@udvbud-basic-a:~/ngrok-cli$ pwd /home/tom/ngrok-cli tom@udvbud-basic-a:~/ngrok-cli$ ls ngrok ngrok.cfg tom@udvbud-basic-a:~/ngrok-cli$ cat ngrok.cfg server_addr: \u0026ldquo;hkshop.club:4443\u0026rdquo; trust_host_root_certs: false tom@udvbud-basic-a:~/ngrok-cli$ ./ngrok -subdomain=pub -proto=http -config=ngrok.cfg 80\n写一个简单的配置文件，随意命名如 ngrok.cfg：  server_addr: \u0026ldquo;hkshop.club:4443\u0026rdquo; trust_host_root_certs: false\n指定子域、要转发的协议和端口，以及配置文件，运行客户端：  ./ngrok -subdomain=pub -proto=http -config=ngrok.cfg 80\n不出意外可以看到这样的界面，这说明已经成功连上远端服务了： ![ngrok_client](https://st.imququ.com/i/webp/static/uploads/2015/04/ngrok_client.png.webp) 现在再访问 http://pub.hkshop.club:8081，访问到的已经是我本机 80 端口上的服务了。 ### 管理界面 \u0026gt; 管理界面, 只能通过`127.0.0.1:4040`打开,而不能通过`192.168.31.106:4040`打开, 也就意味着, 应该把 ngrok 客户端放在一台有 desktop 的机器上.  tom@udvbud-basic-a:~$ telnet 127.0.0.1 4040 Trying 127.0.0.1\u0026hellip; Connected to 127.0.0.1. Escape character is \u0026lsquo;^]\u0026rsquo;. ^]\n telnet\u0026gt; quit Connection closed. tom@udvbud-basic-a:~$ telnet 192.168.31.106 4040 Trying 192.168.31.106\u0026hellip; telnet: Unable to connect to remote host: Connection refused tom@udvbud-basic-a:~$\n 上面那张 ngrok 客户端运行界面截图中，有一个 Web Interface 地址，这是 ngrok 提供的监控界面。通过这个界面可以看到远端转发过来的 http 详情，包括完整的 request/response 信息，非常方便。 ![ngrok_manager](https://st.imququ.com/i/webp/static/uploads/2015/04/ngrok_manager.png.webp) 实际上，由于 ngrok 可以转发 TCP，所以还有很多玩法，原理都一样，这里就不多写了。 ### 服务端设置为系统程序，并后台运行。 服务器在运行ngrokd时，如果关闭会话窗口，会导致服务中断，很显然这不是我们想要的结果，我们需要服务不断的在后台运行，当需要的时候在停止。 在/etc/systemd/system/目录下创建服务ngrok.service. 其中要根据自己的实际目录修改相对应的目录。 这样我们就可以了通过`systemctl start ngrok.service`启动服务。然后就可以愉快的玩耍了。  ubuntu@VM-0-12-ubuntu:/etc/systemd/system$ pwd /etc/systemd/system ubuntu@VM-0-12-ubuntu:/etc/systemd/system$ cat ngrok-e.service [Unit] Description=ngrok After=network.target\n[Service] ExecStart=/home/ubuntu/ngrok/ngrok-e/ngrok/bin/ngrokd -tlsKey=/home/ubuntu/ngrok/ngrok-e/ngrok/server.key -tlsCrt=/home/ubuntu/ngrok/ngrok-e/ngrok/server.crt -domain=\u0026ldquo;hkshop.club\u0026rdquo; -httpAddr=\u0026rdquo;:8081\u0026rdquo; -httpsAddr=\u0026rdquo;:8082\u0026rdquo;\n[Install] WantedBy=multi-user.target ubuntu@VM-0-12-ubuntu:/etc/systemd/system$\nubuntu@VM-0-12-ubuntu:/etc/systemd/system$ sudo systemctl start ngrok-e.service ubuntu@VM-0-12-ubuntu:/etc/systemd/system$ sudo systemctl status ngrok-e.service ● ngrok-e.service - ngrok Loaded: loaded (/etc/systemd/system/ngrok-e.service; disabled; vendor preset: enabled) Active: active (running) since Sat 2018-04-21 08:25:50 CST; 2s ago Main PID: 19361 (ngrokd) Tasks: 3 Memory: 1.1M CPU: 3ms CGroup: /system.slice/ngrok-e.service └─19361 /home/ubuntu/ngrok/ngrok-e/ngrok/bin/ngrokd -tlsKey=/home/ubuntu/ngrok/ngrok-e/ngrok/server.key -tlsCrt=/home/ubuntu/ngrok/ngrok-e/ngrok/server.crt -domain=hkshop.club -httpAddr=:8081 -\nApr 21 08:25:50 VM-0-12-ubuntu systemd[1]: Started ngrok. Apr 21 08:25:50 VM-0-12-ubuntu ngrokd[19361]: [08:25:50 CST 2018/04/21] INFO [registry] [tun] No affinity cache specified Apr 21 08:25:50 VM-0-12-ubuntu ngrokd[19361]: [08:25:50 CST 2018/04/21] INFO Listening for public http connections on [::]:8081 Apr 21 08:25:50 VM-0-12-ubuntu ngrokd[19361]: [08:25:50 CST 2018/04/21] INFO Listening for public https connections on [::]:8082 Apr 21 08:25:50 VM-0-12-ubuntu ngrokd[19361]: [08:25:50 CST 2018/04/21] INFO Listening for control and proxy connections on [::]:4443 Apr 21 08:25:50 VM-0-12-ubuntu ngrokd[19361]: [08:25:50 CST 2018/04/21] INFO [metrics] Reporting every 30 seconds ubuntu@VM-0-12-ubuntu:/etc/systemd/system$\n ### 注意事项 #### 客户端ngrok.cfg中server_addr后的值必须严格与-domain以及证书中的NGROK_BASE_DOMAIN相同，否则Server端就会出现如下错误日志：  [03/13/15 09:55:46] [INFO] [tun:15dd7522] New connection from 54.149.100.42:38252 [03/13/15 09:55:46] [DEBG] [tun:15dd7522] Waiting to read message [03/13/15 09:55:46] [WARN] [tun:15dd7522] Failed to read message: remote error: bad certificate [03/13/15 09:55:46] [DEBG] [tun:15dd7522] Closing\n #### 域名一直不能访问 如果域名一直不能访问 需要配置DNS 两个A记录 泛解析*和@这样创建的域名才能访问你的本地配置的地址 #### make release-server时发现每次都在gopkg时没反应 注意在make release-server时发现每次都在gopkg时没反应，后来查到是Git版本太老了 ，安装git (`yum install git`). 记得按上述方法安装git前,先运行 删除旧版本(`yum remove git`)。 #### 找不到 sync.Pool 在编译生成的时候执行  GOOS=windows GOARCH=386 make release-server ``` 生成服务器端一切正常，可是生成客户端的时候一直报错，说找不到 sync.Pool。后来发现是GO语言软件版本太低了，使用1.3以上版本就不会有问题。\nTODO 把一级域名修改成二级域名 让用户通过 ***.ngrok.hkshop.club 的方式访问内网服务\n多个ngrok服务 ref  搭建 ngrok 服务实现内网穿透 一分钟实现内网穿透（ngrok服务器搭建） 搭建自己的ngrok服务 小米球ngrok 10分钟教你搭建自己的ngrok服务器 最新图解 利用 ngrok 免费内网穿透部署 微信开发 调试环境 如何让外网访问到本地内网-ngrok内网穿透免费服务器  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-install-uwsgi.html",
	"title": "Python Install Uwsgi",
	"tags": ["pip", "python"],
	"description": "",
	"content": " env  IP: home, 192.168.31.109 OS: ubuntu, 16.04.03  step pip install uwsgi==2.0.17时出错: lto1: fatal error: bytecode stream generated with LTO version 6.0 instead of the expected 4.1 (saleor-a-1) tom@saleor-a:~/saleor$ pip install uwsgi==2.0.17 _offload/offload.o plugins/router_memcached/router_memcached.o plugins/router_redis/router_redis.o plugins/router_hash/router_hash.o plugins/router_expires/expires.o plugins/router_metrics/plugin.o plugins/transformation_template/tt.o plugins/stats_pusher_socket/plugin.o -lpthread -lm -rdynamic -ldl -L/home/tom/anaconda3/lib -lpcre -L/home/tom/anaconda3/lib -lxml2 -L/home/tom/anaconda3/lib -lz -L/home/tom/anaconda3/lib -llzma -L/home/tom/anaconda3/lib -L/home/tom/anaconda3/lib -licui18n -licuuc -licudata -lm -ldl -lpthread -ldl -lutil -lrt -lm /home/tom/anaconda3/lib/python3.6/config-3.6m-x86_64-linux-gnu/libpython3.6m.a -lutil -lcrypt lto1: fatal error: bytecode stream generated with LTO version 6.0 instead of the expected 4.1 compilation terminated. lto-wrapper: fatal error: gcc returned 1 exit status compilation terminated. /home/tom/anaconda3/compiler_compat/ld: error: lto-wrapper failed collect2: error: ld returned 1 exit status *** error linking uWSGI *** ---------------------------------------- Command \u0026quot;/home/tom/.virtualenvs/saleor-a-1/bin/python -u -c \u0026quot;import setuptools, tokenize;__file__='/tmp/pip-install-it5mt8_t/uwsgi/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\u0026quot; install --record /tmp/pip-record-dnakrkb4/install-record.txt --single-version-externally-managed --compile --install-headers /home/tom/.virtualenvs/saleor-a-1/include/site/python3.6/uwsgi\u0026quot; failed with error code 1 in /tmp/pip-install-it5mt8_t/uwsgi/ (saleor-a-1) tom@saleor-a:~/saleor$   \u0026mdash;我是分割线\u0026mdash;\n 后来, 在某天, 我又给找到了 Ubuntu16.04上使用Anaconda3的Python3.6的pip安装UWSGI报错解决办法 一文, 测试了一下. 成功了. 我了个去呀\u0026hellip;\n 原因是Ubuntu系统的gcc版本问题，我安装时本机的gcc版本是5.4，然后我把gcc版本修改成了4.7，重新使用pip install uwsgi，完美解决问题。\n安装gcc4.7:sudo apt install gcc-4.7 -y\n修改系统默认的gcc版本：https://blog.csdn.net/jacke121/article/details/54565281\n 操作一下\n(saleor-a-1) tom@saleor-a:~/saleor$ sudo apt install gcc-4.7 -y (saleor-a-1) tom@saleor-a:~/saleor$ ls /usr/bin/gcc* -l lrwxrwxrwx 1 root root 5 Feb 11 2016 /usr/bin/gcc -\u0026gt; gcc-5 -rwxr-xr-x 1 root root 578880 Jan 19 2016 /usr/bin/gcc-4.7 -rwxr-xr-x 1 root root 915736 Feb 6 12:31 /usr/bin/gcc-5 lrwxrwxrwx 1 root root 8 Feb 11 2016 /usr/bin/gcc-ar -\u0026gt; gcc-ar-5 -rwxr-xr-x 1 root root 22912 Jan 19 2016 /usr/bin/gcc-ar-4.7 -rwxr-xr-x 1 root root 31136 Feb 6 12:31 /usr/bin/gcc-ar-5 lrwxrwxrwx 1 root root 8 Feb 11 2016 /usr/bin/gcc-nm -\u0026gt; gcc-nm-5 -rwxr-xr-x 1 root root 22912 Jan 19 2016 /usr/bin/gcc-nm-4.7 -rwxr-xr-x 1 root root 31136 Feb 6 12:31 /usr/bin/gcc-nm-5 lrwxrwxrwx 1 root root 12 Feb 11 2016 /usr/bin/gcc-ranlib -\u0026gt; gcc-ranlib-5 -rwxr-xr-x 1 root root 22912 Jan 19 2016 /usr/bin/gcc-ranlib-4.7 -rwxr-xr-x 1 root root 31136 Feb 6 12:31 /usr/bin/gcc-ranlib-5 (saleor-a-1) tom@saleor-a:~/saleor$ sudo rm -rf /usr/bin/gcc (saleor-a-1) tom@saleor-a:~/saleor$ sudo ln -s /usr/bin/gcc-4.7 /usr/bin/gcc (saleor-a-1) tom@saleor-a:~/saleor$ ls /usr/bin/gcc* -l lrwxrwxrwx 1 root root 16 Apr 23 23:32 /usr/bin/gcc -\u0026gt; /usr/bin/gcc-4.7 -rwxr-xr-x 1 root root 578880 Jan 19 2016 /usr/bin/gcc-4.7 -rwxr-xr-x 1 root root 915736 Feb 6 12:31 /usr/bin/gcc-5 lrwxrwxrwx 1 root root 8 Feb 11 2016 /usr/bin/gcc-ar -\u0026gt; gcc-ar-5 -rwxr-xr-x 1 root root 22912 Jan 19 2016 /usr/bin/gcc-ar-4.7 -rwxr-xr-x 1 root root 31136 Feb 6 12:31 /usr/bin/gcc-ar-5 lrwxrwxrwx 1 root root 8 Feb 11 2016 /usr/bin/gcc-nm -\u0026gt; gcc-nm-5 -rwxr-xr-x 1 root root 22912 Jan 19 2016 /usr/bin/gcc-nm-4.7 -rwxr-xr-x 1 root root 31136 Feb 6 12:31 /usr/bin/gcc-nm-5 lrwxrwxrwx 1 root root 12 Feb 11 2016 /usr/bin/gcc-ranlib -\u0026gt; gcc-ranlib-5 -rwxr-xr-x 1 root root 22912 Jan 19 2016 /usr/bin/gcc-ranlib-4.7 -rwxr-xr-x 1 root root 31136 Feb 6 12:31 /usr/bin/gcc-ranlib-5 (saleor-a-1) tom@saleor-a:~/saleor$  再次安装\n(saleor-a-1) tom@saleor-a:~/saleor$ pip install uwsgi==2.0.17  成功了\u0026hellip;\n下面是心路历程, 呵呵, 可忽略 这个问题, 找了下面几个网站, 但是, 还没有深入进去,\n https://techoverflow.net/2017/06/22/how-to-resolve-fatal-error-bytecode-stream-generated-with-lto-version-instead-of-the-expected/ https://segmentfault.com/q/1010000002459736 https://github.com/numenta/nupic/issues/2102 https://github.com/numenta/nupic/issues/1699  后来,又 找到官网, 使用另一种安装方式作为替换(这个方法,没有成功)\n效仿官方WSGIquickstart安装方式之\ncurl https://uwsgi.it/install | bash -s pypy /tmp/uwsgi  而得到\ncurl https://uwsgi.it/install | bash -s pypy /home/tom/.virtualenvs/saleor-a-1/bin/uwsgi  但是, 还是没有安装成功.\n经验 不认真看bug日志的程序员,不是一个好程序员\u0026hellip;\nref  Ubuntu16.04上使用Anaconda3的Python3.6的pip安装UWSGI报错解决办法 官方WSGIquickstart  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-change-password.html",
	"title": "gitlab修改密码",
	"tags": ["gitlab"],
	"description": "",
	"content": " gitlab修改密码\nenv  IP: 192.168.31.169 OS: ubuntu-16.04 gitlab: 10.6.4  step root@gitlab:~# sudo gitlab-rails console production Warning: fuzzy message was ignored. : msgid '\u0026lt;strong\u0026gt;Removes\u0026lt;/strong\u0026gt; source branch' Warning: fuzzy message was ignored. : msgid 'A new branch will be created in your fork and a new merge request will be started.' Warning: fuzzy message was ignored. : msgid 'A user with write access to the source branch selected this option' Warning: fuzzy message was ignored. : msgid 'All features are enabled for blank projects, from templates, or when importing, but you can disable them afterward in the project settings.' Warning: fuzzy message was ignored. : msgid 'Allow edits from maintainers.' Warning: fuzzy message was ignored. : msgid 'Branches|Active' Warning: fuzzy message was ignored. : msgid 'Branches|Active branches' Warning: fuzzy message was ignored. : msgid 'Branches|All' Warning: fuzzy message was ignored. : msgid 'Branches|Overview' Warning: fuzzy message was ignored. : msgid 'Branches|Protected branches can be managed in %{project_settings_link}.' Warning: fuzzy message was ignored. : msgid 'Branches|Show active branches' Warning: fuzzy message was ignored. : msgid 'Branches|Show all branches' Warning: fuzzy message was ignored. : msgid 'Branches|Show more active branches' Warning: fuzzy message was ignored. : msgid 'Branches|Show more stale branches' Warning: fuzzy message was ignored. : msgid 'Branches|Show overview of the branches' Warning: fuzzy message was ignored. : msgid 'Branches|Show stale branches' Warning: fuzzy message was ignored. : msgid 'Branches|Stale' Warning: fuzzy message was ignored. : msgid 'Branches|Stale branches' Warning: fuzzy message was ignored. : msgid 'ClusterIntegration|Learn more about security configuration' Warning: fuzzy message was ignored. : msgid 'ClusterIntegration|Security' Warning: fuzzy message was ignored. : msgid 'Contribution' Warning: fuzzy message was ignored. : msgid 'Done' Warning: fuzzy message was ignored. : msgid 'Failed' Warning: fuzzy message was ignored. : msgid 'Forking in progress' Warning: fuzzy message was ignored. : msgid 'If your HTTP repository is not publicly accessible, add authentication information to the URL: \u0026lt;code\u0026gt;https://username:password@gitlab.company.com/group/project.git\u0026lt;/code\u0026gt;.' Warning: fuzzy message was ignored. : msgid 'Import all repositories' Warning: fuzzy message was ignored. : msgid 'Label' Warning: fuzzy message was ignored. : msgid 'Labels can be applied to %{features}. Group labels are available for any project within the group.' Warning: fuzzy message was ignored. : msgid 'Labels|Promote Label' Warning: fuzzy message was ignored. : msgid 'Labels|Promote label %{labelTitle} to Group Label?' Warning: fuzzy message was ignored. : msgid 'Milestones|Promote %{milestoneTitle} to group milestone?' Warning: fuzzy message was ignored. : msgid 'Not available for private projects' Warning: fuzzy message was ignored. : msgid 'Not available for protected branches' Warning: fuzzy message was ignored. : msgid 'Personal Access Token' Warning: fuzzy message was ignored. : msgid 'Pipelines|CI Lint' Warning: fuzzy message was ignored. : msgid 'Pipelines|Clear Runner Caches' Warning: fuzzy message was ignored. : msgid 'Pipelines|Loading Pipelines' Warning: fuzzy message was ignored. : msgid 'Pipelines|Project cache successfully reset.' Warning: fuzzy message was ignored. : msgid 'Pipelines|Run Pipeline' Warning: fuzzy message was ignored. : msgid 'Pipelines|Something went wrong while cleaning runners cache.' Warning: fuzzy message was ignored. : msgid 'Pipelines|There are currently no %{scope} pipelines.' Warning: fuzzy message was ignored. : msgid 'Pipelines|There are currently no pipelines.' Warning: fuzzy message was ignored. : msgid 'Pipelines|This project is not currently set up to run pipelines.' Warning: fuzzy message was ignored. : msgid 'PrometheusService|Common metrics' Warning: fuzzy message was ignored. : msgid 'Promote' Warning: fuzzy message was ignored. : msgid 'Scheduled' Warning: fuzzy message was ignored. : msgid 'Search' Warning: fuzzy message was ignored. : msgid 'Started' Warning: fuzzy message was ignored. : msgid 'You are going to remove %{project_full_name}. Removed project CANNOT be restored! Are you ABSOLUTELY sure?' Warning: fuzzy message was ignored. : msgid 'You are going to transfer %{project_full_name} to another owner. Are you ABSOLUTELY sure?' Warning: fuzzy message was ignored. : msgid 'You are on a read-only GitLab instance.' Warning: fuzzy message was ignored. : msgid 'Your changes can be committed to %{branch_name} because a merge request is open.' Warning: fuzzy message was ignored. : msgid 'mrWidget|Allows edits from maintainers' Loading production environment (Rails 4.2.10) irb(main):001:0\u0026gt; irb(main):012:0\u0026gt; user=User.where(name: \u0026quot;tom\u0026quot;).first =\u0026gt; nil irb(main):013:0\u0026gt; user.password=12345678 NoMethodError: undefined method `password=' for nil:NilClass from (irb):13 from /opt/gitlab/embedded/lib/ruby/gems/2.3.0/gems/railties-4.2.10/lib/rails/commands/console.rb:110:in `start' from /opt/gitlab/embedded/lib/ruby/gems/2.3.0/gems/railties-4.2.10/lib/rails/commands/console.rb:9:in `start' from /opt/gitlab/embedded/lib/ruby/gems/2.3.0/gems/railties-4.2.10/lib/rails/commands/commands_tasks.rb:68:in `console' from /opt/gitlab/embedded/lib/ruby/gems/2.3.0/gems/railties-4.2.10/lib/rails/commands/commands_tasks.rb:39:in `run_command!' from /opt/gitlab/embedded/lib/ruby/gems/2.3.0/gems/railties-4.2.10/lib/rails/commands.rb:17:in `\u0026lt;top (required)\u0026gt;' from bin/rails:9:in `require' from bin/rails:9:in `\u0026lt;main\u0026gt;' irb(main):014:0\u0026gt; user=User.where(name: \u0026quot;root\u0026quot;).first =\u0026gt; nil irb(main):015:0\u0026gt; user=User.where(name: \u0026quot;tom\u0026quot;).first =\u0026gt; nil irb(main):016:0\u0026gt; user = User.where(email: 'zengyl@jiaolongchuhai.com').first =\u0026gt; #\u0026lt;User id:2 @tom\u0026gt; irb(main):017:0\u0026gt; user.password = 'yourpassword' =\u0026gt; \u0026quot;yourpassword\u0026quot; irb(main):018:0\u0026gt; user.save! Enqueued ActionMailer::DeliveryJob (Job ID: d7bca2e5-0408-4509-9933-624e67c47358) to Sidekiq(mailers) with arguments: \u0026quot;DeviseMailer\u0026quot;, \u0026quot;password_change\u0026quot;, \u0026quot;deliver_now\u0026quot;, gid://gitlab/User/2 =\u0026gt; true irb(main):019:0\u0026gt; user.save! =\u0026gt; true irb(main):020:0\u0026gt; exit root@gitlab:~#  发现了吧,\n 通过邮件,可以找到用户,从而修改密码, 而通过用户名, 却找不到用户,从而修改不了密码.  ref  gitlab忘记密码如何重置  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-cn.html",
	"title": "Gitlab汉化",
	"tags": ["gitlab", "git"],
	"description": "",
	"content": " 对gitlab进行汉化\nenv IP: 192.168.31.148 OS: ubuntu-14.04.5 gitlab: 10.6.4\nstep mkdir xhang \u0026amp;\u0026amp; cd xhang git clone https://gitlab.com/xhang/gitlab.git cd gitlab/ git fetch gitlab_version=$(sudo cat /opt/gitlab/embedded/service/gitlab-rails/VERSION) echo ${gitlab_version} git diff v${gitlab_version} v${gitlab_version}-zh \u0026gt; ../${gitlab_version}-zh.diff cd .. sudo gitlab-ctl stop sudo patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 \u0026lt; 10.6.4-zh.diff sudo gitlab-ctl start sudo gitlab-ctl reconfigure telnet 192.168.31.148 7890  ref  汉化指南，基于 Larry Li 版汉化指南 修改  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-install-base-ubuntu14.04.html",
	"title": "Gitlab Install Base Ubuntu14.04",
	"tags": ["gitlab", "ubuntu"],
	"description": "",
	"content": " gitlab在ubuntu14.04和ubuntu16.04上安装\nenv IP: 192.168.31.148 OS: ubuntu-14.04.5 gitlab: 10.6.4\nenv2 IP: 192.168.31.169 OS: ubuntu-16.04 gitlab: 10.6.4\nstep 按照 清华大学 Gitlab Community Edition 镜像使用帮助 安装就可以了.\n一定要注意系统版本\n修改IP, sudo vi /etc/gitlab/gitlab.rb修改下面内容\nexternal_url 'http://192.168.31.148:7890'  重启\nsudo gitlab-ctl reconfigure  浏览器打开 http://192.168.31.148:7890 修改密码,重新登陆.\nfaq libstdc++.so.6: version `GLIBCXX_3.4.21\u0026rsquo; not found strings /home/kzl/anaconda2/bin/../lib/libstdc++.so.6 | grep GLIBCXX  可以看到所有的安装的 glibc++ 版本, 这里确实是没有3.4.21版本\n后来才发现,我安装的时候,没有选择正确的系统版本(最先选择了ubuntu16.04,应该先看一下系统版本,然后选择 ubuntu14.04)\nref  Gitlab Community Edition 镜像使用帮助 version `GLIBCXX_3.4.21\u0026rsquo; not found 解决办法 ImportError: /home/kzl/anaconda2/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.21\u0026rsquo; not found  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/saleor/saleor-faq.html",
	"title": "Saleor",
	"tags": ["shop"],
	"description": "",
	"content": " 关于 saleor 项目\nenv  IP: home, 192.168.31.109 OS: ubuntu, 16.04.03  step FAQ-1 pip install uwsgi==2.0.17时出错: lto1: fatal error: bytecode stream generated with LTO version 6.0 instead of the expected 4.1 见 python-install-uwsgi 一文.\nFAQ-2 这一小节是一个大大的错误, 可直接看下一小节\nexport SECRET_KEY='**********' export DATABASE_URL='*********' sudo vi /etc/postgresql/9.6/main/pg_hba.conf ls /etc/init.d/postgresql sudo /etc/init.d/postgresql reload createuser -P -s -e saleor # 报错 createuser -P -s -e saleor -U postgres python manage.py migrate # 报错 which createdb createdb saleorBillions # 报错 createdb saleorBillions -U postgres python manage.py migrate # 报错  还是报错,如下\n(saleor-a-1) tom@saleor-a:~/saleor$ python manage.py migrate Traceback (most recent call last): File \u0026quot;manage.py\u0026quot;, line 10, in \u0026lt;module\u0026gt; execute_from_command_line(sys.argv) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/__init__.py\u0026quot;, line 371, in execute_from_command_line utility.execute() File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/__init__.py\u0026quot;, line 317, in execute settings.INSTALLED_APPS File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/conf/__init__.py\u0026quot;, line 56, in __getattr__ self._setup(name) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/conf/__init__.py\u0026quot;, line 43, in _setup self._wrapped = Settings(settings_module) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/conf/__init__.py\u0026quot;, line 106, in __init__ mod = importlib.import_module(self.SETTINGS_MODULE) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/importlib/__init__.py\u0026quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 994, in _gcd_import File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 971, in _find_and_load File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 955, in _find_and_load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 665, in _load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap_external\u0026gt;\u0026quot;, line 678, in exec_module File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 219, in _call_with_frames_removed File \u0026quot;/home/tom/saleor/saleor/settings.py\u0026quot;, line 42, in \u0026lt;module\u0026gt; conn_max_age=600)} File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/dj_database_url.py\u0026quot;, line 53, in config config = parse(s, engine, conn_max_age) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/dj_database_url.py\u0026quot;, line 110, in parse engine = SCHEMES[url.scheme] if engine is None else engine KeyError: '' (saleor-a-1) tom@saleor-a:~/saleor$  走到这里, 说明已经要深入到代码内部了,我感到可怕\u0026hellip;\n重新梳理一下..\n发现, 原来在项目中, 有一个 common.env 文件, 我去, 原来, 配置文件在这里\n去除原来的配置 去除 DATABASE_URL\n(saleor-a-1) tom@saleor-a:~/saleor$ unset DATABASE_URL (saleor-a-1) tom@saleor-a:~/saleor$ echo $DATABASE_URL (saleor-a-1) tom@saleor-a:~/saleor$  开始吧 创建database: saleor (saleor-a-1) tom@saleor-a:~/saleor$ createdb saleor -U postgres perl: warning: Setting locale failed. perl: warning: Please check that your locale settings: LANGUAGE = \u0026quot;en_US:en\u0026quot;, LC_ALL = (unset), LC_PAPER = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_ADDRESS = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_MONETARY = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_NUMERIC = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_TELEPHONE = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_IDENTIFICATION = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_MEASUREMENT = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_TIME = \u0026quot;zh_CN.UTF-8\u0026quot;, LC_NAME = \u0026quot;zh_CN.UTF-8\u0026quot;, LANG = \u0026quot;en_US.UTF-8\u0026quot; are supported and installed on your system. perl: warning: Falling back to a fallback locale (\u0026quot;en_US.UTF-8\u0026quot;). (saleor-a-1) tom@saleor-a:~/saleor$  修改 common.env 文件 tom@saleor-a:~/saleor$ cat common.env DATABASE_URL=postgres://saleor:saleor@db/saleor DEFAULT_FROM_EMAIL=noreply@example.com ELASTICSEARCH_URL=http://search:9200 OPENEXCHANGERATES_API_KEY CACHE_URL=redis://redis:6379/0 CELERY_BROKER_URL=redis://redis:6379/1 SECRET_KEY=i2aru5o8MJrN4yT7 JWT_VERIFY_EXPIRATION=True tom@saleor-a:~/saleor$  再次 python manage.py migrate (saleor-a-1) tom@saleor-a:~/saleor$ python manage.py migrate System check identified some issues: WARNINGS: saleor.W001: Session caching cannot work with locmem backend HINT: User sessions need to be globally shared, use a cache server like Redis. Operations to perform: Apply all migrations: account, auth, cart, contenttypes, discount, django_celery_results, django_prices_openexchangerates, impersonate, menu, order, page, product, sessions, shipping, site, sites, social_django Running migrations: Applying contenttypes.0001_initial... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0001_initial... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying account.0001_initial... OK Applying account.0002_auto_20150907_0602... OK Applying account.0003_auto_20151104_1102... OK Applying account.0004_auto_20160114_0419... OK Applying account.0005_auto_20160205_0651... OK Applying account.0006_auto_20160829_0819... OK Applying account.0007_auto_20161115_0940... OK Applying account.0008_auto_20161115_1011... OK Applying account.0009_auto_20170206_0407... OK Applying account.0010_auto_20170919_0839... OK Applying account.0011_auto_20171110_0552... OK Applying account.0012_auto_20171117_0846... OK ... ... ... Applying social_django.0003_alter_email_max_length... OK Applying social_django.0004_auto_20160423_0400... OK Applying social_django.0005_auto_20160727_2333... OK Applying social_django.0006_partial... OK Applying social_django.0007_code_timestamp... OK Applying social_django.0008_partial_timestamp... OK (saleor-a-1) tom@saleor-a:~/saleor$  到这里, 说明我们是真的安装完成了.\nFAQ-3, 再次启动 再次启动时, 报The SECRET_KEY setting must not be empty. 如下.\n(saleor-a-1) tom@saleor-a:~/saleor$ python manage.py runserver Traceback (most recent call last): File \u0026quot;manage.py\u0026quot;, line 10, in \u0026lt;module\u0026gt; execute_from_command_line(sys.argv) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/__init__.py\u0026quot;, line 371, in execute_from_command_line utility.execute() File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/__init__.py\u0026quot;, line 365, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/base.py\u0026quot;, line 288, in run_from_argv self.execute(*args, **cmd_options) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/commands/runserver.py\u0026quot;, line 61, in execute super().execute(*args, **options) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/base.py\u0026quot;, line 335, in execute output = self.handle(*args, **options) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/core/management/commands/runserver.py\u0026quot;, line 70, in handle if not settings.DEBUG and not settings.ALLOWED_HOSTS: File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/conf/__init__.py\u0026quot;, line 56, in __getattr__ self._setup(name) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/conf/__init__.py\u0026quot;, line 43, in _setup self._wrapped = Settings(settings_module) File \u0026quot;/home/tom/.virtualenvs/saleor-a-1/lib/python3.6/site-packages/django/conf/__init__.py\u0026quot;, line 125, in __init__ raise ImproperlyConfigured(\u0026quot;The SECRET_KEY setting must not be empty.\u0026quot;) django.core.exceptions.ImproperlyConfigured: The SECRET_KEY setting must not be empty. (saleor-a-1) tom@saleor-a:~/saleor$  再次启动时, 要先运行, export SECRET_KEY='i2aru5o8MJrN4yT7'\n(saleor-a-1) tom@saleor-a:~/saleor$ export SECRET_KEY='i2aru5o8MJrN4yT7' (saleor-a-1) tom@saleor-a:~/saleor$ python manage.py runserver Performing system checks... System check identified some issues: WARNINGS: saleor.W001: Session caching cannot work with locmem backend HINT: User sessions need to be globally shared, use a cache server like Redis. System check identified 1 issue (0 silenced). April 23, 2018 - 23:18:58 Django version 2.0.3, using settings 'saleor.settings' Starting development server at http://127.0.0.1:8000/ Quit the server with CONTROL-C. (saleor-a-1) tom@saleor-a:~/saleor$  ref  saleor-installation-linux 解决createdb: could not connect to database postgres: FATAL: Peer authentication failed for user \u0026ldquo;postgres\u0026rdquo;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/command-github.html",
	"title": "Github",
	"tags": ["github", "command"],
	"description": "",
	"content": " 建立 github.io 工程页面 建立项目主页\n 新建一个repo，repo名字随意。 点进repo主页然后点击右面的Settings，页面往下拉到GitHub Pages部分，选择Launch automatic page generator\u0026gt;Continue to layouts\u0026gt;Publish page即可.（由于大部分情况下并不用默认的页面和样式，所以这里不需要太纠结于内容编辑）   这样一个项目主页就建立完成了，此时可以用.github.io/访问到了。\n 比如, 我这里有一个repo(如cheatsheets)是可以作为一个项目主页, 然后项目主页建立完成了后，此时可以用.github.io/访问到了\u0026hellip;\nref  单个GitHub帐号下添加多个GitHub Pages的相关问题  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-ssh-github.html",
	"title": "Mac上SSH-Key对应多个github账号",
	"tags": ["mac", "ssh", "github"],
	"description": "",
	"content": " Mac 上SSH-Key对应多个github账号\n当然, 也不单是github帐号, gitlab或者其它账号都是可以的哟\u0026hellip;\n前言 因为最近在其他公司帮忙，而其公司用的是他们自己的git服务器，自己本公司又有自己的git服务器，然后自己还用github，造成三个git账号的都要ssh-key，而在网上一搜生成ssh-key的方法都是直接就给你弄全局了，然后肯定又会覆盖原有的ssh-key，所以查了一下关于同机器多账号的ssh-key配置，在此记录一下。\n操作步骤 如果我们Mac上面已经有了ssh-key再创建ssh-key的话，需要给我们的ssh-key文件取不同的名字，默认是id_rsa，如果不重新起名的话，会把原有的给覆盖掉。\n1.新建ssh-key\u0026amp;重新命名 //切换到ssh目录 cd ~/.ssh //新建ssh-key ssh-keygen -t rsa -C \u0026quot;mywork@email.com\u0026quot; //为新建的ssh-key重新命名 Enter file in which to save the key (/Users/bombvote-zql/.ssh/id_rsa):id_ras_bill_github  2.新ssh-key添加到ssh agent中 因为默认只读取id_rsa，为了让SSH识别新的私钥，需将其添加到SSH agent中：\nssh-add ~/.ssh/id_ras_bill_github  3.配置 将不同账号的工程图服务器与ssh-key关联 #thub user(first@email.com) Host github1 HostName git.some.com/ User git IdentityFile /Users/bombvote-zql/.ssh/id_rsa # second user(second@email.com) # 建一个github别名，新建的帐号使用这个别名做克隆和更新 Host github2 HostName github.com User git IdentityFile /Users/bombvote-zql/.ssh/id_ras_bill_github  4.在git服务器上添加公钥 vim ~/.ssh/id_rsa_bill_github.pub  然后将内容复制添加到服务器账号里面 其规则就是：从上至下读取config的内容，在每个Host下寻找对应的私钥。这里将GitHub SSH仓库地址中的git@github.com替换成新建的Host别名如：github2，那么原地址是：git@github.com:username/Mywork.git，替换后应该是：github2:username/Mywork.git.\n测试一下：\nssh -T github2 Hi 0xJoker! You've successfully authenticated, but GitHub does not provide shell  链接：https://www.jianshu.com/p/65303f8e5f10\nstep 看一下我的配置, 以及一个内部gitlab的仓库, 可能你就明白了\u0026hellip;\n其实可以理解成 Host(如:jlch_gitlab_169_root) 代替 User@HostName (如:git@192.168.31.169) 整合起来就是: jlch_gitlab_169_root:root/test.git 代替 git@192.168.31.169:root/test.git\n➜ .ssh pwd /Users/tom/.ssh ➜ .ssh ls authorized_keys id_rsa.pub id_rsa_jlch_gitlab_148_root.pub id_rsa_jlch_gitlab_169_root.pub tomMacAir cdn240 id_rsa_jlch_gitlab_169_a id_rsa_jlch_gitlab_a config id_rsa_jlch_gitlab_169_a.pub id_rsa_jlch_gitlab_a.pub id_rsa id_rsa_jlch_gitlab_148_root id_rsa_jlch_gitlab_169_root known_hosts ➜ .ssh cat config Host jlch_gitlab_148_root HostName 192.168.31.148 User git IdentityFile /Users/tom/.ssh/id_rsa_jlch_gitlab_148_root Host jlch_gitlab_148_tom HostName 192.168.31.148 User git IdentityFile /Users/tom/.ssh/id_rsa_jlch_gitlab_a Host jlch_gitlab_169_root HostName 192.168.31.169 User git IdentityFile /Users/tom/.ssh/id_rsa_jlch_gitlab_169_root Host jlch_gitlab_169_tom HostName 192.168.31.169 User git IdentityFile /Users/tom/.ssh/id_rsa_jlch_gitlab_169_a ➜ .ssh cd ~/gitlab-test/169-root-test ➜ 169-root-test git:(master) git remote -v origin\tjlch_gitlab_169_root:root/test.git (fetch) origin\tjlch_gitlab_169_root:root/test.git (push) ➜ 169-root-test git:(master)  ref  Mac 上SSH-Key对应多个git账号  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-gitment.html",
	"title": "Hugo Gitment",
	"tags": ["hugo"],
	"description": "",
	"content": " Hugo 集成 Gitment 评论插件\nref  Hugo 集成 Gitment 评论插件  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/python.html",
	"title": "Python",
	"tags": ["python", "command"],
	"description": "",
	"content": " python shell 中如何实现清屏 方法1\nctrl+L\n方法2\nimport os i=os.system('cls')  查模块版本\n(django1.11) ➜ example_i18n_polymorphic git:(master) ✗ python -m django --version 1.11 (django1.11) ➜ example_i18n_polymorphic git:(master) ✗  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/python.html",
	"title": "Python",
	"tags": ["resource", "python"],
	"description": "",
	"content": " 金角大王等待唐僧的日子\nipython - bpython 一直用的是 ipython，感觉比 bpython 好些，\n关于它们之间对比可以参看 http://stackoverflow.com/questions/4232923/ipython-or-bpython\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/kubernetes.html",
	"title": "Kubernetes Resource",
	"tags": ["kubernetes", "resource"],
	"description": "",
	"content": " docker8.com/\n k8s.docker8.com/\n feiskyer/kubernetes-handbook\n ctolib.com-kubernetes-handbook/introduction\n ctolib.com-kubernetes-handbook\n magicsandbox,边做边学K8S,Learn Kubernetes by doing.\n KeKe-Li/kubernetes-tutorial\n StudyXX/google-containers\n  https://github.com/gjmzj/kubeasz\nrootsongjc 的 kubernetes-vagrant-centos-cluster\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-heapster-install.html",
	"title": "Kubernetes Heapster Install",
	"tags": ["kubernetes", "heapster"],
	"description": "",
	"content": " env 192.168.31.120 master\nstep root@km:~/heapster# git remote -v origin\thttps://github.com/kubernetes/heapster.git (fetch) origin\thttps://github.com/kubernetes/heapster.git (push) root@km:~/heapster# git status On branch master Your branch is up-to-date with 'origin/master'. Changes not staged for commit: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git checkout -- \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) modified: deploy/kube-config/influxdb/grafana.yaml modified: deploy/kube-config/influxdb/heapster.yaml modified: deploy/kube-config/influxdb/influxdb.yaml no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) root@km:~/heapster# git diff deploy/kube-config/influxdb/grafana.yaml diff --git a/deploy/kube-config/influxdb/grafana.yaml b/deploy/kube-config/influxdb/grafana.yaml index de98b65..d06c665 100644 --- a/deploy/kube-config/influxdb/grafana.yaml +++ b/deploy/kube-config/influxdb/grafana.yaml @@ -65,8 +65,10 @@ spec: # type: LoadBalancer # You could also use NodePort to expose the service at a randomly-generated port # type: NodePort + type: NodePort ports: - port: 80 targetPort: 3000 + nodePort: 30002 selector: k8s-app: grafana root@km:~/heapster# git diff deploy/kube-config/influxdb/heapster.yaml diff --git a/deploy/kube-config/influxdb/heapster.yaml b/deploy/kube-config/influxdb/heapster.yaml index 9d45dea..0e92361 100644 --- a/deploy/kube-config/influxdb/heapster.yaml +++ b/deploy/kube-config/influxdb/heapster.yaml @@ -25,7 +25,7 @@ spec: command: - /heapster - --source=kubernetes:https://kubernetes.default - - --sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086 + - --sink=influxdb:http://monitoring-influxdb.kube-system.svc.cluster.local:8086 --- apiVersion: v1 kind: Service root@km:~/heapster# git diff deploy/kube-config/influxdb/influxdb.yaml diff --git a/deploy/kube-config/influxdb/influxdb.yaml b/deploy/kube-config/influxdb/influxdb.yaml index 03e717b..87062f7 100644 --- a/deploy/kube-config/influxdb/influxdb.yaml +++ b/deploy/kube-config/influxdb/influxdb.yaml @@ -33,8 +33,10 @@ metadata: name: monitoring-influxdb namespace: kube-system spec: + type: NodePort ports: - port: 8086 targetPort: 8086 + nodePort: 30003 selector: k8s-app: influxdb root@km:~/heapster#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/mysql.html",
	"title": "Mysql Command",
	"tags": ["mysql", "command"],
	"description": "",
	"content": " 查看 MYSQL连接数 show processlist;  设置mysql远程连接root权限 MariaDB [(none)]\u0026gt; Grant all privileges on *.* to 'root'@'%' identified by 'mysql' with grant option; Query OK, 0 rows affected (0.00 sec) MariaDB [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) MariaDB [(none)]\u0026gt;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/linux.html",
	"title": "Linux Command",
	"tags": ["linux", "command"],
	"description": "",
	"content": " 查看 机器的连接数 netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-passwd.html",
	"title": "Mysql Passwd",
	"tags": ["mysql", "passwd"],
	"description": "",
	"content": " mysql插入密码 \u0026gt; INSERT INTO `factor_administrator` (`id_admin`,`name`,`pwd`,`admin`) VALUES (1,'wuxuan',md5('gws20180129'),1);  那么, 这时, 用户与密码就是: wuxuan, gws20180129\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/cheatsheet.html",
	"title": "Cheatsheet",
	"tags": ["cheatsheet"],
	"description": "",
	"content": " cheetsheat  cheat-sheets.org  linux  unix-linux-cheat-sheet linux-commands-cheat-sheet linux-command-shelf  docker  docker-command-manual docker-cli-to-kubectl  kubernetes  kubernetes(不全) Kubernetes核心概念总结  bash  jimmysong.io/cheatsheets/bash  nginx ops  运维不仅仅是Linux，居然还要知道这么多？ 史上最全互联网运维工作规划！十分钟找到职业方向！ 建设DevOps统一运维监控平台，先从日志监控说起  mysql  cheat-sheets/mysql overapi.com/mysql cheat-sheets/mysql 不全  python  PQRC-2.4-A4-latest cheat-sheets/python/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/javascript/javascript-faq.html",
	"title": "Javascript Faq",
	"tags": ["javascript", "faq"],
	"description": "",
	"content": "Mixpanel error: \u0026quot;mixpanel\u0026quot; object not initialized. Ensure you are using the latest version of the Mixpanel JS Library along with the snippet we provide.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/interview/telephone-interview.html",
	"title": "Telephone Interview",
	"tags": ["interview"],
	"description": "",
	"content": " 环境  安静 接耳塞 嘴巴不含有其它东西(口香糖) 坐姿端正,面带微笑 注意声调,不要用升调  事前准备  了解公司 发展情况, 公司概况 了解岗位 一份简历, 对简历作标注 笔纸 记录下面内容  试官的名字 重要内容  提问的问题  不要问薪资报酬相关的问题,等对方问我们   聆听  开始  早上好、下午好, 而不是你好,  进行中  热情 不抢话 句子之间多停顿 回答问题时语速不必太快，发音吐字要清晰，表述要简洁、直截了当、充满热情，使得谈话有趣而易于进行，快了反而会弄巧成拙。 切忌用 YES NO 简单回答 \u0026ldquo;以上是我的回答,您看如何\u0026rdquo; \u0026ldquo;对不起,请让我再来一次\u0026rdquo; 总结类，情景扮演类，或是其它任何你觉得困难的，不要犹豫，直接询问考官是否可以给你半分钟到一分钟的时间准备  提问  面试官的姓名?主要负责什么?现在面临的技术挑战是什么? 岗位细节? 公司有没有社区活动? 什么时候, 什么形式得到面试结果通知? 如果气氛不错，可以问问对方对自己的印象 今天表现有哪里不足需要改进的  结束 表示感谢 谢谢! 今天很荣幸与您/你交谈，受益良多。\n其它 通话结束，等待HR先挂电话。\n结束后  感谢邮件   ref  接受电话面试时有哪些注意事项？  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-faq.html",
	"title": "Mac Faq",
	"tags": ["mac", "faq"],
	"description": "",
	"content": " how-to-open-app-from-unidentified-developer-in-mac-os-x how-to-open-app-from-unidentified-developer-in-mac-os-x\nhttps://zhidao.baidu.com/question/466554299.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac.html",
	"title": "Mac Faq",
	"tags": ["mac", "faq"],
	"description": "",
	"content": "mac\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/wechat/weixin-send-messages.html",
	"title": "WeChat Send Messages",
	"tags": ["wechat"],
	"description": "",
	"content": "  监控服务调用微信API如何给自己发告警信息 微信开发之发送消息接口 微信智能问答机器人  golang  golang-wechat golang-wechat https://github.com/songtianyi/wechat-go https://github.com/liushuchun/wechatcmd wechat_pusher - 基于Golang开发的高性能微信消息定时推送框架 https://github.com/yaotian/gowechat  个人号  最优雅的微信个人号 API\n微信机器人 机器人\n 机器人\n WeChatRebot\n http://reverland.org/javascript/2016/01/15/webchat-user-bot/\n 微信机器人\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/javascript/javascript-type.html",
	"title": "Javascript Type",
	"tags": ["javascript"],
	"description": "",
	"content": "简单谈谈Javascript中类型的判断\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock/stock-iwencai-crawler.html",
	"title": "Stock Iwencai Crawler",
	"tags": ["stock", "iwencai", "crawler"],
	"description": "",
	"content": " iwencai爬虫\n以下这几个, 记得回来, 找时间 coding\ngithub  https://github.com/GraySilver/wencai-master https://github.com/zhangzheng88/iwencai_spider https://github.com/wuxiaoxiaoshen/WenCai https://github.com/HiddenStrawberry/iWencai  自写  base headless-chrome-crawler  这个部分的示例代码,请看 仓库\n crawler, 这个是失败的, 不用再试了  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/curl.html",
	"title": "Curl",
	"tags": ["curl"],
	"description": "",
	"content": " 获取header env 要求发送get请求，只看服务器返回的头信息\ncurl --head xxxx.com 这样可以看服务器返回的头信息，但是，发送的是head请求\n请问，怎么做？\nstep ➜ ~ curl -X GET -I https://www.baidu.com/ HTTP/1.1 200 OK Server: nginx Date: Thu, 08 Mar 2018 09:46:48 GMT Content-Type: text/html;charset=utf-8 Content-Length: 491 Vary: Accept-Encoding Set-Cookie: vvvv=1; Path=/; Expires=Thu, 08-Mar-18 09:47:48 GMT Vary: Accept-Encoding X-Cache: MISS from bs88.10jqka.com.cn X-Cache: MISS from cachexs Via: 1.1 bs88.10jqka.com.cn (squid/3.5.20), 1.1 cachexs (squid/3.5.20) Connection: keep-alive ➜ ~  获取复杂URL内容 ➜ ~ curl -H \u0026quot;Content-Type:application/json\u0026quot; -X GET -sL https://www.iwencai.com/stockpick/load-data\\?typed\\=0\\\u0026amp;preParams\\=\\\u0026amp;ts\\=1\\\u0026amp;f\\=1\\\u0026amp;qs\\=result_original\\\u0026amp;selfsectsn\\=\\\u0026amp;querytype\\=stock\\\u0026amp;searchfilter\\=\\\u0026amp;tid\\=stockpick\\\u0026amp;w\\=%E6%98%A8%E6%97%A5%E6%B6%A8%E5%81%9C,%E4%BB%8A%E5%A4%A9%E6%B6%A8%E5%B9%85%3E5%\\\u0026amp;queryarea\\= \u0026lt;html\u0026gt;\u0026lt;body\u0026gt; \u0026lt;script src=\u0026quot;//s.thsi.cn/js/chameleon/chameleon.min.1520503.js\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script language=\u0026quot;javascript\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt; window.location.href=\u0026quot;http://www.iwencai.com/stockpick/load-data?typed=0\u0026amp;preParams=\u0026amp;ts=1\u0026amp;f=1\u0026amp;qs=result_original\u0026amp;selfsectsn=\u0026amp;querytype=stock\u0026amp;searchfilter=\u0026amp;tid=stockpick\u0026amp;w=%E6%98%A8%E6%97%A5%E6%B6%A8%E5%81%9C,%E4%BB%8A%E5%A4%A9%E6%B6%A8%E5%B9%85%3E5%\u0026amp;queryarea=\u0026quot;; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; ➜ ~  这样, 不是我们想要的结果. 怎么办?\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock/stock-iwencai.html",
	"title": "Stock Iwencai",
	"tags": ["stock", "iwencai"],
	"description": "",
	"content": " 搜索股票 env 搜索 \u0026ldquo;昨日涨停,今天涨幅\u0026gt;5%\u0026ldquo;的股票\nhttps://www.iwencai.com/stockpick/search?querytype=stock\u0026amp;tid=stockpick\u0026amp;w=\u0026quot;量价巨增，底部吸筹\u0026quot;\nstep 准备URL  方法1  打开url解码工具\n昨日涨停,今天涨幅\u0026gt;5%  放到左边, 点击解码,得到\n%e6%98%a8%e6%97%a5%e6%b6%a8%e5%81%9c%2c%e4%bb%8a%e5%a4%a9%e6%b6%a8%e5%b9%85%3e5%25  把刚刚得到的结果, 替换到下面w后面的位置\nhttps://www.iwencai.com/stockpick/load-data?typed=0\u0026amp;preParams=\u0026amp;ts=1\u0026amp;f=1\u0026amp;qs=result_original\u0026amp;selfsectsn=\u0026amp;querytype=stock\u0026amp;searchfilter=\u0026amp;tid=stockpick\u0026amp;w=%E9%87%8F%E4%BB%B7%E5%B7%A8%E5%A2%9E%EF%BC%8C%E5%BA%95%E9%83%A8%E5%90%B8%E7%AD%B9\u0026amp;queryarea=  成\nhttps://www.iwencai.com/stockpick/load-data?typed=0\u0026amp;preParams=\u0026amp;ts=1\u0026amp;f=1\u0026amp;qs=result_original\u0026amp;selfsectsn=\u0026amp;querytype=stock\u0026amp;searchfilter=\u0026amp;tid=stockpick\u0026amp;w=%e6%98%a8%e6%97%a5%e6%b6%a8%e5%81%9c%2c%20%e4%bb%8a%e5%a4%a9%e6%b6%a8%e5%b9%85%3e5%25\u0026amp;queryarea=   方法2  把搜索条件 替换到下面w后面的位置\nhttps://www.iwencai.com/stockpick/load-data?typed=0\u0026amp;preParams=\u0026amp;ts=1\u0026amp;f=1\u0026amp;qs=result_original\u0026amp;selfsectsn=\u0026amp;querytype=stock\u0026amp;searchfilter=\u0026amp;tid=stockpick\u0026amp;w=%E9%87%8F%E4%BB%B7%E5%B7%A8%E5%A2%9E%EF%BC%8C%E5%BA%95%E9%83%A8%E5%90%B8%E7%AD%B9\u0026amp;queryarea=  成\nhttps://www.iwencai.com/stockpick/load-data?typed=0\u0026amp;preParams=\u0026amp;ts=1\u0026amp;f=1\u0026amp;qs=result_original\u0026amp;selfsectsn=\u0026amp;querytype=stock\u0026amp;searchfilter=\u0026amp;tid=stockpick\u0026amp;w=昨日涨停,今天涨幅\u0026gt;5%\u0026amp;queryarea=  得到股票  浏览器  然后, 打开刚刚得到的 url, 就能得到我们想要的股票了\n curl  没成功\n➜ src git:(master) ✗ curl -sL https://www.iwencai.com/stockpick/load-data\\?typed\\=0\\\u0026amp;preParams\\=\\\u0026amp;ts\\=1\\\u0026amp;f\\=1\\\u0026amp;qs\\=result_original\\\u0026amp;selfsectsn\\=\\\u0026amp;querytype\\=stock\\\u0026amp;searchfilter\\=\\\u0026amp;tid\\=stockpick\\\u0026amp;w\\=昨日涨停,今天涨幅\\\u0026gt;5%\\\u0026amp;queryarea\\= \u0026lt;html\u0026gt;\u0026lt;body\u0026gt; \u0026lt;script src=\u0026quot;//s.thsi.cn/js/chameleon/chameleon.min.1520561.js\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script language=\u0026quot;javascript\u0026quot; type=\u0026quot;text/javascript\u0026quot;\u0026gt; window.location.href=\u0026quot;http://www.iwencai.com/stockpick/load-data?typed=0\u0026amp;preParams=\u0026amp;ts=1\u0026amp;f=1\u0026amp;qs=result_original\u0026amp;selfsectsn=\u0026amp;querytype=stock\u0026amp;searchfilter=\u0026amp;tid=stockpick\u0026amp;w=昨日涨停,今天涨幅\u0026gt;5%\u0026amp;queryarea=\u0026quot;; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; ➜ src git:(master) ✗   crawler  这个部分见, stock-iwencai-crawler.md 文件\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/html/html-decoder.html",
	"title": "Html Decoder",
	"tags": ["html", "decoder"],
	"description": "",
	"content": " 在线解码 http://www.ofmonkey.com/encode/unicode\nhtml-decoder 包的使用 install [jlch@check gen]$ sudo npm install -g html-decoder [jlch@check gen]$ cd /usr/local/lib/node_modules/html-decoder/ [jlch@check html-decoder]$ ls bin data dist Gruntfile.js LICENSE package.json README.md src tests  测试 [jlch@check html-decoder]$ sudo vi data/entities.json ## 把想decoder的内容放进去 [jlch@check html-decoder]$ sudo ./bin/genhtmlentities data/entities.json Completed in 49 milliseconds! [jlch@check html-decoder]$ cat ./src/gen/trie.json ## 这个是存放结果的地方 {\u0026quot;1\u0026quot;:{},\u0026quot;2\u0026quot;:{},\u0026quot;3\u0026quot;:{},\u0026quot;5\u0026quot;:{},\u0026quot;6\u0026quot;:{},\u0026quot;7\u0026quot;:{},\u0026quot;8\u0026quot;:{},\u0026quot;9\u0026quot;:{}} [jlch@check html-decoder]$ ll ./src/gen/trie.json -rw-r--r-- 1 root root 57 3月 8 15:49 ./src/gen/trie.json [jlch@check html-decoder]$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock/hedge-fund.html",
	"title": "Hedge Fund",
	"tags": ["hedge-fund"],
	"description": "",
	"content": " Steve Cohen http://blog.sina.com.cn/s/blog_51fc34e90102wgw5.html\nhttps://www.zhihu.com/question/27100014\nhttps://wallstreetcn.com/articles/308468\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/gcc-rpm-install-offline.html",
	"title": "Gcc Rpm Install Offline",
	"tags": ["centos", "rpm", "gcc"],
	"description": "",
	"content": "gcc rpm 安装包下载\n安装gcc, 下载\n[root@localhost jlch]# rpm -ivh gcc-4.8.5-16.el7_4.1.x86_64.rpm warning: gcc-4.8.5-16.el7_4.1.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY error: Failed dependencies: cpp = 4.8.5-16.el7_4.1 is needed by gcc-4.8.5-16.el7_4.1.x86_64 glibc-devel \u0026gt;= 2.2.90-12 is needed by gcc-4.8.5-16.el7_4.1.x86_64 libgcc \u0026gt;= 4.8.5-16.el7_4.1 is needed by gcc-4.8.5-16.el7_4.1.x86_64 libgomp = 4.8.5-16.el7_4.1 is needed by gcc-4.8.5-16.el7_4.1.x86_64 libmpc.so.3()(64bit) is needed by gcc-4.8.5-16.el7_4.1.x86_64 libmpfr.so.4()(64bit) is needed by gcc-4.8.5-16.el7_4.1.x86_64 [root@localhost jlch]#  所有的下载地址如下:\nhttp://mirror.centos.org/centos/7/os/x86_64/Packages/libgcc-4.8.5-16.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/gcc-4.8.5-16.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/cpp-4.8.5-16.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/glibc-devel-2.17-196.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/libgomp-4.8.5-16.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/libmpc-1.0.1-3.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/mpfr-3.1.1-4.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/glibc-headers-2.17-196.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/kernel-headers-3.10.0-693.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/glibc-2.17-196.el7.x86_64.rpm http://mirror.centos.org/centos/7/os/x86_64/Packages/glibc-common-2.17-196.el7.x86_64.rpm\n[root@localhost gcc]# cat rpm.sh #!/bin/bash echo \u0026quot;start\u0026quot; rpm_packages_all=\u0026quot;\u0026quot; for rpm_packages in `cat rpm.txt` do echo ${rpm_packages} rpm_packages_all=\u0026quot;${rpm_packages_all} ${rpm_packages}\u0026quot; done echo ${rpm_packages_all} rpm -ivh ${rpm_packages_all} echo \u0026quot;rpm -ivh, end\u0026quot; echo `which gcc`  [root@localhost gcc]# cat rpm.txt cpp-4.8.5-16.el7.x86_64.rpm glibc-devel-2.17-196.el7.x86_64.rpm libgcc-4.8.5-16.el7.x86_64.rpm libgomp-4.8.5-16.el7.x86_64.rpm libmpc-1.0.1-3.el7.x86_64.rpm mpfr-3.1.1-4.el7.x86_64.rpm glibc-headers-2.17-196.el7.x86_64.rpm kernel-headers-3.10.0-693.el7.x86_64.rpm glibc-2.17-196.el7.x86_64.rpm glibc-common-2.17-196.el7.x86_64.rpm gcc-4.8.5-16.el7.x86_64.rpm  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-install-2-base-centos.html",
	"title": "Mysql Install 2 Base Centos",
	"tags": ["mysql", "install"],
	"description": "",
	"content": " 主要参考： http://blog.csdn.net/renfufei/article/details/17616549\n过程 说明: 首先必须能链接外网. 如果不能直接访问,那也可以设置代理,请参考: 在内网机器上设置yum代理 使用 yum 的权限要求是 root 用户,如果你不是,那么可以需要 在 shell命令之前加上 sudo, 或者 su root 切换到 super 管理员进行操作. 并可能需要输入密码.\n1. 添加 yum 数据源  安装mariadb10.1 官方的通过yum安装教程\n根据不同的系统来下载repo吧，更多的MariaDB.repo\n 建议命名为 MariaDB.repo 类似的名字：\ncd /etc/yum.repos.d/ vim /etc/yum.repos.d/MariaDB.repo  然后,写入文件内容:(建议使用 10.0)\n# MariaDB 10.0 CentOS repository list - created 2015-08-12 10:59 UTC # http://mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos6-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1  该文件的内容是参考官网,并从官网上生成的，设置安装源仓库的 具体的地址为: https://downloads.mariadb.org/mariadb/repositories/ 选择好操作系统版本之后既可以查看，其他操作系统的安装源也可以在此处查看并设置。 如果服务器不支持https协议，或者gpgkey 保错，确保没问题的话，可以将 gpgcheck=1 修改为 gpgcheck=0,则不进行校验.\n2. 安装数据库 yum remove MariaDB-server MariaDB-client yum -y install MariaDB-server MariaDB-client  如果要删除旧的数据库可以使用remove, 参数 -y 是确认，不用提示。此处，安装的是服务器和客户端，一般来说安装这两个就可以了。\n3. 启动数据库 如果不用进行其他的操作，则现在就可以直接启动数据库，并进行测试了。\n查看mysql状态;关闭数据库\n# service mysql status\n# service mysql stop\n启动数据库\n# service mysql start\n4. 修改root密码 # 修改root密码 mysqladmin -u root password 'root'  因为安装好以后的root密码是空,所以需要设置; 如果是测试服务器,那么你可以直接使用root,不重要的密码很多时候可以设置为和用户名一致，以免忘记了又想不起来。 如果是重要的服务器，请使用复杂密码，例如邮箱，各种自由组合的规则的字符等。\n5. 登录数据库 mysql -u root -p  如果是本机,那可以直接使用上面的命令登录，当然，需要输入密码. 如果是其他机器，那么可能需要如下的形式:\nmysql -h 127.0.0.1 -P 3306 -u root -p  6. 简单SQL测试 \u0026gt; -- 查看MySQL的状态 status; -- 显示支持的引擎 show engines; -- 显示所有数据库 show databases; -- 切换数据库上下文,即设置当前会话的默认数据库 use test; -- 显示本数据库所有的表 show tables; -- 创建一个表 CREATETABLE t_test ( id int(11) UNSIGNED NOTNULL AUTO_INCREMENT, userId char(36), lastLoginTime timestamp, PRIMARYKEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; -- 插入测试数据 insertinto t_test(userId) values ('admin') ,('haha') ; -- 简单查询 select * from t_test; select id,userId from t_test where userId='admin' ;  7. 修改数据存放目录 mysql, MariaDB 的默认数据存放在 /var/lib/mysql/ 目录下,如果不想放到此处,或者是想要程序和数据分离，或者是磁盘原因,需要切换到其他路径,则可以通过修改 datadir系统变量来达成目的.\n# 停止数据库 service mysql stop # 创建目录,假设没有的话 mkdir /usr/local/ieternal/mysql_data # 拷贝默认数据库到新的位置 # -a 命令是将文件属性一起拷贝,否则各种问题 cp -a /var/lib/mysql /usr/local/ieternal/mysql_data # 备份原来的数据 cp -a /etc/my.cnf /etc/my.cnf_original # 其实查看 /etc/my.cnf 文件可以发现 # MariaDB 的此文件之中只有一个包含语句 # 所以需要修改的配置文件为 /etc/my.cnf.d/server.cnf cp /etc/my.cnf.d/server.cnf /etc/my.cnf.d/server.cnf_original vim /etc/my.cnf.d/server.cnf  然后 按 i 进入编辑模式,可以插入相关内容.使用键盘的上下左右键可以移动光标, 编辑完成以后，按 ESC 退出编辑模式(进入命令模式), 然后输入命令:wq 保存并退出\n# 在文件的 mysqld 节下添加内容 [mysqld] datadir=/usr/local/ieternal/mysql_data/mysql socket=/var/lib/mysql/mysql.sock #default-character-set=utf8 character_set_server=utf8 slow_query_log=on slow_query_log_file=/usr/local/ieternal/mysql_data/slow_query_log.log long_query_time=2  其中,也只有 datadir 和 socket 比较重要; 而 default-character-set 是 mysql 自己认识的,而 mariadb5.5 就不认识,相当于变成了 character_set_server\n7.1 创建慢查询日志文件 既然上面指定了慢查询日志文件，我后来看了下MariaDB的err日志，发现MariaDB不会自己创建该文件，所以我们需要自己创建,并修改相应的文件权限(比如 MySQL 采用 mysql用户，可能我们使用 root用户创建的文件,此时要求慢查询日志文件对mysql用户可读可写就行。)\ntouch /usr/local/ieternal/mysql_data/slow_query_log.log chmod 666 /usr/local/ieternal/mysql_data/slow_query_log.log  然后重新启动MySQL.\nservice mysql start  综合命令 方便大家ctrl+c, ctrl+v\nsudo systemctl status mariadb.service sudo systemctl stop mariadb.service cd /data/ ls sudo mkdir ./mariadb/mysql/ -p ls cd mariadb/mysql/ ls sudo cp -a /var/lib/mysql /data/mariadb/ ls cd ../ ls cd mysql/ ls sudo cp -a /etc/my.cnf /etc/my.cnf_original sudo cp /etc/my.cnf.d/server.cnf /etc/my.cnf.d/server.cnf_original sudo vim /etc/my.cnf.d/server.cnf sudo touch /data/mariadb/mysql/slow_query_log.log sudo chmod 666 /data/mariadb/mysql/slow_query_log.log sudo systemctl restart mariadb.service  其中 vim /etc/my.cnf.d/server.cnf\n# # These groups are read by MariaDB server. # Use it for options that only the server (but not clients) should see # # See the examples of server my.cnf files in /usr/share/mysql/ # # this is read by the standalone daemon and embedded servers [server] # this is only for the mysqld standalone daemon [mysqld] datadir=/data/mariadb/mysql socket=/var/lib/mysql/mysql.sock #default-character-set=utf8 character_set_server=utf8 slow_query_log=on slow_query_log_file=/data/mariadb/mysql/slow_query_log.log long_query_time=2 # this is only for embedded server [embedded] # This group is only read by MariaDB-5.5 servers. # If you use the same .cnf file for MariaDB of different versions, # use this group for options that older servers don't understand [mysqld-5.5] # These two groups are only read by MariaDB servers, not by MySQL. # If you use the same .cnf file for MySQL and MariaDB, # you can put MariaDB-only options here [mariadb] [mariadb-5.5]  end "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-length.html",
	"title": "Mysql Length",
	"tags": ["mysql"],
	"description": "",
	"content": "转载自: http://yishouce.com/mysql/func/length\n一句话说明: 获取字符串长度的mysql内置函数\nlength是mysql的一个用来来获取字符串长度的内置函数方法, 同样的获取字符串长度的还有char_length. length: 是计算字段的长度, utf8编码下,一个汉字是算三个字符,一个数字或字母算一个字符。其他编码下,一个汉字算两个字符, 一个数字或字母算一个字符。\n例子1: 查看mysql字符串的长度\nSELECT LENGTH(\u0026quot;要查看长度的mysql字段/mysql字符串\u0026quot;);  例子2: 根据记录的某个字段长度排序\nSELECT * FROM table WHERE 1 ORDER BY LENGTH(name) ASC;  相关: char_length:在任何编码下, 不管汉字还是数字或者是字母都算是一个字符. CHARACTER_LENGTH(str) CHARACTER_LENGTH()是CHAR_LENGTH()的同义词。 BIT_LENGTH(str) 返回2进制长度.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hexo/hexo-tomtsang.html",
	"title": "Hexo Tomtsang",
	"tags": ["hexo"],
	"description": "",
	"content": " hexo tomtsang\u0026rsquo;s blogs\n--- layout: photo title: tomtsang53535ere date: 2016-11-01 16:38:42 tags: description: 你对本页的描述 photos: - http://bruce.u.qiniudn.com/2013/11/27/reading/photos-0.jpg - http://bruce.u.qiniudn.com/2013/11/27/reading/photos-1.jpg --- Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).  Quick Start Create a new post $ hexo new \u0026quot;My New Post\u0026quot;  More info: Writing\nRun server $ hexo server  More info: Server\nGenerate static files $ hexo generate  More info: Generating\nDeploy to remote sites $ hexo deploy  More info: Deployment\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/nodejs-npm.html",
	"title": "Nodejs Npm Command",
	"tags": ["nodejs", "npm", "command"],
	"description": "",
	"content": " nodejs系列之npm的常用命令\nref  http://www.jb51.net/article/52409.htm  要点 分享几个npm的常用命令\nnpm -v #显示版本，检查npm 是否正确安装。\nnpm install express #安装express模块\nnpm install -g express #全局安装express模块\nnpm list #列出已安装模块\nnpm show express #显示模块详情\nnpm update #升级当前目录下的项目的所有模块\nnpm update express #升级当前目录下的项目的指定模块\nnpm update -g express #升级全局安装的express模块\nnpm uninstall express #删除指定的模块\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs-version.html",
	"title": "Nodejs Version",
	"tags": ["nodejs", "version"],
	"description": "",
	"content": " nodejs系列之使用n管理nodejs版本\nref  http://blog.csdn.net/jiangbo_phd/article/details/51476155  主要点 npm -g XXX :安装的XXX软件，在linux下的目录 /usr/lib/node_modules/\nsudo n :切换node版本\nn 切换之后的 node 默认装在 /usr/local/bin/node，你最好用 which node 检查一下当前使用的 node 是否是这个路径下的。\n问题  如果安装过程中因为某原因（主要是网络原因），未安装成功，则删除对应的目录，重新安装就可以了。\ntom@adata:~/Projects/OpenX/lib$ sudo n latest [sudo] password for tom:\n install : node-v7.2.0 mkdir : /usr/local/n/versions/node/7.2.0 fetch : https://nodejs.org/dist/v7.2.0/node-v7.2.0-linux-x64.tar.gz  ###################################################### 75.1% curl: (56) GnuTLS recv error (-54): Error in the pull function.\ngzip: stdin: unexpected end of file tar: Unexpected EOF in archive tar: Unexpected EOF in archive tar: Error is not recoverable: exiting now cp: cannot stat \u0026lsquo;/usr/local/n/versions/node/7.2.0/lib\u0026rsquo;: No such file or directory cp: cannot stat \u0026lsquo;/usr/local/n/versions/node/7.2.0/include\u0026rsquo;: No such file or directory cp: cannot stat \u0026lsquo;/usr/local/n/versions/node/7.2.0/share\u0026rsquo;: No such file or directory installed : v7.2.0\ntom@adata:~/Projects/OpenX/lib$ ll /usr/local/n/versions/node/7.2.0/ total 12 drwxr-xr-x 3 root root 4096 11月 23 13:07 ./ drwxr-xr-x 4 root root 4096 11月 23 13:00 ../ drwxrwxr-x 2 500 500 4096 11月 23 06:35 bin/ tom@adata:~/Projects/OpenX/lib$ sudo n latest [sudo] password for tom: tom@adata:~/Projects/OpenX/lib$ sudo n latest tom@adata:~/Projects/OpenX/lib$ sudo rm -rf /usr/local/n/versions/node/7.2.0/ tom@adata:~/Projects/OpenX/lib$ sudo n latest\n install : node-v7.2.0 mkdir : /usr/local/n/versions/node/7.2.0 fetch : https://nodejs.org/dist/v7.2.0/node-v7.2.0-linux-x64.tar.gz  ######################################################################## 100.0% installed : v7.2.0\ntom@adata:~/Projects/OpenX/lib$\n 安装完成后，不要直接看node版本，另开一个terminal，查看。\ntom@adata:~/Projects/OpenX/lib$ node -v v6.7.0 tom@adata:~/Projects/OpenX/lib$\n  看吧，上面这个明显还是老版本。另开一个terminal，查看就是新版本了。\n实战 [jlch@kube-node-15 ~]$ sudo npm i n -g [sudo] password for jlch: /usr/bin/n -\u0026gt; /usr/lib/node_modules/n/bin/n n@2.1.4 /usr/lib/node_modules/n [jlch@kube-node-15 ~]$ ll /usr/lib/node_modules/ # 看一下，n是不是真的安装成功 total 8 drwxr-xr-x. 3 nobody jlch 66 11月 23 14:08 n drwxr-xr-x. 9 root root 4096 6月 8 16:05 npm drwxr-xr-x. 5 nobody jlch 4096 6月 8 18:00 pm2 [jlch@kube-node-15 ~]$ sudo n --help # 找帮助 Usage: n [options/env] [COMMAND] [args] Environments: n [COMMAND] [args] Uses default env (node) n io [COMMAND] Sets env as io n project [COMMAND] Uses custom env-variables to use non-official sources Commands: n Output versions installed n latest Install or activate the latest node release n -a x86 latest As above but force 32 bit architecture n stable Install or activate the latest stable node release n lts Install or activate the latest LTS node release n \u0026lt;version\u0026gt; Install node \u0026lt;version\u0026gt; n use \u0026lt;version\u0026gt; [args ...] Execute node \u0026lt;version\u0026gt; with [args ...] n bin \u0026lt;version\u0026gt; Output bin path for \u0026lt;version\u0026gt; n rm \u0026lt;version ...\u0026gt; Remove the given version(s) n --latest Output the latest node version available n --stable Output the latest stable node version available n --lts Output the latest LTS node version available n ls Output the versions of node available (iojs): n io latest Install or activate the latest iojs release n io -a x86 latest As above but force 32 bit architecture n io \u0026lt;version\u0026gt; Install iojs \u0026lt;version\u0026gt; n io use \u0026lt;version\u0026gt; [args ...] Execute iojs \u0026lt;version\u0026gt; with [args ...] n io bin \u0026lt;version\u0026gt; Output bin path for \u0026lt;version\u0026gt; n io rm \u0026lt;version ...\u0026gt; Remove the given version(s) n io --latest Output the latest iojs version available n io ls Output the versions of iojs available Options: -V, --version Output current version of n -h, --help Display help information -q, --quiet Disable curl output (if available) -d, --download Download only -a, --arch Override system architecture Aliases: which bin use as list ls - rm [jlch@kube-node-15 ~]$ sudo n --version 2.1.3 [jlch@kube-node-15 ~]$ node -v v4.4.5 [jlch@kube-node-15 ~]$ sudo n 4.4.6 install : node-v4.4.6 mkdir : /usr/local/n/versions/node/4.4.6 fetch : https://nodejs.org/dist/v4.4.6/node-v4.4.6-linux-x64.tar.gz ################## 26.0%  查一下，各自的路径\ntom@adata:~/m6s/blogs/tomtsang$ which node /usr/local/bin/node tom@adata:~/m6s/blogs/tomtsang$ which n /usr/bin/n tom@adata:~/m6s/blogs/tomtsang$  切换着玩一下。\ntom@adata:~/Projects/OpenX/lib$ node -v v6.9.1 tom@adata:~/Projects/OpenX/lib$ sudo n [sudo] password for tom: tom@adata:~/Projects/OpenX/lib$ node -v v7.2.0 tom@adata:~/Projects/OpenX/lib$ sudo n tom@adata:~/Projects/OpenX/lib$ node -v v6.9.1 tom@adata:~/Projects/OpenX/lib$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs-mongodb.html",
	"title": "Nodejs Mongodb",
	"tags": ["nodejs", "mongodb"],
	"description": "",
	"content": "nodejs系列之mongodb\nvar mongodb = require(\u0026quot;mongodb\u0026quot;);  这个 mongodb 包的API文档：\nhttp://mongodb.github.io/node-mongodb-native/2.2/api/index.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs-npm-faq-1.html",
	"title": "Nodejs Npm Faq 1",
	"tags": ["nodejs", "faq"],
	"description": "",
	"content": " nodejs系列之npm报错\n报错 报错1，permission denied, open '/usr/local/lib/node_modules/npm/lib/ tom@adata:~/in/ttt$ npm i npm ERR! Linux 4.4.0-47-generic npm ERR! argv \u0026quot;/usr/local/bin/node\u0026quot; \u0026quot;/usr/local/bin/npm\u0026quot; \u0026quot;i\u0026quot; npm ERR! node v6.9.1 npm ERR! npm v3.10.8 npm ERR! path /usr/local/lib/node_modules/npm/lib/fetch-package-metadata.js npm ERR! code EACCES npm ERR! errno -13 npm ERR! syscall open npm ERR! Error: EACCES: permission denied, open '/usr/local/lib/node_modules/npm/lib/fetch-package-metadata.js' npm ERR! at Error (native) npm ERR! at Object.fs.openSync (fs.js:640:18) npm ERR! at Object.fs.readFileSync (fs.js:508:33) npm ERR! at Object.Module._extensions..js (module.js:578:20) npm ERR! at Module.load (module.js:487:32) npm ERR! at tryModuleLoad (module.js:446:12) npm ERR! at Function.Module._load (module.js:438:3) npm ERR! at Module.require (module.js:497:17) npm ERR! at require (internal/module.js:20:19) npm ERR! at Object.\u0026lt;anonymous\u0026gt; (/usr/local/lib/node_modules/npm/lib/install/deps.js:15:28) npm ERR! { Error: EACCES: permission denied, open '/usr/local/lib/node_modules/npm/lib/fetch-package-metadata.js' npm ERR! at Error (native) npm ERR! at Object.fs.openSync (fs.js:640:18) npm ERR! at Object.fs.readFileSync (fs.js:508:33) npm ERR! at Object.Module._extensions..js (module.js:578:20) npm ERR! at Module.load (module.js:487:32) npm ERR! at tryModuleLoad (module.js:446:12) npm ERR! at Function.Module._load (module.js:438:3) npm ERR! at Module.require (module.js:497:17) npm ERR! at require (internal/module.js:20:19) npm ERR! at Object.\u0026lt;anonymous\u0026gt; (/usr/local/lib/node_modules/npm/lib/install/deps.js:15:28) npm ERR! errno: -13, npm ERR! code: 'EACCES', npm ERR! syscall: 'open', npm ERR! path: '/usr/local/lib/node_modules/npm/lib/fetch-package-metadata.js' } npm ERR! npm ERR! Please try running this command again as root/Administrator. npm ERR! Please include the following file with any support request: npm ERR! /home/tom/in/ttt/npm-debug.log tom@adata:~/in/ttt$_  解决：\n先查node，npm版本\ntom@adata:~/in/ttt$ node -v v6.9.1 tom@adata:~/in/ttt$ ls -l /usr/local/sbin/bin/n* ls: cannot access '/usr/local/sbin/bin/n*': No such file or directory tom@adata:~/in/ttt$ which node /usr/local/bin/node tom@adata:~/in/ttt$ ls -l /usr/local/bin/n* -rwxr-xr-x 1 root root 30194989 11月 24 09:45 /usr/local/bin/node lrwxrwxrwx 1 root root 38 11月 24 09:45 /usr/local/bin/npm -\u0026gt; ../lib/node_modules/npm/bin/npm-cli.js tom@adata:~/in/ttt$  发现，npm是一个软链接，所以，可能问题出在这里，这样呢，我们更新一下 npm 本身吧。sudo npm i npm -g。走起。\ntom@adata:~/in/ttt$ sudo npm i npm -g [sudo] password for tom: /usr/local/bin/npm -\u0026gt; /usr/local/lib/node_modules/npm/bin/npm-cli.js - retry@0.10.0 node_modules/npm/node_modules/npm-registry-client/node_modules/retry - core-util-is@1.0.2 node_modules/npm/node_modules/request/node_modules/bl/node_modules/readable-stream/node_modules/core-util-is - isarray@1.0.0 node_modules/npm/node_modules/request/node_modules/bl/node_modules/readable-stream/node_modules/isarray - process-nextick-args@1.0.7 node_modules/npm/node_modules/request/node_modules/bl/node_modules/readable-stream/node_modules/process-nextick-args - string_decoder@0.10.31 node_modules/npm/node_modules/request/node_modules/bl/node_modules/readable-stream/node_modules/string_decoder - util-deprecate@1.0.2 node_modules/npm/node_modules/request/node_modules/bl/node_modules/readable-stream/node_modules/util-deprecate - readable-stream@2.0.6 node_modules/npm/node_modules/request/node_modules/bl/node_modules/readable-stream - bl@1.1.2 node_modules/npm/node_modules/request/node_modules/bl - async@1.5.2 node_modules/npm/node_modules/request/node_modules/form-data/node_modules/async /usr/local/lib └─┬ npm@4.0.2 ├── asap@2.0.5 ├── config-chain@1.1.11 ... ... ... tom@adata:~/in/ttt$  我们重新再尝试吧。\ntom@adata:~/in/ttt$ ls package.json tom@adata:~/in/ttt$ npm i openQuote2@2.0.0 /home/tom/in/ttt ├── async@1.5.2 ├─┬ mongodb@2.2.12 │ ├── es6-promise@3.2.1 │ ├─┬ mongodb-core@2.0.14 │ │ ├── bson@0.5.7 │ │ └─┬ require_optional@1.0.0 │ │ ├── resolve-from@2.0.0 │ │ └── semver@5.3.0 │ └─┬ readable-stream@2.1.5 │ ├── buffer-shims@1.0.0 │ ├── core-util-is@1.0.2 │ ├── inherits@2.0.3 │ ├── isarray@1.0.0 │ ├── process-nextick-args@1.0.7 │ ├── string_decoder@0.10.31 │ └── util-deprecate@1.0.2 └─┬ mysql@2.12.0 ├── bignumber.js@2.4.0 ├─┬ readable-stream@1.1.14 │ └── isarray@0.0.1 └── sqlstring@2.2.0 tom@adata:~/in/ttt$  好了，成功了。 但是，我重新再去查\ntom@adata:~/in/ttt$ which npm /usr/local/bin/npm tom@adata:~/in/ttt$ which node /usr/local/bin/node tom@adata:~/in/ttt$ ls -l /usr/local/bin/n* -rwxr-xr-x 1 root root 30194989 11月 24 09:45 /usr/local/bin/node lrwxrwxrwx 1 root root 38 11月 24 09:45 /usr/local/bin/npm -\u0026gt; ../lib/node_modules/npm/bin/npm-cli.js tom@adata:~/in/ttt$ tom@adata:~/in/ttt$ npm -v 4.0.2 tom@adata:~/in/ttt$  发现只更新了 npm 的版本，而已呀。看来，升级npm，才是解决这个问题的关键。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs-tofixed.html",
	"title": "Nodejs Tofixed",
	"tags": ["nodejs"],
	"description": "",
	"content": "nodejs系列之toFixed\n在遇到，4147.8015这样的浮点数时的，toFixed()的替代方案。\n通过下面这一段，应该知道，这里的toFixed2 中的 “9”（是可以设置成限定的位数的准确度的，不应该设置成“2”，“2”太小了，是有问题的，所以设置成大数“9”）。\ntom@adata:~/m6s/nodejs/module/toFixed$ node \u0026gt; var aux = Math.pow(0.1, 1 + 2) undefined \u0026gt; var number = 14.44999 undefined \u0026gt; number + aux 14.45099 \u0026gt; (number + aux).toFixed(1) '14.5'  下面，直接上代码吧。共2个js文件。写法不同，意思相同。\ntoFixedTest1.js\nmodule.exports.MathHelper = MathHelper; var MathHelper = (function() { this.round = function(number, numberOfDecimals) { var aux = Math.pow(10, numberOfDecimals); return Math.round(number * aux) / aux; }; this.floor = function(number, numberOfDecimals) { var aux = Math.pow(10, numberOfDecimals); return Math.floor(number * aux) / aux; }; this.ceil = function(number, numberOfDecimals) { var aux = Math.pow(10, numberOfDecimals); return Math.ceil(number * aux) / aux; }; this.toFixed = function(number, numberOfDecimals) { return (number + 0.000001).toFixed(numberOfDecimals); }; this.toFixed2 = function(number, numberOfDecimals) { var aux = Math.pow(0.1, numberOfDecimals + 9); // 这里的这个9,只是让它小一点，再小一点。 return (number + aux).toFixed(numberOfDecimals); }; this.toFixed3 = function(number, numberOfDecimals) { var aux = Math.pow(0.1, numberOfDecimals); console.log(\u0026quot;aux =\u0026gt;\u0026quot;, aux); return (number + aux).toFixed(numberOfDecimals); }; return { round: round, floor: floor, ceil: ceil, toFixed: toFixed, toFixed2: toFixed2, toFixed3: round }; })(); var ToFixedHelper = (function() { this.toFixed = function(number, numberOfDecimals) { var aux = Math.pow(0.1, numberOfDecimals); return (number + aux).toFixed(numberOfDecimals); }; return { toFixed: toFixed } })(); console.log(MathHelper.round(5.175, 2)); console.log(MathHelper.toFixed(5.175, 2)); console.log(MathHelper.toFixed(4147.8015, 3)); console.log(MathHelper.toFixed2(4147.8015, 3)); console.log(ToFixedHelper.toFixed(4147.8015, 3)); var number = 4147.8015; var num = 10000; console.time(\u0026quot;toFixed\u0026quot;); for (var i = 0; i \u0026lt; num; i++) { number.toFixed(3); } console.timeEnd(\u0026quot;toFixed\u0026quot;); console.time(\u0026quot;toFixed1\u0026quot;); for (var i = 0; i \u0026lt; num; i++) { MathHelper.toFixed(number, 3); } console.timeEnd(\u0026quot;toFixed1\u0026quot;); console.time(\u0026quot;toFixed2\u0026quot;); for (var i = 0; i \u0026lt; num; i++) { MathHelper.toFixed2(number, 3); } console.timeEnd(\u0026quot;toFixed2\u0026quot;);  toFixedTest2.js\nvar MathHelper = { toFixed : function(number, numberOfDecimals) { // var aux = Math.pow(0.1, numberOfDecimals + 2) + Math.pow(0.1, numberOfDecimals + 1); var aux = 0.000001; // Math.pow(0.1, numberOfDecimals + 2); return (number + aux).toFixed(numberOfDecimals); }, toFixed2 : function(number, numberOfDecimals) { // var aux = Math.pow(0.1, numberOfDecimals + 2) + Math.pow(0.1, numberOfDecimals + 1); var aux = Math.pow(0.1, numberOfDecimals + 9); return (number + aux).toFixed(numberOfDecimals); } }; console.log(MathHelper.toFixed(5.175, 2)); console.log(5.175.toFixed(2)); console.log(MathHelper.toFixed(4147.8015, 3)); console.log(4147.8015.toFixed(3)); console.log(MathHelper.toFixed(14.499, 1)); console.log(14.499.toFixed(1)); console.log(14.44999.toFixed(1)); console.log(MathHelper.toFixed(14.44999, 1)); console.log(MathHelper.toFixed2(14.44999, 1)); var number = 4147.8015; var num = 10000; console.time(\u0026quot;toFixed\u0026quot;); for (var i = 0; i \u0026lt; num; i++) { number.toFixed(3); } console.timeEnd(\u0026quot;toFixed\u0026quot;); console.time(\u0026quot;toFixed1\u0026quot;); for (var i = 0; i \u0026lt; num; i++) { MathHelper.toFixed(number, 3); } console.timeEnd(\u0026quot;toFixed1\u0026quot;); console.time(\u0026quot;toFixed1\u0026quot;); for (var i = 0; i \u0026lt; num; i++) { MathHelper.toFixed(number, 3); } console.timeEnd(\u0026quot;toFixed1\u0026quot;);  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-faq-2.html",
	"title": "Nginx Faq 2",
	"tags": ["nginx"],
	"description": "",
	"content": " nginx txt,json文件 中文乱码\nnginx 中 txt,json文件 中文乱码 在 /etc/nginx/conf.d/default.conf 中找到 location / { ,然后加入\ncharset utf-8; charset_types text/html  如：\nserver { listen 8000; server_name localhost; #default_type 'text/html'; #charset utf-8; #charset koi8-r; #access_log /var/log/nginx/log/host.access.log main; location / { charset utf-8; charset_types text/html application/json; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-faq-1.html",
	"title": "Nginx Faq 1",
	"tags": ["nginx"],
	"description": "",
	"content": " nginx 跨域访问\n nginx 解决跨域访问的问题 跨域造成session丢失  nginx 解决跨域访问的问题。 https://michielkalkman.com/snippets/nginx-cors-open-configuration.html\nhttp://enable-cors.org/server_nginx.html\n 所有网页都实现跨域  把下面的代码，放到 ，配置文件 /etc/nginx/conf.d/default.conf 中的 location / { 内\nadd_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';   部分url（下以 /ok 为例） 请求实现跨域访问  把下面的代码，放到 ，配置文件 /etc/nginx/conf.d/default.conf 中 的 location /ok { 内\n# # Wide-open CORS config for nginx # location / { if ($request_method = 'OPTIONS') { add_header 'Access-Control-Allow-Origin' '*'; # # Om nom nom cookies # add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; # # Custom headers and headers various browsers *should* be OK with but aren't # add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; # # Tell client that this pre-flight info is valid for 20 days # add_header 'Access-Control-Max-Age' 1728000; add_header 'Content-Type' 'text/plain charset=UTF-8'; add_header 'Content-Length' 0; return 204; } if ($request_method = 'POST') { add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; } if ($request_method = 'GET') { add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; } }  跨域造成session丢失 https://segmentfault.com/q/1010000002905817\n重点参考下面这个地方：\n这个配置在不少地方应该都能找到，不同的主要是两点： 1。response.setHeader(\u0026quot;Access-Control-Allow-Credentials\u0026quot;,\u0026quot;true\u0026quot;); //是否支持cookie跨域 2。response.setHeader(\u0026quot;Access-Control-Allow-Origin\u0026quot;, request.getHeader(\u0026quot;Origin\u0026quot;)); 首先，配置了allow-credentials之后，如果allow-origin设为*，跨域时会报错说因为允许credentials，origin不能设为通配*，那所以设为简单的某个domain也是可以的，这种写法应该就是达到了任意domain都可以的效果吧。 然后angular部分也要设定个东西，举个栗子~  解决方法：\n填加下面的代码到 服务端代码 如：limitup/route/index.js中。\napp.all('*', function(req, res, next) { res.header('Access-Control-Allow-Origin', req.headers.origin); res.header('Access-Control-Allow-Methods', 'GET, POST'); res.header('Access-Control-Allow-Headers', 'Content-Type'); res.header('Access-Control-Allow-Credentials', 'true'); next(); });  end "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-mysqlslap.html",
	"title": "Mysql Mysqlslap",
	"tags": ["mysql", "mysqlslap"],
	"description": "",
	"content": " mysqlslap模拟并发测试数据库性能\n安装：简单，装了mysql就有了\n作用：模拟并发测试数据库性能。\nreference 参考网址\n命令主要参数, 示例与解析 示例:\nmysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema='stock' --query=\\'\u0026quot;$line\u0026quot;\\' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01\n解析:\nmysqlslap 程序名 -h10.10.15.240 mysql IP地址 -P3306 端口 --concurrency=10 并发数 --iterations=1 迭代数, 多次迭代使得数据有统计意义 --create-schema='stock' 数据库名 --query=\\'\u0026quot;$line\u0026quot;\\' 要测试的sql语句, 因为sql语句, 很可能含有 `select * `, 所以这里必须使用 \\'\u0026quot; 和 \u0026quot;\\' 把 sql 语句包起来 --number-of-queries=100000 总query数 --debug-info -udeveloper01 用户名 -pdeveloper01 密码  结果, 示例及解析 示例:\nUser time 3.81, System time 2.55 Maximum resident set size 3620, Integral resident set size 0 Non-physical pagefaults 1116, Physical pagefaults 0, Swaps 0 Blocks in 0 out 0, Messages in 0 out 0, Signals 0 Voluntary context switches 100269, Involuntary context switches 19 Benchmark Average number of seconds to run all queries: 5.659 seconds Minimum number of seconds to run all queries: 5.659 seconds Maximum number of seconds to run all queries: 5.659 seconds Number of clients running queries: 10 Average number of queries per client: 10000  解析:\nUser time 3.81, System time 2.55 Maximum resident set size 3620, Integral resident set size 0 Non-physical pagefaults 1116, Physical pagefaults 0, Swaps 0 Blocks in 0 out 0, Messages in 0 out 0, Signals 0 Voluntary context switches 100269, Involuntary context switches 19 Benchmark Average number of seconds to run all queries: 5.659 seconds : 运行所有的 10000 次请求, 花了 5.659 秒.也就是 10000/5.659 次/秒 的处理能力 Minimum number of seconds to run all queries: 5.659 seconds : 最少时间 Maximum number of seconds to run all queries: 5.659 seconds : 最多时间 Number of clients running queries: 10 : 并发数 Average number of queries per client: 10000 每一个客户端的请求数  程序入口 files [tom@check mm]$ tree ./ ./ ├── mysql_strings.txt 存放要测试的 sql 语句 ├── mysql_test.sh 把 sql 语句, 生成 mysqlslap 语句 ├── mysql.test.sh 执行 mysqlslap 语句 ├── mysql.test.sh.log 结果的 log └── mysql.tt.sh 把前面几个, 全串在一起, 放在 sh中. 0 directories, 5 files [tom@check mm]$  一个一个来过一下吧\n mysql_strings.txt\n[tom@check mm]$ cat mysql_strings.txt SELECT * FROM diag_stocka_zhongtai WHERE stock_code=\u0026quot;000001.SZ\u0026quot; SELECT research_report_str FROM diag_stocka_zhongtai WHERE stock_code=\u0026quot;000001.SZ\u0026quot; SELECT inst_num,mai_ru,zeng_chi,zhong_xing,jian_chi,mai_chu FROM diag_stocka_zhongtai WHERE stock_code=\u0026quot;000001.SZ\u0026quot; SELECT factor_name,factor_type,factor_id,is_buy_sell FROM diag_factor_zhongtai WHERE stock_code =\u0026quot;000001.SZ\u0026quot; SELECT trade_date,stock_code,main_money_net FROM diag_quot_zhongtai WHERE data_type=\u0026quot;stocka\u0026quot; AND stock_code=\u0026quot;000001.SZ\u0026quot; ORDER BY trade_date DESC LIMIT 5 SELECT rating_inst,trade_date,recent_rating,pre_rating FROM diag_quot_zhongtai WHERE data_type=\u0026quot;rating\u0026quot; AND stock_code=\u0026quot;000001.SZ\u0026quot; AND trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 59,1) ORDER BY trade_date DESC LIMIT 5 SELECT trade_date,stock_code,price_change FROM diag_quot_zhongtai WHERE data_type=\u0026quot;index\u0026quot; AND stock_code=\u0026quot;000001.SH\u0026quot; AND trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 15,1) SELECT trade_date,stock_code,price_change FROM diag_quot_zhongtai WHERE data_type=\u0026quot;stocka\u0026quot; AND stock_code=\u0026quot;000001.SZ\u0026quot; AND trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 15,1) SELECT a.trade_date,a.stock_code,a.price_change FROM diag_quot_zhongtai a,diag_stocka_zhongtai b WHERE data_type=\u0026quot;indus\u0026quot; AND a.stock_code=b.indus_name AND b.stock_code=\u0026quot;000001.SZ\u0026quot; AND a.trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 15,1)  mysql_test.sh\n[tom@check mm]$ cat mysql_test.sh #! /bin/bash echo \u0026quot;#! /bin/bash\u0026quot; \u0026gt; mysql.test.sh while read line do #echo $line #echo \u0026quot;$line\u0026quot; \u0026quot;haha\u0026quot; #echo mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema='stock' --query=\\'$line\\' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 #echo mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema='stock' --query=\\'$line\\' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 \u0026gt;\u0026gt; mysql.test.sh #echo mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema='stock' --query=\\'\u0026quot;$line\u0026quot;\\' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 echo mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema='stock' --query=\\'\u0026quot;$line\u0026quot;\\' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 #echo mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema='stock' --query=\\'\u0026quot;$line\u0026quot;\\' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 \u0026gt;\u0026gt; mysql.test.sh done chmod +x mysql.test.sh [tom@check mm]$  mysql.test.sh\n[tom@check mm]$ cat mysql.test.sh #! /bin/bash mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT * FROM diag_stocka_zhongtai WHERE stock_code=\u0026quot;000001.SZ\u0026quot;' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT research_report_str FROM diag_stocka_zhongtai WHERE stock_code=\u0026quot;000001.SZ\u0026quot;' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT inst_num,mai_ru,zeng_chi,zhong_xing,jian_chi,mai_chu FROM diag_stocka_zhongtai WHERE stock_code=\u0026quot;000001.SZ\u0026quot;' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT factor_name,factor_type,factor_id,is_buy_sell FROM diag_factor_zhongtai WHERE stock_code =\u0026quot;000001.SZ\u0026quot;' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT trade_date,stock_code,main_money_net FROM diag_quot_zhongtai WHERE data_type=\u0026quot;stocka\u0026quot; AND stock_code=\u0026quot;000001.SZ\u0026quot; ORDER BY trade_date DESC LIMIT 5' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT rating_inst,trade_date,recent_rating,pre_rating FROM diag_quot_zhongtai WHERE data_type=\u0026quot;rating\u0026quot; AND stock_code=\u0026quot;000001.SZ\u0026quot; AND trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 59,1) ORDER BY trade_date DESC LIMIT 5' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT trade_date,stock_code,price_change FROM diag_quot_zhongtai WHERE data_type=\u0026quot;index\u0026quot; AND stock_code=\u0026quot;000001.SH\u0026quot; AND trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 15,1)' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT trade_date,stock_code,price_change FROM diag_quot_zhongtai WHERE data_type=\u0026quot;stocka\u0026quot; AND stock_code=\u0026quot;000001.SZ\u0026quot; AND trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 15,1)' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 mysqlslap -h10.10.15.240 -P3306 --concurrency=10 --iterations=1 --create-schema=stock --query='SELECT a.trade_date,a.stock_code,a.price_change FROM diag_quot_zhongtai a,diag_stocka_zhongtai b WHERE data_type=\u0026quot;indus\u0026quot; AND a.stock_code=b.indus_name AND b.stock_code=\u0026quot;000001.SZ\u0026quot; AND a.trade_date\u0026gt;=(SELECT DISTINCT trade_date FROM diag_quot_zhongtai ORDER BY trade_date DESC LIMIT 15,1)' --number-of-queries=100000 --debug-info -udeveloper01 -pdeveloper01 [tom@check mm]$  cat mysql.tt.sh\n[tom@check mm]$ cat mysql.tt.sh #! /bin/bash cat mysql_strings.txt | ./mysql_test.sh \u0026gt;\u0026gt; mysql.test.sh cat ./mysql.test.sh ./mysql.test.sh | tee -a ./mysql.test.sh.log [tom@check mm]$  mysql.test.sh.log\n[tom@check mm]$ cat mysql.test.sh.log Benchmark Average number of seconds to run all queries: 1.716 seconds Minimum number of seconds to run all queries: 1.716 seconds Maximum number of seconds to run all queries: 1.716 seconds Number of clients running queries: 10 Average number of queries per client: 10000 Benchmark Average number of seconds to run all queries: 2.109 seconds Minimum number of seconds to run all queries: 2.109 seconds Maximum number of seconds to run all queries: 2.109 seconds Number of clients running queries: 10 Average number of queries per client: 10000 Benchmark Average number of seconds to run all queries: 2.577 seconds Minimum number   "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-random-get-one-or-multi-records.html",
	"title": "Mysql随机获取一条或者多条数据",
	"tags": ["mysql"],
	"description": "",
	"content": "https://www.cnblogs.com/leezhxing/p/3951801.html\nselect id, name, image from device_rent_manage where functionType = 'JCSB' and type = 'YNSBXLJC' and id \u0026gt;= ((SELECT MAX(id) FROM device_rent_manage where functionType = 'JCSB' and type = 'YNSBXLJC')-(SELECT MIN(id) FROM device_rent_manage where functionType = 'JCSB' and type = 'YNSBXLJC')) * RAND() + (SELECT MIN(id) FROM device_rent_manage where functionType = 'JCSB' and type = 'YNSBXLJC' ) LIMIT 3;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-from-docker-to-bare.html",
	"title": "Mariadb Galera From Docker to Bare",
	"tags": ["mariadb", "galera", "docker"],
	"description": "",
	"content": " mysql系列之 从 docker+Galera 转到 Galera(去除 docker)\ncontext 之前在 docker之docker-mariadb-galera(panubo版) 中成功在 docker 中安装了 Galera, 突然, 由于业务调整, 需要把 Galera 从docker中脱离出来, 直接在 裸机 上跑..\nnode0, 10.10.13.110, primary node1, 10.10.15.240 node2, 10.10.12.13(这一台暂时没用上)\nstep  [在node0, node1, node2上]把 Galera 从 docker 中删除\ndocker stop abcd\n [node0上]然后, 我尝试重新启动 MariaDB-Galera-cluster, 怎么重启, 那自然是参考 mysql系列之集群 MariaDB Galera Cluster 部署\n  来到 node0上,\nsudo /etc/init.d/mysql status sudo /etc/init.d/mysql start --wsrep-new-cluster  发现, 直接报错了..\n[tom@mariadb-node-0 ~]$ sudo /etc/init.d/mysql start --wsrep-new-cluster Starting MySQL.170317 13:22:10 mysqld_safe Logging to '/data/mariadb/mysql/mariadb-node-0.err'. ERROR! [tom@mariadb-node-0 ~]$  这下可好了, 怎么办呢?\n去调试吧\u0026hellip;\n 调试, 使用 --verbose\nsudo -u mysql mysqld \u0026ndash;verbose \u0026ndash;defaults-file=/etc/my.cnf.d/server.cnf 去查一下, 发现, 原来是权限不对..为什么会权限不对? 噢,\u0008 原来是因为, 之前是在 docker 下安装的 galera, 那自然, 下面的这些数据目录(/data/mariadb/mysql/),是属于 docker 的所有者(panubo)的啦.然后现在要直接在机器上安装galera,那自然这些数据目录(/data/mariadb/mysql/)应该要属于 mysql:mysql才对, 那意味着, 用户组不对, 自然没权限, 自然报错啦\u0026hellip;\n  怎么搞? 修改权限啦!\nsudo chown -R mysql:mysql /data/mariadb/mysql/  好了, 重新启动galera集群 sudo /etc/init.d/mysql start \u0026ndash;wsrep-new-cluster\n哈哈, 成功启动 node0 了..\n 把 node1, node2, 也同样地, 修改 数据目录 的所有者权限..重启mysql吧..\n[tom@mariadb-node-2 ~]$ sudo /etc/init.d/mysql start Starting MySQL.170317 16:54:53 mysqld_safe Logging to \u0026lsquo;/data/mariadb/mysql/mariadb-node-2.err\u0026rsquo;. \u0026hellip;. SUCCESS! [tom@mariadb-node-2 ~]$\n  哈哈, 成功启动 node1, node2..\n 那检查一下, galera, 正常了没有\u0026hellip;\n[tom@test_240 ~]$ mysql -u root -p -e \u0026ldquo;show status like \u0026lsquo;wsrep%\u0026rsquo;;\u0026rdquo; Enter password: +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+ | Variable_name | Value | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+ | wsrep_local_state_uuid | 825cf372-abf0-11e6-9f33-b3514b1b22d5 | \u0026hellip; | wsrep_cluster_conf_id | 3 | | wsrep_cluster_size | 3 \u0026hellip;\n  哈哈, 说明, 我们的 galera , 真的成功启动了\u0026hellip;\nend "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-user.html",
	"title": "Mysql User",
	"tags": ["mysql", "user"],
	"description": "",
	"content": " mysql系列之MySQL查看用户权限\nreference http://www.oschina.net/code/snippet_222150_12541\n##\nshow grants for 你的用户; show grants for root@\u0026lsquo;localhost\u0026rsquo;; show grants for webgametest@10.3.18.158; show create database dbname; 这个可以看到创建数据库时用到的一些参数。 show create table tickets; 可以看到创建表时用到的一些参数\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-navicat.html",
	"title": "Mysql Navicat",
	"tags": ["mysql", "navicat"],
	"description": "",
	"content": " mysql系列之navicat\nreference http://blog.csdn.net/lwei_998/article/details/45560483\nhttp://blog.csdn.net/moneyshi/article/details/50906650\nhttp://mt.sohu.com/20160324/n441844650.shtml\n导出连接设置 Navicat 版本 8 1.选择文件 -\u0026gt; 导出登录数据文件。导出的文件（.reg）包含你的全部连接设置。 2.备份已导出的文件（.reg）。 3.在现有的计算机解除安装 Navicat。 4.在新的计算机重新安装 Navicat。 5.在新的计算机运行已导出的文件（.reg）。\nNavicat 版本 9 或以上 1.在 Navicat，选择文件 -\u0026gt; 导出连接。导出的文件（.ncx）包含你的全部连接设置。 2.备份已导出的文件（.ncx）。 3.在现有的计算机解除安装 Navicat。** 4.在新的计算机重新安装 Navicat。 5.在新的计算机打开 Navicat 和选择文件 -\u0026gt; 导入连接。\n** 如果你使用版本 11 或以上，请在解除安装 Navicat 前取消激活注册码。\n当创建一个新的连接，Navicat 将创建一个子文件夾（名为各数据库的名）在设置保存路径內。所有备份（.psc、.psb）、报表（.rtm）、查询（.sql）、导入/导出设置文件等都是保存在该子文件夾。要查找路径，你可以右击连接，然后选择连接属性 -\u0026gt; 高级 -\u0026gt; 设置保存路径/设置位置。\n此外，全部已保存的设置文件（批处理作业设置文件）会保存在 profiles 文件夾。要查找路径，选择工具 -\u0026gt; 选项 -\u0026gt; 其他 -\u0026gt; 设置文件保存路径/设置文件位置。\n异常收集之：navicatdesignquery.sql.bak 系统找不到指定路径 今天使用Navicat ，其他功能都正常，但是新建查询的时候，出现一个很奇葩的问题\nC:\\Program Files (x86)\\PremiumSoft\\Navicat for MySQL8.1/_NAVICAT_DESIGNQUERY.sql.bak 系统找不到指定路径\n找了半天找不到解决办法，下载navicat 11都没用， 更改版本也没用。\n最后发现，navicat 的每个连接，有个连接属性\n具体操作： 在连接\u0026mdash;属性\u0026mdash;高级。修改一下路径，改成你现在安装的navicat目录就好了\n如何迁移 Navicat 到新的计算机 迁移Navicat到新的计算机的步骤：\n　1. 选择文件-\u0026gt;导出连接。导出的文件（.ncx）包含了全部连接设置内容。 2. 备份已导出的文件（.ncx）。 3. 在Navicat，选择帮助-\u0026gt;注册，并点击“取消激活”来在线取消激活Navicat注册码。 4. 在现有的计算机解除安装Navicat。 5. 在新的计算机重新安装Navicat。 6. 在新的计算机中，打开Navicat，选择文件-\u0026gt;导入连接。\n当创建一个新的连接，Navicat将在设置位置创建一个子文件夹。大多数文件都保存在该子文件夹，右击选择属性-\u0026gt;打开文件位置可查找路径。\n此外，全部已保存的设置文件会保存在Profiles文件夹，选择工具-\u0026gt;选项-\u0026gt;其他-\u0026gt;文件位置，即可查找存储路径。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-cluster-install-base-centos.html",
	"title": "Mariadb Cluster Install Base Centos",
	"tags": ["mysql", "mariadb", "cluster", "install"],
	"description": "",
	"content": " mysql系列之mysql-cluster\n主要参考 http://mariadb.org/\n环境  centos7-amd64 mariadb10.1（IP:10.10.13.110） + mariadb5.5(IP:192.168.31.240)  步骤 准备2台机器 安装mariadb10.1\n参考这里\n把 mariadb5.5 的数据，导出后，导入到 mariadb10.1 导出 导入 mysql主从复制 第一步，就要看这几个参考 依次看 http://blog.csdn.net/gaowenhui2008/article/details/46698321 http://blog.csdn.net/hguisu/article/details/7325124 http://blog.jobbole.com/94595/ http://www.xuejiehome.com/blread-1664.html MYSQL主从同步的管理 参考 http://blog.csdn.net/gaowenhui2008/article/details/46698321 1. 停止MYSQL同步 1. 停止MYSQL同步 STOP SLAVE IO_THREAD; #停止IO进程 STOP SLAVE SQL_THREAD; #停止SQL进程 STOP SLAVE; #停止IO和SQL进程 2. 启动MYSQL同步 START SLAVE IO_THREAD; #启动IO进程 START SLAVE SQL_THREAD; #启动SQL进程 START SLAVE; #启动IO和SQL进程 3. 重置MYSQL同步 RESET SLAVE; 用于让从属服务器忘记其在主服务器的二进制日志中的复制位置, 它会删除master.info和relay-log.info文件，以及所有的中继日志，并启动一个新的中继日志,当你不需要主从的时候可以在从上执行这个操作。不然以后还会同步，可能会覆盖掉你的数据库，我以前就遇到过这样傻叉的事情。哈哈！ 4. 查看MYSQL同步状态 SHOW SLAVE STATUS; 这个命令主要查看Slave_IO_Running、Slave_SQL_Running、Seconds_Behind_Master、Last_IO_Error、Last_SQL_Error这些值来把握复制的状态。 5. 临时跳过MYSQL同步错误 经常会朋友mysql主从同步遇到错误的时候，比如一个主键冲突等，那么我就需要在确保那一行数据一致的情况下临时的跳过这个错误，那就需要使用SQL_SLAVE_SKIP_COUNTER = n命令了，n是表示跳过后面的n个事件,比如我跳过一个事件的操作如下： STOP SLAVE; SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1; START SLAVE; 6. 从指定位置重新同步 有的时候主从同步有问题了以后，需要从log位置的下一个位置进行同步，相当于跳过那个错误，这时候也可以使用CHANGE MASTER命令来处理，只要找到对应的LOG位置就可以,比如： CHANGE MASTER TO MASTER_HOST=\u0026lsquo;10.1.1.75\u0026rsquo;,MASTER_USER=\u0026lsquo;replication\u0026rsquo;,MASTER_PASSWORD=\u0026lsquo;123456\u0026rsquo;,MASTER_LOG_FILE=\u0026lsquo;mysql-bin.000006\u0026rsquo;, MASTER_LOG_POS=106; START SLAVE; MYSQL主从同步的管理经验介绍 1. 不要乱使用SQL_SLAVE_SKIP_COUNTER命令。 这个命令跳过之后很可能会导致你的主从数据不一致，一定要先将指定的错误记录下来，然后再去检查数据是否一致，尤其是核心的业务数据。 2. 结合percona-toolkit工具pt-table-checksum定期查看数据是否一致 这个是DBA必须要定期做的事情，呵呵，有合适的工具何乐而不为呢？另外percona-toolkit还提供了对数据库不一致的解决方案，可以采用pt-table-sync，这个工具不会更改主的数据。还可以使用pt-heartbeat来查看从服务器的复制落后情况。 具体的请查看：http://blog.chinaunix.net/uid-20639775-id-3229211.html。 3. 使用replicate-wild-ignore-table选项而不要使用replicate-do-db或者replicate-ignore-db。 原因已经在上面做了说明。 4. 将主服务器的日志模式调整成mixed。 5. 每个表都加上主键，主键对数据库的同步会有影响尤其是居于ROW复制模式。 mysql主从复制 情况１：主从mysql，之前都无数据 参考 http://blog.jobbole.com/94595/ http://www.xuejiehome.com/blread-1664.html 步骤 目标 10.10.12.14(主) 10.10.12.15(从) 1、主从安装mysql，版本一致 mysql\u0026gt;status;\nMariaDB [test]\u0026gt; status; mysql Ver 15.1 Distrib 5.5.44-MariaDB, for Linux (x86_64) using readline 5.1\nConnection id: 4 Current database: test Current user: root@localhost SSL: Not in use Current pager: stdout Using outfile: \u0026ldquo; Using delimiter: ; Server: MariaDB Server version: 5.5.44-MariaDB-log MariaDB Server Protocol version: 10 Connection: Localhost via UNIX socket Server characterset: utf8 Db characterset: utf8 Client characterset: utf8 Conn. characterset: utf8 UNIX socket: /var/lib/mysql/mysql.sock Uptime: 18 min 15 sec\nThreads: 2 Questions: 24 Slow queries: 0 Opens: 1 Flush tables: 2 Open tables: 27 Queries per second avg: 0.021 MariaDB [test]\u0026gt;\n 2、修改master，slave服务器 master服务器配置： sudo　vi /etc/my.cnf [mysqld]  datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock\nDisabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0\nSettings user and group are ignored when systemd is used. If you need to run mysqld under a different user or group, customize your systemd unit file for mariadb according to the instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin server-id=14 binlog-ignore-db = mysql,information_schema\n[mysqld] server-id=14\n#设置服务器唯一的id，默认是1，一般取IP最后一段，我们设置ip最后一段，slave设置14 log-bin=mysql-bin\n启用二进制日志 binlog-ignore-db = mysql,information_schema\n#忽略写入binlog的库 slave服务器配置： sudo　vi /etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock\nDisabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0\nSettings user and group are ignored when systemd is used. If you need to run mysqld under a different user or group, customize your systemd unit file for mariadb according to the instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin server-id=15 replicate-wild-ignore-table=test.% #replicate-do-db = test #slave-skip-errors = all\n replicate-wild-ignore-table=test.%  #　replicate-do-db = test\n#上面２句都可以表示只同步test库(但是第一句更好，不要使用第２名)，　＃如果同步所有的库，则不要加上这一句 slave-skip-errors = all\n#忽略因复制出现的所有错误 3、重启主从服务器mysql sudo systemctl restart mariadb.service sudo systemctl status mariadb.service 4、在主服务器上建立帐户并授权slave GRANT REPLICATION SLAVE ON . to \u0026lsquo;sync\u0026rsquo;@\u0026lsquo;10.10.12.%\u0026rsquo; identified by \u0026lsquo;123.com\u0026rsquo;; 注意，这里是　10.10.12.%, 而不是 10.10.12.* 我犯过这样的错误 GRANT REPLICATION SLAVE ON . to \u0026lsquo;sync\u0026rsquo;@\u0026lsquo;10.10.12.15\u0026rsquo; identified by \u0026lsquo;123.com\u0026rsquo;; 注意：大家在设置权限的时候不要将密码设置过于简单！ 5、查看主数据库状态 show master status\\G; MariaDB [(none)]\u0026gt; show master status; +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | mysql-bin.000002 | 707 | | mysql,information_schema | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ 1 row in set (0.00 sec)\nMariaDB [(none)]\u0026gt; MariaDB [(none)]\u0026gt; show master status\\G; *************************** 1. row *************************** File: mysql-bin.000002 Position: 707 Binlog_Do_DB: Binlog_Ignore_DB: mysql,information_schema 1 row in set (0.01 sec)\nERROR: No query specified\nMariaDB [(none)]\u0026gt; 记录下 File 及 Position 的值，在后面进行从服务器操作的时候需要用到。 6、配置从数据库 change master to master_host=\u0026lsquo;10.10.12.14\u0026rsquo;, master_user=\u0026lsquo;sync\u0026rsquo;, master_password=\u0026lsquo;123.com\u0026rsquo;, master_log_file\u0026rsquo;=\u0026lsquo;mysql-bin.000002\u0026rsquo;, master_log_pos=707; 7、启动slave同步进程并 MariaDB [(none)]\u0026gt; start slave; 查看状态 MariaDB [(none)]\u0026gt; show slave status\\G; MariaDB [(none)]\u0026gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.12.14 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 707 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 838 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: test 其中Slave_IO_Running 与 Slave_SQL_Running 的值都必须为YES，才表明状态正常。 报错 主从同步出现一下错误：Slave_IO_Running: Connecting 导致lave_IO_Running 为connecting 的原因主要有以下 3 个方面： 1、网络不通 2、密码不对 解决 从服务器 STOP SLAVE; #停止IO和SQL进程 RESET SLAVE; STOP SLAVE; #停止IO和SQL进程 6、配置从数据库 change master to master_host=\u0026lsquo;10.10.12.14\u0026rsquo;, master_user=\u0026lsquo;sync\u0026rsquo;, master_password=\u0026lsquo;123.com\u0026rsquo;, master_log_file\u0026rsquo;=\u0026lsquo;mysql-bin.000002\u0026rsquo;, master_log_pos=707; START SLAVE; #启动IO和SQL进程 实操 MariaDB [(none)]\u0026gt; reset slave; ERROR 1198 (HY000): This operation cannot be performed with a running slave; run STOP SLAVE first MariaDB [(none)]\u0026gt; stop slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; reset slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; show slave status\\G; MariaDB [(none)]\u0026gt; stop slave; Query OK, 0 rows affected, 1 warning (0.00 sec)\nMariaDB [(none)]\u0026gt; change master to -\u0026gt; master_host=\u0026lsquo;10.10.13.100\u0026rsquo;, -\u0026gt; master_user=\u0026lsquo;sync\u0026rsquo;, -\u0026gt; master_password=\u0026lsquo;sync.com\u0026rsquo;, -\u0026gt; master_log_file=\u0026lsquo;mysql-bin.000001\u0026rsquo;, -\u0026gt; master_log_pos=927; Query OK, 0 rows affected (0.01 sec)\nMariaDB [(none)]\u0026gt; start slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.13.100 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 927 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 529 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 3、pos不对 8、验证主从同步\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-cluster-install-faq-base-centos.html",
	"title": "Mariadb Galera Cluster Install Faq Base Centos",
	"tags": ["mariadb", "galera"],
	"description": "",
	"content": " mysql系列之集群 MariaDB-Galera-cluster 报错\n报错1, /etc/my.cnf.d/下 有一个 不应该存在的 .cnf 错误原因：\nmysql 加载了 /etc/my.cnf.d/下的所有 *.cnf 文件，其中又有一个之前的不应该存在的 *.cnf。\n正确情况下，应该只有4个.cnf文件。 [spa@s11 ~]$ ls /etc/my.cnf.d/ client.cnf mysql-clients.cnf server.cnf tokudb.cnf [spa@s11 ~]$\n错误情况：\n[tom@kube-node-13 ~]$ sudo /etc/init.d/mysql start --wsrep-new-cluster Starting MySQL.161116 17:44:54 mysqld_safe Logging to '/data/mariadb/mysql/kube-node-13.err'. . SUCCESS! [tom@kube-node-13 ~]$ mysql -u root -p -e \u0026quot;show status like 'wsrep%'\u0026quot; Enter password: +--------------------------+----------------------+ | Variable_name | Value | +--------------------------+----------------------+ | wsrep_cluster_conf_id | 18446744073709551615 | | wsrep_cluster_size | 0 | | wsrep_cluster_state_uuid | | | wsrep_cluster_status | Disconnected | | wsrep_connected | OFF | | wsrep_local_bf_aborts | 0 | | wsrep_local_index | 18446744073709551615 | | wsrep_provider_name | | | wsrep_provider_vendor | | | wsrep_provider_version | | | wsrep_ready | ON | | wsrep_thread_count | 0 | +--------------------------+----------------------+ [tom@kube-node-13 ~]$  解决过程：\n怎么办呢？\n先看状态\n[tom@kube-node-13 ~]$ sudo service mysql status -l SUCCESS! MySQL running (11946)  关闭掉，我们来手动启动查原因。\n[tom@kube-node-13 ~]$ sudo service mysql stop Shutting down MySQL... SUCCESS! [tom@kube-node-13 ~]$  查一下，如何手动启动\n[spa@s11 ~]$ which mysqld /usr/sbin/mysqld [cdn@test_240 OpenPicker]$ mysqld --help mysqld Ver 10.0.28-MariaDB-wsrep for Linux on x86_64 (MariaDB Server, wsrep_25.16.rc3fc46e) Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others. Starts the MariaDB database server. Usage: mysqld [OPTIONS] For more help options (several pages), use mysqld --verbose --help. [cdn@test_240 OpenPicker]$ use mysqld --verbose --help ... 一大串 ...  手动启动\n[tom@kube-node-13 ~]$ mysqld --verbose 161116 18:30:01 [Note] mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 12713 ... 161116 18:30:01 [Warning] Can't create test file /data/mariadb/mysql/kube-node-13.lower-test 161116 18:30:01 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:30:01 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib/galera/libgalera_smm.so' 161116 18:30:01 [ERROR] WSREP: wsrep_load(): dlopen(): /usr/lib/galera/libgalera_smm.so: cannot open shared object file: No such file or directory 161116 18:30:01 [ERROR] WSREP: wsrep_load(/usr/lib/galera/libgalera_smm.so) failed: Invalid argument (22). Reverting to no provider. 161116 18:30:01 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:30:01 [Note] WSREP: wsrep_load(): loading provider library 'none' 2016-11-16 18:30:01 7f1069f42880 InnoDB: Warning: Using innodb_locks_unsafe_for_binlog is DEPRECATED. This option may be removed in future releases. Please use READ COMMITTED transaction isolation level instead, see http://dev.mysql.com/doc/refman/5.6/en/set-transaction.html. 161116 18:30:01 [Note] InnoDB: Using mutexes to ref count buffer pool pages 161116 18:30:01 [Note] InnoDB: The InnoDB memory heap is disabled 161116 18:30:01 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins 161116 18:30:01 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier 161116 18:30:01 [Note] InnoDB: Compressed tables use zlib 1.2.7 161116 18:30:01 [Note] InnoDB: Using Linux native AIO 161116 18:30:01 [Note] InnoDB: Using CPU crc32 instructions 161116 18:30:01 [Note] InnoDB: Initializing buffer pool, size = 128.0M 161116 18:30:01 [Note] InnoDB: Completed initialization of buffer pool 161116 18:30:01 [ERROR] InnoDB: ./ibdata1 can't be opened in read-write mode 161116 18:30:01 [ERROR] InnoDB: The system tablespace must be writable! 161116 18:30:01 [ERROR] Plugin 'InnoDB' init function returned error. 161116 18:30:01 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed. 161116 18:30:01 [ERROR] mysqld: File '/data/mariadb/mysql/aria_log_control' not found (Errcode: 13 \u0026quot;Permission denied\u0026quot;) 161116 18:30:01 [ERROR] mysqld: Got error 'Can't open file' when trying to use aria control file '/data/mariadb/mysql/aria_log_control' 161116 18:30:01 [ERROR] Plugin 'Aria' init function returned error. 161116 18:30:01 [ERROR] Plugin 'Aria' registration as a STORAGE ENGINE failed. 161116 18:30:01 [Note] Plugin 'FEEDBACK' is disabled. 161116 18:30:01 [ERROR] Can't open the mysql.plugin table. Please run mysql_upgrade to create it. 161116 18:30:01 [ERROR] Unknown/unsupported storage engine: innodb 161116 18:30:01 [ERROR] Aborting 161116 18:30:01 [Note] WSREP: Service disconnected. 161116 18:30:02 [Note] WSREP: Some threads may fail to exit. 161116 18:30:02 [Note] mysqld: Shutdown complete  看到了吧，上面有一行\n161116 18:30:01 [ERROR] WSREP: wsrep_load(): dlopen(): /usr/lib/galera/libgalera_smm.so: cannot open shared object file: No such file or directory\n说明有问题了吧。 先这样，我们确保一下，启动程序的用户是mysql,来吧。\n[tom@kube-node-13 ~]$ sudo --help sudo: invalid option -- '-' usage: sudo [-D level] -h | -K | -k | -V usage: sudo -v [-AknS] [-D level] [-g groupname|#gid] [-p prompt] [-u user name|#uid] usage: sudo -l[l] [-AknS] [-D level] [-g groupname|#gid] [-p prompt] [-U user name] [-u user name|#uid] [-g groupname|#gid] [command] usage: sudo [-AbEHknPS] [-r role] [-t type] [-C fd] [-D level] [-g groupname|#gid] [-p prompt] [-u user name|#uid] [-g groupname|#gid] [VAR=value] [-i|-s] [\u0026lt;command\u0026gt;] usage: sudo -e [-AknS] [-r role] [-t type] [-C fd] [-D level] [-g groupname|#gid] [-p prompt] [-u user name|#uid] file ... [tom@kube-node-13 ~]$  好了，知道了，用sudo -u ,那这个 -u 后面接什么用户呢？mysql ,还是 mysqld？\n[tom@kube-node-13 ~]$ ll /var/lib/mysql/ total 217128 -rw-rw----. 1 mysql mysql 16384 11月 16 18:18 aria_log.00000001 -rw-rw----. 1 mysql mysql 52 11月 16 18:18 aria_log_control -rw-rw----. 1 mysql mysql 12582912 11月 16 18:18 ibdata1 -rw-rw----. 1 mysql mysql 104857600 11月 16 18:18 ib_logfile0 -rw-rw----. 1 mysql mysql 104857600 11月 16 18:18 ib_logfile1 -rw-r-----. 1 mysql root 5489 11月 16 18:18 kube-node-13.err -rw-rw----. 1 mysql mysql 0 11月 16 13:34 multi-master.info drwx--x--x. 2 mysql mysql 4096 11月 16 12:51 mysql srwxrwxrwx. 1 mysql mysql 0 11月 17 10:28 mysql.sock drwx------. 2 mysql mysql 4096 11月 16 12:51 performance_schema -rw-------. 1 mysql root 2538 11月 16 18:18 wsrep_recovery.N15shv [tom@kube-node-13 ~]$  好了，现在知道了，这些文件都是 mysql用户的，那自然，我们应该是 sudo -u mysql . 来吧。\n[tom@kube-node-13 ~]$ sudo -u mysql mysqld --verbose 161116 18:32:38 [Note] mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 12963 ... 161116 18:32:38 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:32:38 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib/galera/libgalera_smm.so' 161116 18:32:38 [ERROR] WSREP: wsrep_load(): dlopen(): /usr/lib/galera/libgalera_smm.so: cannot open shared object file: No such file or directory 161116 18:32:38 [ERROR] WSREP: wsrep_load(/usr/lib/galera/libgalera_smm.so) failed: Invalid argument (22). Reverting to no provider. 161116 18:32:38 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:32:38 [Note] WSREP: wsrep_load(): loading provider library 'none' 2016-11-16 18:32:38 7f71c04dd880 InnoDB: Warning: Using innodb_locks_unsafe_for_binlog is DEPRECATED. This option may be removed in future releases. Please use READ COMMITTED transaction isolation level instead, see http://dev.mysql.com/doc/refman/5.6/en/set-transaction.html. 161116 18:32:38 [Note] InnoDB: Using mutexes to ref count buffer pool pages 161116 18:32:38 [Note] InnoDB: The InnoDB memory heap is disabled 161116 18:32:38 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins 161116 18:32:38 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier 161116 18:32:38 [Note] InnoDB: Compressed tables use zlib 1.2.7 161116 18:32:38 [Note] InnoDB: Using Linux native AIO 161116 18:32:38 [Note] InnoDB: Using CPU crc32 instructions 161116 18:32:38 [Note] InnoDB: Initializing buffer pool, size = 128.0M 161116 18:32:38 [Note] InnoDB: Completed initialization of buffer pool 161116 18:32:38 [Note] InnoDB: Highest supported file format is Barracuda. 161116 18:32:38 [Note] InnoDB: 128 rollback segment(s) are active. 161116 18:32:38 [Note] InnoDB: Waiting for purge to start 161116 18:32:38 [Note] InnoDB: Percona XtraDB (http://www.percona.com) 5.6.32-79.0 started; log sequence number 1624176 161116 18:32:38 [Note] Plugin 'FEEDBACK' is disabled. 161116 18:32:38 [Note] Server socket created on IP: '0.0.0.0'. 161116 18:32:38 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:32:38 [Note] WSREP: wsrep_load(): loading provider library 'none' 161116 18:32:38 [Note] mysqld: ready for connections. Version: '10.0.28-MariaDB-wsrep' socket: '/var/lib/mysql/mysql.sock' port: 3306 MariaDB Server, wsrep_25.16.rc3fc46e ^C^C^C^C^C^CKilled [tom@kube-node-13 ~]$  看到了。错误\n161116 18:32:38 [ERROR] WSREP: wsrep_load(): dlopen(): /usr/lib/galera/libgalera_smm.so: cannot open shared object file: No such file or directory\n还在。\n找一下，看这个文件在不在了？\n[tom@kube-node-13 ~]$ sudo ls -l /usr/lib/galera/libgalera_smm.so ls: cannot access /usr/lib/galera/libgalera_smm.so: No such file or directory  好了，这个文件真的不存在。 那试一下 /usr/lib64/ 下有没有这个文件呢？\n[tom@kube-node-13 ~]$ sudo ls /usr/lib64/galera/libgalera_smm.so /usr/lib64/galera/libgalera_smm.so  哈哈。有呀。 那看一下，我们配置里面的是哪个？\n[tom@kube-node-13 ~]$ sudo cat /etc/my.cnf.d/server.cnf ... binlog_format=ROW default-storage-engine=innodb innodb_autoinc_lock_mode=2 innodb_locks_unsafe_for_binlog=1 query_cache_size=0 query_cache_type=0 bind-address=0.0.0.0 datadir=/data/mariadb/mysql #datadir=/var/lib/mysql innodb_log_file_size=100M innodb_file_per_table innodb_flush_log_at_trx_commit=2 wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=\u0026quot;gcomm://10.10.13.110,192.168.31.240,10.10.12.13\u0026quot; wsrep_cluster_name='galera_cluster' wsrep_node_address='10.10.12.13' wsrep_node_name='db3' wsrep_sst_method=rsync wsrep_sst_auth=sst_user:dbpass  看到了吧，是wsrep_provider=/usr/lib64/galera/libgalera_smm.so。是/usr/lib64/。那说明了，程序没有成功加载我们的配置文件呀。\n无论怎样，我们先做一个软链接，看下，能不能成功。\n注意哈，这里是直接把整个文件夹做成软链接，不要写错了。不是sudo ln -s /usr/lib64/galera/ /usr/lib/galera/， 更不是sudo ln -s /usr/lib64/galera/ /usr/lib/galera/。\n[tom@kube-node-13 galera]$ sudo ln -s /usr/lib64/galera /usr/lib/galera [tom@kube-node-13 galera]$ cd /usr/lib/galera/ [tom@kube-node-13 galera]$ ls libgalera_smm.so [tom@kube-node-13 galera]$  做好了。再来一次。\n[tom@kube-node-13 galera]$ sudo -u mysql mysqld --verbose 161116 18:46:07 [Note] mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 14216 ... 161116 18:46:07 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:46:07 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib/galera/libgalera_smm.so' 161116 18:46:07 [Note] WSREP: wsrep_load(): Galera 25.3.18(r3632) by Codership Oy \u0026lt;info@codership.com\u0026gt; loaded successfully. 161116 18:46:07 [Note] WSREP: CRC-32C: using hardware acceleration. 161116 18:46:07 [Warning] WSREP: Could not open state file for reading: '/data/mariadb/mysql//grastate.dat' 161116 18:46:07 [Note] WSREP: Found saved state: 00000000-0000-0000-0000-000000000000:-1 161116 18:46:07 [Note] WSREP: Passing config to GCS: base_dir = /data/mariadb/mysql/; base_host = 10.10.12.13; base_port = 4567; cert.log_conflicts = no; debug = no; evs.auto_evict = 0; evs.delay_margin = PT1S; evs.delayed_keep_period = PT30S; evs.inactive_check_period = PT0.5S; evs.inactive_timeout = PT15S; evs.join_retrans_period = PT1S; evs.max_install_timeouts = 3; evs.send_window = 4; evs.stats_report_period = PT1M; evs.suspect_timeout = PT5S; evs.user_send_window = 2; evs.view_forget_timeout = PT24H; gcache.dir = /data/mariadb/mysql/; gcache.keep_pages_size = 0; gcache.mem_size = 0; gcache.name = /data/mariadb/mysql//galera.cache; gcache.page_size = 128M; gcache.size = 128M; gcomm.thread_prio = ; gcs.fc_debug = 0; gcs.fc_factor = 1.0; gcs.fc_limit = 16; gcs.fc_master_slave = no; gcs.max_packet_size = 64500; gcs.max_throttle = 0.25; gcs.recv_q_hard_limit = 9223372036854775807; gcs.recv_q_soft_limit = 0.25; gcs.sync_donor = no; gmcast.segment = 0; gmcast.version = 0; pc.announce_timeout = PT3S; pc.checksum = false; pc.ignore_q 161116 18:46:07 [Note] WSREP: Service thread queue flushed. 161116 18:46:07 [Note] WSREP: Assign initial position for certification: -1, protocol version: -1 161116 18:46:07 [Note] WSREP: wsrep_sst_grab() 161116 18:46:07 [Note] WSREP: Start replication 161116 18:46:07 [Note] WSREP: Setting initial position to 00000000-0000-0000-0000-000000000000:-1 161116 18:46:07 [Note] WSREP: protonet asio version 0 161116 18:46:07 [Note] WSREP: Using CRC-32C for message checksums. 161116 18:46:07 [Note] WSREP: backend: asio 161116 18:46:07 [Note] WSREP: gcomm thread scheduling priority set to other:0 161116 18:46:07 [Warning] WSREP: access file(/data/mariadb/mysql//gvwstate.dat) failed(No such file or directory) 161116 18:46:07 [Note] WSREP: restore pc from disk failed 161116 18:46:07 [Note] WSREP: GMCast version 0 161116 18:46:07 [Note] WSREP: (e0f5cb2a, 'tcp://0.0.0.0:4567') listening at tcp://0.0.0.0:4567 161116 18:46:07 [Note] WSREP: (e0f5cb2a, 'tcp://0.0.0.0:4567') multicast: , ttl: 1 161116 18:46:07 [Note] WSREP: EVS version 0 161116 18:46:07 [Note] WSREP: gcomm: connecting to group 'my_wsrep_cluster', peer '10.10.13.110:' 161116 18:46:10 [Warning] WSREP: no nodes coming from prim view, prim not possible 161116 18:46:10 [Note] WSREP: view(view_id(NON_PRIM,e0f5cb2a,1) memb { e0f5cb2a,0 } joined { } left { } partitioned { }) 161116 18:46:10 [Warning] WSREP: last inactive check more than PT1.5S ago (PT3.50279S), skipping check 161116 18:46:40 [Note] WSREP: view((empty)) 161116 18:46:40 [ERROR] WSREP: failed to open gcomm backend connection: 110: failed to reach primary view: 110 (Connection timed out) at gcomm/src/pc.cpp:connect():162 161116 18:46:40 [ERROR] WSREP: gcs/src/gcs_core.cpp:gcs_core_open():208: Failed to open backend connection: -110 (Connection timed out) 161116 18:46:40 [ERROR] WSREP: gcs/src/gcs.cpp:gcs_open():1380: Failed to open channel 'my_wsrep_cluster' at 'gcomm://10.10.13.110': -110 (Connection timed out) 161116 18:46:40 [ERROR] WSREP: gcs connect failed: Connection timed out 161116 18:46:40 [ERROR] WSREP: wsrep::connect(gcomm://10.10.13.110) failed: 7 161116 18:46:40 [ERROR] Aborting 161116 18:46:40 [Note] WSREP: Service disconnected. 161116 18:46:41 [Note] WSREP: Some threads may fail to exit. 161116 18:46:41 [Note] mysqld: Shutdown complete [tom@kube-node-13 galera]$  哈哈，看 161116 18:46:07 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib/galera/libgalera_smm.so' 知道，这个错误，确实是跳过去了。 现在来找第一个 [Warning] 。找到了。161116 18:46:07 [Warning] WSREP: Could not open state file for reading: '/data/mariadb/mysql//grastate.dat' 那看下，这个文件有没有？\n[tom@kube-node-13 galera]$ cd /data/mariadb/mysql [tom@kube-node-13 mysql]$ ls -lZ -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 aria_log.00000001 -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 aria_log_control -rw-------. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 galera.cache -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 grastate.dat -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 ibdata1 -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 ib_logfile0 -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 ib_logfile1 -rw-r-----. mysql root unconfined_u:object_r:mysqld_db_t:s0 kube-node-13.err -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 kube-node-13.pid -rw-rw----. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 multi-master.info drwx--x--x. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 mysql drwx------. mysql mysql unconfined_u:object_r:mysqld_db_t:s0 performance_schema -rw-rw-rw-. root root unconfined_u:object_r:mysqld_db_t:s0 slow_query_log.log  有/data/mariadb/mysql//grastate.dat呀。什么鬼？ 不要手动启动了。用sudo service 启动一下。\n[tom@kube-node-13 mysql]$ sudo service mysql start Starting MySQL SUCCESS! [tom@kube-node-13 mysql]$ 161116 18:50:43 mysqld_safe Logging to '/data/mariadb/mysql/kube-node-13.err'. ^C [tom@kube-node-13 mysql]$  好了，再把现有的 mysqld 关闭了去。\n[tom@kube-node-13 mysql]$ sudo service mysql stop Shutting down MySQL161116 18:54:00 [Note] mysqld: Normal shutdown .161116 18:54:00 [Note] WSREP: Stop replication 161116 18:54:00 [Note] Event Scheduler: Purging the queue. 0 events 161116 18:54:00 [Note] InnoDB: FTS optimize thread exiting. 161116 18:54:00 [Note] InnoDB: Starting shutdown... 161116 18:54:01 [Note] InnoDB: Waiting for page_cleaner to finish flushing of buffer pool ..161116 18:54:02 [Note] InnoDB: Shutdown completed; log sequence number 1624196 161116 18:54:02 [Note] mysqld: Shutdown complete SUCCESS! [tom@kube-node-13 mysql]$ ps -ef | grep mysql tom 15073 36010 0 18:54 pts/1 00:00:00 grep --color=auto mysql [tom@kube-node-13 mysql]$ sudo service mysql start Starting MySQL.161116 18:54:29 mysqld_safe Logging to '/data/mariadb/mysql/kube-node-13.err'. .. ................................ ERROR! [tom@kube-node-13 mysql]$  有错误日志了。看去。\n[tom@kube-node-13 mysql]$ sudo cat /data/mariadb/mysql/kube-node-13.err ... ... ... 161116 18:19:18 [Note] WSREP: wsrep_load(): loading provider library 'none' 161116 18:19:18 [Note] /usr/sbin/mysqld: ready for connections. Version: '10.0.28-MariaDB-wsrep' socket: '/var/lib/mysql/mysql.sock' port: 3306 MariaDB Server, wsrep_25.16.rc3fc46e 161116 18:29:53 [Note] /usr/sbin/mysqld: Normal shutdown 161116 18:29:53 [Note] WSREP: Stop replication 161116 18:29:53 [Note] Event Scheduler: Purging the queue. 0 events 161116 18:29:53 [Note] InnoDB: FTS optimize thread exiting. 161116 18:29:53 [Note] InnoDB: Starting shutdown... 161116 18:29:54 [Note] InnoDB: Waiting for page_cleaner to finish flushing of buffer pool 161116 18:29:56 [Note] InnoDB: Shutdown completed; log sequence number 1624176 161116 18:29:56 [Note] /usr/sbin/mysqld: Shutdown complete 161116 18:29:56 mysqld_safe mysqld from pid file /data/mariadb/mysql/kube-node-13.pid ended 161116 18:54:29 mysqld_safe Starting mysqld daemon with databases from /data/mariadb/mysql 161116 18:54:29 mysqld_safe WSREP: Running position recovery with --log_error='/data/mariadb/mysql/wsrep_recovery.N6pzuB' --pid-file='/data/mariadb/mysql/kube-node-13-recover.pid' 161116 18:54:29 [Note] /usr/sbin/mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 15313 ... 161116 18:54:32 mysqld_safe WSREP: Recovered position 00000000-0000-0000-0000-000000000000:-1 161116 18:54:32 [Note] /usr/sbin/mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 15379 ... 161116 18:54:32 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 18:54:32 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib/galera/libgalera_smm.so' 161116 18:54:32 [Note] WSREP: wsrep_load(): Galera 25.3.18(r3632) by Codership Oy \u0026lt;info@codership.com\u0026gt; loaded successfully. 161116 18:54:32 [Note] WSREP: CRC-32C: using hardware acceleration. 161116 18:54:32 [Note] WSREP: Found saved state: 00000000-0000-0000-0000-000000000000:-1 161116 18:54:32 [Note] WSREP: Passing config to GCS: base_dir = /data/mariadb/mysql/; base_host = 10.10.12.13; base_port = 4567; cert.log_conflicts = no; debug = no; evs.auto_evict = 0; evs.delay_margin = PT1S; evs.delayed_keep_period = PT30S; evs.inactive_check_period = PT0.5S; evs.inactive_timeout = PT15S; evs.join_retrans_period = PT1S; evs.max_install_timeouts = 3; evs.send_window = 4; evs.stats_report_period = PT1M; evs.suspect_timeout = PT5S; evs.user_send_window = 2; evs.view_forget_timeout = PT24H; gcache.dir = /data/mariadb/mysql/; gcache.keep_pages_size = 0; gcache.mem_size = 0; gcache.name = /data/mariadb/mysql//galera.cache; gcache.page_size = 128M; gcache.size = 128M; gcomm.thread_prio = ; gcs.fc_debug = 0; gcs.fc_factor = 1.0; gcs.fc_limit = 16; gcs.fc_master_slave = no; gcs.max_packet_size = 64500; gcs.max_throttle = 0.25; gcs.recv_q_hard_limit = 9223372036854775807; gcs.recv_q_soft_limit = 0.25; gcs.sync_donor = no; gmcast.segment = 0; gmcast.version = 0; pc.announce_timeout = PT3S; pc.checksum = false; pc.ignore_q 161116 18:54:32 [Note] WSREP: Service thread queue flushed. 161116 18:54:32 [Note] WSREP: Assign initial position for certification: -1, protocol version: -1 161116 18:54:32 [Note] WSREP: wsrep_sst_grab() 161116 18:54:32 [Note] WSREP: Start replication 161116 18:54:32 [Note] WSREP: Setting initial position to 00000000-0000-0000-0000-000000000000:-1 161116 18:54:32 [Note] WSREP: protonet asio version 0 161116 18:54:32 [Note] WSREP: Using CRC-32C for message checksums. 161116 18:54:32 [Note] WSREP: backend: asio 161116 18:54:32 [Note] WSREP: gcomm thread scheduling priority set to other:0 161116 18:54:32 [Warning] WSREP: access file(/data/mariadb/mysql//gvwstate.dat) failed(No such file or directory) 161116 18:54:32 [Note] WSREP: restore pc from disk failed 161116 18:54:32 [Note] WSREP: GMCast version 0 161116 18:54:32 [Note] WSREP: (0e6fea53, 'tcp://0.0.0.0:4567') listening at tcp://0.0.0.0:4567 161116 18:54:32 [Note] WSREP: (0e6fea53, 'tcp://0.0.0.0:4567') multicast: , ttl: 1 161116 18:54:32 [Note] WSREP: EVS version 0 161116 18:54:32 [Note] WSREP: gcomm: connecting to group 'my_wsrep_cluster', peer '10.10.13.110:' 161116 18:54:35 [Warning] WSREP: no nodes coming from prim view, prim not possible 161116 18:54:35 [Note] WSREP: view(view_id(NON_PRIM,0e6fea53,1) memb { 0e6fea53,0 } joined { } left { } partitioned { }) 161116 18:54:36 [Warning] WSREP: last inactive check more than PT1.5S ago (PT3.50217S), skipping check 161116 18:55:05 [Note] WSREP: view((empty)) 161116 18:55:05 [ERROR] WSREP: failed to open gcomm backend connection: 110: failed to reach primary view: 110 (Connection timed out) at gcomm/src/pc.cpp:connect():162 161116 18:55:05 [ERROR] WSREP: gcs/src/gcs_core.cpp:gcs_core_open():208: Failed to open backend connection: -110 (Connection timed out) 161116 18:55:05 [ERROR] WSREP: gcs/src/gcs.cpp:gcs_open():1380: Failed to open channel 'my_wsrep_cluster' at 'gcomm://10.10.13.110': -110 (Connection timed out) 161116 18:55:05 [ERROR] WSREP: gcs connect failed: Connection timed out 161116 18:55:05 [ERROR] WSREP: wsrep::connect(gcomm://10.10.13.110) failed: 7 161116 18:55:05 [ERROR] Aborting 161116 18:55:05 [Note] WSREP: Service disconnected. 161116 18:55:06 [Note] WSREP: Some threads may fail to exit. 161116 18:55:06 [Note] /usr/sbin/mysqld: Shutdown complete 161116 18:55:06 mysqld_safe mysqld from pid file /data/mariadb/mysql/kube-node-13.pid ended [tom@kube-node-13 mysql]$ date 2016年 11月 16日 星期三 18:55:16 CST [tom@kube-node-13 mysql]$  嗯，确实是现在的日志。 来看一下。\n161116 18:54:32 [Warning] WSREP: access file(/data/mariadb/mysql//gvwstate.dat) failed(No such file or directory) 161116 18:54:32 [Note] WSREP: restore pc from disk failed 161116 18:54:32 [Note] WSREP: GMCast version 0 161116 18:54:32 [Note] WSREP: (0e6fea53, 'tcp://0.0.0.0:4567') listening at tcp://0.0.0.0:4567 161116 18:54:32 [Note] WSREP: (0e6fea53, 'tcp://0.0.0.0:4567') multicast: , ttl: 1 161116 18:54:32 [Note] WSREP: EVS version 0 161116 18:54:32 [Note] WSREP: gcomm: connecting to group 'my_wsrep_cluster', peer '10.10.13.110:'  哈。有问题呀。我们在配置文件中的 wsrep_cluster_address=\u0026quot;gcomm://10.10.13.110,192.168.31.240,10.10.12.13\u0026quot; wsrep_cluster_name='galera_cluster' 到这里怎么是这样的啦！！！\n好吧。快回忆，是哪里配置过 my_wsrep_cluster.\n想到了。 之前在 /etc/my.cnf.d/wsrep.cnf 里面配置过这个。\n[tom@kube-node-13 mysql]$ cd /etc/my.cnf.d/ [tom@kube-node-13 my.cnf.d]$ ls -la total 40 drwxr-xr-x. 2 root root 4096 11月 16 19:09 . drwxr-xr-x. 141 root root 8192 11月 16 16:45 .. -rw-r--r--. 1 root root 295 10月 28 01:16 client.cnf -rw-r--r--. 1 root root 232 10月 28 01:16 mysql-clients.cnf -rw-r--r--. 1 root root 1772 11月 16 18:59 server.cnf -rw-r--r--. 1 root root 1007 11月 16 14:10 server.cnf_original -rw-r--r--. 1 root root 285 11月 3 09:14 tokudb.cnf -rw-r--r--. 1 root root 3611 11月 16 15:10 wsrep.cnf [tom@kube-node-13 my.cnf.d]$ vi wsrep.cnf  查了一下，里面确实就是有呀。哭了。原来是这个文件的 那把这个文件移出去，再试一下吧。\n[tom@kube-node-13 my.cnf.d]$ sudo mv wsrep.cnf ~/wsrep.cnf.bak [tom@kube-node-13 my.cnf.d]$ ls client.cnf mysql-clients.cnf server.cnf server.cnf_original tokudb.cnf [tom@kube-node-13 my.cnf.d]$ sudo service mysql status ERROR! MySQL is not running, but lock file (/var/lock/subsys/mysql) exists [tom@kube-node-13 my.cnf.d]$ sudo service mysql stop ERROR! MySQL server PID file could not be found! [tom@kube-node-13 my.cnf.d]$ sudo service mysql start Starting MySQL.161116 19:12:20 mysqld_safe Logging to '/data/mariadb/mysql/kube-node-13.err'. ............a...................... ERROR! [tom@kube-node-13 my.cnf.d]$  崩溃，看日志。\n[tom@kube-node-13 my.cnf.d]$ sudo cat /data/mariadb/mysql/kube-node-13.err ... ... ... 161116 19:02:19 mysqld_safe mysqld from pid file /data/mariadb/mysql/kube-node-13.pid ended 161116 19:12:20 mysqld_safe Starting mysqld daemon with databases from /data/mariadb/mysql 161116 19:12:20 mysqld_safe WSREP: Running position recovery with --log_error='/data/mariadb/mysql/wsrep_recovery.3kyk74' --pid-file='/data/mariadb/mysql/kube-node-13-recover.pid' 161116 19:12:20 [Note] /usr/sbin/mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 17474 ... 161116 19:12:23 mysqld_safe WSREP: Recovered position 00000000-0000-0000-0000-000000000000:-1 161116 19:12:23 [Note] /usr/sbin/mysqld (mysqld 10.0.28-MariaDB-wsrep) starting as process 17514 ... 161116 19:12:23 [Note] WSREP: Read nil XID from storage engines, skipping position init 161116 19:12:23 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib64/galera/libgalera_smm.so' 161116 19:12:23 [Note] WSREP: wsrep_load(): Galera 25.3.18(r3632) by Codership Oy \u0026lt;info@codership.com\u0026gt; loaded successfully. 161116 19:12:23 [Note] WSREP: CRC-32C: using hardware acceleration. 161116 19:12:23 [Note] WSREP: Found saved state: 00000000-0000-0000-0000-000000000000:-1 161116 19:12:23 [Note] WSREP: Passing config to GCS: base_dir = /data/mariadb/mysql/; base_host = 10.10.12.13; base_port = 4567; cert.log_conflicts = no; debug = no; evs.auto_evict = 0; evs.delay_margin = PT1S; evs.delayed_keep_period = PT30S; evs.inactive_check_period = PT0.5S; evs.inactive_timeout = PT15S; evs.join_retrans_period = PT1S; evs.max_install_timeouts = 3; evs.send_window = 4; evs.stats_report_period = PT1M; evs.suspect_timeout = PT5S; evs.user_send_window = 2; evs.view_forget_timeout = PT24H; gcache.dir = /data/mariadb/mysql/; gcache.keep_pages_size = 0; gcache.mem_size = 0; gcache.name = /data/mariadb/mysql//galera.cache; gcache.page_size = 128M; gcache.size = 128M; gcomm.thread_prio = ; gcs.fc_debug = 0; gcs.fc_factor = 1.0; gcs.fc_limit = 16; gcs.fc_master_slave = no; gcs.max_packet_size = 64500; gcs.max_throttle = 0.25; gcs.recv_q_hard_limit = 9223372036854775807; gcs.recv_q_soft_limit = 0.25; gcs.sync_donor = no; gmcast.segment = 0; gmcast.version = 0; pc.announce_timeout = PT3S; pc.checksum = false; pc.ignore_q 161116 19:12:23 [Note] WSREP: Service thread queue flushed. 161116 19:12:23 [Note] WSREP: Assign initial position for certification: -1, protocol version: -1 161116 19:12:23 [Note] WSREP: wsrep_sst_grab() 161116 19:12:23 [Note] WSREP: Start replication 161116 19:12:23 [Note] WSREP: Setting initial position to 00000000-0000-0000-0000-000000000000:-1 161116 19:12:23 [Note] WSREP: protonet asio version 0 161116 19:12:23 [Note] WSREP: Using CRC-32C for message checksums. 161116 19:12:23 [Note] WSREP: backend: asio 161116 19:12:23 [Note] WSREP: gcomm thread scheduling priority set to other:0 161116 19:12:23 [Warning] WSREP: access file(/data/mariadb/mysql//gvwstate.dat) failed(No such file or directory) 161116 19:12:23 [Note] WSREP: restore pc from disk failed 161116 19:12:23 [Note] WSREP: GMCast version 0 161116 19:12:23 [Note] WSREP: (8c84d2c7, 'tcp://0.0.0.0:4567') listening at tcp://0.0.0.0:4567 161116 19:12:23 [Note] WSREP: (8c84d2c7, 'tcp://0.0.0.0:4567') multicast: , ttl: 1 161116 19:12:23 [Note] WSREP: EVS version 0 161116 19:12:23 [Note] WSREP: gcomm: connecting to group 'galera_cluster', peer '10.10.12.13:,10.10.13.110:,192.168.31.240:' 161116 19:12:23 [Note] WSREP: (8c84d2c7, 'tcp://0.0.0.0:4567') connection established to 8c84d2c7 tcp://10.10.12.13:4567 161116 19:12:23 [Warning] WSREP: (8c84d2c7, 'tcp://0.0.0.0:4567') address 'tcp://10.10.12.13:4567' points to own listening address, blacklisting 161116 19:12:23 [Note] WSREP: (8c84d2c7, 'tcp://0.0.0.0:4567') connection established to 8c84d2c7 tcp://10.10.12.13:4567 161116 19:12:26 [Warning] WSREP: no nodes coming from prim view, prim not possible 161116 19:12:26 [Note] WSREP: view(view_id(NON_PRIM,8c84d2c7,1) memb { 8c84d2c7,0 } joined { } left { } partitioned { }) 161116 19:12:26 [Warning] WSREP: last inactive check more than PT1.5S ago (PT3.50305S), skipping check 161116 19:12:56 [Note] WSREP: view((empty)) 161116 19:12:56 [ERROR] WSREP: failed to open gcomm backend connection: 110: failed to reach primary view: 110 (Connection timed out) at gcomm/src/pc.cpp:connect():162 161116 19:12:56 [ERROR] WSREP: gcs/src/gcs_core.cpp:gcs_core_open():208: Failed to open backend connection: -110 (Connection timed out) 161116 19:12:56 [ERROR] WSREP: gcs/src/gcs.cpp:gcs_open():1380: Failed to open channel 'galera_cluster' at 'gcomm://10.10.12.13,10.10.13.110,192.168.31.240': -110 (Connection timed out) 161116 19:12:56 [ERROR] WSREP: gcs connect failed: Connection timed out 161116 19:12:56 [ERROR] WSREP: wsrep::connect(gcomm://10.10.12.13,10.10.13.110,192.168.31.240) failed: 7 161116 19:12:56 [ERROR] Aborting 161116 19:12:56 [Note] WSREP: Service disconnected. 161116 19:12:57 [Note] WSREP: Some threads may fail to exit. 161116 19:12:57 [Note] /usr/sbin/mysqld: Shutdown complete 161116 19:12:57 mysqld_safe mysqld from pid file /data/mariadb/mysql/kube-node-13.pid ended [tom@kube-node-13 my.cnf.d]$  好事情。 161116 19:12:23 [Note] WSREP: wsrep_load(): loading provider library '/usr/lib64/galera/libgalera_smm.so' 161116 19:12:23 [Note] WSREP: gcomm: connecting to group 'galera_cluster', peer '10.10.12.13:,10.10.13.110:,192.168.31.240:' 161116 19:12:23 [Note] WSREP: (8c84d2c7, 'tcp://0.0.0.0:4567') connection established to 8c84d2c7 tcp://10.10.12.13:4567 这几个关键的点，都正常了。\n但是为什么还出错了呢。崩溃了吧。\n清醒一下，让我想想，为什么？\n叮咚。\n明白了。刚刚是，只启动cluster的第一台机器，命令错了哈。应该用 sudo /etc/init.d/mysql start --wsrep-new-cluster，下回要注意呀。\n[tom@kube-node-13 my.cnf.d]$ sudo /etc/init.d/mysql start --wsrep-new-cluster Starting MySQL.161116 19:17:28 mysqld_safe Logging to '/data/mariadb/mysql/kube-node-13.err'. . SUCCESS! [tom@kube-node-13 my.cnf.d]$ mysql -u root -p -e \u0026quot;show status like 'wsrep%'\u0026quot;; Enter password: +------------------------------+---------------------------------------------+ | Variable_name | Value | +------------------------------+---------------------------------------------+ | wsrep_local_state_uuid | 440fe21c-abee-11e6-b1c1-9bfbe1e4335d | | wsrep_protocol_version | 7 | | wsrep_last_committed | 0 | | wsrep_replicated | 0 | | wsrep_replicated_bytes | 0 | | wsrep_repl_keys | 0 | | wsrep_repl_keys_bytes | 0 | | wsrep_repl_data_bytes | 0 | | wsrep_repl_other_bytes | 0 | | wsrep_received | 2 | | wsrep_received_bytes | 138 | | wsrep_local_commits | 0 | | wsrep_local_cert_failures | 0 | | wsrep_local_replays | 0 | | wsrep_local_send_queue | 0 | | wsrep_local_send_queue_max | 1 | | wsrep_local_send_queue_min | 0 | | wsrep_local_send_queue_avg | 0.000000 | | wsrep_local_recv_queue | 0 | | wsrep_local_recv_queue_max | 2 | | wsrep_local_recv_queue_min | 0 | | wsrep_local_recv_queue_avg | 0.500000 | | wsrep_local_cached_downto | 18446744073709551615 | | wsrep_flow_control_paused_ns | 0 | | wsrep_flow_control_paused | 0.000000 | | wsrep_flow_control_sent | 0 | | wsrep_flow_control_recv | 0 | | wsrep_cert_deps_distance | 0.000000 | | wsrep_apply_oooe | 0.000000 | | wsrep_apply_oool | 0.000000 | | wsrep_apply_window | 0.000000 | | wsrep_commit_oooe | 0.000000 | | wsrep_commit_oool | 0.000000 | | wsrep_commit_window | 0.000000 | | wsrep_local_state | 4 | | wsrep_local_state_comment | Synced | | wsrep_cert_index_size | 0 | | wsrep_causal_reads | 0 | | wsrep_cert_interval | 0.000000 | | wsrep_incoming_addresses | 10.10.12.13:3306 | | wsrep_desync_count | 0 | | wsrep_evs_delayed | | | wsrep_evs_evict_list | | | wsrep_evs_repl_latency | 4.903e-06/9.301e-06/1.892e-05/5.26662e-06/5 | | wsrep_evs_state | OPERATIONAL | | wsrep_gcomm_uuid | 440ea66b-abee-11e6-9185-f7b2a306dbf2 | | wsrep_cluster_conf_id | 1 | | wsrep_cluster_size | 1 | | wsrep_cluster_state_uuid | 440fe21c-abee-11e6-b1c1-9bfbe1e4335d | | wsrep_cluster_status | Primary | | wsrep_connected | ON | | wsrep_local_bf_aborts | 0 | | wsrep_local_index | 0 | | wsrep_provider_name | Galera | | wsrep_provider_vendor | Codership Oy \u0026lt;info@codership.com\u0026gt; | | wsrep_provider_version | 25.3.18(r3632) | | wsrep_ready | ON | | wsrep_thread_count | 2 | +------------------------------+---------------------------------------------+ [tom@kube-node-13 my.cnf.d]$  终于是成功了! 终于是成功了! 终于是成功了!\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-cluster-install-base-centos.html",
	"title": "Mariadb Galera Cluster Install Base Centos",
	"tags": ["mariadb", "galera"],
	"description": "",
	"content": " mysql系列之集群 MariaDB Galera Cluster 部署\n参考 How To Setup MariaDB Galera Cluster 10.0 On CentOS http://www.unixmen.com/setup-mariadb-galera-cluster-10-0-centos/\n安装 过程 MariaDB is a relational database management system (RDBMS) and MariaDB Galera Cluster is a synchronous multi-master cluster for MariaDB. It is available on Linux only, and only supports the XtraDB/InnoDB storage engines. This article explains how to setup MariaDB Galera Cluster 10.0 with 3 nodes running on CentOS 6.5(tom注：在CentOS 7.0上也成功) x86_64 resulting in a HA (high-availability) database cluster.\nCLUSTER DETAILS We using 3 freshly deployed VMs running a minimal install of CentOS 6.5 x86_64.\nCluster node 1 has hostname db1 and IP address 1.1.1.1 Cluster node 2 has hostname db2 and IP address 1.1.1.2 Cluster node 3 has hostname db3 and IP address 1.1.1.3  Step 1: Add MariaDB Repositories Create a mariadb repository /etc/yum.repos.d/mariadb.repo using following content in your system.\nFor CentOS 7 – 64bit:\n[mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos7-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1  For CentOS 7 – 32bit:\n[mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos7-x86 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1  Step 2 – Set SELinux in permissive mode Before starting the setup put SELinux into permissive mode on all nodes:\nsudo setenforce 0  Step 3 – Install MariaDB Galera Cluster 10.0 software If you did a CentOS 6 minimal installation then make sure you install the socat package from the EPEL repository before proceeding with installing the MariaDB Galera Cluster 10.0 software.\nYou can install socat package directly from EPEL with the following command (for x86_64):\nsudo yum install http://dl.fedoraproject.org/pub/epel/6/x86_64/socat-1.7.2.3-1.el6.x86_64.rpm  On CentOS 7 you can install socat package with following command.\nsudo yum install socat -y  Install the MariaDB Galera Cluster 10.0 software by executing the following command on all nodes:\nsudo yum install MariaDB-Galera-server MariaDB-client rsync galera -y  如果说，这一步没有安装成功，请参考之前的那一篇mysql系列之集群 MariaDB-Galera-server 安装\nStep 4: Setup MariaDB security Start the mysql ( init script in MariaDB 10.0 is still called mysql)\nsudo service mysql start  Run the mysql_secure_installation script so we can improve the security. Run the following command on all nodes:\nsudo /usr/bin/mysql_secure_installation  I choose password as ‘dbpass’ and accepted all defaults (so answered yes to all questions).\nStep 5 – Create MariaDB Galera Cluster users Now, we have to create some users that must be able to access the database. The ‘sst_user’ is the user which a database node will use for authenticating to another database node in the State Transfer Snapshot (SST) phase. Run the following command on all nodes:\nmysql -u root -p mysql\u0026gt; DELETE FROM mysql.user WHERE user=''; mysql\u0026gt; GRANT ALL ON *.* TO 'root'@'%' IDENTIFIED BY 'dbpass'; mysql\u0026gt; GRANT USAGE ON *.* to sst_user@'%' IDENTIFIED BY 'dbpass'; mysql\u0026gt; GRANT ALL PRIVILEGES on *.* to sst_user@'%'; mysql\u0026gt; FLUSH PRIVILEGES; mysql\u0026gt; quit  You are suggested to change ‘%’ to hostname(s) or IP addresses from which those users can access the database. Because ‘%’ means that the root or sst_user is allowed to access the database from any host, So less security.\nStep 6 – Create the MariaDB Galera Cluster config First stop the mysql services on all nodes:\nsudo service mysql stop  Next, We are going to create the MariaDB Galera Cluster configuration by the following command on all nodes (go through the IMPORTANT NOTE after the config and make required changes for db2, and db3):\nsudo cat \u0026gt;\u0026gt; /etc/my.cnf.d/server.cnf \u0026lt;\u0026lt; EOF [mariadb-10.0] binlog_format=ROW default-storage-engine=innodb innodb_autoinc_lock_mode=2 innodb_locks_unsafe_for_binlog=1 query_cache_size=0 query_cache_type=0 bind-address=0.0.0.0 datadir=/var/lib/mysql innodb_log_file_size=100M innodb_file_per_table innodb_flush_log_at_trx_commit=2 wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=\u0026quot;gcomm://1.1.1.1,1.1.1.2,1.1.1.3\u0026quot; wsrep_cluster_name='galera_cluster' wsrep_node_address='1.1.1.1' wsrep_node_name='db1' wsrep_sst_method=rsync wsrep_sst_auth=sst_user:dbpass EOF  IMPORTANT NOTE: when executing this command on db2 and db3 do not forget to adjust the wsrep_node_address and wsrep_node_name variables.\nOn db2 :\nwsrep_node_address=1.1.1.2 wsrep_node_name='db2'  On db3 :\nwsrep_node_address='1.1.1.3' wsrep_node_name='db3'  Step 7– Initialize the first cluster node Start MariaDB with the special ‘‐‐wsrep-new-cluster’ option , Do it on node db1 only so the primary node of the cluster is initialized:\nsudo /etc/init.d/mysql start --wsrep-new-cluster  Check status by run the following command on node db1 only:\nmysql -u root -p -e \u0026quot;show status like 'wsrep%';\u0026quot;  Some important information in the output are the following lines:\nwsrep_local_state_comment | Synced \u0026lt;-- cluster is synced wsrep_incoming_addresses | 1.1.1.1:3306 \u0026lt;-- node db1 is a provider wsrep_cluster_size | 1 \u0026lt;-- cluster consists of 1 node wsrep_ready | ON \u0026lt;-- good :)  如果说这里报错了，请参考mysql系列之集群 MariaDB-Galera-cluster 报错\nStep 8– Add the other cluster nodes Check and confirm nodes db2 and db3 have the correct configuration in /etc/my.cnf.d/server.cnf under the [mariadb-10.0] as described in step 6.\nWith the correct configuration in place, all that is required to make db2 and db3 a member of the cluster is to start them like you would start any regular service. On db2 issue the following command:\nsudo service mysql start  Check what has changed in the cluster status by executing the following command on db1 or db2:\nmysql -u root -p -e \u0026quot;show status like 'wsrep%';\u0026quot;  And you will see that node db2 is now known as the cluster size is ‘2’ and the IP address of node db2 is listed:\n| wsrep_local_state_comment | Synced | | wsrep_incoming_addre sses | 1.1.1.1:3306,1.1.1.2:3306 | | wsrep_cluster_size | 2 | | wsrep_connected | ON | | wsrep_ready | ON |  Repeat the same step for node db3. On node db3 only execute the following command\nsudo service mysql start  Check what has changed in the cluster status by executing the following command on for example db1:\nmysql -u root -p -e \u0026quot;show status like 'wsrep%';\u0026quot;  And you should see that node db3 is now known as the cluster size is ‘3’ and the IP address of node db3 is listed:\n| wsrep_local_state_comment | Synced | | wsrep_incoming_addresses | 1.1.1.3:3306,1.1.1.1:3306,1.1.1.2:3306 | | wsrep_cluster_size | 3 | | wsrep_connected | ON | | wsrep_ready | ON |  Step 9 – Verify replication Now the cluster is running. Let’s test whether it is working. On db1 create a database ‘clustertest’ by run the following command:\nmysql -u root -p -e 'CREATE DATABASE clustertest;' mysql -u root -p -e 'CREATE TABLE clustertest.mycluster ( id INT NOT NULL AUTO_INCREMENT, name VARCHAR(50), ipaddress VARCHAR(20), PRIMARY KEY(id));' mysql -u root -p -e 'INSERT INTO clustertest.mycluster (name, ipaddress) VALUES (\u0026quot;db1\u0026quot;, \u0026quot;1.1.1.1\u0026quot;);'  Check if the database, table and data exists:\nmysql -u root -p -e 'SELECT * FROM clustertest.mycluster;' Enter password: +----+------+-----------+ | id | name | ipaddress | +----+------+-----------+ | 2 | db1 | 1.1.1.1 | +----+------+-----------+  Now do the check on node db2:\nmysql -u root -p -e 'SELECT * FROM clustertest.mycluster;' Enter password: +----+------+-----------+ | id | name | ipaddress | +----+------+-----------+ | 2 | db1 | 1.1.1.1 | +----+------+-----------+  Now do the same check on node db3:\nmysql -u root -p -e 'SELECT * FROM clustertest.mycluster;' Enter password: +----+------+-----------+ | id | name | ipaddress | +----+------+-----------+ | 2 | db1 | 1.1.1.1 | +----+------+-----------+  From these outputs we can confirm that everything was successfully replicated by node db1 across all other nodes.\nThat’s it.\nCheers!\nctrl + v 吧 sudo vi /etc/hosts 10.10.162.11 db1 10.10.162.12 db2 10.10.162.13 db3 sudo vi /etc/yum.repos.d/mariadb.repo # MariaDB 10.1 CentOS repository list - created 2016-11-15 02:38 UTC # http://downloads.mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos7-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1 sudo setenforce 0 sudo yum install socat -y sudo yum install socat MariaDB-Galera-server MariaDB-client rsync galera -y sudo service mysql start sudo /usr/bin/mysql_secure_installation mysql -u root -p sudo service mysql stop sudo cat \u0026gt;\u0026gt; /etc/my.cnf.d/server.cnf \u0026lt;\u0026lt; EOF binlog_format=ROW default-storage-engine=innodb innodb_autoinc_lock_mode=2 innodb_locks_unsafe_for_binlog=1 query_cache_size=0 query_cache_type=0 bind-address=0.0.0.0 datadir=/var/lib/mysql innodb_log_file_size=100M innodb_file_per_table innodb_flush_log_at_trx_commit=2 wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=\u0026quot;gcomm://1.1.1.1,1.1.1.2,1.1.1.3\u0026quot; wsrep_cluster_name='galera_cluster' wsrep_node_address='1.1.1.1' wsrep_node_name='db1' wsrep_sst_method=rsync wsrep_sst_auth=sst_user:dbpass EOF # 上面这个好像会出错，算了，我们 sudo vi 吧 sudo vi /etc/my.cnf.d/server.cnf sudo cp -a /etc/my.cnf.d/server.cnf . ls sudo cp -a server.cnf server.cnf.12 sudo cp -a server.cnf server.cnf.13 sudo vi server.cnf.12 sudo vi server.cnf.13 scp server.cnf.12 spa@s12:/home/spa/ # 之后在spa@s12中改一改吧。 scp server.cnf.13 spa@s13:/home/spa/ # 好了，现在三台机器的配置都完成啦！ sudo /etc/init.d/mysql start --wsrep-new-cluster mysql -u root -p -e \u0026quot;show status like 'wsrep%';\u0026quot; # 好了，如果没有问题，我们把其它2台机器也启动下。 sudo service mysql start; sudo service mysql status; mysql -u root -p -e 'CREATE DATABASE clustertest;' mysql -u root -p -e 'CREATE TABLE clustertest.mycluster ( id INT NOT NULL AUTO_INCREMENT, name VARCHAR(50), ipaddress VARCHAR(20), PRIMARY KEY(id));' mysql -u root -p -e 'INSERT INTO clustertest.mycluster (name, ipaddress) VALUES (\u0026quot;db1\u0026quot;, \u0026quot;1.1.1.1\u0026quot;);' mysql -u root -p -e 'SELECT * FROM clustertest.mycluster;' # 到其它2台机器上也查一下吧。 mysql -u root -p -e 'SELECT * FROM clustertest.mycluster;' # 如果其它机器也显示出来了，那就Cheers!  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-use.html",
	"title": "Mysql Use",
	"tags": ["mysql"],
	"description": "",
	"content": " mysql系列之mysql使用规范\nmysql使用规范\n级别说明 所有级别：\n 级别1，必须做到 级别2，优先做到  级别：1\n 库名，表名，字段名：使用小写 字符：utf8 表：不使用删除表（drop），而使用清空表（truncate，或者delete from） 表：记录数超过10000的情况下，加索引  级别：2\n 库名，表名，字段名：使用下划线分割。如：day_stocka_wind 表：加主键 清空表：优先使用truncate（命令：truncate table tbl_name;），其次使用delete from(命令：delete from tbl_name;）  关于删除表 删除表：使用DROP TABLE tbl_name;， 或者DROP TABLE IF EXISTS tbl_name;\n若有业务确实需要删除表的，请联系小鱼。\nend "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-secure-installation.html",
	"title": "Mysql Secure Installation",
	"tags": ["mysql"],
	"description": "",
	"content": " mysql系列之mysql_secure_installation\n参考 http://www.myexception.cn/mysql/1902013.html\n过程 安装完mysql-server 会提示可以运行mysql_secure_installation。 运行mysql_secure_installation会执行几个设置： a)为root用户设置密码 b)删除匿名账号 c)取消root用户远程登录 d)删除test库和对test库的访问权限 e)刷新授权表使修改生效 通过这几项的设置能够提高mysql库的安全。建议生产环境中mysql安装这完成后一定要运行一次mysql_secure_installation，详细步骤请参看下面的命令:\n[root@dns ~]# mysql_secure_installation /usr/bin/mysql_secure_installation:行379: find_mysql_client: 未找到命令 NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES) Enter current password for root (enter for none): --\u0026gt;初次运行直接enter OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] Y New password: Re-enter new password: Password updated successfully! Reloading privilege tables.. ... Success! By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] y ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] ... Success! By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB!  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-cluster-base-centos.html",
	"title": "Mariadb Cluster Base Centos",
	"tags": ["mysql", "mariadb", "cluster"],
	"description": "",
	"content": " mysql-cluster\n主要参考 http://mariadb.org/\n环境  centos7-amd64 mariadb10.1（IP:10.10.13.110） + mariadb5.5(IP:192.168.31.240)  步骤 准备2台机器 安装mariadb10.1\n参考这里\n把 mariadb5.5 的数据，导出后，导入到 mariadb10.1 导出 导入 mysql主从复制 第一步，就要看这几个参考 依次看 http://blog.csdn.net/gaowenhui2008/article/details/46698321 http://blog.csdn.net/hguisu/article/details/7325124 http://blog.jobbole.com/94595/ http://www.xuejiehome.com/blread-1664.html MYSQL主从同步的管理 参考 http://blog.csdn.net/gaowenhui2008/article/details/46698321 1. 停止MYSQL同步 1. 停止MYSQL同步 STOP SLAVE IO_THREAD; #停止IO进程 STOP SLAVE SQL_THREAD; #停止SQL进程 STOP SLAVE; #停止IO和SQL进程 2. 启动MYSQL同步 START SLAVE IO_THREAD; #启动IO进程 START SLAVE SQL_THREAD; #启动SQL进程 START SLAVE; #启动IO和SQL进程 3. 重置MYSQL同步 RESET SLAVE; 用于让从属服务器忘记其在主服务器的二进制日志中的复制位置, 它会删除master.info和relay-log.info文件，以及所有的中继日志，并启动一个新的中继日志,当你不需要主从的时候可以在从上执行这个操作。不然以后还会同步，可能会覆盖掉你的数据库，我以前就遇到过这样傻叉的事情。哈哈！ 4. 查看MYSQL同步状态 SHOW SLAVE STATUS; 这个命令主要查看Slave_IO_Running、Slave_SQL_Running、Seconds_Behind_Master、Last_IO_Error、Last_SQL_Error这些值来把握复制的状态。 5. 临时跳过MYSQL同步错误 经常会朋友mysql主从同步遇到错误的时候，比如一个主键冲突等，那么我就需要在确保那一行数据一致的情况下临时的跳过这个错误，那就需要使用SQL_SLAVE_SKIP_COUNTER = n命令了，n是表示跳过后面的n个事件,比如我跳过一个事件的操作如下： STOP SLAVE; SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1; START SLAVE; 6. 从指定位置重新同步 有的时候主从同步有问题了以后，需要从log位置的下一个位置进行同步，相当于跳过那个错误，这时候也可以使用CHANGE MASTER命令来处理，只要找到对应的LOG位置就可以,比如： CHANGE MASTER TO MASTER_HOST=\u0026lsquo;10.1.1.75\u0026rsquo;,MASTER_USER=\u0026lsquo;replication\u0026rsquo;,MASTER_PASSWORD=\u0026lsquo;123456\u0026rsquo;,MASTER_LOG_FILE=\u0026lsquo;mysql-bin.000006\u0026rsquo;, MASTER_LOG_POS=106; START SLAVE; MYSQL主从同步的管理经验介绍 1. 不要乱使用SQL_SLAVE_SKIP_COUNTER命令。 这个命令跳过之后很可能会导致你的主从数据不一致，一定要先将指定的错误记录下来，然后再去检查数据是否一致，尤其是核心的业务数据。 2. 结合percona-toolkit工具pt-table-checksum定期查看数据是否一致 这个是DBA必须要定期做的事情，呵呵，有合适的工具何乐而不为呢？另外percona-toolkit还提供了对数据库不一致的解决方案，可以采用pt-table-sync，这个工具不会更改主的数据。还可以使用pt-heartbeat来查看从服务器的复制落后情况。 具体的请查看：http://blog.chinaunix.net/uid-20639775-id-3229211.html。 3. 使用replicate-wild-ignore-table选项而不要使用replicate-do-db或者replicate-ignore-db。 原因已经在上面做了说明。 4. 将主服务器的日志模式调整成mixed。 5. 每个表都加上主键，主键对数据库的同步会有影响尤其是居于ROW复制模式。 mysql主从复制 情况１：主从mysql，之前都无数据 参考 http://blog.jobbole.com/94595/ http://www.xuejiehome.com/blread-1664.html 步骤 目标 10.10.12.14(主) 10.10.12.15(从) 1、主从安装mysql，版本一致 mysql\u0026gt;status;\nMariaDB [test]\u0026gt; status; mysql Ver 15.1 Distrib 5.5.44-MariaDB, for Linux (x86_64) using readline 5.1\nConnection id: 4 Current database: test Current user: root@localhost SSL: Not in use Current pager: stdout Using outfile: \u0026ldquo; Using delimiter: ; Server: MariaDB Server version: 5.5.44-MariaDB-log MariaDB Server Protocol version: 10 Connection: Localhost via UNIX socket Server characterset: utf8 Db characterset: utf8 Client characterset: utf8 Conn. characterset: utf8 UNIX socket: /var/lib/mysql/mysql.sock Uptime: 18 min 15 sec\nThreads: 2 Questions: 24 Slow queries: 0 Opens: 1 Flush tables: 2 Open tables: 27 Queries per second avg: 0.021 MariaDB [test]\u0026gt;\n 2、修改master，slave服务器 master服务器配置： sudo　vi /etc/my.cnf [mysqld]  datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock\nDisabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0\nSettings user and group are ignored when systemd is used. If you need to run mysqld under a different user or group, customize your systemd unit file for mariadb according to the instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin server-id=14 binlog-ignore-db = mysql,information_schema\n[mysqld] server-id=14\n#设置服务器唯一的id，默认是1，一般取IP最后一段，我们设置ip最后一段，slave设置14 log-bin=mysql-bin\n启用二进制日志 binlog-ignore-db = mysql,information_schema\n#忽略写入binlog的库 slave服务器配置： sudo　vi /etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock\nDisabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0\nSettings user and group are ignored when systemd is used. If you need to run mysqld under a different user or group, customize your systemd unit file for mariadb according to the instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin server-id=15 replicate-wild-ignore-table=test.% #replicate-do-db = test #slave-skip-errors = all\n replicate-wild-ignore-table=test.%  #　replicate-do-db = test\n#上面２句都可以表示只同步test库(但是第一句更好，不要使用第２名)，　＃如果同步所有的库，则不要加上这一句 slave-skip-errors = all\n#忽略因复制出现的所有错误 3、重启主从服务器mysql sudo systemctl restart mariadb.service sudo systemctl status mariadb.service 4、在主服务器上建立帐户并授权slave GRANT REPLICATION SLAVE ON . to \u0026lsquo;sync\u0026rsquo;@\u0026lsquo;10.10.12.%\u0026rsquo; identified by \u0026lsquo;123.com\u0026rsquo;; 注意，这里是　10.10.12.%, 而不是 10.10.12.* 我犯过这样的错误 GRANT REPLICATION SLAVE ON . to \u0026lsquo;sync\u0026rsquo;@\u0026lsquo;10.10.12.15\u0026rsquo; identified by \u0026lsquo;123.com\u0026rsquo;; 注意：大家在设置权限的时候不要将密码设置过于简单！ 5、查看主数据库状态 show master status\\G; MariaDB [(none)]\u0026gt; show master status; +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | mysql-bin.000002 | 707 | | mysql,information_schema | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ 1 row in set (0.00 sec)\nMariaDB [(none)]\u0026gt; MariaDB [(none)]\u0026gt; show master status\\G; *************************** 1. row *************************** File: mysql-bin.000002 Position: 707 Binlog_Do_DB: Binlog_Ignore_DB: mysql,information_schema 1 row in set (0.01 sec)\nERROR: No query specified\nMariaDB [(none)]\u0026gt; 记录下 File 及 Position 的值，在后面进行从服务器操作的时候需要用到。 6、配置从数据库 change master to master_host=\u0026lsquo;10.10.12.14\u0026rsquo;, master_user=\u0026lsquo;sync\u0026rsquo;, master_password=\u0026lsquo;123.com\u0026rsquo;, master_log_file\u0026rsquo;=\u0026lsquo;mysql-bin.000002\u0026rsquo;, master_log_pos=707; 7、启动slave同步进程并 MariaDB [(none)]\u0026gt; start slave; 查看状态 MariaDB [(none)]\u0026gt; show slave status\\G; MariaDB [(none)]\u0026gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.12.14 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 707 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 838 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: test 其中Slave_IO_Running 与 Slave_SQL_Running 的值都必须为YES，才表明状态正常。 报错 主从同步出现一下错误：Slave_IO_Running: Connecting 导致lave_IO_Running 为connecting 的原因主要有以下 3 个方面： 1、网络不通 2、密码不对 解决 从服务器 STOP SLAVE; #停止IO和SQL进程 RESET SLAVE; STOP SLAVE; #停止IO和SQL进程 6、配置从数据库 change master to master_host=\u0026lsquo;10.10.12.14\u0026rsquo;, master_user=\u0026lsquo;sync\u0026rsquo;, master_password=\u0026lsquo;123.com\u0026rsquo;, master_log_file\u0026rsquo;=\u0026lsquo;mysql-bin.000002\u0026rsquo;, master_log_pos=707; START SLAVE; #启动IO和SQL进程 实操 MariaDB [(none)]\u0026gt; reset slave; ERROR 1198 (HY000): This operation cannot be performed with a running slave; run STOP SLAVE first MariaDB [(none)]\u0026gt; stop slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; reset slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; show slave status\\G; MariaDB [(none)]\u0026gt; stop slave; Query OK, 0 rows affected, 1 warning (0.00 sec)\nMariaDB [(none)]\u0026gt; change master to -\u0026gt; master_host=\u0026lsquo;10.10.13.100\u0026rsquo;, -\u0026gt; master_user=\u0026lsquo;sync\u0026rsquo;, -\u0026gt; master_password=\u0026lsquo;sync.com\u0026rsquo;, -\u0026gt; master_log_file=\u0026lsquo;mysql-bin.000001\u0026rsquo;, -\u0026gt; master_log_pos=927; Query OK, 0 rows affected (0.01 sec)\nMariaDB [(none)]\u0026gt; start slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.13.100 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 927 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 529 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 3、pos不对 8、验证主从同步\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-cluster-infile-base-centos.html",
	"title": "Mariadb Cluster Infile Base Centos",
	"tags": ["mysql", "mariadb", "cluster", "infile"],
	"description": "",
	"content": " mysql-cluster\n主要参考 http://mariadb.org/\n环境  centos7-amd64 mariadb10.1（IP:10.10.13.110） + mariadb5.5(IP:192.168.31.240)  步骤 准备2台机器 安装mariadb10.1\n参考这里\n把 mariadb5.5 的数据，导出后，导入到 mariadb10.1 导出 导入 mysql主从复制 第一步，就要看这几个参考 依次看 http://blog.csdn.net/gaowenhui2008/article/details/46698321 http://blog.csdn.net/hguisu/article/details/7325124 http://blog.jobbole.com/94595/ http://www.xuejiehome.com/blread-1664.html MYSQL主从同步的管理 参考 http://blog.csdn.net/gaowenhui2008/article/details/46698321 1. 停止MYSQL同步 1. 停止MYSQL同步 STOP SLAVE IO_THREAD; #停止IO进程 STOP SLAVE SQL_THREAD; #停止SQL进程 STOP SLAVE; #停止IO和SQL进程 2. 启动MYSQL同步 START SLAVE IO_THREAD; #启动IO进程 START SLAVE SQL_THREAD; #启动SQL进程 START SLAVE; #启动IO和SQL进程 3. 重置MYSQL同步 RESET SLAVE; 用于让从属服务器忘记其在主服务器的二进制日志中的复制位置, 它会删除master.info和relay-log.info文件，以及所有的中继日志，并启动一个新的中继日志,当你不需要主从的时候可以在从上执行这个操作。不然以后还会同步，可能会覆盖掉你的数据库，我以前就遇到过这样傻叉的事情。哈哈！ 4. 查看MYSQL同步状态 SHOW SLAVE STATUS; 这个命令主要查看Slave_IO_Running、Slave_SQL_Running、Seconds_Behind_Master、Last_IO_Error、Last_SQL_Error这些值来把握复制的状态。 5. 临时跳过MYSQL同步错误 经常会朋友mysql主从同步遇到错误的时候，比如一个主键冲突等，那么我就需要在确保那一行数据一致的情况下临时的跳过这个错误，那就需要使用SQL_SLAVE_SKIP_COUNTER = n命令了，n是表示跳过后面的n个事件,比如我跳过一个事件的操作如下： STOP SLAVE; SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1; START SLAVE; 6. 从指定位置重新同步 有的时候主从同步有问题了以后，需要从log位置的下一个位置进行同步，相当于跳过那个错误，这时候也可以使用CHANGE MASTER命令来处理，只要找到对应的LOG位置就可以,比如： CHANGE MASTER TO MASTER_HOST=\u0026lsquo;10.1.1.75\u0026rsquo;,MASTER_USER=\u0026lsquo;replication\u0026rsquo;,MASTER_PASSWORD=\u0026lsquo;123456\u0026rsquo;,MASTER_LOG_FILE=\u0026lsquo;mysql-bin.000006\u0026rsquo;, MASTER_LOG_POS=106; START SLAVE; MYSQL主从同步的管理经验介绍 1. 不要乱使用SQL_SLAVE_SKIP_COUNTER命令。 这个命令跳过之后很可能会导致你的主从数据不一致，一定要先将指定的错误记录下来，然后再去检查数据是否一致，尤其是核心的业务数据。 2. 结合percona-toolkit工具pt-table-checksum定期查看数据是否一致 这个是DBA必须要定期做的事情，呵呵，有合适的工具何乐而不为呢？另外percona-toolkit还提供了对数据库不一致的解决方案，可以采用pt-table-sync，这个工具不会更改主的数据。还可以使用pt-heartbeat来查看从服务器的复制落后情况。 具体的请查看：http://blog.chinaunix.net/uid-20639775-id-3229211.html。 3. 使用replicate-wild-ignore-table选项而不要使用replicate-do-db或者replicate-ignore-db。 原因已经在上面做了说明。 4. 将主服务器的日志模式调整成mixed。 5. 每个表都加上主键，主键对数据库的同步会有影响尤其是居于ROW复制模式。 mysql主从复制 情况１：主从mysql，之前都无数据 参考 http://blog.jobbole.com/94595/ http://www.xuejiehome.com/blread-1664.html 步骤 目标 10.10.12.14(主) 10.10.12.15(从) 1、主从安装mysql，版本一致 mysql\u0026gt;status;\nMariaDB [test]\u0026gt; status; mysql Ver 15.1 Distrib 5.5.44-MariaDB, for Linux (x86_64) using readline 5.1\nConnection id: 4 Current database: test Current user: root@localhost SSL: Not in use Current pager: stdout Using outfile: \u0026ldquo; Using delimiter: ; Server: MariaDB Server version: 5.5.44-MariaDB-log MariaDB Server Protocol version: 10 Connection: Localhost via UNIX socket Server characterset: utf8 Db characterset: utf8 Client characterset: utf8 Conn. characterset: utf8 UNIX socket: /var/lib/mysql/mysql.sock Uptime: 18 min 15 sec\nThreads: 2 Questions: 24 Slow queries: 0 Opens: 1 Flush tables: 2 Open tables: 27 Queries per second avg: 0.021 MariaDB [test]\u0026gt;\n 2、修改master，slave服务器 master服务器配置： sudo　vi /etc/my.cnf [mysqld]  datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock\nDisabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0\nSettings user and group are ignored when systemd is used. If you need to run mysqld under a different user or group, customize your systemd unit file for mariadb according to the instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin server-id=14 binlog-ignore-db = mysql,information_schema\n[mysqld] server-id=14\n#设置服务器唯一的id，默认是1，一般取IP最后一段，我们设置ip最后一段，slave设置14 log-bin=mysql-bin\n启用二进制日志 binlog-ignore-db = mysql,information_schema\n#忽略写入binlog的库 slave服务器配置： sudo　vi /etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock\nDisabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0\nSettings user and group are ignored when systemd is used. If you need to run mysqld under a different user or group, customize your systemd unit file for mariadb according to the instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin server-id=15 replicate-wild-ignore-table=test.% #replicate-do-db = test #slave-skip-errors = all\n replicate-wild-ignore-table=test.%  #　replicate-do-db = test\n#上面２句都可以表示只同步test库(但是第一句更好，不要使用第２名)，　＃如果同步所有的库，则不要加上这一句 slave-skip-errors = all\n#忽略因复制出现的所有错误 3、重启主从服务器mysql sudo systemctl restart mariadb.service sudo systemctl status mariadb.service 4、在主服务器上建立帐户并授权slave GRANT REPLICATION SLAVE ON . to \u0026lsquo;sync\u0026rsquo;@\u0026lsquo;10.10.12.%\u0026rsquo; identified by \u0026lsquo;123.com\u0026rsquo;; 注意，这里是　10.10.12.%, 而不是 10.10.12.* 我犯过这样的错误 GRANT REPLICATION SLAVE ON . to \u0026lsquo;sync\u0026rsquo;@\u0026lsquo;10.10.12.15\u0026rsquo; identified by \u0026lsquo;123.com\u0026rsquo;; 注意：大家在设置权限的时候不要将密码设置过于简单！ 5、查看主数据库状态 show master status\\G; MariaDB [(none)]\u0026gt; show master status; +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ | mysql-bin.000002 | 707 | | mysql,information_schema | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+ 1 row in set (0.00 sec)\nMariaDB [(none)]\u0026gt; MariaDB [(none)]\u0026gt; show master status\\G; *************************** 1. row *************************** File: mysql-bin.000002 Position: 707 Binlog_Do_DB: Binlog_Ignore_DB: mysql,information_schema 1 row in set (0.01 sec)\nERROR: No query specified\nMariaDB [(none)]\u0026gt; 记录下 File 及 Position 的值，在后面进行从服务器操作的时候需要用到。 6、配置从数据库 change master to master_host=\u0026lsquo;10.10.12.14\u0026rsquo;, master_user=\u0026lsquo;sync\u0026rsquo;, master_password=\u0026lsquo;123.com\u0026rsquo;, master_log_file\u0026rsquo;=\u0026lsquo;mysql-bin.000002\u0026rsquo;, master_log_pos=707; 7、启动slave同步进程并 MariaDB [(none)]\u0026gt; start slave; 查看状态 MariaDB [(none)]\u0026gt; show slave status\\G; MariaDB [(none)]\u0026gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.12.14 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 707 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 838 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: test 其中Slave_IO_Running 与 Slave_SQL_Running 的值都必须为YES，才表明状态正常。 报错 主从同步出现一下错误：Slave_IO_Running: Connecting 导致lave_IO_Running 为connecting 的原因主要有以下 3 个方面： 1、网络不通 2、密码不对 解决 从服务器 STOP SLAVE; #停止IO和SQL进程 RESET SLAVE; STOP SLAVE; #停止IO和SQL进程 6、配置从数据库 change master to master_host=\u0026lsquo;10.10.12.14\u0026rsquo;, master_user=\u0026lsquo;sync\u0026rsquo;, master_password=\u0026lsquo;123.com\u0026rsquo;, master_log_file\u0026rsquo;=\u0026lsquo;mysql-bin.000002\u0026rsquo;, master_log_pos=707; START SLAVE; #启动IO和SQL进程 实操 MariaDB [(none)]\u0026gt; reset slave; ERROR 1198 (HY000): This operation cannot be performed with a running slave; run STOP SLAVE first MariaDB [(none)]\u0026gt; stop slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; reset slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; show slave status\\G; MariaDB [(none)]\u0026gt; stop slave; Query OK, 0 rows affected, 1 warning (0.00 sec)\nMariaDB [(none)]\u0026gt; change master to -\u0026gt; master_host=\u0026lsquo;10.10.13.100\u0026rsquo;, -\u0026gt; master_user=\u0026lsquo;sync\u0026rsquo;, -\u0026gt; master_password=\u0026lsquo;sync.com\u0026rsquo;, -\u0026gt; master_log_file=\u0026lsquo;mysql-bin.000001\u0026rsquo;, -\u0026gt; master_log_pos=927; Query OK, 0 rows affected (0.01 sec)\nMariaDB [(none)]\u0026gt; start slave; Query OK, 0 rows affected (0.00 sec)\nMariaDB [(none)]\u0026gt; show slave status\\G; *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.13.100 Master_User: sync Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 927 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 529 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 3、pos不对 8、验证主从同步\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/find-mysql-password-with-java-source-code.html",
	"title": "java源码找到mysql用户密码",
	"tags": ["mysql", "mariadb", "cluster"],
	"description": "",
	"content": " 在有java源码的情况下，找到mysql用户密码\n进入项目查找 mysql ip 字符串 lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ grep \u0026quot;aliyuncs\u0026quot; -rn ./bin/ lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ grep \u0026quot;aliyuncs\u0026quot; -rn ./conf/ lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ grep \u0026quot;aliyuncs\u0026quot; -rn ./lib/ lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ grep \u0026quot;aliyuncs\u0026quot; -rn ./webapps/ ./webapps/lcnxdata/WEB-INF/classes/applicationContext.xml:30: \u0026lt;value\u0026gt;jdbc:mysql://rm-wz95k1f761xu890f3.mysql.rds.aliyuncs.com:3306/lcnx\u0026lt;/value\u0026gt; lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ cat ./webapps/lcnxdata/WEB-INF/classes/applicationContext.xml \u0026lt;bean id=\u0026quot;dataSource\u0026quot; class=\u0026quot;org.logicalcobwebs.proxool.ProxoolDataSource\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;driver\u0026quot;\u0026gt; \u0026lt;value\u0026gt;com.mysql.jdbc.Driver\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026quot;driverUrl\u0026quot;\u0026gt; \u0026lt;!-- \u0026lt;value\u0026gt;jdbc:mysql://192.168.0.188:3306/nemmp\u0026lt;/value\u0026gt; --\u0026gt; \u0026lt;value\u0026gt;jdbc:mysql://rm-wz95k1f761xu890f3.mysql.rds.aliyuncs.com:3306/lcnx\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026quot;user\u0026quot; value=\u0026quot;*********\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;password\u0026quot; value=\u0026quot;**********\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;alias\u0026quot; value=\u0026quot;*********\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;prototypeCount\u0026quot; value=\u0026quot;150\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;maximumConnectionCount\u0026quot; value=\u0026quot;1100\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;minimumConnectionCount\u0026quot; value=\u0026quot;300\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;simultaneousBuildThrottle\u0026quot; value=\u0026quot;300\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;houseKeepingTestSql\u0026quot; value=\u0026quot;select CURRENT_DATE\u0026quot; /\u0026gt; \u0026lt;property name=\u0026quot;trace\u0026quot; value=\u0026quot;true\u0026quot; /\u0026gt; \u0026lt;/bean\u0026gt; lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$  确认mysql可通后，用帐号密码连接就可以了。\nlcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ telnet rm-wz95k1f761xu890f3.mysql.rds.aliyuncs.com 3306 Trying 172.18.70.94... Connected to rm-wz95k1f761xu890f3.mysql.rds.aliyuncs.com. Escape character is '^]'. J 5.6.70f𞒭UfJG%D࠷!oD\u0026amp;:,@tTO)G.Amysql_native_password ^C Connection closed by foreign host. lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ which mysql /alidata/server/mysql/bin/mysql lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$ mysql -h rm-wz95k1f761xu890f3.mysql.rds.aliyuncs.com -u user -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 537495688 Server version: 5.6.70 Source distribution Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u0026gt; exit Bye lcnx@iZwz95dxhc92qtibd4f399Z:~/server/tomcat-data$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-install-base-centos.html",
	"title": "Mariadb Galera Install Base Centos",
	"tags": ["mariadb"],
	"description": "",
	"content": " mysql系列之集群 MariaDB-Galera-server 安装\nMariaDB Galera Cluster 部署\n参考 http://www.linuxidc.com/Linux/2015-07/119512.htm\n安装 安装mariadb10.0  官方的通过yum安装教程\n根据不同的系统来下载repo吧，更多的MariaDB.repo\n 或者，查看之前的 mariadb安装教程，就可以了。\n具体，我的是这样的。 1. MariaDB.repo\n[cdn@test_240 yum.repos.d]$ cat /etc/yum.repos.d/MariaDB.repo # MariaDB 10.0 CentOS repository list - created 2016-11-16 02:27 UTC # http://downloads.mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos7-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1  2. 安装数据库 sudo yum clean all sudo yum install MariaDB-Galera-server MariaDB-client galera -y  卸载 sudo yum remove MariaDB-server MariaDB-client sudo yum remove MariaDB-common -y\n如果要删除旧的数据库可以使用remove, 参数 -y 是确认，不用提示。此处，安装的是服务器和客户端，一般来说安装这两个就可以了。\n3. 启动数据库 如果不用进行其他的操作，则现在就可以直接启动数据库，并进行测试了。\n查看mysql状态;关闭数据库\n# service mysql status # sudo /etc/init.d/mysql status # service mysql stop\n# sudo /etc/init.d/mysql stop 启动数据库 # service mysql start # sudo /etc/init.d/mysql start\n开机自启动 # sudo chkconfig mysql on\nsudo systemctl start mariadb.service类似这种的方式，在这已失效\n[cdn@test_240 ~]$ sudo systemctl start mariadb.service [sudo] password for cdn: Failed to start mariadb.service: Unit mariadb.service failed to load: No such file or directory. [cdn@test_240 ~]$ sudo /etc/init.d/mysql start Starting MySQL.161116 13:34:03 mysqld_safe Logging to '/var/lib/mysql/test_240.err'. .. SUCCESS! [cdn@test_240 ~]$ sudo chkconfig mysql on [cdn@test_240 ~]$ sudo /etc/init.d/mysql status SUCCESS! MySQL running (13959) [cdn@test_240 ~]$ sudo /etc/init.d/mysql stop Shutting down MySQL... SUCCESS! [cdn@test_240 ~]$  4. 修改root密码 # 修改root密码 mysqladmin -u root password 'root'  因为安装好以后的root密码是空,所以需要设置; 如果是测试服务器,那么你可以直接使用root,不重要的密码很多时候可以设置为和用户名一致，以免忘记了又想不起来。 如果是重要的服务器，请使用复杂密码，例如邮箱，各种自由组合的规则的字符等。\n5. 登录数据库 mysql -u root -p  如果是本机,那可以直接使用上面的命令登录，当然，需要输入密码. 如果是其他机器，那么可能需要如下的形式:\nmysql -h 127.0.0.1 -P 3306 -u root -p  6. 简单SQL测试 \u0026gt; -- 查看MySQL的状态 status; -- 显示支持的引擎 show engines; -- 显示所有数据库 show databases; -- 切换数据库上下文,即设置当前会话的默认数据库 use test; -- 显示本数据库所有的表 show tables; -- 创建一个表 CREATETABLE t_test ( id int(11) UNSIGNED NOTNULL AUTO_INCREMENT, userId char(36), lastLoginTime timestamp, PRIMARYKEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; -- 插入测试数据 insertinto t_test(userId) values ('admin') ,('haha') ; -- 简单查询 select * from t_test; select id,userId from t_test where userId='admin' ;  7. 修改数据存放目录 mysql, MariaDB 的默认数据存放在 /var/lib/mysql/ 目录下,如果不想放到此处,或者是想要程序和数据分离，或者是磁盘原因,需要切换到其他路径,则可以通过修改 datadir系统变量来达成目的.\n# 停止数据库 service mysql stop # 创建目录,假设没有的话 mkdir /usr/local/ieternal/mysql_data # 拷贝默认数据库到新的位置 # -a 命令是将文件属性一起拷贝,否则各种问题 cp -a /var/lib/mysql /usr/local/ieternal/mysql_data # 备份原来的数据 cp -a /etc/my.cnf /etc/my.cnf_original # 其实查看 /etc/my.cnf 文件可以发现 # MariaDB 的此文件之中只有一个包含语句 # 所以需要修改的配置文件为 /etc/my.cnf.d/server.cnf cp /etc/my.cnf.d/server.cnf /etc/my.cnf.d/server.cnf_original vim /etc/my.cnf.d/server.cnf  然后 按 i 进入编辑模式,可以插入相关内容.使用键盘的上下左右键可以移动光标, 编辑完成以后，按 ESC 退出编辑模式(进入命令模式), 然后输入命令:wq 保存并退出\n# 在文件的 mysqld 节下添加内容 [mysqld] datadir=/usr/local/ieternal/mysql_data/mysql socket=/var/lib/mysql/mysql.sock #default-character-set=utf8 character_set_server=utf8 slow_query_log=on slow_query_log_file=/usr/local/ieternal/mysql_data/slow_query_log.log long_query_time=2  其中,也只有 datadir 和 socket 比较重要; 而 default-character-set 是 mysql 自己认识的,而 mariadb5.5 就不认识,相当于变成了 character_set_server\n7.1 创建慢查询日志文件 既然上面指定了慢查询日志文件，我后来看了下MariaDB的err日志，发现MariaDB不会自己创建该文件，所以我们需要自己创建,并修改相应的文件权限(比如 MySQL 采用 mysql用户，可能我们使用 root用户创建的文件,此时要求慢查询日志文件对mysql用户可读可写就行。)\ntouch /usr/local/ieternal/mysql_data/slow_query_log.log chmod 666 /usr/local/ieternal/mysql_data/slow_query_log.log  然后重新启动MySQL.\nservice mysql start  综合命令 方便大家ctrl+c, ctrl+v\nsudo service mysql status sudo service mysql stop cd /data/ ls sudo mkdir ./mariadb/mysql/ -p ls cd mariadb/mysql/ ls sudo cp -a /var/lib/mysql /data/mariadb/ ls cd ../ ls cd mysql/ ls sudo cp -a /etc/my.cnf /etc/my.cnf_original sudo cp /etc/my.cnf.d/server.cnf /etc/my.cnf.d/server.cnf_original sudo vim /etc/my.cnf.d/server.cnf sudo touch /data/mariadb/mysql/slow_query_log.log sudo chmod 666 /data/mariadb/mysql/slow_query_log.log sudo systemctl restart mariadb.service  其中 vim /etc/my.cnf.d/server.cnf\n# # These groups are read by MariaDB server. # Use it for options that only the server (but not clients) should see # # See the examples of server my.cnf files in /usr/share/mysql/ # # this is read by the standalone daemon and embedded servers [server] # this is only for the mysqld standalone daemon [mysqld] datadir=/data/mariadb/mysql socket=/var/lib/mysql/mysql.sock #default-character-set=utf8 character_set_server=utf8 slow_query_log=on slow_query_log_file=/data/mariadb/mysql/slow_query_log.log long_query_time=2 # this is only for embedded server [embedded] # This group is only read by MariaDB-5.5 servers. # If you use the same .cnf file for MariaDB of different versions, # use this group for options that older servers don't understand [mysqld-5.5] # These two groups are only read by MariaDB servers, not by MySQL. # If you use the same .cnf file for MySQL and MariaDB, # you can put MariaDB-only options here [mariadb] [mariadb-5.5]  安装报错 报错1 报错：\nMariaDB-client-10.1.19-1.el7.centos.x86_64: [Errno 256] No more mirrors to try.  出错原因：\n之前已经在 /etc/yum.repos.d/MariaDB.repo 中设置过 baseurl = http://yum.mariadb.org/10.1/centos6-amd64, 而后又觉得不对，要降低为baseurl = http://yum.mariadb.org/10.0/centos6-amd64, 导致之前的缓存没有清除。\n解决：\n运行sudo yum clean all，然后再次运行sudo yum install MariaDB-Galera-server MariaDB-client galera -y\n具体报错如下：\n[tom@kube-node-13 ~]$ ll /etc/yum.repos.d/ 总用量 44 -rw-r--r--. 1 root root 1664 12月 9 2015 CentOS-Base.repo -rw-r--r--. 1 root root 1309 12月 9 2015 CentOS-CR.repo -rw-r--r--. 1 root root 649 12月 9 2015 CentOS-Debuginfo.repo -rw-r--r--. 1 root root 290 12月 9 2015 CentOS-fasttrack.repo -rw-r--r--. 1 root root 630 12月 9 2015 CentOS-Media.repo -rw-r--r--. 1 root root 1331 12月 9 2015 CentOS-Sources.repo -rw-r--r--. 1 root root 1952 12月 9 2015 CentOS-Vault.repo -rw-r--r--. 1 root root 957 3月 31 2016 epel.repo -rw-r--r--. 1 root root 1056 3月 31 2016 epel-testing.repo -rw-r--r--. 1 root root 261 11月 16 10:28 MariaDB.repo -rw-r--r--. 1 root root 401 2月 15 2016 zabbix.repo [tom@kube-node-13 ~]$ sudo yum install MariaDB-client galera -y 已加载插件：fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: ftp.sjtu.edu.cn * epel: free.nchc.org.tw * extras: ftp.sjtu.edu.cn * updates: ftp.sjtu.edu.cn 正在解决依赖关系 --\u0026gt; 正在检查事务 ---\u0026gt; 软件包 MariaDB-client.x86_64.0.10.1.19-1.el7.centos 将被 安装 --\u0026gt; 正在处理依赖关系 MariaDB-common，它被软件包 MariaDB-client-10.1.19-1.el7.centos.x86_64 需要 ---\u0026gt; 软件包 galera.x86_64.0.25.3.18-1.rhel7.el7.centos 将被 安装 --\u0026gt; 正在处理依赖关系 libboost_program_options.so.1.53.0()(64bit)，它被软件包 galera-25.3.18-1.rhel7.el7.centos.x86_64 需要 --\u0026gt; 正在检查事务 ---\u0026gt; 软件包 MariaDB-common.x86_64.0.10.1.19-1.el7.centos 将被 安装 ---\u0026gt; 软件包 boost-program-options.x86_64.0.1.53.0-25.el7 将被 安装 --\u0026gt; 处理 MariaDB-common-10.1.19-1.el7.centos.x86_64 与 mariadb-libs \u0026lt; 1:10.1.19-1.el7.centos 的冲突 --\u0026gt; 正在使用新的信息重新解决依赖关系 --\u0026gt; 正在检查事务 ---\u0026gt; 软件包 MariaDB-shared.x86_64.0.10.1.19-1.el7.centos 将被 舍弃 ---\u0026gt; 软件包 mariadb-libs.x86_64.1.5.5.50-1.el7_2 将被 取代 --\u0026gt; 解决依赖关系完成 依赖关系解决 ==================================================================================================================================================================================================================== Package 架构 版本 源 大小 ==================================================================================================================================================================================================================== 正在安装: MariaDB-client x86_64 10.1.19-1.el7.centos mariadb 39 M MariaDB-shared x86_64 10.1.19-1.el7.centos mariadb 1.3 M 替换 mariadb-libs.x86_64 1:5.5.50-1.el7_2 galera x86_64 25.3.18-1.rhel7.el7.centos mariadb 7.8 M 为依赖而安装: MariaDB-common x86_64 10.1.19-1.el7.centos mariadb 43 k boost-program-options x86_64 1.53.0-25.el7 base 155 k 事务概要 ==================================================================================================================================================================================================================== 安装 3 软件包 (+2 依赖软件包) 总计：48 M 总下载量：40 M Downloading packages: MariaDB-10.1.19-centos7-x86_64 FAILED http://yum.mariadb.org/10.0/centos7-amd64/rpms/MariaDB-10.1.19-centos7-x86_64-client.rpm: [Errno 14] HTTP Error 404 - Not Found ] 0.0 B/s | 0 B --:--:-- ETA 正在尝试其它镜像。 To address this issue please refer to the below knowledge base article https://access.redhat.com/articles/1320623 If above article doesn't help to resolve this issue please create a bug on https://bugs.centos.org/ MariaDB-10.1.19-centos7-x86_64 FAILED http://yum.mariadb.org/10.0/centos7-amd64/rpms/MariaDB-10.1.19-centos7-x86_64-common.rpm: [Errno 14] HTTP Error 404 - Not Found ] 0.0 B/s | 0 B --:--:-- ETA 正在尝试其它镜像。 MariaDB-10.1.19-centos7-x86_64 FAILED http://yum.mariadb.org/10.0/centos7-amd64/rpms/MariaDB-10.1.19-centos7-x86_64-shared.rpm: [Errno 14] HTTP Error 404 - Not Found ] 0.0 B/s | 0 B --:--:-- ETA 正在尝试其它镜像。 Error downloading packages: MariaDB-client-10.1.19-1.el7.centos.x86_64: [Errno 256] No more mirrors to try. MariaDB-shared-10.1.19-1.el7.centos.x86_64: [Errno 256] No more mirrors to try. MariaDB-common-10.1.19-1.el7.centos.x86_64: [Errno 256] No more mirrors to try. [tom@kube-node-13 ~]$  end "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-install-base-centos.html",
	"title": "Mariadb Install Base Centos",
	"tags": ["mariadb", "install", "centos"],
	"description": "",
	"content": " mysql-0mysql系列之mariadb-install\nref  http://blog.csdn.net/renfufei/article/details/17616549  过程 说明: 首先必须能链接外网. 如果不能直接访问,那也可以设置代理,请参考: 在内网机器上设置yum代理 使用 yum 的权限要求是 root 用户,如果你不是,那么可以需要 在 shell命令之前加上 sudo, 或者 su root 切换到 super 管理员进行操作. 并可能需要输入密码.\n1. 添加 yum 数据源  安装mariadb10.1 官方的通过yum安装教程\n根据不同的系统来下载repo吧，更多的MariaDB.repo\n 建议命名为 MariaDB.repo 类似的名字：\ncd /etc/yum.repos.d/ vim /etc/yum.repos.d/MariaDB.repo  然后,写入文件内容:(建议使用 10.0)\n# MariaDB 10.0 CentOS repository list - created 2015-08-12 10:59 UTC # http://mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos6-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1  这个baseurl可以通过浏览器打开，然后在 http://yum.mariadb.org/10.0/centos7-amd64/rpms/ 中 可以看到这里面有些什么 .rpm 文件。\n该文件的内容是参考官网,并从官网上生成的，设置安装源仓库的 具体的地址为: https://downloads.mariadb.org/mariadb/repositories/ 选择好操作系统版本之后既可以查看，其他操作系统的安装源也可以在此处查看并设置。 如果服务器不支持https协议，或者gpgkey 保错，确保没问题的话，可以将 gpgcheck=1 修改为 gpgcheck=0,则不进行校验.\n2. 安装数据库 yum remove MariaDB-server MariaDB-client yum -y install MariaDB-server MariaDB-client  如果要删除旧的数据库可以使用remove, 参数 -y 是确认，不用提示。此处，安装的是服务器和客户端，一般来说安装这两个就可以了。\n3. 启动数据库 如果不用进行其他的操作，则现在就可以直接启动数据库，并进行测试了。\n查看mysql状态;关闭数据库\n# service mysql status\n# service mysql stop\n启动数据库\n# service mysql start\n4. 修改root密码 # 修改root密码 mysqladmin -u root password 'root'  因为安装好以后的root密码是空,所以需要设置; 如果是测试服务器,那么你可以直接使用root,不重要的密码很多时候可以设置为和用户名一致，以免忘记了又想不起来。 如果是重要的服务器，请使用复杂密码，例如邮箱，各种自由组合的规则的字符等。\n5. 登录数据库 mysql -u root -p  如果是本机,那可以直接使用上面的命令登录，当然，需要输入密码. 如果是其他机器，那么可能需要如下的形式:\nmysql -h 127.0.0.1 -P 3306 -u root -p  6. 简单SQL测试 \u0026gt; -- 查看MySQL的状态 status; -- 显示支持的引擎 show engines; -- 显示所有数据库 show databases; -- 切换数据库上下文,即设置当前会话的默认数据库 use test; -- 显示本数据库所有的表 show tables; -- 创建一个表 CREATETABLE t_test ( id int(11) UNSIGNED NOTNULL AUTO_INCREMENT, userId char(36), lastLoginTime timestamp, PRIMARYKEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; -- 插入测试数据 insertinto t_test(userId) values ('admin') ,('haha') ; -- 简单查询 select * from t_test; select id,userId from t_test where userId='admin' ;  7. 修改数据存放目录 mysql, MariaDB 的默认数据存放在 /var/lib/mysql/ 目录下,如果不想放到此处,或者是想要程序和数据分离，或者是磁盘原因,需要切换到其他路径,则可以通过修改 datadir系统变量来达成目的.\n# 停止数据库 service mysql stop # 创建目录,假设没有的话 mkdir /usr/local/ieternal/mysql_data # 拷贝默认数据库到新的位置 # -a 命令是将文件属性一起拷贝,否则各种问题 cp -a /var/lib/mysql /usr/local/ieternal/mysql_data # 备份原来的数据 cp -a /etc/my.cnf /etc/my.cnf_original # 其实查看 /etc/my.cnf 文件可以发现 # MariaDB 的此文件之中只有一个包含语句 # 所以需要修改的配置文件为 /etc/my.cnf.d/server.cnf cp /etc/my.cnf.d/server.cnf /etc/my.cnf.d/server.cnf_original vim /etc/my.cnf.d/server.cnf  然后 按 i 进入编辑模式,可以插入相关内容.使用键盘的上下左右键可以移动光标, 编辑完成以后，按 ESC 退出编辑模式(进入命令模式), 然后输入命令:wq 保存并退出\n# 在文件的 mysqld 节下添加内容 [mysqld] datadir=/usr/local/ieternal/mysql_data/mysql socket=/var/lib/mysql/mysql.sock #default-character-set=utf8 character_set_server=utf8 slow_query_log=on slow_query_log_file=/usr/local/ieternal/mysql_data/slow_query_log.log long_query_time=2  其中,也只有 datadir 和 socket 比较重要; 而 default-character-set 是 mysql 自己认识的,而 mariadb5.5 就不认识,相当于变成了 character_set_server\n7.1 创建慢查询日志文件 既然上面指定了慢查询日志文件，我后来看了下MariaDB的err日志，发现MariaDB不会自己创建该文件，所以我们需要自己创建,并修改相应的文件权限(比如 MySQL 采用 mysql用户，可能我们使用 root用户创建的文件,此时要求慢查询日志文件对mysql用户可读可写就行。)\ntouch /usr/local/ieternal/mysql_data/slow_query_log.log chmod 666 /usr/local/ieternal/mysql_data/slow_query_log.log  然后重新启动MySQL.\nservice mysql start  综合命令 方便大家ctrl+c, ctrl+v\nsudo systemctl status mariadb.service sudo systemctl stop mariadb.service cd /data/ ls sudo mkdir ./mariadb/mysql/ -p ls cd mariadb/mysql/ ls sudo cp -a /var/lib/mysql /data/mariadb/ ls cd ../ ls cd mysql/ ls sudo cp -a /etc/my.cnf /etc/my.cnf_original sudo cp /etc/my.cnf.d/server.cnf /etc/my.cnf.d/server.cnf_original sudo vim /etc/my.cnf.d/server.cnf sudo touch /data/mariadb/mysql/slow_query_log.log sudo chmod 666 /data/mariadb/mysql/slow_query_log.log sudo systemctl restart mariadb.service  其中 vim /etc/my.cnf.d/server.cnf\n# # These groups are read by MariaDB server. # Use it for options that only the server (but not clients) should see # # See the examples of server my.cnf files in /usr/share/mysql/ # # this is read by the standalone daemon and embedded servers [server] # this is only for the mysqld standalone daemon [mysqld] datadir=/data/mariadb/mysql socket=/var/lib/mysql/mysql.sock #default-character-set=utf8 character_set_server=utf8 slow_query_log=on slow_query_log_file=/data/mariadb/mysql/slow_query_log.log long_query_time=2 # this is only for embedded server [embedded] # This group is only read by MariaDB-5.5 servers. # If you use the same .cnf file for MariaDB of different versions, # use this group for options that older servers don't understand [mysqld-5.5] # These two groups are only read by MariaDB servers, not by MySQL. # If you use the same .cnf file for MySQL and MariaDB, # you can put MariaDB-only options here [mariadb] [mariadb-5.5]  卸载 sudo yum remove MariaDB-server -y sudo yum remove MariaDB-client -y sudo yum remove MariaDB-common -y  end "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-install.html",
	"title": "Mariadb Install",
	"tags": ["mariadb", "install"],
	"description": "",
	"content": " mariadb install "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb/mongodb-update.html",
	"title": "Mongodb Update",
	"tags": ["mongodb", "update"],
	"description": "",
	"content": " mongodb系列之update\n只要是批量，后头加 {multi: true} 吧。\n批量，新增一个k-v db.Signals_Day.update({TrdDt:20161129}, {$set: {\u0026ldquo;Real\u0026rdquo;: true}}, {multi: true})\ntestrs:PRIMARY\u0026gt; db.Signals_Day.update({TrdDt:20161129}, {$set: {\u0026quot;Real\u0026quot;: true}}, {multi: true}) WriteResult({ \u0026quot;nMatched\u0026quot; : 8935, \u0026quot;nUpserted\u0026quot; : 0, \u0026quot;nModified\u0026quot; : 8933 }) testrs:PRIMARY\u0026gt; db.Signals_Day.find({TrdDt:20161129}) { \u0026quot;_id\u0026quot; : ObjectId(\u0026quot;583d27735868c24cb078e925\u0026quot;), \u0026quot;Type\u0026quot; : \u0026quot;NewHighLow\u0026quot;, \u0026quot;Sign\u0026quot; : -1, \u0026quot;ID\u0026quot; : \u0026quot;000785.SZ\u0026quot;, \u0026quot;TrdDt\u0026quot; : 20161129, \u0026quot;TrdTm\u0026quot; : 1500, \u0026quot;PrevClsPx\u0026quot; : 14.99, \u0026quot;LastPx\u0026quot; : 14.4, \u0026quot;Real\u0026quot; : true } { \u0026quot;_id\u0026quot; : ObjectId(\u0026quot;583d27735868c24cb078e92a\u0026quot;), \u0026quot;Type\u0026quot; : \u0026quot;RSI\u0026quot;, \u0026quot;Sign\u0026quot; : -1, \u0026quot;ID\u0026quot; : \u0026quot;002117.SZ\u0026quot;, \u0026quot;TrdDt\u0026quot; : 20161129, \u0026quot;TrdTm\u0026quot; : 1500, \u0026quot;PrevClsPx\u0026quot; : 29.88, \u0026quot;LastPx\u0026quot; : 29.84, \u0026quot;Real\u0026quot; : true } Type \u0026quot;it\u0026quot; for more testrs:PRIMARY\u0026gt;_  批量，修改一个key的value, 原value乘以100 db.Signals_Day.update({TrdDt:20161129}, {$mul: {\u0026ldquo;TrdTm\u0026rdquo;:100}}, {multi: true} )\ntestrs:PRIMARY\u0026gt; db.Signals_Day.update({TrdDt:20161129}, {$mul: {\u0026quot;TrdTm\u0026quot;:100}}, {multi: true} ) WriteResult({ \u0026quot;nMatched\u0026quot; : 8935, \u0026quot;nUpserted\u0026quot; : 0, \u0026quot;nModified\u0026quot; : 8935 }) testrs:PRIMARY\u0026gt; db.Signals_Day.find({TrdDt:20161129})  手工修改 VIP 用户数 修改某一天\ntestrs:PRIMARY\u0026gt; db.user.update({\u0026quot;vip.level\u0026quot;:0, \u0026quot;registerTime\u0026quot; : /20180317/}, {$set: {\u0026quot;vip\u0026quot; : { \u0026quot;level\u0026quot; : 1, \u0026quot;value\u0026quot; : \u0026quot;会员\u0026quot;, \u0026quot;createTime\u0026quot; : \u0026quot;20180317010101\u0026quot;, \u0026quot;endTime\u0026quot; : \u0026quot;20180417235959\u0026quot; }}}, { multi: 1}) WriteResult({ \u0026quot;nMatched\u0026quot; : 8, \u0026quot;nUpserted\u0026quot; : 0, \u0026quot;nModified\u0026quot; : 8 })  修改小于某个指定日期\ntestrs:PRIMARY\u0026gt; db.user.find({\u0026quot;vip.level\u0026quot;:0, \u0026quot;registerTime\u0026quot; : {$lt :\u0026quot;20180317000000\u0026quot;}}).count() 3487 testrs:PRIMARY\u0026gt; db.user.update({\u0026quot;vip.level\u0026quot;:0, \u0026quot;registerTime\u0026quot; : {$lt :\u0026quot;20180317000000\u0026quot;}}, {$set: {\u0026quot;vip\u0026quot; : { \u0026quot;level\u0026quot; : 1, \u0026quot;value\u0026quot; : \u0026quot;会员\u0026quot;, \u0026quot;createTime\u0026quot; : \u0026quot;20180316010101\u0026quot;, \u0026quot;endTime\u0026quot; : \u0026quot;20180516235959\u0026quot; }}}, { multi: 1}) WriteResult({ \u0026quot;nMatched\u0026quot; : 3487, \u0026quot;nUpserted\u0026quot; : 0, \u0026quot;nModified\u0026quot; : 3487 }) testrs:PRIMARY\u0026gt;  ##\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb/mongodb-distinct.html",
	"title": "Mongodb Distinct",
	"tags": ["mongodb", "distinct"],
	"description": "",
	"content": " mongodb系列之distinct\nreference https://docs.mongodb.com/manual/reference/method/db.collection.distinct/\nhttp://www.jb51.net/article/65929.htm\ndestinct  MongoDB的destinct命令是获取特定字段中不同值列表。该命令适用于普通字段，数组字段和数组内嵌文档.  mongodb的distinct的语句： db.users.distinct(\u0026lsquo;last_name\u0026rsquo;）;\n等同于 SQL 语句: select DISTINCT last_name from users;\n表示的是根据指定的字段返回不同的记录集。\n 如果，有相关的查询，则放在后面。\ntestrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;LastPx\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161101, \u0026ldquo;ID\u0026rdquo;: \u0026ldquo;600650.SH\u0026rdquo;}) [ 25.88, 25.89, 25.87, 25.86 ] testrs:PRIMARY\u0026gt;\n示例  db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;).length 114 db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;)\n testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161102, \u0026ldquo;ID\u0026rdquo;: /^60.*SH/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1081 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161101, \u0026ldquo;ID\u0026rdquo;: /^60.*SH/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1109 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161103, \u0026ldquo;ID\u0026rdquo;: /^60.*SH/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1083 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161031, \u0026ldquo;ID\u0026rdquo;: /^60.*SH/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1107 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161025, \u0026ldquo;ID\u0026rdquo;: /^60.*SH/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1077 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161025, \u0026ldquo;ID\u0026rdquo;: /^00.*SZ/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1168 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161031, \u0026ldquo;ID\u0026rdquo;: /^00.*SZ/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1271 testrs:PRIMARY\u0026gt; db.KLine_1Min.distinct(\u0026ldquo;ID\u0026rdquo;, {\u0026ldquo;TrdDt\u0026rdquo;:20161101, \u0026ldquo;ID\u0026rdquo;: /^00.*SZ/, \u0026ldquo;TrdTm\u0026rdquo;:1441}).length 1271 testrs:PRIMARY\u0026gt;\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb/mongodb-findoneandupdate.html",
	"title": "Mongodb Findoneandupdate",
	"tags": ["mongodb"],
	"description": "",
	"content": " mongodb系列之findOneAndUpdate\n参考 http://mongodb.github.io/node-mongodb-native/2.2/api/Collection.html#findOneAndUpdate\nhttps://docs.mongodb.com/manual/reference/method/db.collection.findOneAndUpdate/\n示例 修改键（字段）的值,修改了{b:2}\nvar MongoClient = require('mongodb').MongoClient; MongoClient.connect('mongodb://192.168.31.240:27017/test', function(err, db) { // Get the collection var col = db.collection('find_one_and_update'); col.insertMany([{a:1, b:1}], {w:1}, function(err, r) { col.findOneAndUpdate({a:1} , {$set: {b:2}} , { upsert: true } , function(err, r) { db.close(); }); }); });  增加新的键，增加了{d:1}\nvar MongoClient = require('mongodb').MongoClient, test = require('assert'); MongoClient.connect('mongodb://192.168.31.240:27017/test', function(err, db) { // Get the collection var col = db.collection('find_one_and_update'); col.insertMany([{a:1, b:1}], {w:1}, function(err, r) { col.findOneAndUpdate({a:1} , {$set: {d:1}} , { upsert: true } , function(err, r) { db.close(); }); }); });  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown/markdown.html",
	"title": "Markdown",
	"tags": ["markdown"],
	"description": "",
	"content": " Markdown转HTML 在线版：\n 在一起（这个网站还有很多其实转换工具） 带了样式，但是不能用于 表格\n 作业部落 不带样式，但是可用于 表格\n  HTML转Markdown 在线版：\n 在线工具 （这个网站还有很多其实转换工具） *  Markdown 快速生成表格 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-port-process.html",
	"title": "Linux Port Process",
	"tags": ["linux", "port"],
	"description": "",
	"content": " linux系列之端口与进程\nlinux如何查看端口被哪个进程占用 使用netstat 和lsof命令，并用grep来过滤你需要查看的端口。 例如查看tcp有哪些端口打开了：\nnetstat -a| grep tcp  然后查看哪个进程占用了这些端口：\nlsof -i  如果要查看某个端口，比如80端口是哪个进程：\nlsof -i | grep :80  如果说，tom用户查到了一些端口号被占用，但是，用lsof却查不到。怎么办？ 则要考虑，是不是端口被root用户占用，没有权限。所以要再一次用sudo lsof来查一查。\n示例 netstat -ant | grep 8060 ps -aux | grep node lsof -i:8060 man lsof lsof -i lsof -i -n lsof -iTCP sudo lsof -i  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos-yum.html",
	"title": "Centos Yum",
	"tags": ["centos", "yum"],
	"description": "",
	"content": " centos系列之yum\nyum安装的软件在哪? linux下如何查看某个软件 是否安装？安装路径在哪? linux下如何查看某个软件 是否安装？安装路径在哪\n使用sudo rpm -qa来查看通过 yum安装的软件\n[tom@kube-node-11 ~]$ sudo rpm -qa | grep Maria MariaDB-client-10.1.19-1.el7.centos.x86_64 MariaDB-common-10.1.19-1.el7.centos.x86_64 MariaDB-Galera-server-10.0.28-1.el7.centos.x86_64 MariaDB-shared-10.1.19-1.el7.centos.x86_64  linux 通过 yum search 得到，在当前情况下，能安装哪些软件，哪些软件安装不了。 如下面 这个地方，显示 MariaDB-Galera-server 找不到。\n[cdn@test_240 ~]$ sudo yum install MariaDB-Galera-server MariaDB-client galera -y Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.cn99.com * extras: mirrors.cn99.com * updates: mirrors.cn99.com No package MariaDB-Galera-server available. Package MariaDB-client-10.1.19-1.el7.centos.x86_64 already installed and latest version Package galera-25.3.18-1.rhel7.el7.centos.x86_64 already installed and latest version Nothing to do [cdn@test_240 ~]$  那么，我们怎么办呢？ 用yum search吧\n 确保 MariaDB.repo 存在\n[cdn@test_240 ~]$ ll /etc/yum.repos.d/ [cdn@test_240 ~]$ cat /etc/yum.repos.d/MariaDB.repo\nMariaDB 10.1 CentOS repository list - created 2016-11-15 02:38 UTC http://downloads.mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos7-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1 [cdn@test_240 ~]$\n 确保 MariaDB.repo 生效\n  先查是否能ping到baseurl\n[cdn@test_240 ~]$ cat /etc/yum.repos.d/MariaDB.repo # MariaDB 10.0 CentOS repository list - created 2016-11-16 02:27 UTC # http://downloads.mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/10.0/centos7-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1 [cdn@test_240 ~]$ ping yum.mariabdb.org ^C [cdn@test_240 ~]$ ping yum.mariadb.org PING yum.mariadb.org (142.4.217.28) 56(84) bytes of data. 64 bytes from bb02.mariadb.net (142.4.217.28): icmp_seq=1 ttl=47 time=272 ms 64 bytes from bb02.mariadb.net (142.4.217.28): icmp_seq=2 ttl=47 time=272 ms 64 bytes from bb02.mariadb.net (142.4.217.28): icmp_seq=3 ttl=47 time=272 ms ^C --- yum.mariadb.org ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2001ms rtt min/avg/max/mdev = 272.301/272.492/272.588/0.135 ms  说明可以ping yum.mariadb.org。\n用 yum search查，有MariaDB.repo VS 没有MariaDB.repo情况下，得到的软件列表是否相同。\n先走一个 sudo yum search MariaDB\n[cdn@test_240 ~]$ sudo yum search MariaDB Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.nwsuaf.edu.cn * epel: ftp.cuhk.edu.hk * extras: mirrors.cn99.com * updates: mirrors.cn99.com =============================================================================================== N/S matched: MariaDB =============================================================================================== MariaDB-client.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-common.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-compat.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-connect-engine.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-cracklib-password-check.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-devel.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-gssapi-client.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-gssapi-server.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-oqgraph-engine.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-server.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-shared.x86_64 : MariaDB: a very fast and robust SQL database server MariaDB-test.x86_64 : MariaDB: a very fast and robust SQL database server mariadb-bench.x86_64 : MariaDB benchmark scripts and data mariadb-devel.i686 : Files for development of MariaDB/MySQL applications mariadb-devel.x86_64 : Files for development of MariaDB/MySQL applications mariadb-embedded.i686 : MariaDB as an embeddable library mariadb-embedded.x86_64 : MariaDB as an embeddable library mariadb-embedded-devel.i686 : Development files for MariaDB as an embeddable library mariadb-embedded-devel.x86_64 : Development files for MariaDB as an embeddable library mariadb-libs.i686 : The shared libraries required for MariaDB/MySQL clients mariadb-libs.x86_64 : The shared libraries required for MariaDB/MySQL clients mariadb-server.x86_64 : The MariaDB server and related files mariadb.x86_64 : A community developed branch of MySQL mariadb-test.x86_64 : The test suite distributed with MariaD percona-xtrabackup.x86_64 : Online backup for InnoDB/XtraDB in MySQL, Percona Server and MariaDB Name and summary matches only, use \u0026quot;search all\u0026quot; for everything. [cdn@test_240 ~]$  两2种方法（2种用其1就可以了）：\n 方法1, 把MariaDB.repo移除。 不MariaDB.repo 移除，再运行 sudo yum search MariaDB。 把MariaDB.repo 移除，再运行 sudo yum search MariaDB。\n 方法2, 用yum search --disablerepo=。\n先 sudo yum search MariaDB。 再运行 sudo yum search MariaDB --disablerepo=base,extras,updates,epel。\n  对比结果。最后，可知，列表不同。说明本MariaDB.repo 已生效。\n所以，以后每次安装软件前，可以先用yum search一下，这样，确保我们想要安装的，就是实际安装的\nyum install 之前要做的事  sudo yum makecache sudo yum clean all sudo yum search XXX  end "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/hexo.html",
	"title": "Hexo Command",
	"tags": ["hexo", "command"],
	"description": "",
	"content": " hexo系列之使用1\nhexo下新建页面下如何放多个文章？ https://www.zhihu.com/question/33324071\nhexo分类与tags配置 Hexo中如何给一篇文章加多个tags？ 下面2种方式：\n tags: [a,b,c] # 冒号后有一个空格 tags: - tag1 - tag2  可以做到自动增加哟。 tom@adata:~/m6s/blogs/tomtsang$ hexo n \u0026quot;mysql-21\u0026quot; INFO Created: ~/m6s/blogs/tomtsang/source/_posts/mysql-21.md tom@adata:~/m6s/blogs/tomtsang$ hexo n \u0026quot;mysql\u0026quot; INFO Created: ~/m6s/blogs/tomtsang/source/_posts/mysql-22.md tom@adata:~/m6s/blogs/tomtsang$ hexo n \u0026quot;mysql\u0026quot; INFO Created: ~/m6s/blogs/tomtsang/source/_posts/mysql-23.md_  这样的话，方便形成系列的文章。每次就不用管是第几个mysql系列文章了。 不过系列文章，最好用的，还是 categories\n可以用自定义的post: tom@adata:~/m6s/blogs/tomtsang$ hexo n \u0026quot;mysql\u0026quot; [mysql] INFO Created: ~/m6s/blogs/tomtsang/source/_posts/mysql-4.md tom@adata:~/m6s/blogs/tomtsang$ hexo n \u0026quot;mysql\u0026quot; [mysql] INFO Created: ~/m6s/blogs/tomtsang/source/_posts/mysql-5.md tom@adata:~/m6s/blogs/tomtsang$ hexo n \u0026quot;mysql\u0026quot; [mysql] INFO Created: ~/m6s/blogs/tomtsang/source/_posts/mysql-1.md_  end "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hexo/hexo-hello-world.html",
	"title": "Hexo Hello World",
	"tags": ["hexo", "hello-world"],
	"description": "",
	"content": " Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026quot;My New Post\u0026quot;  More info: Writing\nRun server $ hexo server  More info: Server\nGenerate static files $ hexo generate  More info: Generating\nDeploy to remote sites $ hexo deploy  More info: Deployment\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git-workflow.html",
	"title": "Git Workflow",
	"tags": ["gitlab", "workflow"],
	"description": "",
	"content": " gitlab系列之workflow\n本文是 官方 workflow 的中文翻译\n参考 https://docs.gitlab.com/ee/workflow/gitlab_flow.html\n中文 介绍 使用git进行版本管理使得分支和合并比旧版本系统（如SVN）容易得多。 这允许多种分支策略和工作流程。 几乎所有这些都是对git之前使用的方法的改进。 但是许多组织最终没有明确定义，过于复杂或没有与问题跟踪系统（issue tracking systems）集成的，工作流。 因此，我们建议GitLab flow作为明确定义的一套最佳实践。 它结合了功能驱动开发和功能分支的问题跟踪。\n来自其他版本控制系统的组织经常发现很难开发有效的工作流。 本文介绍“将git工作流与问题跟踪系统集成”的GitLab流程。 它提供了一个简单，透明和有效的方式使用git。\n当转换到git时，你必须习惯于在与同事共享提交之前有三个步骤。 大多数版本控制系统只有一个步骤，从工作副本提交到共享服务器。 在git中，您可以将文件从工作副本添加到暂存区域。 之后，你提交他们到本地回购。 第三步是推送到共享远程存储库。 在习惯了这三个步骤之后，分支模型成为挑战。\n因为许多组织，对于git是新认识，没有公约如何使用它，那么很快git变成一团糟。 他们遇到的最大的问题是，许多长期运行的分支，每个包含了一部分的变化。 人们很难确定他们应该开发或部署到生产的是哪个分支。 通常对这个问题的反应是采用标准化模式，例如git流和GitHub流。 我们认为仍有改进的余地，并将详细介绍一组我们称为GitLab流程的做法。\nGit flow and its problems Git流是一个第一建议使用git分支的vcs，它得到了很多的关注。它主张一个主分支、一个单独开发分支以及支持特性功能开发，发布版本和修补程序的其它分支。开发发生在开发分支上，移动到发布分支，并最终合并到主分支。 Git流是有一个定义良好的标准，但它的复杂性引入了两个问题。第一个问题是开发人员必须使用develop分支而不是master，master是保留给用于发布生产版本的代码。这是一个约定，称默认分支为master，并主要从此master分支，合并到此master。由于大多数工具自动使master分支成为默认分支，并在默认情况下显示该分支，因此必须切换到另一个分支。git流的第二个问题是修补程序和发布分支引入的复杂性。这些分支对于一些组织来说可能是一个好主意，但对于绝大多数组织来说是过分了。现在大多数组织实施持续交付，这意味着可以部署您的默认master分支。这意味着要prevented修补程序和发布分支，包括它们引入的所有仪式（ceremony）。这个仪式的一个例子是合并发布分支。虽然存在专门的工具来解决这个问题，但它们需要文档并增加复杂性。开发人员经常犯错误，例如更改只会合并到master中，而不会合并到develop分支中。这些错误的根本原因是git流对于大多数用例来说太复杂了。并且发布并不自动意味着也做修补程序。\nGitHub flow as a simpler alternative 在对git流的应对中，一个更简单的选择是，详细的GitHub流。 此流仅具有特征分支和master分支。 这是非常简单和干净，许多组织已经采用它与巨大的成功。 Atlassian推荐一个类似的策略，虽然他们rebase特征分支。 将所有内容合并到主分支并经常部署,意味着您最小化“库存”中的代码量，这符合精益和持续交付最佳实践。 但是这个流程仍然有许多关于部署，环境，发布和问题集成的问题。 使用GitLab流程，我们为这些问题提供额外的指导。\nProduction branch with GitLab flow GitHub流假设你能够在每次合并特性分支时都部署到生产环境。这对于SaaS应用程序是可能的，但在许多情况下，这是不可能的。一种情况是，你不能控制确切的发布时刻，例如需要通过App Store验证的iOS应用程序。另一个例子是，当您有部署窗口时间（工作日从上午10点到下午4点，当操作团队满员时），但您也可以在其他时间合并代码。在这些情况下，您可以创建一个反映部署代码的生产分支。您可以通过将master合并到生产（production）分支来部署新版本。如果你需要知道在生产分支中是什么代码，你可以只是checkout到生产分支看看。部署的大致时间，很容易显示为版本控制系统中的合并提交时间。如果您自动部署生产分支，这一时间是相当准确的。如果您需要更准确的时间，您可以让部署脚本在每个部署中创建一个tag。此流防止了，git流的发布，标记和合并的开销。\nEnvironment branches with GitLab flow 建立一个自动更新到master分支的环境可能是个好主意。只有在这种情况下，此环境的名称可能与分支名称不同。假设您有一个暂存环境（staging environment），一个预生产环境和一个生产环境。在这种情况下，主分支将部署在暂存环境。当有人想要部署到预生产时，他们创建从主分支到预生产分支的合并请求。并且通过合并预生产分支到生产分支。此工作流只提交下游流确保一切都已在所有环境中测试过。如果您需要使用修补程序选择一个提交，通常在特性分支上进行开发，并将其与合并请求合并到master中，不要删除特性分支。如果master是好的（它应该是好的，如果你是连续交付的），然后将它合并到其他分支（也就是合并到预生产环境和生产环境）。如果这是不可能的（因为可能需要更多的手动测试），您可以将功能分支的合并请求发送到下游分支。 环境分支的一个“极端”版本，就是，正在为Teatro所做的，每个功能分支设置一个环境。\nRelease branches with GitLab flow 只有在需要将软件发布到外部世界的情况下，您才需要使用版本发布分支。在这种情况下，每个分支包含次要版本（2-3稳定版，2-4稳定版等）。稳定分支使用master作为起点，并尽可能晚地创建。通过尽可能晚的提交分支，您必须将错误修复应用到多个分支的时间最小化。在发布了一个发布分支后，只有严重的错误修复包括在发布分支中。如果可能的话，这些错误修复首先合并到master中，然后进入发布分支。这种方式下，你不能忘记cherry-picked他们进 master 和 遇到相同的bug的后续版本。这称为“上游第一”策略，也是由Google和Red Hat实施的。每次在发布分支中包括错误修复时，通过设置新标签来提高补丁版本（以符合语义版本控制）。一些项目也有一个稳定的分支，指向与最新发布的分支相同的提交。在这个流程中，有一个生产分支（或git flow master分支）是不常见的。\nMerge/pull requests with GitLab flow 合并或拉取请求在git管理应用程序中创建，并要求分配任务的人合并两个分支。诸如GitHub和Bitbucket之类的工具选择名称为拉动请求（pull request），因为第一个手动动作将是拉取pull特征分支。诸如GitLab和其他工具之类的工具选择名称为合并请求（merge request），因为最终动作是请求代理人的动作。在本文中，我们将它们称为合并请求。\n如果你在一个功能分支上工作超过几个小时，最好与团队的其他成员分享中间结果。这可以通过创建合并请求（而不是将任务分配给任何人，相应地，你在（描述或注释中）提醒其他人），来完成。这意味着它还没有准备好被合并，但欢迎反馈。您的团队成员可以对一般的合并请求或具有行注释的特定行，发表评论。合并请求作为代码审查工具，不需要单独的工具，如Gerrit和reviewboard。如果审查揭示了缺点（shortcomings），任何人可以提交和推动修复。通常，这样做的人，是合并/拉取请求的创建者。当在分支上推送新提交时，merge / pull请求中的diff会自动更新。\n当你觉得合并它的时候，你可以把它分配给那些最了解你正在改变的代码库的人，并提及 你希望从任何其他人那里得到反馈的人员名单。有更多的反馈空间，在分配的人员后，进行分支合并的结果，会让人感到舒适。如果被分配的人不舒服，他们可以关闭合并请求而不合并。\n在GitLab中，通常保护长期分支（例如master分支），以便正常的开发人员不能修改这些受保护的分支。所以如果你想把它合并到一个受保护的分支，你可以将它分配给有master权限的人。\nIssues with GitLab flow GitLab流是一种使代码和问题跟踪之间的关系更透明的方式。\n代码的任何重大更改应从描述目标的问题（issue）开始。每个代码更改的原因是重要的通知团队中的每个人，并帮助人们保持功能分支的范围小。在GitLab中，对代码库的每个更改都从问题跟踪系统中的问题开始。如果有重大的工作被涉及（超过1小时），即使没有issue，那也应该首先创建issue。对于许多组织，这将是自然的，因为问题（issue）将必须被估计。问题标题应该描述系统的期望状态，例如“作为管理员，我要删除用户, 而不是收到一个error”，而不是“管理员无法删除用户”。\n当您准备好编码时，从master分支启动一个问题分支。此分支的名称应以问题编号开头，例如\u0026rsquo;15 -require-a-password-to-change-it\u0026rsquo;。\n当你完成代码了或者当你想讨论代码时，你要打开一个合并请求。这是一个在线的地方，用于讨论这次更改，并且审查代码。打开合并请求是手动操作，因为您不是总想合并您推送的新分支，它可能是长期运行的环境或发布分支。如果打开合并请求，但没有将其分配给任何人，则它是一个处于“正在进行（Work In Progress）”状态的合并请求。这些用于讨论某些建议的实现，但尚未准备好纳入master分支中。专家提示：合并请求的标题使用[WIP]或WIP作为开始，以防止合并请求在准备就绪之前被合并了。\n当作者认为代码就绪时，合并请求将分配给审阅者（reviewer）。当审阅者认为代码准备放进在master分支中时，就按下合并按钮。在这种情况下，代码被合并，并生成合并提交，使此事件后来很容易可见。合并请求总是创建一个合并提交，即使当commit可以被添加(added)，但是没有一个提交。这个合并策略在git中称为“no fast-forward”。合并后，特征分支被删除，因为它不再需要。在GitLab中，这种删除动作在合并时，是可选的。\n假设分支被合并，但是在这合并后又发现一个新问题，那就重新打开这个问题。在这种情况下，重用相同的分支名称是没有问题的，因为当合并分支时它被删除。任何时候，每个问题最多只有一个分支。一个特征分支可能解决多个问题。\nLinking and closing issues from merge requests 链接到问题（issue）会在下面这个情况下发生：在提交消息（修复＃14，关闭＃67等）中提及，或从合并请求描述中提及。 合并请求提及问题（issue）的情况，在GitLab中，会在这个issue中，创建一个注解。 并且合并请求会显示这个linked issues。 一旦代码合并到默认分支中，这些问题就会关闭。\n如果你只想参考没有关闭的issue，你也可以提到它：“Duck typing是首选。＃12”。\n如果您有跨多个存储库的问题，最好的办法是为每个存储库创建一个问题，并将所有问题链接到父问题(parent issue)。\nSquashing commits with rebase 使用git，您可以使用交互式rebase（rebase -i）将多个提交压缩成一个并重新排序。在GitLab EE和.com中，您还可以在Web界面合并之前进行rebase。如果您在开发过程中进行了一些小的更改，并希望用单个提交替换它们，或者想要使顺序更具逻辑性，则此功能非常有用。然而，你不应该rebase提交推送到远程服务器。有人可以参考提交或樱桃选择他们。当你rebase时，你改变提交的标识符（SHA-1），这是令人困惑的。如果你这样做，相同的更改将在多个标识符下，这可能会导致很多混乱。如果人们已经审查你的代码，他们将很难仅仅审查自那时以来由你所做的改进，如果你已经rebased 一切修改为一个提交。不要rebase的另一个原因是，你失去了作者信息，也许有人创建了一个合并请求，另一个人推送一个提交，以改善它，第三个合并它。在这种情况下，将所有提交重新映射为一个，以防止其他作者，被正确归因和共享一部分git blame。\n鼓励人们经常提交，并经常推送到远程存储库，以便其他人知道每个人都在做什么。这将导致每个更改的许多提交，这使得历史更难以理解。但是具有稳定的标识符（stable identifiers）的优点胜过这个缺点。为了理解上下文中的变化，可以总是去看合并提交，因为当代码合并到master分支时会将所有提交被分组在一起。\n将特性分支的多个提交合并到主分支后，这更难撤消。如果你将所有的提交压缩成一个你可以刚刚恢复这个提交，但正如我们所指出的，你不应该在提交后重做提交。幸运的是，还原在一段时间以前的合并，是可以用git完成的。但是，这需要对您要恢复的提交，进行一个特定合并提交（specific merge commits）。如果你还原合并，你又改变主意，那么你要恢复这次还原（而不是再次合并），因为git将不允许你再次合并代码。\n能够还原合并（revert a merge）是一个很好的原因，当您手动用\u0026ndash;no-ff选项合并时，始终创建合并提交。当您接受合并请求时，Git管理软件将始终创建合并提交。\nDo not order commits with rebase END "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/git.html",
	"title": "Git Command",
	"tags": ["git", "command"],
	"description": "",
	"content": " git reset \u0026ndash;hard commit_id Git允许我们在版本的历史之间穿梭，使用命令\ngit reset --hard commit_id  去除对　已添加的文件或文件夹　的跟踪 git rm -r --cached -- .idea/  这样呢，文件夹里 .idea/　的修改，git都不跟踪了。\ngit rm -r --cached -- node_modules/  git clone 指定分支 git clone -b test-v1 git@xxx:xxx.git  使用git stash命令保存和恢复进度 使用git stash命令保存和恢复进度\n最近一次提交的 hash 短字符串, 如\u0026rdquo;de34928\u0026rdquo; git rev-parse --short HEAD  ref  git clone 指定分支操作  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-install.html",
	"title": "Gitlab Install",
	"tags": ["gitlab", "install"],
	"description": "",
	"content": " git系列之gitlab安装\nenv 阿里云 - IP: 120.25.204.216 - OS: centos7\nstep sudo firewall-cmd --permanent --add-service=http sudo systemctl reload firewalld  注意这个写法\nsudo EXTERNAL_URL=\u0026quot;http://gitlab.example.com\u0026quot; yum install -y gitlab-ee  修改成 下面这种 方式, 但是, 这样下载会比较慢了\nsudo EXTERNAL_URL=\u0026quot;http://120.25.204.216:7890\u0026quot; yum install -y gitlab-ee  我们用 清华镜像 吧\n[root@jlch_web_001 ~]# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-10.6.2-ce.0.el7.x86_64.rpm --2018-04-12 15:11:25-- https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-10.6.2-ce.0.el7.x86_64.rpm Resolving mirrors.tuna.tsinghua.edu.cn (mirrors.tuna.tsinghua.edu.cn)... 101.6.8.193, 2402:f000:1:408:8100::1 Connecting to mirrors.tuna.tsinghua.edu.cn (mirrors.tuna.tsinghua.edu.cn)|101.6.8.193|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 417757949 (398M) [application/x-redhat-package-manager] Saving to: ‘gitlab-ce-10.6.2-ce.0.el7.x86_64.rpm’ 100%[==================================================================================================================================================================\u0026gt;] 417,757,949 19.1MB/s in 21s 2018-04-12 15:11:46 (18.6 MB/s) - ‘gitlab-ce-10.6.2-ce.0.el7.x86_64.rpm’ saved [417757949/417757949] [root@jlch_web_001 ~]# rpm -ivh gitlab-ce-10.6.2-ce.0.el7.x86_64.rpm warning: gitlab-ce-10.6.2-ce.0.el7.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID f27eab47: NOKEY Preparing... ################################# [100%] Updating / installing... 1:gitlab-ce-10.6.2-ce.0.el7 ################################# [100%] It looks like GitLab has not been configured yet; skipping the upgrade script. *. *. *** *** ***** ***** .****** ******* ******** ******** ,,,,,,,,,***********,,,,,,,,, ,,,,,,,,,,,*********,,,,,,,,,,, .,,,,,,,,,,,*******,,,,,,,,,,,, ,,,,,,,,,*****,,,,,,,,,. ,,,,,,,****,,,,,, .,,,***,,,, ,*,. _______ __ __ __ / ____(_) /_/ / ____ _/ /_ / / __/ / __/ / / __ `/ __ \\ / /_/ / / /_/ /___/ /_/ / /_/ / \\____/_/\\__/_____/\\__,_/_.___/ Thank you for installing GitLab! GitLab was unable to detect a valid hostname for your instance. Please configure a URL for your GitLab instance by setting `external_url` configuration in /etc/gitlab/gitlab.rb file. Then, you can start your GitLab instance by running the following command: sudo gitlab-ctl reconfigure For a comprehensive list of configuration options please see the Omnibus GitLab readme https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md [root@jlch_web_001 ~]#  然后修改IP端口吧\nvim /etc/gitlab/gitlab.rb ### 修改内容为: external_url 'http://120.25.204.216:7890'  然后\nsudo gitlab-ctl reconfigure  等待\ngitlab-ctl restart  FAQ sudo systemctl start postfix  出错了\n启动postfix出错，查看centos中的postfix日志\nmore /var/log/maillog postfix: fatal: parameter inet_interfaces: no local interface found for ::1  修改postfix的配置文件\nvi /etc/postfix/main.cf  发现配置为：\ninet_interfaces = localhost inet_protocols = all  改成：\ninet_interfaces = all inet_protocols = all  重新启动\nsudo systemctl start postfix [root@jlch_web_001 tom]# sudo systemctl status postfix ● postfix.service - Postfix Mail Transport Agent Loaded: loaded (/usr/lib/systemd/system/postfix.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2018-04-12 14:51:04 CST; 4s ago Process: 13058 ExecStart=/usr/sbin/postfix start (code=exited, status=0/SUCCESS) Process: 13054 ExecStartPre=/usr/libexec/postfix/chroot-update (code=exited, status=0/SUCCESS) Process: 13049 ExecStartPre=/usr/libexec/postfix/aliasesdb (code=exited, status=0/SUCCESS) Main PID: 13130 (master) Memory: 3.6M CGroup: /system.slice/postfix.service ├─13130 /usr/libexec/postfix/master -w ├─13131 pickup -l -t unix -u └─13132 qmgr -l -t unix -u Apr 12 14:51:03 jlch_web_001 systemd[1]: Starting Postfix Mail Transport Agent... Apr 12 14:51:03 jlch_web_001 postfix/postfix-script[13128]: starting the Postfix mail system Apr 12 14:51:04 jlch_web_001 postfix/master[13130]: daemon started -- version 2.10.1, configuration /etc/postfix Apr 12 14:51:04 jlch_web_001 systemd[1]: Started Postfix Mail Transport Agent. [root@jlch_web_001 tom]#  ref https://gitlab.com/gitlab-org/gitlab-ce/tree/master - https://about.gitlab.com/installation/#centos-7 - postfix报错postfix: fatal: parameter inet_interfaces: no local interface found for ::1 - centos7安装部署gitlab服务器\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git-from-outside.html",
	"title": "Git From Outside",
	"tags": ["git"],
	"description": "",
	"content": " 从外部复制一个.git文件，如何使用\n问题 有.git 文件　，直接使用，报错如下：\nfatal: '/srv/OpenX.git' does not appear to be a git repository fatal: Could not read from remote repository.  现在有一个新来的.git文件, 如：OpenX.git\n 放到本机的git仓库目录\n[tom@check repositories]$ sudo cp -a OpenX.git/ /srv/  建立新的下传使用目录\n[tom@check repositories]$ cd ../testgit/ [tom@check testgit]$ mkdir testgit2 [tom@check testgit]$ ls OpenXtest testgit2 [tom@check testgit]$ cd testgit2/ [tom@check testgit2]$ git init Initialized empty Git repository in /home/tom/in/testgit/testgit2/.git/  下传pull\n remote报错啦\n[tom@check testgit2]$ git remote add checkgit git@192.168.31.181:/srv/OpenX.git [tom@check testgit2]$ git pull checkgit master git@192.168.31.181's password: fatal: '/srv/OpenX.git' does not appear to be a git repository fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. [tom@check testgit2]$  clone也是会报错哟\n[tom@check testgit2]$ git clone git@192.168.31.181:/srv/OpenX.git Cloning into 'OpenX'... git@192.168.31.181's password: fatal: '/srv/OpenX.git' does not appear to be a git repository fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. [tom@check testgit2]$    解决　 查看文件属性\n[tom@check testgit2]$ ll /srv/ total 0 drwxr-xr-x 7 git git 111 Jan 19 18:13 conan.git drwxr-xr-x 7 git git 111 Jan 11 10:52 crawler.git drwxr-xr-x 7 git git 111 Jan 8 16:19 eastmoney.git drwx------ 7 tom tom 107 Feb 28 08:59 OpenX.git drwxr-xr-x 7 git git 111 Jan 19 11:18 qlw.git drwxr-xr-x 7 git git 111 Jan 6 15:03 sample.git [tom@check testgit2]$  发现OpenX.git 属性不对.\n检查是否安装git,并有git用户。如果没有，则建立git账户和密码 修改 OpenX.git 属性\n[tom@check testgit2]$ sudo chown -R git:git /srv/OpenX.git/ [tom@check testgit2]$ sudo chmod -R 755 /srv/OpenX.git/ [tom@check testgit2]$ ll /srv/ total 0 drwxr-xr-x 7 git git 111 Jan 19 18:13 conan.git drwxr-xr-x 7 git git 111 Jan 11 10:52 crawler.git drwxr-xr-x 7 git git 111 Jan 8 16:19 eastmoney.git drwxr-xr-x 7 git git 107 Feb 28 08:59 OpenX.git drwxr-xr-x 7 git git 111 Jan 19 11:18 qlw.git drwxr-xr-x 7 git git 111 Jan 6 15:03 sample.git [tom@check testgit2]$  验收\n[tom@check testgit2]$ git remote add checkgit git@192.168.31.181:/srv/OpenX.git fatal: remote checkgit already exists. [tom@check testgit2]$ git pull checkgit master git@192.168.31.181's password: remote: Counting objects: 1673, done. remote: Compressing objects: 100% (1637/1637), done. remote: Total 1673 (delta 928), reused 76 (delta 32) Receiving objects: 100% (1673/1673), 6.90 MiB | 7.48 MiB/s, done. Resolving deltas: 100% (928/928), done. From 192.168.31.181:/srv/OpenX * branch master -\u0026gt; FETCH_HEAD [tom@check testgit2]$ ls lib OpenInfo OpenQuote [tom@check testgit2]$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/environment-about-it.html",
	"title": "Environment About It",
	"tags": ["env"],
	"description": "",
	"content": " 生产环境、测试环境、开发环境、 https://my.oschina.net/sancuo/blog/214904\n开发环境 production environment;\n测试环境 testing environment;\n开发环境 development environment;\n开发环境：开发环境是程序猿们专门用于开发的服务器，配置可以比较随意， 为了开发调试方便，一般打开全部错误报告。 测试环境：一般是克隆一份生产环境的配置，一个程序在测试环境工作不正常，那么肯定不能把它发布到生产机上。 生产环境：是值正式提供对外服务的，一般会关掉错误报告，打开错误日志。  三个环境也可以说是系统开发的三个阶段：开发-\u0026gt;测试-\u0026gt;上线，其中生产环境也就是通常说的真实环境。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-registry-install-for-jlch.html",
	"title": "Docker Registry Install For Jlch",
	"tags": ["docker", "registry", "install"],
	"description": "",
	"content": " docker之registry搭建(当然更建议使用Harbor)\nreference  http://www.zimug.com/317.html?utm_source=tuicool\u0026amp;utm_medium=referral docker-registry  env docker版本大于1.6.0(docker -v)\n机器3台: * registry server , IP: 192.168.31.240 * registry client a(docker push), IP: 10.10.12.18 * registry client b(docker pull), IP: 10.10.13.10\nstep 1. 创建registry server端 下载镜像\ndocker pull registry:2  生成自签名证书\ncd ~/;mkdir registry \u0026amp;\u0026amp; cd registry \u0026amp;\u0026amp; mkdir certs \u0026amp;\u0026amp; cd certs;openssl req -x509 -days 3650 -subj '/CN=reg.jlch.com/' -nodes -newkey rsa:2048 -keyout registry.key -out registry.crt;  生成用户和密码\ncd ~/registry\u0026amp;\u0026amp; mkdir auth;docker run --entrypoint htpasswd registry:2 -Bbn zimug zimug_password \u0026gt; auth/htpasswd;  用户：zimug 密码：zimug_password 可随便填写自己想填写的\n启动registry server\n脚本 start_registry.sh 放在~/registry目录下\ndocker run -d -p 5000:5000 --restart=always --name registry \\ -v `pwd`/auth:/auth \\ -e \u0026quot;REGISTRY_AUTH=htpasswd\u0026quot; \\ -e \u0026quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\u0026quot; \\ -e \u0026quot;REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd\u0026quot; \\ -v `pwd`/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key \\ -v ~/data/registry2:/var/lib/registry \\ registry:2  确认registry server是UP状态，docker ps -a | grep registry\n2. 配置docker server端 同registry server在同一台服务器上配置：\n创建证书目录(没有此目录自己创建，注意端口号)\nsudo mkdir -p /etc/docker/certs.d/reg.jlch.com:5000  下载证书\nsudo cp ~/registry/certs/registry.crt /etc/docker/certs.d/reg.jlch.com:5000  域名解析,如果有DNS解析无需做此步骤（registry-server-ip=192.168.31.240）\nsudo echo 192.168.31.240 reg.jlch.com \u0026gt;\u0026gt; /etc/hosts  3. 配置 registry client a 和 registry client b 其他主机(registry client a 和 registry client b)配置：\n创建证书目录(没有此目录自己创建，注意端口号)\nsudo mkdir -p /etc/docker/certs.d/reg.jlch.com:5000  下载证书\nsudo scp -r tom@192.168.31.240:~/registry/certs/registry.crt /etc/docker/certs.d/reg.jlch.com:5000  域名解析,如果有DNS解析无需做此步骤（registry-server-ip=192.168.31.240）\necho 192.168.31.240 reg.jlch.com \u0026gt;\u0026gt; /etc/hosts  验证测试\n登陆(注意加端口号)\ndocker login reg.jlch.com:5000  输入用户zimug，密码zimug_password以及邮箱\n完成 docker push 更改镜像tag\ndocker tag busybox reg.jlch.com:5000/busybox:1.0  push镜像\ndocker push reg.jlch.com:5000/busybox:1.0  完成 docker pull pull镜像\ndocker pull reg.jlch.com:5000/busybox:1.0  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-panubo2-base-docker.html",
	"title": "Mariadb Galera Panubo2 Base Docker",
	"tags": ["mariadb", "panubo", "galera", "docker"],
	"description": "",
	"content": " docker之docker-mariadb-galera(panubo版)(2017-02)\nref  https://github.com/panubo/docker-mariadb-galera  env  node0, 10.10.13.110, primary node1, 10.10.15.240 node2, 10.10.12.13(这一台暂时没用上)  step  拉取 (panubo版)git 代码, 取 image  三台机器, 各运行一下\nmkdir ~/docker \u0026amp;\u0026amp; cd ~/docker \u0026amp;\u0026amp; git clone https://github.com/panubo/docker-mariadb-galera \u0026amp;\u0026amp; cd docker-mariadb-galera/ \u0026amp;\u0026amp; docker pull panubo/mariadb-galera   设置环境变量  在node0上:\ncat \u0026gt;\u0026gt; ~/.bashrc \u0026lt;\u0026lt; EOF WSREP_NODE_ADDRESS=10.10.13.110 WSREP_CLUSTER_ADDRESS=gcomm://10.10.13.110:4567,10.10.12.13:4567,10.10.15.240:4567 WSREP_CLUSTER_NAME=my_wsrep_cluster WSREP_NODE_NAME=mariadb-node-0 EOF source ~/.bashrc  在node1上:\ncat \u0026gt;\u0026gt; ~/.bashrc \u0026lt;\u0026lt; EOF WSREP_NODE_ADDRESS=10.10.15.240 WSREP_CLUSTER_ADDRESS=gcomm://10.10.13.110:4567,10.10.12.13:4567,10.10.15.240:4567 WSREP_CLUSTER_NAME=my_wsrep_cluster WSREP_NODE_NAME=mariadb-node-1 EOF source ~/.bashrc  在node2上:\ncat \u0026gt;\u0026gt; ~/.bashrc \u0026lt;\u0026lt; EOF WSREP_NODE_ADDRESS=10.10.12.13 WSREP_CLUSTER_ADDRESS=gcomm://10.10.13.110:4567,10.10.12.13:4567,10.10.15.240:4567 WSREP_CLUSTER_NAME=my_wsrep_cluster WSREP_NODE_NAME=mariadb-node-2 EOF source ~/.bashrc   打开端口  在每一台机器上:\nsudo firewall-cmd --permanent --add-port=3306/tcp; sudo firewall-cmd --permanent --add-port=4567/udp; sudo firewall-cmd --permanent --add-port=4567/tcp; sudo firewall-cmd --permanent --add-port=4568/tcp; sudo firewall-cmd --permanent --add-port=4444/tcp; sudo firewall-cmd --reload; sudo firewall-cmd --permanent --list-port;   (这一步, 可以不做)Running Garbd  在 node0 上:\ndocker run -d --net host --name galera-garbd \\ -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS \\ panubo/mariadb-galera \\ garbd   运行container, 创建新的数据库目录下  在 node0 上:\nsudo mkdir -p /mnt/data/galera.service/mysql/mysql  没有道理了哈, 下面这个成功了, 上面几个都没有成功..\ndocker run -d --net host --name galera -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS -e MYSQL_ROOT_PASSWORD=like1123 -p 3306:3306 -p 4567:4567/udp -p 4567-4568:4567-4568 -p 4444:4444 -v /mnt/data/galera.service/mysql:/var/lib/mysql:Z panubo/mariadb-galera mysqld --wsrep-new-cluster  这里设置了 , mysql的root用户的密码为like1123\n在node1上:\nsudo mkdir -p /mnt/data/galera.service/mysql/mysql docker run -d --net host --name galera -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS \\ -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS \\ -p 3306:3306 \\ -p 4567:4567/udp \\ -p 4567-4568:4567-4568 \\ -p 4444:4444 \\ -v /mnt/data/galera.service/mysql:/var/lib/mysql:Z \\ panubo/mariadb-galera \\ mysqld   连接到 已有的数据库目录/data/mariadb/mysql  下面, 我们连接到 已有的数据库目录/data/mariadb/mysql:\n准备工作, 每台机, 关闭, 删除container, 重新启动 docker.service :\ndocker stop 3b8adb3825e1 \u0026amp;\u0026amp; docker rm 3b8adb3825e1 sudo rm -rf /mnt/data/galera.service/mysql sudo systemctl restart docker.service \u0026amp;\u0026amp; sudo systemctl status docker.service  现在开始:\n创建 数据库的数据目录, 如果有了, 就不用创建了, 只要把下面的目录修改成 数据目录 就可以了.\n在node0上:\n因为, 我们这里之前有过 数据库(但是, 不是docker下运行的), 数据库的数据目录为/data/mariadb/mysql, 所以这里直接用了\ndocker run -d --net host --name galera -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS -e MYSQL_ROOT_PASSWORD=like1123 -p 3306:3306 -p 4567:4567/udp -p 4567-4568:4567-4568 -p 4444:4444 -v /data/mariadb/mysql:/var/lib/mysql:Z panubo/mariadb-galera mysqld --wsrep-new-cluster  在node1上:\ndocker run -d --net host --name galera -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS -p 3306:3306 -p 4567:4567/udp -p 4567-4568:4567-4568 -p 4444:4444 -v /data/mariadb/mysql:/var/lib/mysql:Z panubo/mariadb-galera mysqld   添加 node2 进集群  确保一下, 数据库的数据目录为/data/mariadb/mysql\n方式与 node1 一样, 直接添加, 就可以了.\n在 node2 上:\ndocker run -d --net host --name galera -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS -p 3306:3306 -p 4567:4567/udp -p 4567-4568:4567-4568 -p 4444:4444 -v /data/mariadb/mysql:/var/lib/mysql:Z panubo/mariadb-galera mysqld   验收:  验收1:\n在 node0, 运行 docker exec -ti node11-container-sha1 mysql -p -e 'show status like \u0026quot;wsrep_cluster_size\u0026quot;', 查看 集群的节点数.\n[tom@mariadb-node-1 ~]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0c6fa26b49a panubo/mariadb-galera \u0026quot;/galera-entrypoin...\u0026quot; 41 hours ago Up 7 hours galera [tom@mariadb-node-1 ~]$ docker exec -ti c0c6fa26b49a mysql -p -e 'show status like \u0026quot;wsrep_cluster_size\u0026quot;' Enter password: +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | wsrep_cluster_size | 2 | +--------------------+-------+ [tom@mariadb-node-1 ~]$  验收2:\n去 node0, 进入container, 新建立一个库,\n[tom@mariadb-node-0 ~]$ docker exec -it 1de01ad721ad /bin/bash root@mariadb-node-0:/# mysql -u root -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 5 Server version: 10.1.21-MariaDB-1~jessie mariadb.org binary distribution Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]\u0026gt; CREATE DATABASE IF NOT EXISTS my_db default character set utf8 COLLATE utf8_general_ci;  去 node1, 进入container, 检查, 是否有\nshow databases;  或者直接这样:\ncontainer_sha1=c0c6fa26b49a # 这个是container sha1 字符串 docker exec -ti $container_sha1 mysql -p -e 'CREATE DATABASE IF NOT EXISTS my_db default character set utf8 COLLATE utf8_general_ci;' docker exec -ti $container_sha1 mysql -p -e 'show databases;'  ok, 现在说明, galera已经建立好了.\n 怎么让其它机器访问 galera  登陆其它机器\nmysql -h 10.10.12.17 -u root -pmysql_root_password\n这样, 就可以访问到 node0 上的mysql 啦.\n Q\u0026amp;A  Q: 把 node1 的container docker restart , 是否 mysql 正常 A: 正常\nQ: 把 node0 的container docker restart , 是否mysql 正常 A: container, 不正常. 重启后, 起不来了. 原因: 可能是因为, node0, 的安装过程中, 有--wsrep-new-clusterr参数, 重启, 则意味着, 在原来的文件夹上建立一个新的--wsrep-new-clusterr(相同的directory, 当然是不允许的), 所以报错. 如果不小心, 重启了 node0上的主container, 那怎么办? * 方法1(适用于, 不要数据的情况)\n先删除数据, 然后重新启动 docker.service, 就可以了. * 方法2(适用于, 已有数据, 且要保留数据的情况)\nTODO\n 尝试 TODO  Q: 把端口号, 分别设置成node0:3306, node1:4406, node0:4406, node1:3306, node0:4406, node1:4406, 会有什么效果 A: TODO\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vscode/vscode-extensions.html",
	"title": "Vscode Extensions",
	"tags": ["vscode", "extensions"],
	"description": "",
	"content": "用VS Code打造最佳Markdown编辑器\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-registry-install.html",
	"title": "Docker Registry Install",
	"tags": ["docker", "registry", "install"],
	"description": "",
	"content": " docker之registry搭建(当然更建议使用Harbor)\nreference  http://www.zimug.com/317.html?utm_source=tuicool\u0026amp;utm_medium=referral\n docker-registry\n  env docker版本大于1.6.0(docker -v)\n机器3台: * registry server , IP: 10.10.12.17 * registry client a(docker push), IP: 10.10.12.18 * registry client b(docker pull), IP: 10.10.13.10\nstep 1. 创建registry server端 下载镜像\ndocker pull registry:2  生成自签名证书\ncd ~/;mkdir registry \u0026amp;\u0026amp; cd registry \u0026amp;\u0026amp; mkdir certs \u0026amp;\u0026amp; cd certs;openssl req -x509 -days 3650 -subj '/CN=reg.zimug.com/' -nodes -newkey rsa:2048 -keyout registry.key -out registry.crt;  生成用户和密码\ncd ~/registry\u0026amp;\u0026amp; mkdir auth;docker run --entrypoint htpasswd registry:2 -Bbn zimug zimug_password \u0026gt; auth/htpasswd;  用户：zimug 密码：zimug_password 可随便填写自己想填写的\n启动registry server\n脚本 start_registry.sh 放在~/registry目录下\ndocker run -d -p 5000:5000 --restart=always --name registry \\ -v `pwd`/auth:/auth \\ -e \u0026quot;REGISTRY_AUTH=htpasswd\u0026quot; \\ -e \u0026quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\u0026quot; \\ -e \u0026quot;REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd\u0026quot; \\ -v `pwd`/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key \\ -v ~/data/registry2:/var/lib/registry \\ registry:2  确认registry server是UP状态，docker ps -a | grep registry\n2. 配置docker server端 同registry server在同一台服务器上配置：\n创建证书目录(没有此目录自己创建，注意端口号)\nsudo mkdir -p /etc/docker/certs.d/reg.zimug.com:5000  下载证书\nsudo cp ~/registry/certs/registry.crt /etc/docker/certs.d/reg.zimug.com:5000  域名解析,如果有DNS解析无需做此步骤（registry-server-ip=10.10.12.17）\nsudo echo 10.10.12.17 reg.zimug.com \u0026gt;\u0026gt; /etc/hosts  3. 配置 registry client a 和 registry client b 其他主机(registry client a 和 registry client b)配置：\n创建证书目录(没有此目录自己创建，注意端口号)\nsudo mkdir -p /etc/docker/certs.d/reg.zimug.com:5000  下载证书\nsudo scp -r zimug@10.10.12.17:~/registry/certs/registry.crt /etc/docker/certs.d/reg.zimug.com:5000  域名解析,如果有DNS解析无需做此步骤（registry-server-ip=10.10.12.17）\necho 10.10.12.17 reg.zimug.com \u0026gt;\u0026gt; /etc/hosts  验证测试\n登陆(注意加端口号)\ndocker login reg.zimug.com:5000  输入用户zimug，密码zimug_password以及邮箱\n完成 docker push 更改镜像tag\ndocker tag busybox reg.zimug.com:5000/busybox:1.0  push镜像\ndocker push reg.zimug.com:5000/busybox:1.0  完成 docker pull pull镜像\ndocker pull reg.zimug.com:5000/busybox:1.0  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-base-docker-coreos.html",
	"title": "Mariadb Galera Base Docker Coreos",
	"tags": ["mariadb", "panubo", "coreos", "docker"],
	"description": "",
	"content": " MariaDB Galera cluster running on CoreOS using the official Docker images\nenv Coreos + any public cloud (Azure, AWS, Google, etc)\nstep 开端口:\nsudo firewall-cmd --permanent --add-port=4567/udp; sudo firewall-cmd --permanent --add-port=4567/tcp; sudo firewall-cmd --permanent --add-port=4568/tcp; sudo firewall-cmd --permanent --add-port=4444/tcp; sudo firewall-cmd --permanent --add-port=3306/tcp; sudo firewall-cmd --reload; sudo firewall-cmd --permanent --list-port  检查mysql 是不是起来了:\nsudo yum install -y telnet telnet 127.0.0.1 22 Telnet 127.0.0.1 3306\n检查日志\ndocker logs -f mariadb-container-0\n单独启动\ndocker run \u0026ndash;name mariadb-container-0 -d -v /opt/mysql.conf.d:/etc/mysql/conf.d -v /data/mariadb_galera/data:/var/lib/mysql -e MYSQL_INITDB_SKIP_TZINFO=yes -e MYSQL_ROOT_PASSWORD=my-secret-pw -p 3306:3306 -p 4567:4567/udp -p 4567-4568:4567-4568 -p 4444:4444 mariadb:10.1 \u0026ndash;wsrep-new-cluster \u0026ndash;wsrep_node_address=10.10.12.17\ndocker run \u0026ndash;name mariadb-container-1 -d -v /opt/mysql.conf.d:/etc/mysql/conf.d -v /data/mariadb_galera/data:/var/lib/mysql -p 3306:3306 -p 4567:4567/udp -p 4567-4568:4567-4568 -p 4444:4444 mariadb:10.1 \u0026ndash;wsrep_node_address=10.10.12.18\nref  https://github.com/EgoAleSum/mariadb-cluster\n http://withblue.ink/2016/03/09/galera-cluster-mariadb-coreos-and-docker-part-1.html\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-panubo-base-docker.html",
	"title": "Mariadb Galera Panubo Base Docker",
	"tags": ["mariadb", "panubo", "galera", "docker"],
	"description": "",
	"content": " docker之docker-mariadb-galera(panubo版)\nenv  node0, 10.10.12.17 node1, 10.10.12.18 node2, 10.10.13.10(这一台暂时没用上)  step  拉取 (panubo版)git 代码\nmkdir ~/docker \u0026amp;\u0026amp; cd ~/docker \u0026amp;\u0026amp; git clone https://github.com/panubo/docker-mariadb-galera \u0026amp;\u0026amp; cd docker-mariadb-galera/\n 设置环境变量\n  在node0上:\ncat \u0026gt;\u0026gt; ~/.bashrc \u0026lt;\u0026lt; EOF WSREP_NODE_ADDRESS=10.10.12.17 WSREP_CLUSTER_ADDRESS=gcomm://10.10.12.17:4567,10.10.12.18:4567,10.10.13.10:4567 EOF source ~/.bashrc  在node1上:\ncat \u0026gt;\u0026gt; ~/.bashrc \u0026lt;\u0026lt; EOF WSREP_NODE_ADDRESS=10.10.12.18 WSREP_CLUSTER_ADDRESS=gcomm://10.10.12.17:4567,10.10.12.18:4567,10.10.13.10:4567 EOF source ~/.bashrc   Running Garbd  在 node0 上:\ndocker run -d --net host --name galera-garbd \\ -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS \\ panubo/mariadb-galera \\ garbd   运行container  在node0上:\n创建 数据库的数据目录, 如果有了, 就不用创建了, 只要把下面的目录修改成 数据目录 就可以了.\nmkdir -p /mnt/data/galera.service/mysql/mysql docker run -d --net host --name galera \\ -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS \\ -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS \\ -e MYSQL_ROOT_PASSWORD={{mysql_root_password}} \\ -p 3306:3306 \\ -p 4567:4567/udp \\ -p 4567-4568:4567-4568 \\ -p 4444:4444 \\ -v /mnt/data/galera.service/mysql:/var/lib/mysql:Z \\ panubo/mariadb-galera \\ mysqld \\ --wsrep-new-clusterr  在node1上:\nmkdir -p /mnt/data/galera.service/mysql/mysql docker run -d --net host --name galera \\ -e WSREP_NODE_ADDRESS=$WSREP_NODE_ADDRESS \\ -e WSREP_CLUSTER_ADDRESS=$WSREP_CLUSTER_ADDRESS \\ -p 3306:3306 \\ -p 4567:4567/udp \\ -p 4567-4568:4567-4568 \\ -p 4444:4444 \\ -v /mnt/data/galera.service/mysql:/var/lib/mysql:Z \\ panubo/mariadb-galera \\ mysqld   验收:  验收1:\n在 node0, 运行 docker exec -ti node11-container-sha1 mysql -p -e 'show status like \u0026quot;wsrep_cluster_size\u0026quot;', 查看 集群的节点数.\n[tom@mariadb-node-1 ~]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0c6fa26b49a panubo/mariadb-galera \u0026quot;/galera-entrypoin...\u0026quot; 41 hours ago Up 7 hours galera [tom@mariadb-node-1 ~]$ docker exec -ti c0c6fa26b49a mysql -p -e 'show status like \u0026quot;wsrep_cluster_size\u0026quot;' Enter password: +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | wsrep_cluster_size | 2 | +--------------------+-------+ [tom@mariadb-node-1 ~]$  验收2:\n去 node0, 进入container, 新建立一个库,\n[tom@mariadb-node-0 ~]$ docker exec -it 1de01ad721ad /bin/bash root@mariadb-node-0:/# mysql -u root -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 5 Server version: 10.1.21-MariaDB-1~jessie mariadb.org binary distribution Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]\u0026gt; CREATE DATABASE IF NOT EXISTS my_db default character set utf8 COLLATE utf8_general_ci;  去 node1, 进入container, 检查, 是否有\nshow databases;  ok, 现在说明, galera已经建立好了.\n 怎么让其它机器访问 galera  登陆其它机器\nmysql -h 10.10.12.17 -u root -pmysql_root_password\n这样, 就可以访问到 node0 上的mysql 啦.\n 尝试 TODO  Q: 把 node1 的container docker restart , 是否 mysql 正常 A: 正常\nQ: 把 node0 的container docker restart , 是否mysql 正常 A: container, 不正常. 重启后, 起不来了. 原因: 可能是因为, node0, 的安装过程中, 有--wsrep-new-clusterr参数, 重启, 则意味着, 在原来的文件夹上建立一个新的--wsrep-new-clusterr(相同的directory, 当然是不允许的), 所以报错. 如果不小心, 重启了 node0上的主container, 那怎么办? 方法1(适用于, 不要数据的情况)\nQ: 把端口号, 分别设置成node0:3306, node1:4406, node0:4406, node1:3306, node0:4406, node1:4406, 会有什么效果 A: TODO\nref  https://github.com/panubo/docker-mariadb-galera  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb-galera-base-docker.html",
	"title": "Mariadb Galera Base Docker",
	"tags": ["mariadb", "docker"],
	"description": "",
	"content": " docker之docker-mariadb-galera各种策略汇总\n使用 FROM mariadb:10.1 的几个docker  https://github.com/EgoAleSum/mariadb-cluster  http://withblue.ink/2016/03/09/galera-cluster-mariadb-coreos-and-docker-part-1.html\nCoreos + any public cloud (Azure, AWS, Google, etc)\n https://github.com/dial-once/docker-mariadb-galera  使用 Docker Cloud/Docker Compose YML\n https://github.com/toughIQ/docker-mariadb-cluster  Swarm\nConsider this a POC and not a production ready system!\nBuilt for use with Docker 1.12.1+ in Swarm Mode\n https://github.com/panubo/docker-mariadb-galera  Galera Arbitrator (aka garbd)\nend "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-install-base-centos.html",
	"title": "Docker Install Base Centos",
	"tags": ["docker", "install", "centos"],
	"description": "",
	"content": " practice [tom@mysql1 ~]$ sudo tee /etc/yum.repos.d/docker.repo \u0026lt;\u0026lt;-'EOF' \u0026gt; [dockerrepo] \u0026gt; name=Docker Repository \u0026gt; baseurl=https://yum.dockerproject.org/repo/main/centos/7/ \u0026gt; enabled=1 \u0026gt; gpgcheck=1 \u0026gt; gpgkey=https://yum.dockerproject.org/gpg \u0026gt; EOF [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/7/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg [tom@mysql1 ~]$ sudo yum install docker-engine -y ... Installed: docker-engine.x86_64 0:1.12.3-1.el7.centos Dependency Installed: docker-engine-selinux.noarch 0:1.12.3-1.el7.centos Complete! [tom@mysql1 ~]$ sudo systemctl enable docker.service Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. [tom@mysql1 ~]$ sudo systemctl start docker [tom@mysql1 ~]$ sudo docker run --rm hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world c04b14da8d14: Pull complete Digest: sha256:0256e8a36e2070f7bf2d0b0763dbabdd67798512411de4cdcf9431a1feb60fd9 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker Hub account: https://hub.docker.com For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ [tom@mysql1 ~]$ sudo groupadd docker groupadd: group 'docker' already exists [tom@mysql1 ~]$ sudo usermod -aG docker tom  ctrl + v [tom@mysql1 ~]$ sudo tee /etc/yum.repos.d/docker.repo \u0026lt;\u0026lt;-'EOF' \u0026gt; [dockerrepo] \u0026gt; name=Docker Repository \u0026gt; baseurl=https://yum.dockerproject.org/repo/main/centos/7/ \u0026gt; enabled=1 \u0026gt; gpgcheck=1 \u0026gt; gpgkey=https://yum.dockerproject.org/gpg \u0026gt; EOF [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/7/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg [tom@mysql1 ~]$ sudo yum install docker-engine -y [tom@mysql1 ~]$ sudo systemctl enable docker.service [tom@mysql1 ~]$ sudo systemctl start docker [tom@mysql1 ~]$ sudo docker run --rm hello-world [tom@mysql1 ~]$ sudo groupadd docker [tom@mysql1 ~]$ sudo usermod -aG docker tom  ref  https://docs.docker.com/engine/installation/linux/centos/  method2 确保能够上网 sudo vi /etc/resolv.conf ## 效果 [tom@1217 ~]$ cat /etc/resolv.conf # Generated by NetworkManager nameserver 202.96.134.133 nameserver 114.114.114.114 nameserver 8.8.8.8  安装 sudo yum install -y yum-utils \u0026amp;\u0026amp; sudo yum-config-manager --add-repo https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo \u0026amp;\u0026amp; sudo yum makecache fast \u0026amp;\u0026amp; sudo yum -y install docker-engine -y  启动服务, 把tom加入组 sudo systemctl start docker.service \u0026amp;\u0026amp; sudo systemctl enable docker.service \u0026amp;\u0026amp; sudo docker run hello-world \u0026amp;\u0026amp; sudo usermod -aG docker tom \u0026amp;\u0026amp; exit  重新登陆 docker run hello-world  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox/virtualbox-install-ubuntu-desktop.html",
	"title": "Virtualbox Install Ubuntu Desktop",
	"tags": ["virtualbox", "ubuntu"],
	"description": "",
	"content": " 在 ubuntu desktop 下安装virtualbox\nenv 在 ubuntu desktop(硬盘9)中安装 virtualbox 总是不能启动\nstep tom@ud-3-1:~$ which VirtualBox /usr/bin/VirtualBox  看一下启动文件\ntom@ud-3-1:~$ ll /usr/bin/VirtualBox lrwxrwxrwx 1 root root 4 3月 16 2017 /usr/bin/VirtualBox -\u0026gt; VBox* tom@ud-3-1:~$ ll /usr/bin/VBox -rwxr-xr-x 1 root root 4589 3月 16 2017 /usr/bin/VBox* tom@ud-3-1:~$ VirtualBox WARNING: The vboxdrv kernel module is not loaded. Either there is no module available for the current kernel (4.10.0-28-generic) or it failed to load. Please recompile the kernel module and install it by sudo /sbin/vboxconfig You will not be able to start VMs until this problem is fixed. VirtualBox: Error -10 in SUPR3HardenedMain! VirtualBox: Effective UID is not root (euid=1000 egid=1000 uid=1000 gid=1000) VirtualBox: Tip! It may help to reinstall VirtualBox. tom@ud-3-1:~$ sudo chmod 4711 /usr/lib/virtualbox/VirtualBox tom@ud-3-1:~$ VirtualBox WARNING: The vboxdrv kernel module is not loaded. Either there is no module available for the current kernel (4.10.0-28-generic) or it failed to load. Please recompile the kernel module and install it by sudo /sbin/vboxconfig You will not be able to start VMs until this problem is fixed. VirtualBox: supR3HardenedMainGetTrustedMain: dlopen(\u0026quot;/usr/lib/virtualbox/VirtualBox.so\u0026quot;,) failed: libQt5X11Extras.so.5: cannot open shared object file: No such file or directory  好像问题转到了libQt5X11Extras.so.5这样的软件依赖上去了, 那么百度吧\ntom@ud-3-1:~$ ls /usr/lib/virtualbox/VirtualBox.so /usr/lib/virtualbox/VirtualBox.so  安装依赖\ntom@ud-3-1:~$ sudo apt-get install libqt5x11extras5 libsdl1.2debian Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: libqt5x11extras5 libsdl1.2debian 0 upgraded, 2 newly installed, 0 to remove and 369 not upgraded. 2 not fully installed or removed. Need to get 175 kB of archives. After this operation, 519 kB of additional disk space will be used. Get:1 http://mirrors.aliyun.com/ubuntu xenial/universe amd64 libqt5x11extras5 amd64 5.5.1-3build1 [7,876 B] Get:2 http://mirrors.aliyun.com/ubuntu xenial/main amd64 libsdl1.2debian amd64 1.2.15+dfsg1-3 [168 kB] Fetched 175 kB in 5s (33.6 kB/s) Selecting previously unselected package libqt5x11extras5:amd64. (Reading database ... 179737 files and directories currently installed.) Preparing to unpack .../libqt5x11extras5_5.5.1-3build1_amd64.deb ... Unpacking libqt5x11extras5:amd64 (5.5.1-3build1) ... Selecting previously unselected package libsdl1.2debian:amd64. Preparing to unpack .../libsdl1.2debian_1.2.15+dfsg1-3_amd64.deb ... Unpacking libsdl1.2debian:amd64 (1.2.15+dfsg1-3) ... Processing triggers for libc-bin (2.23-0ubuntu9) ... Setting up libqt5x11extras5:amd64 (5.5.1-3build1) ... Setting up libsdl1.2debian:amd64 (1.2.15+dfsg1-3) ... Setting up virtualbox-5.1 (5.1.18-114002~Ubuntu~xenial) ... Adding group `vboxusers' (GID 129) ... Done.  启动成功\nref  http://blog.chinaunix.net/uid-20680966-id-5031178.html http://blog.csdn.net/ipsecvpn/article/details/52175279  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-install-ab-httpd-tools.html",
	"title": "Linux Install Ab Httpd Tools",
	"tags": ["linux", "ab", "httpd-tools"],
	"description": "",
	"content": " env 长城证券 压力测试 要安装 ab\nstep 离线安装 下载\n httpd-tools libapr-1.so.0 libaprutil-1.so.0  安装\nrpm -ivh *.rpm which ab  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/project-ok.html",
	"title": "Project Ok",
	"tags": ["project"],
	"description": "",
	"content": "project 必须有以下内容\n 文件  需求文档 技术文档 开发文档 测试文档 验收文件\n 图  流程图 脑图\n 其它  trello git docker README 笔记\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-change-disklabel.html",
	"title": "Linux Change Disklabel",
	"tags": ["linux", "parted"],
	"description": "",
	"content": " parted 來手動改變硬碟為 GPT(或msdos等) [anaconda root@localhost /]# parted /dev/sda GUN Parted 2.1 Using /dev/sda Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) mklabel New disk label type?gpt Warning: The existing disk label on /dev/sda will be destroyed and all data on this disk will be lost. Do you want to continue? Yes/No?Yes (parted) q Information: You may need to update /etc/fstab.  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb/mongodb-replace.html",
	"title": "Mongodb Replace",
	"tags": ["mongodb"],
	"description": "",
	"content": " env jlch\n20180228, 江南嘉捷601313 变更为 三六零601360\nstep testrs:PRIMARY\u0026gt; db.self_stock.find({\u0026quot;groups._sort\u0026quot;:/601313.SH/}) { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t4ipFn59N9tmGQjW1IB0d9M\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;600696.SH|601313.SH|000023.SZ|002416.SZ|002180.SZ|002715.SZ|300104.SZ|002070.SZ|002455.SZ|399001.SZ|000001.SH|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;002416.SZ\u0026quot;, \u0026quot;002180.SZ\u0026quot;, \u0026quot;002715.SZ\u0026quot;, \u0026quot;300104.SZ\u0026quot;, \u0026quot;002070.SZ\u0026quot;, \u0026quot;002455.SZ\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;000001.SH\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;000023.SZ\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;600696.SH\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t581mOc9_CslG6-7KzI2958\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;000546.SZ|601313.SH|600367.SH|601890.SH|600311.SH|002447.SZ|399001.SZ|000001.SH|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000546.SZ\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;600367.SH\u0026quot;, \u0026quot;601890.SH\u0026quot;, \u0026quot;600311.SH\u0026quot;, \u0026quot;002447.SZ\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;000001.SH\u0026quot;, \u0026quot;399006.SZ\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;test@jiaolongchuhai.com\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;000001.SZ|300136.SZ|000928.SZ|002008.SZ|002339.SZ|002375.SZ|002529.SZ|002545.SZ|300004.SZ|300024.SZ|300210.SZ|300220.SZ|300221.SZ|300227.SZ|300337.SZ|300521.SZ|600466.SH|600765.SH|601313.SH|000413.SZ|000536.SZ|002189.SZ|002217.SZ|002273.SZ|300256.SZ|300433.SZ|300503.SZ|300508.SZ|600207.SH|600552.SH|600666.SH|000635.SZ|000890.SZ|002149.SZ|002297.SZ|300034.SZ|600206.SH|600618.SH|601137.SH|000401.SZ|000539.SZ|000601.SZ|000767.SZ|000825.SZ|000877.SZ|000912.SZ|000930.SZ|000932.SZ|002006.SZ|002109.SZ|002234.SZ|600010.SH|600011.SH|600022.SH|600027.SH|600096.SH|600160.SH|600282.SH|600310.SH|600348.SH|600396.SH|600423.SH|600438.SH|600449.SH|600509.SH|600569.SH|600578.SH|600585.SH|600636.SH|600720.SH|600795.SH|600808.SH|600810.SH|600863.SH|601005.SH|601857.SH|601991.SH|000001.SH|399001.SZ|399006.SZ|600039.SH|601766.SH|600971.SH|601398.SH\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;600039.SH\u0026quot;, \u0026quot;601766.SH\u0026quot;, \u0026quot;600971.SH\u0026quot;, \u0026quot;601398.SH\u0026quot;, \u0026quot;000928.SZ\u0026quot;, \u0026quot;002008.SZ\u0026quot;, \u0026quot;002339.SZ\u0026quot;, \u0026quot;002375.SZ\u0026quot;, \u0026quot;002529.SZ\u0026quot;, \u0026quot;002545.SZ\u0026quot;, \u0026quot;300004.SZ\u0026quot;, \u0026quot;300024.SZ\u0026quot;, \u0026quot;300210.SZ\u0026quot;, \u0026quot;300220.SZ\u0026quot;, \u0026quot;300221.SZ\u0026quot;, \u0026quot;300227.SZ\u0026quot;, \u0026quot;300337.SZ\u0026quot;, \u0026quot;300521.SZ\u0026quot;, \u0026quot;600466.SH\u0026quot;, \u0026quot;600765.SH\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;000413.SZ\u0026quot;, \u0026quot;000536.SZ\u0026quot;, \u0026quot;002189.SZ\u0026quot;, \u0026quot;002217.SZ\u0026quot;, \u0026quot;002273.SZ\u0026quot;, \u0026quot;300256.SZ\u0026quot;, \u0026quot;300433.SZ\u0026quot;, \u0026quot;300503.SZ\u0026quot;, \u0026quot;300508.SZ\u0026quot;, \u0026quot;600207.SH\u0026quot;, \u0026quot;600552.SH\u0026quot;, \u0026quot;600666.SH\u0026quot;, \u0026quot;000635.SZ\u0026quot;, \u0026quot;000890.SZ\u0026quot;, \u0026quot;002149.SZ\u0026quot;, \u0026quot;002297.SZ\u0026quot;, \u0026quot;300034.SZ\u0026quot;, \u0026quot;600206.SH\u0026quot;, \u0026quot;600618.SH\u0026quot;, \u0026quot;601137.SH\u0026quot;, \u0026quot;000401.SZ\u0026quot;, \u0026quot;000539.SZ\u0026quot;, \u0026quot;000601.SZ\u0026quot;, \u0026quot;000767.SZ\u0026quot;, \u0026quot;000825.SZ\u0026quot;, \u0026quot;000877.SZ\u0026quot;, \u0026quot;000912.SZ\u0026quot;, \u0026quot;000930.SZ\u0026quot;, \u0026quot;000932.SZ\u0026quot;, \u0026quot;002006.SZ\u0026quot;, \u0026quot;002109.SZ\u0026quot;, \u0026quot;002234.SZ\u0026quot;, \u0026quot;600010.SH\u0026quot;, \u0026quot;600011.SH\u0026quot;, \u0026quot;600022.SH\u0026quot;, \u0026quot;600027.SH\u0026quot;, \u0026quot;600096.SH\u0026quot;, \u0026quot;600160.SH\u0026quot;, \u0026quot;600282.SH\u0026quot;, \u0026quot;600310.SH\u0026quot;, \u0026quot;600348.SH\u0026quot;, \u0026quot;600396.SH\u0026quot;, \u0026quot;600423.SH\u0026quot;, \u0026quot;600438.SH\u0026quot;, \u0026quot;600449.SH\u0026quot;, \u0026quot;600509.SH\u0026quot;, \u0026quot;600569.SH\u0026quot;, \u0026quot;600578.SH\u0026quot;, \u0026quot;600585.SH\u0026quot;, \u0026quot;600636.SH\u0026quot;, \u0026quot;600720.SH\u0026quot;, \u0026quot;600795.SH\u0026quot;, \u0026quot;600808.SH\u0026quot;, \u0026quot;600810.SH\u0026quot;, \u0026quot;600863.SH\u0026quot;, \u0026quot;601005.SH\u0026quot;, \u0026quot;601857.SH\u0026quot;, \u0026quot;601991.SH\u0026quot;, \u0026quot;300136.SZ\u0026quot;, \u0026quot;000001.SZ\u0026quot; ] }, { \u0026quot;_name\u0026quot; : \u0026quot;StockArtifact\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;ALIAS\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;|000001.SH|399001.SZ|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t5T4kKMgPsNCVwoOiAzG3ik\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;002504.SZ|300162.SZ|300085.SZ|601313.SH|300333.SZ|002441.SZ|300299.SZ|300336.SZ|000001.SH|399001.SZ|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;300299.SZ\u0026quot;, \u0026quot;300336.SZ\u0026quot;, \u0026quot;002504.SZ\u0026quot;, \u0026quot;300162.SZ\u0026quot;, \u0026quot;300085.SZ\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;300333.SZ\u0026quot;, \u0026quot;002441.SZ\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t-TeB05y04sIRl_c-uHOn_E\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;000001.SH|002011.SZ|600874.SH|603969.SH|000877.SZ|002307.SZ|002302.SZ|300141.SZ|300073.SZ|002369.SZ|002610.SZ|000672.SZ|002128.SZ|600362.SH|600497.SH|600531.SH|600740.SH|601313.SH|601699.SH|603009.SH|600985.SH|300058.SZ|300277.SZ|300364.SZ|300550.SZ|600583.SH\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;002011.SZ\u0026quot;, \u0026quot;600874.SH\u0026quot;, \u0026quot;603969.SH\u0026quot;, \u0026quot;000877.SZ\u0026quot;, \u0026quot;002307.SZ\u0026quot;, \u0026quot;002302.SZ\u0026quot;, \u0026quot;300141.SZ\u0026quot;, \u0026quot;300073.SZ\u0026quot;, \u0026quot;002369.SZ\u0026quot;, \u0026quot;002610.SZ\u0026quot;, \u0026quot;000672.SZ\u0026quot;, \u0026quot;002128.SZ\u0026quot;, \u0026quot;600362.SH\u0026quot;, \u0026quot;600497.SH\u0026quot;, \u0026quot;600531.SH\u0026quot;, \u0026quot;600740.SH\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;601699.SH\u0026quot;, \u0026quot;603009.SH\u0026quot;, \u0026quot;600985.SH\u0026quot;, \u0026quot;300058.SZ\u0026quot;, \u0026quot;300277.SZ\u0026quot;, \u0026quot;300364.SZ\u0026quot;, \u0026quot;300550.SZ\u0026quot;, \u0026quot;600583.SH\u0026quot;, \u0026quot;603117.SH\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t9zKc8uFxNS1FhBO5YW2x6I\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;000001.SH|399001.SZ|399006.SZ|000725.SZ|002129.SZ|002230.SZ|002916.SZ|600025.SH|600383.SH|600516.SH|600519.SH|600606.SH|601313.SH|601318.SH|601933.SH|000858.SZ|002447.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;000725.SZ\u0026quot;, \u0026quot;002129.SZ\u0026quot;, \u0026quot;002230.SZ\u0026quot;, \u0026quot;002916.SZ\u0026quot;, \u0026quot;600025.SH\u0026quot;, \u0026quot;600383.SH\u0026quot;, \u0026quot;600516.SH\u0026quot;, \u0026quot;600519.SH\u0026quot;, \u0026quot;600606.SH\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;601318.SH\u0026quot;, \u0026quot;601933.SH\u0026quot;, \u0026quot;000858.SZ\u0026quot;, \u0026quot;002447.SZ\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t9uE7aeQ0RzP7h5kLXn_jSE\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;399001.SZ|000001.SH|600571.SH|600064.SH|000839.SZ|000725.SZ|601313.SH|000060.SZ|002146.SZ|601012.SH|000830.SZ|000651.SZ|601318.SH|000001.SZ|000825.SZ|601328.SH|300017.SZ|300104.SZ|601600.SH|600028.SH|300059.SZ|601088.SH|601899.SH|601988.SH|300113.SZ|undefined002229.SZ|undefined300434.SZ|undefined300284.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;undefined002229.SZ\u0026quot;, \u0026quot;undefined300434.SZ\u0026quot;, \u0026quot;undefined300284.SZ\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;000001.SH\u0026quot;, \u0026quot;600571.SH\u0026quot;, \u0026quot;600064.SH\u0026quot;, \u0026quot;000839.SZ\u0026quot;, \u0026quot;000725.SZ\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;000060.SZ\u0026quot;, \u0026quot;002146.SZ\u0026quot;, \u0026quot;601012.SH\u0026quot;, \u0026quot;000830.SZ\u0026quot;, \u0026quot;000651.SZ\u0026quot;, \u0026quot;601318.SH\u0026quot;, \u0026quot;000001.SZ\u0026quot;, \u0026quot;000825.SZ\u0026quot;, \u0026quot;601328.SH\u0026quot;, \u0026quot;300017.SZ\u0026quot;, \u0026quot;300104.SZ\u0026quot;, \u0026quot;601600.SH\u0026quot;, \u0026quot;600028.SH\u0026quot;, \u0026quot;300059.SZ\u0026quot;, \u0026quot;601088.SH\u0026quot;, \u0026quot;601899.SH\u0026quot;, \u0026quot;601988.SH\u0026quot;, \u0026quot;300113.SZ\u0026quot; ] }, { \u0026quot;_name\u0026quot; : \u0026quot;FundKing\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;ALIAS\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;160643.SZ|512570.SH|159951.SZ|512560.SH|502014.SH|150051.SZ|150076.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;160643.SZ\u0026quot;, \u0026quot;512570.SH\u0026quot;, \u0026quot;159951.SZ\u0026quot;, \u0026quot;512560.SH\u0026quot;, \u0026quot;502014.SH\u0026quot;, \u0026quot;150051.SZ\u0026quot;, \u0026quot;150076.SZ\u0026quot;, \u0026quot;150265.SZ\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;|000001.SH|399001.SZ|399006.SZ|002430.SZ|002407.SZ|002106.SZ|002256.SZ|002607.SZ|300611.SZ|600559.SH|601313.SH|002886.SZ|300666.SZ|300176.SZ|300085.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;002430.SZ\u0026quot;, \u0026quot;002407.SZ\u0026quot;, \u0026quot;002106.SZ\u0026quot;, \u0026quot;002256.SZ\u0026quot;, \u0026quot;002607.SZ\u0026quot;, \u0026quot;300611.SZ\u0026quot;, \u0026quot;600559.SH\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;002886.SZ\u0026quot;, \u0026quot;300666.SZ\u0026quot;, \u0026quot;300176.SZ\u0026quot;, \u0026quot;300085.SZ\u0026quot;, \u0026quot;600903.SH\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;837800504@qq.com\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;603818.SH|300104.SZ|000001.SH|300111.SZ|300088.SZ|601288.SH|002687.SZ|601313.SH|300335.SZ|399001.SZ|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;002687.SZ\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;601288.SH\u0026quot;, \u0026quot;300111.SZ\u0026quot;, \u0026quot;300088.SZ\u0026quot;, \u0026quot;300335.SZ\u0026quot;, \u0026quot;300104.SZ\u0026quot;, \u0026quot;603818.SH\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t1vm0k6FgFMWRHBC-zxza24\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;601313.SH|603286.SH|000001.SH|399001.SZ|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;603286.SH\u0026quot;, \u0026quot;601313.SH\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;1340765542@qq.com\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;000001.SH|399001.SZ|399006.SZ|000736.SZ|603676.SH|600362.SH|600497.SH|600531.SH|600740.SH|300364.SZ|300370.SZ|603009.SH|603117.SH|002128.SZ|000672.SZ|600985.SH|300058.SZ|601313.SH|601899.SH|603993.SH|000513.SZ|000725.SZ|000830.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;000736.SZ\u0026quot;, \u0026quot;603676.SH\u0026quot;, \u0026quot;600362.SH\u0026quot;, \u0026quot;600497.SH\u0026quot;, \u0026quot;600531.SH\u0026quot;, \u0026quot;600740.SH\u0026quot;, \u0026quot;300364.SZ\u0026quot;, \u0026quot;300370.SZ\u0026quot;, \u0026quot;603009.SH\u0026quot;, \u0026quot;603117.SH\u0026quot;, \u0026quot;002128.SZ\u0026quot;, \u0026quot;000672.SZ\u0026quot;, \u0026quot;600985.SH\u0026quot;, \u0026quot;300058.SZ\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;601899.SH\u0026quot;, \u0026quot;603993.SH\u0026quot;, \u0026quot;000513.SZ\u0026quot;, \u0026quot;000725.SZ\u0026quot;, \u0026quot;000830.SZ\u0026quot; ] } ] } { \u0026quot;_id\u0026quot; : \u0026quot;dea967838@163.com\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;002685.SZ|603716.SH|002230.SZ|000752.SZ|601678.SH|600231.SH|600160.SH|603505.SH|002355.SZ|002688.SZ|000060.SZ|000983.SZ|002519.SZ|600602.SH|000301.SZ|002336.SZ|603466.SH|002237.SZ|002302.SZ|600351.SH|600359.SH|000552.SZ|600997.SH|002229.SZ|000528.SZ|000816.SZ|002080.SZ|600398.SH|600506.SH|600581.SH|600789.SH|600740.SH|601313.SH|300668.SZ|300553.SZ|300212.SZ|000681.SZ|002050.SZ|000048.SZ|002803.SZ|002383.SZ|000893.SZ|300401.SZ|600853.SH|600436.SH|002853.SZ|002856.SZ|000001.SH|399001.SZ|399006.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;002853.SZ\u0026quot;, \u0026quot;002856.SZ\u0026quot;, \u0026quot;000552.SZ\u0026quot;, \u0026quot;000816.SZ\u0026quot;, \u0026quot;002080.SZ\u0026quot;, \u0026quot;002229.SZ\u0026quot;, \u0026quot;002302.SZ\u0026quot;, \u0026quot;600359.SH\u0026quot;, \u0026quot;600398.SH\u0026quot;, \u0026quot;600506.SH\u0026quot;, \u0026quot;600581.SH\u0026quot;, \u0026quot;600789.SH\u0026quot;, \u0026quot;600997.SH\u0026quot;, \u0026quot;600740.SH\u0026quot;, \u0026quot;601313.SH\u0026quot;, \u0026quot;300668.SZ\u0026quot;, \u0026quot;300553.SZ\u0026quot;, \u0026quot;002519.SZ\u0026quot;, \u0026quot;600602.SH\u0026quot;, \u0026quot;000301.SZ\u0026quot;, \u0026quot;300212.SZ\u0026quot;, \u0026quot;000528.SZ\u0026quot;, \u0026quot;002336.SZ\u0026quot;, \u0026quot;603466.SH\u0026quot;, \u0026quot;002237.SZ\u0026quot;, \u0026quot;000681.SZ\u0026quot;, \u0026quot;600351.SH\u0026quot;, \u0026quot;002050.SZ\u0026quot;, \u0026quot;000048.SZ\u0026quot;, \u0026quot;002803.SZ\u0026quot;, \u0026quot;002383.SZ\u0026quot;, \u0026quot;000893.SZ\u0026quot;, \u0026quot;300401.SZ\u0026quot;, \u0026quot;600853.SH\u0026quot;, \u0026quot;600436.SH\u0026quot;, \u0026quot;000060.SZ\u0026quot;, \u0026quot;000983.SZ\u0026quot;, \u0026quot;002688.SZ\u0026quot;, \u0026quot;002230.SZ\u0026quot;, \u0026quot;000752.SZ\u0026quot;, \u0026quot;601678.SH\u0026quot;, \u0026quot;600231.SH\u0026quot;, \u0026quot;600160.SH\u0026quot;, \u0026quot;603505.SH\u0026quot;, \u0026quot;002355.SZ\u0026quot;, \u0026quot;002685.SZ\u0026quot;, \u0026quot;603716.SH\u0026quot; ] } ] } testrs:PRIMARY\u0026gt;  查找\ndb.test.find({\u0026quot;groups._stocks\u0026quot;:/603286.SH/})  针对,数组(这里是groups.0._stocks)的处理  方法1, 先删除,后插入  testrs:PRIMARY\u0026gt; db.test.update({\u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;}, {$pull: {\u0026quot;groups.0._stocks\u0026quot;:\u0026quot;601313.SH\u0026quot;}}) WriteResult({ \u0026quot;nMatched\u0026quot; : 1, \u0026quot;nUpserted\u0026quot; : 0, \u0026quot;nModified\u0026quot; : 1 }) testrs:PRIMARY\u0026gt; db.test.find({\u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;}) { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;|000001.SH|399001.SZ|399006.SZ|002430.SZ|002407.SZ|002106.SZ|002256.SZ|002607.SZ|300611.SZ|600559.SH|601313.SH|002886.SZ|300666.SZ|300176.SZ|300085.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;002430.SZ\u0026quot;, \u0026quot;002407.SZ\u0026quot;, \u0026quot;002106.SZ\u0026quot;, \u0026quot;002256.SZ\u0026quot;, \u0026quot;002607.SZ\u0026quot;, \u0026quot;300611.SZ\u0026quot;, \u0026quot;600559.SH\u0026quot;, \u0026quot;002886.SZ\u0026quot;, \u0026quot;300666.SZ\u0026quot;, \u0026quot;300176.SZ\u0026quot;, \u0026quot;300085.SZ\u0026quot;, \u0026quot;600903.SH\u0026quot; ] } ] } testrs:PRIMARY\u0026gt; db.test.update({\u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;}, {$push: {\u0026quot;groups.0._stocks\u0026quot;:\u0026quot;601360.SH\u0026quot;}}) WriteResult({ \u0026quot;nMatched\u0026quot; : 1, \u0026quot;nUpserted\u0026quot; : 0, \u0026quot;nModified\u0026quot; : 1 }) testrs:PRIMARY\u0026gt; db.test.find({\u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;}) { \u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;, \u0026quot;groups\u0026quot; : [ { \u0026quot;_name\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_alias\u0026quot; : \u0026quot;default0\u0026quot;, \u0026quot;_sort\u0026quot; : \u0026quot;|000001.SH|399001.SZ|399006.SZ|002430.SZ|002407.SZ|002106.SZ|002256.SZ|002607.SZ|300611.SZ|600559.SH|601313.SH|002886.SZ|300666.SZ|300176.SZ|300085.SZ\u0026quot;, \u0026quot;_stocks\u0026quot; : [ \u0026quot;000001.SH\u0026quot;, \u0026quot;399001.SZ\u0026quot;, \u0026quot;399006.SZ\u0026quot;, \u0026quot;002430.SZ\u0026quot;, \u0026quot;002407.SZ\u0026quot;, \u0026quot;002106.SZ\u0026quot;, \u0026quot;002256.SZ\u0026quot;, \u0026quot;002607.SZ\u0026quot;, \u0026quot;300611.SZ\u0026quot;, \u0026quot;600559.SH\u0026quot;, \u0026quot;002886.SZ\u0026quot;, \u0026quot;300666.SZ\u0026quot;, \u0026quot;300176.SZ\u0026quot;, \u0026quot;300085.SZ\u0026quot;, \u0026quot;600903.SH\u0026quot;, \u0026quot;601360.SH\u0026quot; ] } ] } testrs:PRIMARY\u0026gt; db.test.find({\u0026quot;_id\u0026quot; : \u0026quot;oxKP9t_NthJF6HOdn5j8cW6LE1mE\u0026quot;})  针对,字符串(这里是groups.0._sort)的处理 这个因为有点复杂, 所以参考 git仓库 https://gitee.com/tomt/tom_mongodb_update\nref  Mongodb 内嵌数组操作 MongoDB删除数组元素 mongodb update 字符 操作  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/windows.html",
	"title": "Windows Command",
	"tags": ["windows", "command"],
	"description": "",
	"content": " windows 后台运行 使用start /b +命令即可，具体方法如下：\n 按windows和r组合键打开运行面板； 在运行框内输入cmd，再按回车键进入命令提示符中； 在命令提示符中输入“ start /b 命令 \u0026ldquo; 再按回车，即可后台运行该命令。  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysqldump-faq.html",
	"title": "Mysqldump Faq",
	"tags": ["mysql", "mysqldump"],
	"description": "",
	"content": "mysqldump中断的常见错误和解决措施\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/gem.html",
	"title": "Gem Command",
	"tags": ["gem", "command"],
	"description": "",
	"content": " gem 卸载 软件包 以 cocoapods 为例子\nsudo gem uninstall cocoapods  ref  2017年最新cocoaPods安装、升级、卸载及删除库命令  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-seo.html",
	"title": "Nginx Seo",
	"tags": ["nginx", "seo"],
	"description": "",
	"content": " seo 优化去掉html 页面的后缀 .html ubuntu@VM-0-12-ubuntu:/etc/nginx/conf.d$ cat 8766.conf server { listen 8766; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; # seo 优化去掉html 页面的后缀 .html if (!-f $request_filename){ set $rule_0 1$rule_0; } if ($rule_0 = \u0026quot;1\u0026quot;){ rewrite ^/([^\\.]+)$ /$1.html last; } location / { root /home/ubuntu/registry/tomtsang-rootsongjc-cheatsheet/_site; index index.html index.htm; # proxy_pass http://127.0.0.1:4001; } ...  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-config-server.conf.html",
	"title": "Mysql Config Server.conf",
	"tags": ["mysql", "config"],
	"description": "",
	"content": " 压缩binlog空间 在运行前, 先去数据目录文件夹下查看一下, mysql.000001的文件有多少,并看一下各文件的创建时间.也就是确认一下要删除的binlog日期.\n 按文件序列号删除  如果想要删除mysql.000050(不包含)日期之前的binlog文件, 在mysql下运行这个purge binary logs to 'mysql.000050';\n运行这个后, 会将 数据目录文件夹下的 mysql.000001-mysql.000049的文件删除(如果想删除更多, 修改数字 mysql.000050 为 mysql.000120 等).\n 按时间删除  删除2018-02-15 23:59:59 之前binlog。 purge binary logs before '2018-02-15 23:59:59';\n 通过配置文件删除8天之前的binlog  同时,在配置文件里添加这个：expire_logs_days=8,这个参数表示删除8天之前的binlog\nexpire_logs_days=8  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ruby/gem-install-faq.html",
	"title": "Gem Install Faq",
	"tags": ["ruby", "gem", "faq"],
	"description": "",
	"content": " faq, ruby.h not found ubuntu@VM-0-12-ubuntu:~/registry/tomtsang-rootsongjc-cheatsheet$ bundle install ... ... To see why this extension failed to compile, please check the mkmf.log which can be found here: /tmp/bundler20180226-1352-qwjujmnokogiri-1.8.0/extensions/x86_64-linux/2.3.0/nokogiri-1.8.0/mkmf.log extconf failed, exit code 1 Gem files will remain installed in /tmp/bundler20180226-1352-qwjujmnokogiri-1.8.0/gems/nokogiri-1.8.0 for inspection. Results logged to /tmp/bundler20180226-1352-qwjujmnokogiri-1.8.0/extensions/x86_64-linux/2.3.0/nokogiri-1.8.0/gem_make.out An error occurred while installing nokogiri (1.8.0), and Bundler cannot continue. Make sure that `gem install nokogiri -v '1.8.0'` succeeds before bundling. In Gemfile: github-pages was resolved to 156, which depends on jekyll-mentions was resolved to 1.2.0, which depends on html-pipeline was resolved to 2.7.0, which depends on nokogiri ubuntu@VM-0-12-ubuntu:~/registry/tomtsang-rootsongjc-cheatsheet$  这个时候, 依据提示, 要去安装 ffi, 好, 来吧.\nsudo gem install ffi -v '1.9.18'  如果说报出, 没有找到 ruby.h 文件的错误,则说明没有安装 ruby-dev 包.那么去安装吧.\nsudo apt install ruby-dev  faq, ubuntu@VM-0-12-ubuntu:~/registry/tomtsang-rootsongjc-cheatsheet$ bundle install ... ... To see why this extension failed to compile, please check the mkmf.log which can be found here: /tmp/bundler20180226-1352-qwjujmnokogiri-1.8.0/extensions/x86_64-linux/2.3.0/nokogiri-1.8.0/mkmf.log extconf failed, exit code 1 Gem files will remain installed in /tmp/bundler20180226-1352-qwjujmnokogiri-1.8.0/gems/nokogiri-1.8.0 for inspection. Results logged to /tmp/bundler20180226-1352-qwjujmnokogiri-1.8.0/extensions/x86_64-linux/2.3.0/nokogiri-1.8.0/gem_make.out An error occurred while installing nokogiri (1.8.0), and Bundler cannot continue. Make sure that `gem install nokogiri -v '1.8.0'` succeeds before bundling. In Gemfile: github-pages was resolved to 156, which depends on jekyll-mentions was resolved to 1.2.0, which depends on html-pipeline was resolved to 2.7.0, which depends on nokogiri ubuntu@VM-0-12-ubuntu:~/registry/tomtsang-rootsongjc-cheatsheet$  好, 那就安装 nokogiri\nubuntu@VM-0-12-ubuntu:~/registry/tomtsang-rootsongjc-cheatsheet$ sudo gem install nokogiri -v '1.8.0' Building native extensions. This could take a while... ERROR: Error installing nokogiri: ERROR: Failed to build gem native extension. current directory: /var/lib/gems/2.3.0/gems/nokogiri-1.8.0/ext/nokogiri /usr/bin/ruby2.3 -r ./siteconf20180226-2229-iju4w6.rb extconf.rb checking if the C compiler accepts ... yes Building nokogiri using packaged libraries. Using mini_portile version 2.2.0 checking for gzdopen() in -lz... no zlib is missing; necessary for building libxml2 ## 这里是一个关键点了, zlib 没安装 *** extconf.rb failed *** Could not create Makefile due to some reason, probably lack of necessary libraries and/or headers. Check the mkmf.log file for more details. You may need configuration options. Provided configuration options: --with-opt-dir --without-opt-dir --with-opt-include --without-opt-include=${opt-dir}/include --with-opt-lib --without-opt-lib=${opt-dir}/lib --with-make-prog --without-make-prog --srcdir=. --curdir --ruby=/usr/bin/$(RUBY_BASE_NAME)2.3 --help --clean --use-system-libraries --enable-static --disable-static --with-zlib-dir --without-zlib-dir --with-zlib-include --without-zlib-include=${zlib-dir}/include --with-zlib-lib --without-zlib-lib=${zlib-dir}/lib --enable-cross-build --disable-cross-build To see why this extension failed to compile, please check the mkmf.log which can be found here: /var/lib/gems/2.3.0/extensions/x86_64-linux/2.3.0/nokogiri-1.8.0/mkmf.log extconf failed, exit code 1 Gem files will remain installed in /var/lib/gems/2.3.0/gems/nokogiri-1.8.0 for inspection. Results logged to /var/lib/gems/2.3.0/extensions/x86_64-linux/2.3.0/nokogiri-1.8.0/gem_make.out ubuntu@VM-0-12-ubuntu:~/registry/tomtsang-rootsongjc-cheatsheet$  看上面这里说了 zlib is missing, 所以要安装zlib\nsudo apt install zlib1g sudo apt install zlib1g-dev  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vmware/vmware-workstation.html",
	"title": "Vmware Workstation",
	"tags": ["vmware"],
	"description": "",
	"content": "序列号:\nver 11:\n1F04Z-6D111-7Z029-AV0Q4-3AEH8\nver 12:\n1F04Z-6D111-7Z029-AV0Q4-3AEH8\n5A02H-AU243-TZJ49-GTC7K-3C61N\nVF5XA-FNDDJ-085GZ-4NXZ9-N20E6 UC5MR-8NE16-H81WY-R7QGV-QG2D8 ZG1WH-ATY96-H80QP-X7PEX-Y30V4 AA3E0-0VDE1-0893Z-KGZ59-QGAVF\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ruby/bundle-install.html",
	"title": "Bundle Install",
	"tags": ["bundle", "install"],
	"description": "",
	"content": " env mac book air\nstep 安装 bundle\n➜ ~ sudo gem install bundler Password: Fetching: bundler-1.16.1.gem (100%) Successfully installed bundler-1.16.1 Parsing documentation for bundler-1.16.1 Installing ri documentation for bundler-1.16.1 1 gem installed ➜ ~ ➜ tomtsang-rootsongjc-cheatsheet git:(master) which bundle /usr/local/bin/bundle ➜ tomtsang-rootsongjc-cheatsheet git:(master)  ref  mac 下应该怎么安装 bundle  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yarn/yarn-install.html",
	"title": "Yarn Install",
	"tags": ["yarn", "install"],
	"description": "",
	"content": " env mac book air\nstep 安装 yarn\n➜ tomtsang-rootsongjc-cheatsheet git:(master) brew install yarn Updating Homebrew... ==\u0026gt; Auto-updated Homebrew! Updated 2 taps (caskroom/cask, homebrew/core). ==\u0026gt; Updated Formulae abcmidi braid cryptopp exiftool fdroidserver glbinding haxe pwntools x265 alot cgrep erlang fbi-servefiles freexl graphene miniupnpc ranger ==\u0026gt; Downloading https://yarnpkg.com/downloads/1.3.2/yarn-v1.3.2.tar.gz ==\u0026gt; Downloading from https://github.com/yarnpkg/yarn/releases/download/v1.3.2/yarn-v1.3.2.tar.gz ######################################################################## 100.0% 🍺 /usr/local/Cellar/yarn/1.3.2: 14 files, 3.9MB, built in 40 seconds ➜ tomtsang-rootsongjc-cheatsheet git:(master)  使用, 安装工程中的依赖包\n➜ tomtsang-rootsongjc-cheatsheet git:(master) yarn install yarn install v1.3.2 [1/4] 🔍 Resolving packages... [2/4] 🚚 Fetching packages... [3/4] 🔗 Linking dependencies... warning \u0026quot; \u0026gt; eslint-plugin-flowtype@2.37.0\u0026quot; has unmet peer dependency \u0026quot;eslint@\u0026gt;=2.0.0\u0026quot;. [4/4] 📃 Building fresh packages... ✨ Done in 85.79s. ➜ tomtsang-rootsongjc-cheatsheet git:(master) w  ref  Yarn 构建工具入门基础 yarn 中文网 yarn 安装  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tools/today-learn.html",
	"title": "Today Learn",
	"tags": ["learn", "today"],
	"description": "",
	"content": " 20180223 Hugo 集成 Algolia 搜索\n20180302 telegram 客户端都是开源的，源代码放在官方网站上供人下载，以及修改（遵循 GPL v3 许可协议）。从比特币投资者变成天使投资人的李笑来，最近就用一个星期的时间，开发了一个基于 Telegram 的第三方客户端 Dove。\n李笑来说，“（我）觉得 Telegram 挺开放的，未来可能在这上面长出很多有意思的东西。另外，总体上，它是个比较让人喜欢的软件。”\n不过，Telegram 的服务端是闭源的。\nref\n http://www.ifanr.com/504427  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/mac.html",
	"title": "Mac Command",
	"tags": ["mac", "command"],
	"description": "",
	"content": " brew brew install node brew upgrade node  Mac OS 如何更改文件的默认打开方式 如何显示Mac OS X上的隐藏文件和文件夹 如何显示Mac OS X上的隐藏文件和文件夹\nhttps://wenku.baidu.com/view/ce92f3b877232f60dccca1e0.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs-faq-unexpected-token-function.html",
	"title": "Nodejs Faq Unexpected Token Function",
	"tags": ["nodejs", "faq"],
	"description": "",
	"content": " env 在 hugo-algolia -s命令运行时, 出现了 Unexpected token function 报错\n➜ tomtsang-rootsongjc-hugo git:(master) ✗ hugo-algolia -s /usr/local/lib/node_modules/hugo-algolia/lib/utils.js:11 async function copySynonyms(fromIndex, toIndex) { ^^^^^^^^ SyntaxError: Unexpected token function at Object.exports.runInThisContext (vm.js:78:16) at Module._compile (module.js:543:28) at Object.Module._extensions..js (module.js:580:10) at Module.load (module.js:488:32) at tryModuleLoad (module.js:447:12) at Function.Module._load (module.js:439:3) at Module.require (module.js:498:17) at require (internal/module.js:20:19) at Object.\u0026lt;anonymous\u0026gt; (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:11:52) at Module._compile (module.js:571:32) ➜ tomtsang-rootsongjc-hugo git:(master) ✗  step Unexpected token function 报错, 是指未预期的token 函数, 那先就要查一下, nodejs版本支持与否\n➜ tomtsang-rootsongjc-hugo git:(master) ✗ node -v v7.2.1  报错信息, 知函数为 async function\n➜ tomtsang-rootsongjc-hugo git:(master) ✗ head -n 20 /usr/local/lib/node_modules/hugo-algolia/lib/utils.js function copySettings(fromIndex, toIndex) { const settings = fromIndex.getSettings(); if(settings['replicas'] !== undefined) { settings['replicas'] = undefined; } toIndex.setSettings(settings); } async function copySynonyms(fromIndex, toIndex) { let page = 0; do { let results = await fromIndex.searchSynonyms({ query: '', type: 'synonym,oneWaySynonym', page, }); ➜ tomtsang-rootsongjc-hugo git:(master) ✗  通过 Node.js ES2015 Support, 知道, async function 最少需要 nodejs 在 7.10.1 版本. 所以这个问题就是去升级版本吧\ncheck ➜ tomtsang-rootsongjc-hugo git:(master) ✗ node -v v9.5.0 ➜ tomtsang-rootsongjc-hugo git:(master) ✗ npm -v 5.6.0 ➜ tomtsang-rootsongjc-hugo git:(master) ✗ hugo-algolia -s JSON index file was created in public/algolia.json { updatedAt: '2018-02-23T08:04:32.198Z', taskID: 3509864752 } ➜ tomtsang-rootsongjc-hugo git:(master) ✗  ref  https://github.com/10Dimensional/hugo-algolia/issues/1 Node.js ES2017 Support  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/nodejs.html",
	"title": "Nodejs Resource",
	"tags": ["nodejs", "resource"],
	"description": "",
	"content": "Node.js ES2015 Support\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/route.html",
	"title": "Route",
	"tags": ["route", "linux"],
	"description": "",
	"content": " env 192.168.31.181 上 加一条 wifi 192.168.33.0/24 的路由规则\nref Linux下route add 命令加入路由列表\nstep [root@check ~]# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: em1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 link/ether 44:a8:42:2b:e5:e3 brd ff:ff:ff:ff:ff:ff inet 192.168.31.181/24 brd 192.168.31.255 scope global em1 valid_lft forever preferred_lft forever inet6 fe80::46a8:42ff:fe2b:e5e3/64 scope link valid_lft forever preferred_lft forever 3: em2: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP qlen 1000 link/ether 44:a8:42:2b:e5:e4 brd ff:ff:ff:ff:ff:ff inet 10.10.15.181/24 brd 10.10.15.255 scope global em2 valid_lft forever preferred_lft forever inet6 fe80::46a8:42ff:fe2b:e5e4/64 scope link valid_lft forever preferred_lft forever 4: virbr0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN link/ether 52:54:00:83:1d:10 brd ff:ff:ff:ff:ff:ff inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0 valid_lft forever preferred_lft forever 5: virbr0-nic: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc pfifo_fast master virbr0 state DOWN qlen 500 link/ether 52:54:00:83:1d:10 brd ff:ff:ff:ff:ff:ff 6: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN link/ether 02:42:38:b7:35:73 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0 valid_lft forever preferred_lft forever [root@check ~]# route add -net 192.168.33.0 gw 192.168.31.1 netmask 255.255.255.0 em1 [jlch@check ~]$ route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.10.15.1 0.0.0.0 UG 100 0 0 em2 10.10.15.0 0.0.0.0 255.255.255.0 U 100 0 0 em2 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 192.168.31.0 0.0.0.0 255.255.255.0 U 100 0 0 em1 192.168.33.0 192.168.31.1 255.255.255.0 UG 0 0 0 em1 192.168.33.0 0.0.0.0 255.255.255.0 U 0 0 0 em1 192.168.122.0 0.0.0.0 255.255.255.0 U 0 0 0 virbr0 [jlch@check ~]$  这样, 所有 从 192.168.33.0/24 访问 192.168.31.181 的, 都从 em1 口进出.\n上面这个, 当网络重启时,会失效,要手工再加一次,所以, 我们把它写到文件里, 重启一下网络.\n[jlch@test_240 network-scripts]$ cat /etc/sysconfig/network-scripts/route-em1 192.168.33.0/24 via 192.168.31.1 [jlch@test_240 network-scripts]$ sudo systemctl restart network  删除路由规则\n[root@check ~]# route del -net 192.168.33.0 netmask 255.255.255.0 em1 [root@check ~]#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/blockchain.html",
	"title": "Blockchain Resource",
	"tags": ["resource", "blockchain"],
	"description": "",
	"content": " 如何学习区块链技术？\ncoinmarketcap\nBitUP Intelligent Digital Asset Management, BitUP平台推出的产品都将基于量化交易来实现操作。基于增强学习的自动化交易等\nmetastablecapital We Manage Crypto Asset Hedge Funds\nchia, Chia will be available to the public in the summer of 2018\n币界网\n数字货币导航网\nAICoin\n开发 Node.js开发加密货币\nbitcoin  https://www.gdax.com/trade/BTC-USD  区块链浏览器  searchain Tokenview qukuai ChainFlyer btc.com BlockTrail Blockchair Blockchain  1.我见过的里面最酷炫的，日本BitFlyer交易所的ChainFlyer：https://chainflyer.bitflyer.jp 尤其是创世区块…… 优点：很直观地区分了SW交易和非SW交易；脚本解析看上去做得很棒，非常清晰；OP_RETURN还被显示为消息气泡，细节很赞；收录了历史上的双花交易，并没有把它们直接丢弃。 缺点：好像没有显示矿池的名字。 2.国内的大矿池自带的，访问速度很快：https://btc.com 优点：访问速度快、带有未确认交易内存池统计、算力占比统计等丰富统计数据；还有手续费估计等实用功能；脚本显示也比较清晰。 缺点：属于“矿霸”比特大陆旗下（额这个也算缺点么）；再硬扯一条吧：自带的交易加速功能价格太贵。 3.BlockTrail：https://www.blocktrail.com/BTC 优点：可以直观地显示交易有没有启用Opt-in RBF。 缺点：被比特大陆收购（又来了）；会把原生SW地址的输出脚本错误解析为OP_RETURN。 4.Blockchair：https://blockchair.com/bitcoin 优点：筛选和统计功能非常强大，可以导出CSV数据；数据超级详细；搜索也很强大。 缺点：访问好像有点慢。 5.Blockchain：https://blockchain.info/ 优点：貌似比较老牌；自带各种统计图表，而且可以导出CSV数据；实时滚动更新的未确认交易名单（貌似是没X用的功能？）；还有收录历史上的孤块（双花交易似乎就直接丢了） 缺点：太老，代码更新好像跟不上了，貌似连原生SW地址都没好好兼容；前一阵子发生的“矿工搞丢12.5BTC区块奖励”事件中也崩过一次。  比特币区块链浏览器 简介：\n https://blockchain.info（英文的界面） https://btc.com（中文的界面） https://blockchain.info/zh-cn/\nBasecoin http://www.getbasecoin.com/\n https://www.jianshu.com/p/cb3d5855179f\n https://www.jianshu.com/p/737d0153cb09\n  交易所  https://coinmarketcap.com/  BTC  https://mp.weixin.qq.com/s/cTrDrS5J6K7ohoCRlfiJ8g BTC与美元 https://www.gdax.com/trade/BTC-USD\nETH https://ethgasstation.info/\nSearch ERC20\n  第二届中国区块链开发大赛  http://www.cbdforum.cn/bcweb/index/cbd-project.html http://www.cbdforum.cn/bcweb/index/article/im-28.html  Ref  http://8btc.com/thread-123034-1-3.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/docker.html",
	"title": "Docker Resource",
	"tags": ["resource", "docker"],
	"description": "",
	"content": " 如何使用 DockerHub  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/mount.html",
	"title": "Mount",
	"tags": ["mount"],
	"description": "",
	"content": " 通过 shell root@ud-31-193:~# mkdir /mnt/31.10.share root@ud-31-193:~# mount -t cifs -o username=share,password=\u0026quot;\u0026quot; //192.168.31.10/share /mnt/31.10.share/ root@ud-31-193:~#  通过 auto.misc [jlch@check conf.d]$ sudo cat /etc/auto.misc [sudo] password for jlch: # # This is an automounter map and it has the following format # key [ -mount-options-separated-by-comma ] location # Details may be found in the autofs(5) manpage #cd\t-fstype=iso9660,ro,nosuid,nodev\t:/dev/cdrom #dbf -fstype=cifs,rw,username=administrator,password=jlch@2016 ://10.10.14.11/hq share -fstype=cifs,rw,username=share,password= ://192.168.31.10/share 31245share -fstype=cifs,rw,username=share,password=Jlch1234 ://192.168.31.245/share 319share -fstype=cifs,rw,username=user01,password=User01 ://192.168.31.9/DataVol2/ dbf -fstype=cifs,rw,username=administrator,password=jlch333 ://10.10.12.202/hq shdef -fstype=cifs,rw,username=administrator,password=jlch333 ://10.10.12.201/dbf sse_mstp -fstype=cifs,rw,username=ituser,password=!Tuser0708 ://172.39.187.210/sse_mstp_m szsefiles -fstype=cifs,rw,username=ituser,password=!Tuser0708 ://10.198.7.226/SZSEFiles sse_mstp0 -fstype=cifs,rw,username=ituser,password=!Tuser0708 ://172.39.187.210/data 128share -fstype=cifs,rw,username=ituser,password=SVMSmZ77a7 ://192.168.31.128/Z  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/software-architect.html",
	"title": "Software Architect",
	"tags": ["software", "architect"],
	"description": "",
	"content": "c4model\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/enterprise/enterprise-idea.html",
	"title": "Enterprise Idea",
	"tags": ["enterprise", "idea"],
	"description": "",
	"content": " 有时候,组织需要一些新鲜血液进入,改善环境.比如,2018骑士队的去6来4\n 在 人人都是产品经理 中,有几篙好文章,就是关于公司管理的.\n 招聘, 真的是很重要, 如果说进来的人, 工作能力差, 真的是很头疼..\n 我个人,真的是很不喜欢和不聪明的人打交道, 真的是好累.\n 有些东西,我传达几遍, 多次强调, 还是没有用, 真的是烦得不行.\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/life/life-healthy.html",
	"title": "Life Healthy",
	"tags": ["life", "healthy"],
	"description": "",
	"content": "今天才听同事说去香港打疫苗的事\n 九价疫苗 二价,六价,八价疫苗 上午的医生出症费比下午1点后的便宜100港币 宫颈癌疫苗 有买香港保险后,打疫苗会稍微便宜一点 深圳私立医院卓正医疗,很牛吗?  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-config.html",
	"title": "Mysql Config",
	"tags": ["mysql", "config"],
	"description": "",
	"content": " MySQL5.7初始密码查看及重置 [root@localhost jlch]# grep 'temporary password' /var/log/mysqld.log 2018-02-12T07:28:21.362804Z 1 [Note] A temporary password is generated for root@localhost: Ngu97xLjPL(S [root@localhost jlch]#  MySQL源码安装、配置、初始化及启动 mysql_secure_installation  配置mysql允许远程连接的方法 默认情况下，mysql只允许本地登录，如果要开启远程连接，则需要修改/etc/mysql/my.conf文件。 一、修改/etc/mysql/my.conf 找到bind-address = 127.0.0.1这一行 改为bind-address = 0.0.0.0即可 二、为需要远程登录的用户赋予权限 1、新建用户远程连接mysql数据库 grant all on *.* to admin@'%' identified by '123456' with grant option; flush privileges; 允许任何ip地址(%表示允许任何ip地址)的电脑用admin帐户和密码(123456)来访问这个mysql server。 注意admin账户不一定要存在。 2、支持root用户允许远程连接mysql数据库 grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option; flush privileges;  MySQL5.7 添加用户、删除用户与授权 mysql\u0026gt; CREATE USER 'xieyanke'@'%' IDENTIFIED BY 'xieyanke3306!Q'; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; grant all privileges on *.* to 'xieyanke'@'%' identified by 'xieyanke3306!Q' WITH GRANT OPTION; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec)  MYSQL授权当中的with grant option的作用 mysql\u0026gt; grant all privileges on *.* to test@localhost identified by 'test' with grant option;  这句增加一个本地具有所有权限的test用户（超级用户），密码是test。ON子句中的*.*意味着\u0026rdquo;所有数据库、所有表\u0026rdquo;。with grant option表示它具有grant权限。\nmysql\u0026gt; grant select,insert,update,delete,create,drop privileges on test.* to test1@'192.168.1.0/255.255.255.0' identified by 'test';  这句是增加了一个test1用户，口令是test，但是它只能从C类子网192.168.1连接，对test库有select,insert,update,delete,create,drop操作权限。\n用grant语句创建权限是不需要再手工刷新授权表的，因为它已经自动刷新了。\nmysql create database 指定utf-8编码 mysql\u0026gt; CREATE DATABASE IF NOT EXISTS dps DEFAULT CHARSET utf8 COLLATE utf8_general_ci; Query OK, 1 row affected (0.00 sec) mysql\u0026gt;  mysql5.7设置不区分大小写 lower_case_table_names=1  验证, 密码是 ***Jlch123!@#***\n[root@localhost jlch]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.21 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u0026gt; show variables like '%case_table%'; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | lower_case_table_names | 1 | +------------------------+-------+ 1 row in set (0.00 sec) mysql\u0026gt;  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql-install-rpm.html",
	"title": "Mysql Install Rpm",
	"tags": ["mysql", "install"],
	"description": "",
	"content": " mysql install by rpm on centos 官方下载地址\n在安装了perl的基本上,直接下载以下4个rpm包安装就可以了.\nmysql-community-server-5.7.21-1.el7.x86_64.rpm mysql-community-client-5.7.21-1.el7.x86_64.rpm mysql-community-common-5.7.21-1.el7.x86_64.rpm mysql-community-libs-5.7.21-1.el7.x86_64.rpm  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/github-travis.html",
	"title": "Github Travis",
	"tags": ["github", "hugo", "travis"],
	"description": "",
	"content": "Using Hugo with Travis CI on GitHub Pages\nmartinliu-hugo\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/life/life-film.html",
	"title": "Life Film",
	"tags": ["life", "film"],
	"description": "",
	"content": " film 教育  超脱  观看了, 感觉和之前看过的[狩猎]() 一样, 很深层\u0026hellip;\n [雪国列车]()  这个也很不错. 可以从多个角度去看待此电影\n 有机会再观看下面几个影片  《留下我》《李米的猜想》《生命中所不能沉重之情》《精英部队2》 被嫌弃的松子的一生, 告白, 碧海蓝天\n 已看的其它电影  《肖申克的救赎》 这个杀手不冷\n 星际穿越, 观后感  很不错..科幻..包括了, 家庭, 父女, 承诺, 人类视角, 勇气, 使命\n整体来说, 最突出的是父亲对子女的承诺,科学家对人类负责的使命感\n其中, 5维空间, 对3维空间的描述, 还是很不错的..\n5维 = 3维 + 引力 + 时间 + 爱\n 好家伙  这个影片有点老, 但是, 也还行吧. 可以当成一个反面教材来看吧..\n与 \u0026lt;\u0026lt;无主之城\u0026gt;\u0026gt; 有点像\n黑社会的打打杀杀,最后,还是要回归正常生活\n   "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/golang.html",
	"title": "Golang Resource",
	"tags": ["golang", "resource"],
	"description": "",
	"content": " golang-wiki\ngowalker\nPackageManagementTools\ngodoc\ngometalinter,golang代码质量检查分析工具\nhttps://github.com/itcloudy/go-view\nRef  https://segmentfault.com/a/1190000013553309  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/golang-import-packages.html",
	"title": "Golang Import Packages",
	"tags": ["golang"],
	"description": "",
	"content": " ref https://segmentfault.com/q/1010000010846304\nhttps://my.oschina.net/zlLeaf/blog/174404\nstep 通常情况下，import的包都是相对$GOPATH/src目录引入的，比如从github上面clone下来的项目，直接放到$GOPATH/src目录下，就可以直接import。例如： 如果项目的import路径是这样写的： import \u0026quot;github.com/yourname/projectname\u0026quot; 需要将项目代码放置在： $GOAPTH/src/github.com/yourname/projectname/下 如果项目的import是这样写的： import \u0026quot;message\u0026quot; 则将message.go放到: $GOAPTH/src/message/目录下即可。  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock/stock-trade-discipline.html",
	"title": "Stock Trade Discipline",
	"tags": ["discipline", "trade", "stock"],
	"description": "",
	"content": " 不接飞刀 不买下跌股票 严格止损 盘前必读\n 敬畏市场. 坚持被动交易, 定式交易,永远把保住本金放在第一位 计划交易. 每天写复盘日记,静态阅读市场.每个买卖决定对照交易模型审视确定,并排写计划表 交易计划. 盘前15分钟检查软硬件和盈损点.盘中不许临时起意,挂单撤单不犹豫.尽量使用隔夜挂单 加强保障. 生活节律,保证专注度   "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/code-style.html",
	"title": "Code Style",
	"tags": ["code"],
	"description": "",
	"content": " 三种编程命名规范（匈牙利命名法、驼峰式命名法、帕斯卡命名法)\n代码风格, 所有的语言的代码风格汇总 有的时候，真的是很困惑，我应该用什么代码风格.\n Airbnb JavaScript Style Guide 中文版 Airbnb JavaScript Style Guide Style Guide for Python Code Style guides for Google-originated open-source projects Google 开源项目风格指南 (中文版) Google 开源项目风格指南 github (中文版) Google JavaScript Style Guide(中文 版) analyzing code convention from github commits for Github data challenge, github地址 Code Guide by @AlloyTeam 盼望您的指定  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb/mongodb-output-import.html",
	"title": "Mongodb Output Import",
	"tags": ["mongodb", "export", "import"],
	"description": "",
	"content": " env 从 192.168.31.42/abc/Signals_1Min 转移mongodb数据 到 192.168.31.240/openQuote/Signals_1Min\nref MongoDB导入导出以及数据库备份\nstep mongoexport 导出 准备导出字段\n[jlch@check 42]$ cat field_Signals_1Min.txt _id Type Sign ID TrdDt TrdTm PrevClsPx LastPx TM Vol[jlch@check 42]$  导出\n[jlch@check 43]$ mongoexport -h 192.168.31.42 -d abc -c Signals_1Min -q '{\u0026quot;TrdDt\u0026quot;:20180131, \u0026quot;TrdTm\u0026quot;:{$lt:141900}, \u0026quot;ID\u0026quot;:/SZ/ }' --fieldFile=./field_Signals_1Min.txt --type=csv -o ./Signals_1Min.csv 2018-02-06T11:55:38.885+0800\tconnected to: 192.168.31.42 2018-02-06T11:55:39.053+0800\texported 3256 records [jlch@check 42]$ ls field_Signals_1Min.txt Signals_1Min.csv [jlch@check 42]$  此时生成 Signals_1Min.csv\nmongoimport 导入 [jlch@check 42]$ mongoimport -h 192.168.31.240 -d openQuote -c Signals_1Min --file ./Signals_1Min.csv --type csv --fieldFile=./field_Signals_1Min.txt 2018-02-06T11:42:43.521+0800\tconnected to: 192.168.31.240 2018-02-06T11:42:43.890+0800\timported 4116 documents [jlch@check 42]$  draft pwdd=${PWD} table=KLine_1Min table=KLine_15Min table=KLine_5Min mongoexport -h 192.168.31.42 -d abc -c $table -q '{\u0026quot;TrdDt\u0026quot;:20180131, \u0026quot;TrdTm\u0026quot;:{$lt:1420}, \u0026quot;ID\u0026quot;:/SZ/ }' --fieldFile=$pwdd/field_$table.txt --type=csv -o $pwdd/$table.csv mongoimport -h 192.168.31.240 -d openQuote -c $table --file ./$table.csv --type csv --fieldFile=$pwdd/field_$table.txt  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/telnet-install.html",
	"title": "Telnet Install",
	"tags": ["telnet", "install"],
	"description": "",
	"content": "telnet 安装 by rpm\ntelnet下载\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/microservices-python.html",
	"title": "Microservices Python",
	"tags": ["microservices", "python"],
	"description": "",
	"content": "TDD开发容器化的Python微服务应用\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-sqlalchemy-faq.html",
	"title": "Python sqlalchemy 使用",
	"tags": ["sqlalchemy", "python"],
	"description": "",
	"content": " sqlalchemy 如何在查询的时候排除掉数据库字段为 null的 python语句\nUnReadMsg = session.query(MainMongodbfile).filter_by(id=481) UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1 = \u0026quot;年烧煤--吨\u0026quot;) UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1 = None) UnReadMsg = session.query(MainMongodbfile).filter(MainMongodbfile.indicator_title1 != None)  能正常使用, 但是 使用下面2行,来查询为 null的, 却会报错\nUnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1 == None) UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1.isnot(None)) UnReadMsg = session.query(MainMongodbfile).filter(indicator_title1 != None) UnReadMsg = session.query(MainMongodbfile).filter_by(MainMongodbfile.indicator_title1 != None) UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1 != None) UnReadMsg = session.query(MainMongodbfile).filter_by( not_(indicator_title1.is_(None))) UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1.isnot(null())) UnReadMsg = session.query(MainMongodbfile).filter_by(MainMongodbfile.indicator_title1.isnot(null())) UnReadMsg = session.query(MainMongodbfile).filter_by( not_(indicator_title1.is_(None))) UnReadMsg = session.query(MainMongodbfile).filter_by( not_(MainMongodbfile.indicator_title1.is_(None))) UnReadMsg = session.query(MainMongodbfile).filter_by(MainMongodbfile.indicator_title1.isnot(None))  报错信息如下:\nTraceback (most recent call last): File \u0026quot;mysql_esa_task_indicator.py\u0026quot;, line 112, in \u0026lt;module\u0026gt; UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1.isnot(None)) NameError: name 'indicator_title1' is not defined (py373) DESKTOP-APB1HCJ%  或者\nTraceback (most recent call last): File \u0026quot;mysql_esa_task_indicator.py\u0026quot;, line 123, in \u0026lt;module\u0026gt; UnReadMsg = session.query(MainMongodbfile).filter_by(MainMongodbfile.indicator_title1.isnot(None)) TypeError: filter_by() takes 1 positional argument but 2 were given  所以,\n 选null, 则用  UnReadMsg = session.query(MainMongodbfile).filter_by(indicator_title1 = None)   not null的, 则用  UnReadMsg = session.query(MainMongodbfile).filter(MainMongodbfile.indicator_title1 != None)  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/golang-install.html",
	"title": "Golang Install",
	"tags": ["golang", "install"],
	"description": "",
	"content": " mac Golang在Mac OS上的环境配置\nLiteIDE下载,这个网址,好像现在打不开\n调试 mac安装gdb brew tap homebrew/dupes brew install gdb  delve 参考了 Installing Go, Gocode, GDB and LiteIDE\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/redis/redis-install.html",
	"title": "Redis Install",
	"tags": ["redis", "install"],
	"description": "",
	"content": "CENTOS7下安装REDIS\nCentOS下Redis的安装\n内含 开机自启动\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/learn-golang.html",
	"title": "Go Learn",
	"tags": ["golang", "learn"],
	"description": "",
	"content": " 资料导航 http://www.geeker8.com/go/41\n菜鸟教程 已完成\n优\n 比较易读  缺点\n 没介绍 通道，go协程，等并发概念和原理  Go语言第一课 代码\n已完成\n优\n 比较易读 有代码测试  Go简易教程 代码\n学习中\n在 6.3 小节完全懵逼\n读后感受 整体来说，我感觉，本书内容较淺而对新手不易理解，知识结构展示混乱，且无完整的示例代码。读完了，没有感觉学到东西。\nGo入门指南 gomake\ngodoc\n9.11 在 Go 程序中使用外部库\n学习在 13.2 小节, 停止\u0026hellip;.\nGo并发编程实战 随书源码\n学习中, 现在第3章\nAn Introduction to Programming in Go url\n http://www.golang-book.com/books/intro pdf 中文繁体  code\n随书源码\ngolangbootcamp [官方文档-中文] 官方中文-Go编程语言规范 golang快速入门 done\nchan 部分有错，其它整体很不错了，可以作为小手册，参考用。\ngo语言圣经（中文版） gobyexample done\nhttps://gobyexample.com, 这里有大量使用常规使用案例 https://gobyexample.xgwang.me/channels.html 这个是中文翻译\nGo 状态协程 https://gobyexample.xgwang.me/stateful-goroutines.html 看不懂\nbuild-web-application-with-golan ➜ Learning-Go-zh-cn git:(master) make mmark -html -head inc/head.html -css inc/book.css learninggo.md \u0026gt; learninggo.html panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x48 pc=0x1134c83] goroutine 1 [running]: github.com/mmarkdown/mmark/render/mhtml.bibliographyItem(0x11bc980, 0xc42013fd50, 0xc42013f9d0, 0xc42013fd01) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/mmarkdown/mmark/render/mhtml/hook.go:102 +0x183 github.com/mmarkdown/mmark/render/mhtml.RenderHook(0x11bc980, 0xc42013fd50, 0x11be900, 0xc42013f9d0, 0x1, 0x0, 0xc4200df601) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/mmarkdown/mmark/render/mhtml/hook.go:37 +0x38a github.com/gomarkdown/markdown/html.(*Renderer).RenderNode(0xc4200f6240, 0x11bc980, 0xc42013fd50, 0x11be900, 0xc42013f9d0, 0xc42019b901, 0x0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/html/renderer.go:914 +0x168c github.com/gomarkdown/markdown.Render.func1(0x11be900, 0xc42013f9d0, 0x10f8d01, 0x0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/markdown.go:63 +0x61 github.com/gomarkdown/markdown/ast.NodeVisitorFunc.Visit(0xc4201952c0, 0x11be900, 0xc42013f9d0, 0x1, 0x0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/ast/node.go:547 +0x43 github.com/gomarkdown/markdown/ast.Walk(0x11be900, 0xc42013f9d0, 0x11bcc20, 0xc4201952c0, 0x0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/ast/node.go:519 +0x6c github.com/gomarkdown/markdown/ast.Walk(0x11be8a0, 0xc42013fc70, 0x11bcc20, 0xc4201952c0, 0x0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/ast/node.go:530 +0x1b5 github.com/gomarkdown/markdown/ast.Walk(0x11bde80, 0xc42013f1f0, 0x11bcc20, 0xc4201952c0, 0x0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/ast/node.go:530 +0x1b5 github.com/gomarkdown/markdown/ast.Walk(0x11bde20, 0xc42005e300, 0x11bcc20, 0xc4201952c0, 0xc4201952c0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/ast/node.go:530 +0x1b5 github.com/gomarkdown/markdown/ast.WalkFunc(0x11bde20, 0xc42005e300, 0xc4201952c0) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/ast/node.go:553 +0x4b github.com/gomarkdown/markdown.Render(0x11bde20, 0xc42005e300, 0x11bd180, 0xc4200f6240, 0x11a0d56, 0x13, 0x119f8e9) /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/gomarkdown/markdown/markdown.go:62 +0xe1 main.main() /Users/tomtsang/.gvm/pkgsets/go1.10/global/src/github.com/mmarkdown/mmark/mmark.go:171 +0x694 make: *** [learninggo.html] Error 2 ➜ Learning-Go-zh-cn git:(master)  线上执行环境 https://play.golang.org, 线上执行环境，可演示简单程序\n\u0026lt;学习GO语言\u0026gt;中文版 https://mikespook.com/learning-go/\n常规使用案例 Golang：有趣的 channel 应用 看得不是很明白\nhttp://www.cnblogs.com/luckcs/articles/2588200.html\nRef  https://www.zhihu.com/question/30461290?sort=created https://github.com/dariubs/GoBooks https://studygolang.com/pkgdoc  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/resource/resource.html",
	"title": "Resource",
	"tags": ["resource"],
	"description": "",
	"content": " 综合  21运维\n 程序员在线工具, 这个比较叼了, 好多有用的工具\n RedHat Developers\n 发现用MkDocs来写教程也还挺爽的,还真心不错,示例有TDD开发容器化的Python微服务应用\n 用OpenSWAN做Linux下的IPSec VPN的详细配置指南\n filebeat + logstash + kafka + logstash + kibana + grafana 支持异地多机房, 来源 k8s技术圈的紫木\n helm 完成 dashboard 点击安装应用APP, 如 点击安装 redis, mysql等\n gitops, jenkins, rancher, GoCD, 完成基于kubernetes的CI/CD框架\n 讨论群 gitter, 好处, 不需要wechat或者facebook\n 脚本之家book\n 清华大学开源软件镜像站\n github-format-syntax\n GitLab Flavored Markdown (GFM)\n 真正的inotify+rsync实时同步 彻底告别同步慢\n jpg to png\n  api  apiview\n YApi, 是一个可本地部署的、打通前后端及QA的、可视化的接口管理平台 https://yapi.ymfe.org\n  books  free books\n KeKe-Li/book\n  search  duckduckgo  designers  Dribbble - Show and tell for designers, Dribbble is where designers get inspired and hired.  自媒体聚合平台  mediumRead, write and share stories that matter  tech  MIT Technology Review\n MapR\n hackernoon\n Techmeme\n arstechnica\n  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes-deployment-rollingupdate.html",
	"title": "Kubernetes Deployment Rollingupdate",
	"tags": ["kubernetes", "update"],
	"description": "",
	"content": "使用kubernetes的deployment进行RollingUpdate\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/r/R-Rstudio-vnc-install-centos.html",
	"title": "R Rstudio Vnc Install Centos",
	"tags": ["R", "Rstudio", "install"],
	"description": "",
	"content": "R, Rstudio 在 centos 下安装, 并可通过端口访问\ncd yum install scp ls ifconfig ls yum install R yum install gcc gcc-c++ -y vncserver R sudo systemctl stop firewalld.service yum -y install tigervnc-server tigervnc ll /lib/systemd/system/vncserver@.service cp /lib/systemd/system/vncserver@.service /lib/systemd/system/vncserver@:1.service vi /lib/systemd/system/vncserver@.service systemctl daemon-reload systemctl enable vncserver@:1.service systemctl start vncserver@:1.service cat /etc/sysconfig/iptables sudo systemctl stop firewalld.service service vncserver restart rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm yum install epel-release yum install gcc gcc-c++ -y yum install gcc-gfortran -y yum install readline-devel -y yum install libXt-devel -y yum install fonts-chinese tcl tcl-devel tclx tk tk-devel -y yum install mesa-libGLU mesa-libGLU-devel -y yum install -y openssl openssl-devel sudo yum clean all sudo yum install R -y R mkdir /home/conan/R/Rserve -p vi /etc/Rserv.conf vi /home/conan/R/RServe/source.R R CMD Rserve --RS-settings yum install -y openssl openssl-devel R yum install php-mssql -y sudo yum install iodbc R CMD Rserve --RS-enable-remote netstat -ntlp | grep Rserve sudo systemctl stop firewalld.service R CMD Rserve --RS-enable-remote netstat -ntlp | grep Rserve sudo yum install freetds freetds-devel -y sudo yum install unixODBC unixODBC-devel libtool-ltdl libtool-ltdl-devel -y rpm -aq |grep unixODBC vi /etc/freetds.conf tsql -S stock -U zyl -P \u0026quot;zyl\u0026amp;jlch\u0026quot; tsql -S MYSQLSERVER -U cdn -P cdncdn whereis libtdsodbc.so R vi /etc/Rserv.conf whereis libtdsS.so vi /etc/odbcinst.ini vi /etc/odbc.ini isql -v mssql cdn cdncdn yum install samba samba-client samba-common -y mv /etc/samba/smb.conf /etc/samba/smb.conf.bak vi /etc/samba/smb.conf mkdir -p /samba/anonymous systemctl enable smb.service systemctl enable nmb.service systemctl restart smb.service systemctl restart nmb.service R systemctl restart nmb.service firewall-cmd --permanent --zone=public --add-service=samba firewall-cmd --reload ls -l cd /samba chmod -R 0755 anonymous/ chown -R nobody:nobody anonymous/ ls -l anonymous/ chcon -t samba_share_t anonymous/ ls -l anonymous/ groupadd smbgrp useradd srijan -G smbg smbpasswd -a srijan mkdir -p /samba/secured cd /samba chmod -R 0777 secured/ chcon -t samba_share_t secured/ vi /etc/samba/smb.conf systemctl restart smb.service systemctl restart nmb.service testparm cd /samba chown -R srijan:smbgrp secured/ sudo yum clean all yum update -y ps -aux|grep Rserve netstat -nltp|grep Rserve R CMD Rserve --RS-settings mkdir /home/conan/R/RServe -p shutdown -h now cd yum update ifconfig yum install -y xml2 yum install -y curl curl-devel yum install -y xml2 yum install -y curl curl-devel yum install libxml2 libxml2-devel -y yum install -y xml2 yum install -y curl curl-devel shutdown -r now R yum search libxml2* sudo yum install r-base ps -aux|grep rstudio-server sudo systemctl stop firewalld.service yum update -y sudo yum install curl curl-devel -y sudo yum install libxml2 libxml2-devel install.packages(\u0026quot;RCurl\u0026quot;) install.packages(\u0026quot;RCurl\u0026quot;, contriburl = \u0026quot;http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.15/\u0026quot;) R yum install gcc-gfortran -y yum install gcc gcc-c++ yum install readline-devel yum install libXt-devel yum install libxml2 libxml2-devel sudo yum clean all vmstate 1 yum install -y xml2 yum install libxml2 libxml2-devel yum install -y curl curl-devel sudo yum install curl curl-devel sudo yum -y install libxml2 libxml2-devel sudo systemctl stop firewalld.service sudo vi /etc/Rserv.conf vi /home/conan/R/RServe/gljg_ans_1.R sudo vi /etc/Rserv.conf R CMD Rserve --RS-enable-remote systemctl status Rserve systemctl status RServe vncserver systemctl status Rserve R CMD Rserve --RS-enable-remote vi /home/conan/R/RServe/tingyongciku2.txt R CMD Rserve --RS-enable-remote ab yum update -y ps -aux | grep Rserve R CMD Rserve --RS-enable-remote ps -aux | grep Rserve systemctl top pstree systemctl status rserver systemctl status rserver.service systemctl status httpd.service systemctl start httpd.service chkconfig –list systemctl list-unit-files –type=service ls /etc/systemd/system/*.wants/ chkconfig –-list systemctl pstree systemd-cgls ps -aux | grep Rserve systemd-cgls systemctl systemctl status session-12.scope systemctl stop session-12.scope R kill -9 10535 ls ps -aux | grep Rserve shutdown -r now ps -aux | grep Rserve sudo systemctl stop firewalld.service ps -aux | grep Rserve systemctl status session-12.scope history R CMD Rserve --RS-enable-remote systemctl status session-12.scope history 270 systemd-cgls ps -aux | grep Rserve systemd-cgls ps -aux | grep Rserve vmstat 1 ps -aux | grep Rserve sudo systemctl stop firewalld.service ps -aux | grep Rserve vi /home/conan/R/RServe/gljg_ans_1.R vi /home/conan/R/RServe/gljg_ans_1b.R sudo vi /etc/Rserv.conf ps -aux | grep Rserve 8234 kill -9 3033 R CMD Rserve --RS-enable-remote vi /home/conan/R/RServe/gljg_ans_1b.R vi /etc/freetds.conf ps -aux | grep Rserve kill -9 8234 R CMD Rserve --RS-enable-remote vi /etc/freetds.conf vi /home/conan/R/RServe/gljg_ans_1b.R ps -aux | grep Rserve kill -9 8411 R CMD Rserve --RS-enable-remote vmstat 1 history  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/command/bash.html",
	"title": "Command Tips",
	"tags": ["shell"],
	"description": "",
	"content": "some useful commands\nnetstat -ef | grep 8080 netstat -r | grep nginx netstat -a | grep nginx  vmstat 1  sudo systemctl daemon-reload  cat values.yaml | grep -v ^# | grep -v ^$  按日期删除文件\nfind /root/gws_sync/tasks -mtime +7 -name \u0026quot;*.csv*\u0026quot; -exec rm -rf {} \\; \u0026gt;\u0026gt; ./rm.log 2\u0026gt;\u0026amp;1  删除链接\n有创建就有删除\nrm -rf symbolic_name ## 注意不是rm -rf symbolic_name/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn/svn-install-centos.html",
	"title": "Svn Install Centos",
	"tags": ["svn", "install"],
	"description": "",
	"content": "在 centos 下 安装SVN\nyum install subversion -y svnserve --version mkdir svn cd svn pwd rm /root/svn rm /root/svn -p rm /root/svn/ -p rm /root/svn/ cd pwd rm /root/svn/ cd /home mkdir svn cd svn pwd mkdir project svnadmin create /home/svn/project/ cd project/ ls cd conf/ ls vi passwd vi authz vi svnserve.conf svnserve -d -r /var/svn/svnrepos svnserve -d -r /home/svn/project/ ps -aux | grep svn cd home cd /home ls vi test ls svn import test svn://192.168.31.184/home/svn/project/test -m \u0026quot;test\u0026quot; --force-log vi /root/.subversion/servers yum install openssl openssl-devel svn import test svn://192.168.31.184/home/svn/project/test -m \u0026quot;test\u0026quot; --force-log history  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/redis/redis-history.html",
	"title": "Redis History",
	"tags": ["redis"],
	"description": "",
	"content": "之前 31.240 的 redis 的history\n[tom@kube-node-15 redis-3.0.7]$ src/redis-cli Could not connect to Redis at 127.0.0.1:6379: Connection refused not connected\u0026gt; exit [tom@kube-node-15 redis-3.0.7]$ sudo make install cd src \u0026amp;\u0026amp; make install make[1]: Entering directory `/opt/redis-3.0.7/src' Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install make[1]: Leaving directory `/opt/redis-3.0.7/src' [tom@kube-node-15 redis-3.0.7]$ pwd /opt/redis-3.0.7 [tom@kube-node-15 redis-3.0.7]$ [tom@kube-node-15 redis-3.0.7]$ redis-cli Could not connect to Redis at 127.0.0.1:6379: Connection refused not connected\u0026gt; [tom@kube-node-15 redis-3.0.7]$ which redis-cli /usr/local/bin/redis-cli [tom@kube-node-15 redis-3.0.7]$ cd /usr/local/bin [tom@kube-node-15 bin]$ ls redis-benchmark redis-check-aof redis-check-dump redis-cli redis-sentinel redis-server [tom@kube-node-15 bin]$ cd /opt/redis-3.0.7/[tom@kube-node-15 redis-3.0.7]$ cd utils/ [tom@kube-node-15 utils]$ ls build-static-symbols.tcl create-cluster hyperloglog lru redis-copy.rb redis_init_script.tpl speed-regression.tcl cluster_fail_time.tcl generate-command-help.rb install_server.sh mkrelease.sh redis_init_script redis-sha1.rb whatisdoing.sh [tom@kube-node-15 utils]$ [tom@kube-node-15 utils]$ sudo ./install_server.sh Welcome to the redis service installer This script will help you easily set up a running redis server Please select the redis port for this instance: [6379] Selecting default: 6379 Please select the redis config file name [/etc/redis/6379.conf] Selected default - /etc/redis/6379.conf Please select the redis log file name [/var/log/redis_6379.log] Selected default - /var/log/redis_6379.log Please select the data directory for this instance [/var/lib/redis/6379] Selected default - /var/lib/redis/6379 Please select the redis executable path [] /usr/local/bin/redis-server Selected config: Port : 6379 Config file : /etc/redis/6379.conf Log file : /var/log/redis_6379.log Data dir : /var/lib/redis/6379 Executable : /usr/local/bin/redis-server Cli Executable : /usr/local/bin/redis-cli Is this ok? Then press ENTER to go on or Ctrl-C to abort. Copied /tmp/6379.conf =\u0026gt; /etc/init.d/redis_6379 Installing service... Successfully added to chkconfig! Successfully added to runlevels 345! Starting Redis server... Installation successful! [tom@kube-node-15 utils]$ [tom@kube-node-15 utils]$ sudo chkconfig --add redis_6379 [tom@kube-node-15 utils]$ sudo chkconfig --level 345 chkconfig version 1.3.61 - Copyright (C) 1997-2000 Red Hat, Inc. This may be freely redistributed under the terms of the GNU Public License. usage: chkconfig [--list] [--type \u0026lt;type\u0026gt;] [name] chkconfig --add \u0026lt;name\u0026gt; chkconfig --del \u0026lt;name\u0026gt; chkconfig --override \u0026lt;name\u0026gt; chkconfig [--level \u0026lt;levels\u0026gt;] [--type \u0026lt;type\u0026gt;] \u0026lt;name\u0026gt; \u0026lt;on|off|reset|resetpriorities\u0026gt; [tom@kube-node-15 utils]$ sudo chkconfig --level 345 redis_6379 on [tom@kube-node-15 utils]$ sudo reboot  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/perl-rpm-install-offline.html",
	"title": "Perl Rpm Install Offline",
	"tags": ["perl", "install"],
	"description": "",
	"content": "perl rpm install offline\n$ tar -xzf perl-5.x.y.tar.gz $ cd perl-5.x.y $ ./Configure -de $ make $ make test $ make install  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git-github-tips.html",
	"title": "Git常用命令与GitHub使用技巧技巧整理",
	"tags": ["github", "git"],
	"description": "Git常用命令与GitHub使用技巧日常使用命令整理",
	"content": " 1. GitHub中同步远程分支\n查看本地已有分支\ngit remote -v  增加远程分支\ngit remote add upstream https://github.com/k8smeetup/kubernetes.github.io.git git fetch upstream git checkout master git merge upstream/master  2. 更新Git代码并对比\ngit remote -v git fetch origin master git log -p master.. origin/master git merge origin/master  3. 删除远程分支\ngit push origin --delete \u0026lt;branchName\u0026gt; git push origin --delete tag \u0026lt;tagName\u0026gt;  4. 删除所有历史记录\nCheckout\ngit checkout --orphan latest_branch  Add all the files\n git add -A  Commit the changes\n git commit -am \u0026quot;commit message\u0026quot;  Delete the branch\n git branch -D master  Rename the current branch to master\n git branch -m master  Finally, force update your repository\n git push -f origin master  同一台电脑设置多个公钥与不同GITHUB帐号交互  Mac 上SSH-Key对应多个git账号  致谢  yanchengyc Git常用命令与GitHub使用技巧技巧整理  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos-install-mysql-no-network.html",
	"title": "centos install mysql (no network)",
	"tags": ["mysql", "jlch"],
	"description": "",
	"content": " env 需要在 centos 环境下安装 mysql\n192.168.31.175\nstep 下载mysql的rpm安装包\n[root@localhost jlch]# rpm -ivh mysql-community-server-5.7.21-1.el7.x86_64.rpm warning: mysql-community-server-5.7.21-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEY error: Failed dependencies: /usr/bin/perl is needed by mysql-community-server-5.7.21-1.el7.x86_64 mysql-community-client(x86-64) \u0026gt;= 5.7.9 is needed by mysql-community-server-5.7.21-1.el7.x86_64 mysql-community-common(x86-64) = 5.7.21-1.el7 is needed by mysql-community-server-5.7.21-1.el7.x86_64 net-tools is needed by mysql-community-server-5.7.21-1.el7.x86_64 perl(Getopt::Long) is needed by mysql-community-server-5.7.21-1.el7.x86_64 perl(strict) is needed by mysql-community-server-5.7.21-1.el7.x86_64 [root@localhost jlch]#  要安装 perl, 下载\ntar -zxvf perl-5.26.1.tar.gz cd perl-5.26.1 ./Configure -de  报错, 没有cc,gcc\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox/virtualbox-add-vbox.html",
	"title": "virtualbox加载新的image",
	"tags": ["virtualbox"],
	"description": "",
	"content": " 把 从其它地方复制过来的virtualbox 文件, 转移到此机器.\nenv 把 harbor 转移\nstep virtualbox/file/add, choose *.vbox\n发现当文件很大时, virtualbox所有的资源都给它了, 基本上就不能动了.\n从这里看出来, 在生产环境下, 不能使用 virtualbox 这样的形式, 一旦有了类似这样的占用cpu的操作, 其它机器都卡死了.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-rocks-season-1-day-2-notes.html",
	"title": "Spacemacs Rocks Day 2, Use Org-mode to Management Your Time",
	"tags": ["emacs", "spacemacs"],
	"description": "",
	"content": "进入 agenda\n C-c a\n 进入天，再进入周，再返回至天\n C-c a a 选中项目 Rtn w d\n 这样，就可以把它们绑定一下。那怎么绑定呢？\n子龙山人的 `org-agenda-dir` 相关配置，在`~/.spacemacs.d/layers/zilongshanren/config.el`\norg-agenda-dir \u0026quot;~/org-notes\u0026quot; deft-dir \u0026quot;~/org-notes\u0026quot; blog-admin-dir \u0026quot;~/zilongshanren.com\u0026quot;))  所以，这里要替换成自己的。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/ABOUT_BLOG.html",
	"title": "About blog",
	"tags": ["me"],
	"description": "",
	"content": " 关于博客 简单的说一下这个博客的部署。\n这是一个基于Gitbook的电子书，通过markdown语法以及Gitbook约定的文档结构，可以很有逻辑的讲内容展示出来。整个博客项目托管在我个人的github：https://github.com/huangwjwork/gitbook ，然后通过github与我的vps部署的webhook联动：每当有push行为，github就会post一条请求到我vps上的webhook，然后触发我的gitbook脚本，实现博客的自动更新。\n关于Gitbook，想要了解的可以参考这位大佬的博客：http://gitbook.zhangjikai.com/\n关于github的webhook的部署，网上的资源很多，我用的是https://github.com/hustcc/webhookit，内有中文文档\n安装Gitbook 安装node.js 编译安装或者对应的二进制安装\nyum install nodejs  安装Gitbook 国内环境建议修改npm源为淘宝镜像站后再安装\nnpm install gitbook-cli -g gitbook -V  配置gitbook 可以在github上创建一个项目，然后clone到本地，进入项目根目录，执行gitbook init，编辑gitbook.json，SUMMARY.md，README.md，以及.gitignore\nbook.json book.json是gitbook的配置文件，包括插件的配置文件，通过插件可以丰富电子书的功能，有兴趣的可以去官方找找，很多很有意思的插件（插件越多js文件越多，我的vps流量计费，所以我的是乞丐版 T T）\n贴一下我的book.json\ncat book.json { \u0026quot;title\u0026quot;: \u0026quot;huangwjwork's notes\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;好记性不如烂笔头，记录日常遇到的问题及学习的成果\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;huangwjwork\u0026quot;, \u0026quot;output.name\u0026quot;: \u0026quot;site\u0026quot;, \u0026quot;language\u0026quot;: \u0026quot;zh-hans\u0026quot;, \u0026quot;gitbook\u0026quot;: \u0026quot;3.2.3\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;.\u0026quot;, \u0026quot;links\u0026quot;: { \u0026quot;sidebar\u0026quot;: { \u0026quot;Home\u0026quot;: \u0026quot;https://huangwj.app\u0026quot; } }, \u0026quot;plugins\u0026quot;: [ \u0026quot;github@^2.0.0\u0026quot;, \u0026quot;edit-link@^2.0.2\u0026quot;, \u0026quot;anchors@^0.7.1\u0026quot;, \u0026quot;include-codeblock@^3.0.2\u0026quot;, \u0026quot;splitter@^0.0.8\u0026quot;, \u0026quot;tbfed-pagefooter@^0.0.1\u0026quot;, \u0026quot;expandable-chapters-small@^0.1.7\u0026quot;, \u0026quot;anchor-navigation-ex@0.1.8\u0026quot; ], \u0026quot;pluginsConfig\u0026quot;: { \u0026quot;theme-default\u0026quot;: { \u0026quot;showLevel\u0026quot;: true }, \u0026quot;github\u0026quot;: { \u0026quot;url\u0026quot;: \u0026quot;https://github.com/huangwjwork/gitbook\u0026quot; }, \u0026quot;include-codeblock\u0026quot;: { \u0026quot;template\u0026quot;: \u0026quot;ace\u0026quot;, \u0026quot;unindent\u0026quot;: true, \u0026quot;edit\u0026quot;: true }, \u0026quot;tbfed-pagefooter\u0026quot;: { \u0026quot;copyright\u0026quot;: \u0026quot;Copyright © huangwjwork 2017\u0026quot;, \u0026quot;modify_label\u0026quot;: \u0026quot;该文件修订时间：\u0026quot;, \u0026quot;modify_format\u0026quot;: \u0026quot;YYYY-MM-DD HH:mm:ss\u0026quot; }, \u0026quot;edit-link\u0026quot;: { \u0026quot;base\u0026quot;: \u0026quot;https://github.com/huangwjwork/gitbook/edit/master\u0026quot;, \u0026quot;label\u0026quot;: \u0026quot;Edit This Page\u0026quot; }, \u0026quot;anchor-navigation-ex\u0026quot;: { \u0026quot;isRewritePageTitle\u0026quot;: false, \u0026quot;tocLevel1Icon\u0026quot;: \u0026quot;fa fa-hand-o-right\u0026quot;, \u0026quot;tocLevel2Icon\u0026quot;: \u0026quot;fa fa-hand-o-right\u0026quot;, \u0026quot;tocLevel3Icon\u0026quot;: \u0026quot;fa fa-hand-o-right\u0026quot; } } }  编写完成后在book.json文件目录执行如下命令安装插件\ngitbook install  SUMMARY.md 概要文件主要存放 GitBook 的文件目录信息，左侧的目录就是根据这个文件来生成的，它通过 Markdown 中的列表语法来表示文件的层级关系，下面是一个简单的示例：\n# Summary * [Introduction](README.md) ----- * [个人简历](ABOUT_ME.md) ----- * [关于博客](ABOUT_BLOG.md) ----- * [知识库](knowledge.md) * [操作系统](OS/os.md) * [Linux](OS/linux/linux.md) * [windows](OS/win/windows.md) * [Unix](OS/unix/unix.md)  编写完成后，可以执行init命令让gitbook自动生成上述目录结构\n$ gitbook init info: create SUMMARY.md info: initialization is finished  README.md 电子书的主页，可以在book.json中修改\n.gitignore 由于生成电子书时会产生大量的nodejs文件以及_gitbook的电子书文件，建议配置.gitignore\n[huangwj@instance-1 ~]$ cat /opt/huangwj/gitbook/.gitignore /_book/ /node_modules/  生成gitbook电子书 主要配置文件编辑完成后，就可以生成gitbook电子书，默认生成html，可以在本地起服务查看，也可以将html拷贝到web服务器下查看\n 本地查看，默认端口4000，可以更改  $ gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 41 plugins are installed info: 15 explicitly listed info: loading plugin \u0026quot;github\u0026quot;... OK info: loading plugin \u0026quot;edit-link\u0026quot;... OK info: loading plugin \u0026quot;anchors\u0026quot;... OK info: loading plugin \u0026quot;include-codeblock\u0026quot;... OK info: loading plugin \u0026quot;splitter\u0026quot;... OK info: loading plugin \u0026quot;tbfed-pagefooter\u0026quot;... OK info: loading plugin \u0026quot;expandable-chapters-small\u0026quot;... OK info: loading plugin \u0026quot;anchor-navigation-ex\u0026quot;... OK info: loading plugin \u0026quot;livereload\u0026quot;... OK info: loading plugin \u0026quot;highlight\u0026quot;... OK info: loading plugin \u0026quot;search\u0026quot;... OK info: loading plugin \u0026quot;lunr\u0026quot;... OK info: loading plugin \u0026quot;sharing\u0026quot;... OK info: loading plugin \u0026quot;fontsettings\u0026quot;... OK info: loading plugin \u0026quot;theme-default\u0026quot;... OK info: found 26 pages info: found 27 asset files warn: \u0026quot;options\u0026quot; property is deprecated, use config.get(key) instead info: \u0026gt;\u0026gt; generation finished with success in 5.0s ! Starting server ... Serving book on http://localhost:4000  部署webhook并与github联动 安装webhookit 安装webhookit，并生成默认配置文件，请注意自己的Python环境，调用相应的pip\npip install webhookit webhookit_config \u0026gt; /opt/webhook/webhook_for_github.conf  修改配置文件\n ​ 如果执行脚本在webhook本机，只需要修改如下两个参数  repo_name/branch_name修改成自己的项目名称和分支名 SCRIPT写入自己要执行的脚本   [huangwj@instance-1 ~]$ cat /opt/webhook/webhook_for_github.conf # -*- coding: utf-8 -*- ''' Created on May-25-18 19:10:16 @author: hustcc/webhookit ''' # This means: # When get a webhook request from `repo_name` on branch `branch_name`, # will exec SCRIPT on servers config in the array. WEBHOOKIT_CONFIGURE = { # a web hook request can trigger multiple servers. 'gitbook/master': [{ # if exec shell on local server, keep empty. 'HOST': '', # will exec shell on which server. 'PORT': '', # ssh port, default is 22. 'USER': '', # linux user name 'PWD': '', # user password or private key. # The webhook shell script path. 'SCRIPT': '/opt/huangwj/scripts/gitbook_update.sh \u0026gt; /opt/huangwj/scripts/gitbook_update.log' }] }  我的脚本\n[huangwj@instance-1 scripts]$ cat gitbook_update.sh #!/bin/bash source /etc/profile source /home/huangwj/.bash_profile date cd /opt/huangwj/gitbook git pull gitbook install gitbook build  启动webhookit webhookit -c /opt/webhook/webhook_for_github.conf -p port  启动完成后即可访问localhost:port查看webhook的信息及推送的URL，在github填入URL并配置type为json即可。\n配置github 项目——setting——webhook——ADD webhook\n payload URL：填写webhookURL Content type ：application/json  触发条件可选，我这里选择的是Just the push event. "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/ABOUT_ME.html",
	"title": "About me",
	"tags": ["me"],
	"description": "",
	"content": "Nothing in the world can take the place of Persistence. Talent will not; nothing is more common than unsuccessful men with talent. Genius will not; unrewarded genius is almost a proverb. Education will not; the world is full of educated derelicts. Persistence and Determination alone are omnipotent. The slogan \u0026ldquo;Press On\u0026rdquo; has solved and will always solve the problems of the human race.\n本人正在寻找一位前端工程师，希望一起加油，有意向的可以联系我！\n想联系，加微信!\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/chedan/chedan.html",
	"title": "chat",
	"tags": ["me"],
	"description": "",
	"content": " 瞎扯淡 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/chedan/goal.html",
	"title": "target",
	"tags": ["me"],
	"description": "",
	"content": " 自己的小目标 睡觉睡到自然醒 数钱数到手抽筋  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/README.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Blog Gitbook 此书是我的博客的阅读与理解，帮助大家更快了解我对技能的管理和使用。\n GitHub地址：https://github.com/eiuapp/blog-markdown/\n 在线访问地址：https://eiuapp.github.io/\n  相关资源 关于 本书中引用了一些公开的分享与链接并加以整理。\n本书作于2019年初，会持续更新。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/SUMMARY.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Summary  Introduction   关于  个人简历 关于博客 关于配置 关于作品 理想与现实  自己的小目标 Life  Life Film Life Healthy health      apple  注册香港ID  cloud-native  awesome  aws  教你如何找到AWS Access Key ID and Secret Access Key  kubernetes  rancher备份  bitbucket  bitbucket组来实现不同用户间的共同管理某一个具体repo  blockchain  blockchain note Eth Erc20 Create Xcoin Eth Token Release  org  使用org-mode和ox-hugo写文档 shane sveller blog 笔记 quickly create a new draft post  hugo  使用 hugo-algolia 进行文章内容搜索 使用org-mode和ox-hugo写文档 一位大神的线上deploy shell shane sveller blog 笔记 使用hugo的hugo-material-docs主题模板来构建书籍  centos  CentOS6上ftp服务器搭建实战 centos install mysql (no network) centos6.9开放ftp(vsftpd)的21端口 CentOS查看系统版本及查看机器位数x86-64 centos更新内核 Centos Yum gcc rpm 安装包下载安装 Ip Config Centos Mount Ntfs Base Centos Telnet Install Update Kernel Base Centos  ceph  ceph auth cephfs 安装 ceph安装，基于docker ceph-install-base-ubuntu Block Device Quick Start ceph安装FAQ ceph-install-base-ubuntu Filesystem Quick Start ceph 安装，基于ubuntu系列 ceph 安装，基于ubuntu ceph-install-base-ubuntu Object Storage Quick Start ceph-install-base-ubuntu quick-start-preflight ceph-install-base-ubuntu READM ceph-install-base-ubuntu Storage Cluster Quick Start ceph 安装 系列 ceph intro  常用命令  bash常用命令 gem常用命令 git常用命令 hexo常用命令 linux常用命令 mac常用命令 mysql常用命令 nodejs-npm常用命令 python常用命令 curl常用命令 docker常用命令 Cheatsheet  Django  Django Install using-django中的queries django中测试https  docker 系列  docker build时运行 COPY 时报no such file or directory 错误 docker-compose安装后报specify DOCKER_HOST错误 Docker Install Base Centos Docker Install Base Ubuntu ubuntu中安装docker docker 登陆失败 docker login failure, unauthorized: incorrect username or password Docker Pull With Proxy Docker Registry Install For Jlch Docker Registry Install docker registry Docker Registry Mirrors Base Ubuntu docker-registry-push-pull docker registry ui 批量删除docker images docker 安装 saleor 把用户加入docker组 build dockerfile常见问题 windows安装docker docker使用常见问题 docker save and docker load  hugo  关于 hugo, easy-hugo, ox-hugo, spacemacs 集成相关的问题  emacs  Emacs Flycheck Eslint ubuntu安装最新emacs emacs中启动markdown preview 解决Mac下emacs中alt键不能使用问题 eshell 中 没有完全加载 .zshrc 中的配置 emacs下使用hugo写文档 Emacs与Jupyter notebook之间的集成 easy-hugo使得Hugo中可以使用Org写文档 spacemacs(笔记) spacemacs配置python3环境 yasnippet-setup 在win10上安装emacs  Enterprise  Enterprise Idea Environment About It  Git  Git Faq Git From Outside Git常用命令与GitHub使用技巧技巧整理 git配置公私钥别名 git中submodule子模块的添加、使用和删除 Git Workflow  Github  Git常用命令与GitHub使用技巧技巧整理 Github Star Management Github Travis travis分支白名单导致无法构建 Gitlab Authority github做Markdown图床  Gitlab  gitlab修改密码 Gitlab CI Step by Step Gitlab汉化 Gitlab Install Base Ubuntu14.04 Gitlab Install Gitlab Workflow Gitlab 之 Gitbook 自动集成  Golang  golang channel Golang Gvm Golang Ide Gogland Golang Import Packages Golang Install go-tour-zh离线安装(本地安装) golang channel 的 另一人的理解  Chrome  Google Chrome Helper Google Chrome Setup chrome工具  stock  Hedge Fund 量化小学Lecture4的笔记 Jaqs安装笔记 Stock Iwencai Crawler Stock Iwencai Stock Trade Discipline  Hexo  Hexo Hello World Hexo Tomtsang  Hugo  Hugo Gitment emacs下使用hugo写文档 Hugo Install Base Win10 jane主题中安装百度统计 使用hugo的jane主题时，categories 书写不规范 easy-hugo使得Hugo中可以使用Org写文档 hugo-server-faq  Javascript  Javascript Faq Javascript Type  kubernetes系列  jd.com从openstack转到kubernetes kubeadm build 更新kubeadm clusters 从v1.7.3至v1.8.3 flannel网络模式下ping出错 运行 kubeadm init 之前 使用本地镜像进行kubeadm init ubuntu中安装kubeadm kubeadm-kubelet-cni kubeadm v1.8.3 安装 kubeadm join kubeadm从v1.8.3更新至v1.8.4失败 ubuntu中安装kubeadm v1.8.4 kubernetes中cephfs的deployment的FAQ k8s 与 cephfs 相关的FAQ kubernetes cephfs intro kubernetes-cephfs-make-by-go-get cephfs-k8s 中的 make kubernetes cephfs README 使用 cephfs 完成 statefulset 的练习 k8s 中 cephfs 成功的 yaml 文件 kubernetes delete node Kubernetes Deployment Rollingupdate Kubernetes Heapster Install k8s安装系列 kubernetes 使用 nfs 存储 Kubernetes Role kubernetes storage  linux  Can scp create a directory if it doesn\u0026rsquo;t exist? Shell(Bash)中如何判断是否存在某个命令 Grep Exclude Many File 命令行下如何安装或者更新 CA.crt 文件 How to Install Certificates for Command Line Linux Add Format Mount Harddisk Linux Boot No Enough Space Linux Change Disklabel linux 关闭SSH 连接用户 ubuntu 获取 系统版本信息 Linux Http Proxy Linux Install Ab Httpd Tools Linux Kill Tty linux 软连接 不能加/号 Linux No Passwd Login Linux Port Process Linux Swap Linux Wgetrc Wget Proxy Mailserver Postfix Mount Route linux sed 批量替换字符串 Shell获取某目录下所有文件夹的名称 shell批量替换文件扩展名 Ssh Login ssh登录时如何直接在参数中加入登录密码 vi撤销与恢复撤销 Vsftp Add User linux下删除dos行尾符 命令行高效命令 linux中cp文件夹并过滤文件 mkfs.xfs command not found ssh不能直接免密码登录 zshrc文件中应使用$HOME System is booting up. See pam_nologin(8)  mac  mac 下应该怎么安装 bundle Iterm2 Hotkey mac 上安装 sshpass Mac Faq Mac下为什么有的文件名后带一个*星号 mac 系统中文件的软链接、硬链接 Mac Install Software Mac Iterm2 Ohmyzsh Install Mac Faq Macos Apple Id America Mac Rar Unrar Mac上SSH-Key对应多个github账号 Mac Sed mac tips 在mac zsh下，ls只显示文件名 Yarn Install  Markdown  Markdown Comments Markdown Style Guide  Mongodb  Mongodb Distinct Mongodb Findoneandupdate Mongodb Output Import Mongodb Replace Mongodb Update  Mariadb  Mariadb Cluster Install Base Centos Mariadb Galera Cluster Install Faq Base Centos Mariadb Galera Base Docker Coreos Mariadb Galera Base Docker Mariadb Galera Cluster Install Base Centos Mariadb Galera Cluster on Coreos With Docker Ref EgoAleSum Mariadb Galera From Docker to Bare Mariadb Galera Install Base Centos Mariadb Galera Panubo2 Base Docker Mariadb Galera Panubo Base Docker Mariadb Install Base Centos Mariadb Install  Nginx  Nginx Config Server_name Nginx Faq 1 Nginx Faq 2 Nginx Seo Nginx Servername 记一次nginx漏洞补救 ubuntu 安装 nginx nginx修改cookie path  Mysql  Mysql Config Mysql Config Server.conf Mysqldump Faq Mysql Install 2 Base Centos Mysql Install Rpm Mysql Length Mysql Mysqlslap Mysql Navicat Mysql Passwd Mysql Secure Installation Mysql Use Mysql User Create Mysql User mysql cluster 基于centos mysql cluster infile 安装过程中不能设置mysql密码 mac中navicat连接mysql后报61错误码 mysql 常用用法 Completly remove Mysql from Ubuntu 通过java代码去查找mysql密码  nodejs  Nodejs Faq Unexpected Token Function nodejs 一定要通过 nvm安装 Nodejs Mongodb Nodejs Npm Faq 1 Nodejs Tofixed Nodejs Version.md) 使用nvm安装nodejs 在 ubuntu12 下 nodejs系列之pm2开机自启动  Network  Network Proxy Iphone ubuntu docker change ufw rules linux下使用privoxy将socks转为http代理 Network Proxy Shadowsocks Server ubuntu搭建SS客户端 Network Proxy Win10 [Ngrok Multi User Tunnel](post/ngrok-multi-user-tunnel 让部分软件不使用expressvpn代理 ubuntu-reboot-cannot-ping-qq Ngrok Server Install(搭建自己的ngrok服务器) Ngrok Ssh Privoxy Mac Proxy  shop  django-oscar(笔记) saleor  saleor 设置 templates base docker 安装 saleor saleor 测试（笔记） saleor 常见问题  初始化安装 taro-msparis  gitbook  gitbook（笔记） gitbook book.json介绍  tmux  tmux（笔记） wemux (笔记) tmuxinator（笔记）  org  使用Org写Blog org-mode-set-org-directory org-折行显示  resource  blockchain资源 ddos资源 docker资源 emacs资源 erp-golang资源 golang资源 kubernetes资源 mac资源 nodejs资源 python资源 resource资源 tools资源  other  RST(reStructuredText)转换为MD(Markdown) devops ideas Charts Code Style Gem Install Faq 浏览器则不能连接FTP服务器 通过Gmail设置企业邮箱 Host Protection Html Decoder kids code Mastercard Icard Tapngo Registry Keyboard Perl Rpm Install Offline Php Install Base Ubuntu Project Ok R Rstudio Vnc Install Centos Realtek Shengyin WeChat Send Messages eslint入门  Python  jupyter-notebook 密码查询 Emacs与Jupyter notebook之间的集成 Microservices Python pipenv install 报错 python搭建多个互不干扰的开发环境 Python Faq Openssl Python Install Pip Python Install Pip With Get Pip Py Python Install Setuptools Python Install Uwsgi python面试准备roadmap Python Pip Install Ssl Module Not Available Python Pip Install Virtualenv mac中python安装pyenv python小技巧 Python Upgrade Version Base on Centos Python Zlib Module Missing python报bad interpreter duplicate ubuntu 安装 pip pip安装memcache python：struct模块的pack、unpack  Qor  Qor Admin Test Change Sidebar Qor Admin Test Qor Character Set Database Utf8 Qor Doc Get Started Qor Admin Test Change Title Qor Example Install  Rancher  How to Run Gitlab in Rancher 1 Rancher2 Install Base Aws Ubuntu Rancher Add Worker Rancher Node Driver Add Aliyun Rancher Service Discovery Rancher Single Node Install  Redis  Redis History Redis Install  spacemacs  [spacemacs安装]()  借助 MobaXterm 使得 wsl-ubuntu 在 win10 下可使用 spacemaces (未完成)借助 vcxsrv 使得 wsl-ubuntu 在 win10 下可使用 spacemaces 在win10上安装spacemacs 在win10上安装spacemacs常见问题 安装 Package 失败  spacemacs 在ubuntu下的配置思考 spacemacs key binding Spacemacs Qa 1 Spacemacs Use Zilongshanren Spacemacs Private [Spacemacs Rocks]()  Spacemacs Rocks Day 0, Intro Spacemacs Rocks Day 1, Features \u0026amp; Workflow Spacemacs Rocks Day 2, Use Org-mode to Management Your Time Spacemacs Rocks Day 3, Emacs as a C/C++ IDE Spacemacs Rocks Day 4, Magit workflow Spacemacs Rocks Day 5, Find, Search and replace Spacemacs Rocks Day 6, Org-mode as a blogging engine Spacemacs Rocks Day 7, Spacemacs buffer, file, project and layout management Spacemacs Rocks Day 8, Spacemacs as a JavaScript/Node.js IDE Spacemacs Rocks Day 9, spacemacs as a life style Spacemacs Rocks Day 10, spacemacs tutor Spacemacs Rocks Day 11, spacemacs use daily   Svn  Svn Add Projects Svn Authorization Failed Svn Install Centos Svn Permission Configuration Svn Remove User Name Passwd  learn\n Today Learn blockchain学习 golang学习  jwl\n job\n Telephone Interview  tools\n web框架 Software Architect  ubuntu\n ubuntu16.04升级内核至 4.10 以上 Ubuntu Apt Http Proxy Ubuntu Command Not Found set apt source Ubuntu Desktop 环境安装 Ubuntu Install Faq A Change System Datetime Base Ubuntu Ubuntu Install Wubipinyin Ubuntu Share File to Virtulbox Win7 Keyboard Ubuntu Update Kernel Base Ubuntu Static Ip Ubuntu18 Teamviewer Install Base Ubuntu Yapi Install Base Ubuntu Tomcat Install Base Ubuntu  windows\n U Shendu Win10 Share Files Xshell Ubuntu Transmitter File Windows的四种链接方式 Windows下效率必备软件 windows wsl 子系统 windows笔记 windows包管理工具 scoop autohotkey 用法 搭建优雅的windows开发环境  virtulbox\n 在vmware workstation pro 中给ubuntu增加新分区 virtualbox加载新的image Virtualbox Install Ubuntu Desktop Virtualbox Share File Virtualbox Share Pasteboard vmware创建新VM（从其它机器中复制VM方式） Vmware Workstation vmware workstation pro 安装  Vscode\n Vscode Change File Eol Vscode Extensions vscode integrated terminal and git  Zabbix\n Zabbix Install Base Docker  babun\n babun 中 zsh tab 失效 最快入门 babun babun安装tmuxinator  convert\n html转markdown markdown转org  源码分析\n cmder笔记\n gvm笔记\n programmer-competency-matrix\n [yapi]\n 安装yapi通过docker yapi-practices 记一次yapi的迁移过程 api-format  [ruby]\n install rvm with ubuntu  在有java源码的情况下，找到mysql用户密码\n Ubuntu18.04配置Java环境和安装Tomcat的方法（详细）\n   知识库  操作系统  Linux  https认证逻辑  windows Unix  数据库  mysql redis  监控系统  zabbix  python实现zabbix告警推送钉钉  prometheus  functions函数 storage  ELK  web服务器  nginx  nginx学习笔记  nginx基础 nginx服务器架构初探 nginx服务器的高级配置 gzip压缩 Rewrite proxy nginx缓存    虚拟化  docker kubernetes  基于RBAC实现dashboard只读-view权限 kubernetes权威指南读书笔记  基础概念 pod详解 service详解 核心原理 集群安全机制 日志收集  企业实践整理     "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/centos/centos.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "centos\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ceph/ceph.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "ceph\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/cheatsheets/efficient-command.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 高效命令\nenv os: linux or mac\nstep .zshrc or .bashrc alias ip='osascript -e \u0026quot;IPv4 address of (system info)\u0026quot;' # Mac 下命令行查看本机 IP alias cls='clear' alias ll='ls -l' alias la='ls -a' alias vi='vim' alias javac=\u0026quot;javac -J-Dfile.encoding=utf8\u0026quot; alias grep=\u0026quot;grep --color=auto\u0026quot; alias -s html=mate # 在命令行直接输入后缀为 html 的文件名，会在 TextMate 中打开 alias -s rb=mate # 在命令行直接输入 ruby 文件，会在 TextMate 中打开 alias -s py=vi # 在命令行直接输入 python 文件，会用 vim 中打开，以下类似 alias -s js=vi alias -s c=vi alias -s java=vi alias -s txt=vi alias -s gz='tar -xzvf' alias -s tgz='tar -xzvf' alias -s zip='unzip' alias -s bz2='tar -xjvf' # alias cdhome='cd ~' alias cdroot='cd /' alias gpull='git pull' alias gci='git commit -a' alias gpush='git push origin HEAD:refs/for/master' alias gst='git status' alias sublime='open -a \u0026quot;Sublime Text\u0026quot;' # 加入Sublime Text  ref  https://www.jeffjade.com/2015/07/29/2015-07-29-mac-musthave-software/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/chrome/chrome-tools.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " extensions https://www.zhihu.com/question/19594682\nvimium\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/chrome/chrome.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "chrome\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/code-analysis.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "关于 代码 分析，可以看下面网站\nhttps://github.com/mre/awesome-static-analysis https://github.com/vinta/awesome-python#code-analysis https://www.owasp.org/index.php/Source_Code_Analysis_Tools https://lgtm.com/help/lgtm/about-lgtm\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/ddd.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " DDD的好书哪家强？ 以前daxnet有个系列博客不错\n那个apworks框架原理能吃透就基本完全搞定DDD了，就是可惜是C#\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/dev/programmer-competency-matrix.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " programmer-competency-matrix http://www.starling-software.com/employment/programmer-competency-matrix.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/django/django-runserver-https-ssl.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " How can I test https connections with Django as easily as I can non-https connections using \u0026lsquo;runserver\u0026rsquo;?\n解决方式1 https://stackoverflow.com/questions/8023126/how-can-i-test-https-connections-with-django-as-easily-as-i-can-non-https-connec/28933593#28933593\n解决方式2 Similar to django-sslserver you could use RunServerPlus from django-extensions\nIt has dependencies on Werkzeug (so you get access to the excellent Werkzeug debugger) and pyOpenSSL (only required for ssl mode) so to install run:\npip install django-extensions Werkzeug pyOpenSSL\nAdd it to INSTALLED_APPS in your projects settings.py file:\nINSTALLED_APPS = ( ... 'django_extensions', ... )  Then you can run the server in ssl mode with:\n./manage.py runserver_plus --cert /tmp/cert  This will create a cert file at /tmp/cert.crt and a key file at /tmp/cert.key which can then be reused for future sessions.\nThere is a bunch of extra stuff included in django-extensions that you may find of use so it is worth having a quick flick through the docs.\n实操 上面的整个原理是正确的，但是，在实操的时候，因为包兼容的问题，出现了报错。\npython manage.py runserver_plus --cert-file ./server.crt  确认一下 是不是添加进了 installed-app\n确认一下包是不是安装了\n那就没有理由会报错了。那可能是安装依赖的问题了。\n通过 python 后 import OpenSSL 果然，发现错误了。\n最后发现是错误在 cryptography 这个包上了。\nimport cryptography 后就报错，那就尝试把 包降一下版本，版本查找在这里。\n把 cryptography 降低到 2.3.1 就可以了。\n然后 import OpenSSL 成功。\npython manage.py runserver_plus --cert-file ./server.crt  成功。问题解决。\nref  https://stackoverflow.com/questions/8023126/how-can-i-test-https-connections-with-django-as-easily-as-i-can-non-https-connec/28933593#28933593  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/django/django.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "django\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-build-dockerfile-faq.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " error之 /var/lib/dpkg/), are you root? RUN apt-get update apt install curl\n报错如下：\n ---\u0026gt; Running in c865716a2694 E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied) E: Unable to lock directory /var/lib/apt/lists/ E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied) E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?  这里已经提示没有权限了，所以这里很可能是在这步操作上，用户切换成非root用户了。\nhttps://stackoverflow.com/questions/32576928/how-to-install-new-packages-into-non-root-docker-container\nsource 命令 Step 12 : RUN source /usr/local/bin/virtualenvwrapper.sh ---\u0026gt; Running in c13a187261ec /bin/sh: 1: source: not found  遇到source命令，可以使用下面方式\nRUN /bin/bash -c \u0026quot;source /usr/local/bin/virtualenvwrapper.sh\u0026quot;  https://cloud.tencent.com/developer/ask/70733\noh-my-zsh-install-in-docker-fail RUN sh -c \u0026quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\u0026quot;  这样安装会报下面的错\nPassword: chsh: PAM: Authentication failure  使用下面安装语句, 开始的时候有效，后来又失效了。\nRUN set -uex; \\ wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh; \\ sh ./install.sh; \\ rm ./install.sh  在安装的时候注意安装的用户哟。\nRUN sh -c \u0026quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\u0026quot;; exit 0;`  还有一种思路是下面这种，但是我没有尝试 sudo chsh $USER -s $(which zsh)  https://stackoverflow.com/questions/42262908/oh-my-zsh-install-in-docker-fail https://github.com/robbyrussell/oh-my-zsh/issues/1224#issuecomment-31623113\n缓存 docker的build操作，默认是基于缓存，也就是你修改Dockerfile后，build任务会快速略过你之前成功的步骤，从你修改的那一步之后的操作，都会重新运行。 如果你想每一次build都不基于之前的缓存，在build 命令加上 \u0026ndash;no-cache=true 参数 另外可以参见：\nDockerfile最佳实践\nhttps://tuxknight-notes.readthedocs.io/en/latest/docker/dockerfile_best_practices_take.html https://segmentfault.com/q/1010000004301005\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-install-with-windows.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " win10家庭版安装Docker\nhttps://blog.csdn.net/tidu2chengfo/article/details/84892915\nenv  os: windows 10 HOME  step 安装前准备 进入任务管理器看虚拟化是否已启用。 如果你满足Docker for Windows的环境条件了，那么首先检查电脑的虚拟化开启了没有：进入任务管理器（ctrl+alt+delete），点击性能-\u0026gt;cpu ,查看虚拟化是否已启用，如果虚拟化是已禁用，那么你需要重启电脑进入bios开启虚拟化（我们的发的笔记本cpu都是支持虚拟化的，重启时进入bios按esc -\u0026gt; 再按f12 -\u0026gt; 去开启虚拟化）\n开启虚拟化重启后，进入任务管理器看虚拟化是否已启用。\n使用Coreinfo工具软件 (下载地址）来查看电脑是否支持Hyper-V 可以使用Coreinfo工具软件 (下载地址）来查看电脑是否支持Hyper-V，这是微软SysinternalsSuite工具软件套件中的一个，很实用。具体使用方法，把下载好的Coreinfo解压到桌面上，用管理员模式打开PowerShell，输入：.\\ Coreinfo.exe -v，将显示你电脑虚拟化的相关信息，当然你已经添加了Hyper-V了，就无需使用这个软件了。下图所示的内容表明笔者电脑的CPU是完全支持Hyper-V的。\nWindows 10家庭版 能够安装HYPER-V 其中涉及一个 cmd 文件。也就是把下面的代码，保存到一个 *.cmd 文件中，比如，我保存成 install-hyper-v.cmd 中\npushd \u0026quot;%~dp0\u0026quot; dir /b %SystemRoot%\\servicing\\Packages\\*Hyper-V*.mum \u0026gt;hyper-v.txt for /f %%i in ('findstr /i . hyper-v.txt 2^\u0026gt;nul') do dism /online /norestart /add-package:\u0026quot;%SystemRoot%\\servicing\\Packages\\%%i\u0026quot; del hyper-v.txt Dism /online /enable-feature /featurename:Microsoft-Hyper-V-All /LimitAccess /ALL  然后 打开 cmd 命令行，输入 .\\install-hyper-v.cmd 就运行起来了。\n修改注册表 修改前\n修改后\n下载安装文件【Docker for Windows Installer.exe】 https://docs.docker.com/docker-for-windows/install/\n重新启动安装文件，完成安装，重启电脑后，托盘上出现docker图标 docker 使用 参考 https://blog.csdn.net/hunan961/article/details/79484098\nref  https://blog.csdn.net/tidu2chengfo/article/details/84892915 https://www.ithome.com/html/win10/374942.htm https://blog.csdn.net/hunan961/article/details/79484098 https://www.cnblogs.com/hager/p/7477270.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-save-load.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " docker save and docker load https://blog.csdn.net/weixin_36343850/article/details/80553680\ndocker save vagrant@ubuntu-xenial:~$ docker stop some-redis some-redis vagrant@ubuntu-xenial:~$ docker ps -a | grep some-redis b3e246f35c82 redis:5.0.4 \u0026quot;docker-entrypoint.s…\u0026quot; 2 weeks ago Exited (0) 2 seconds ago some-redis ubuntu-xenial:~$ docker commit some-redis some-redis-save sha256:69ee84b5567bf37f24b81669f7341b6c9730d3a9b78b95d908b22a2cdcc334bd vagrant@ubuntu-xenial:~$ docker images | grep some-redis REPOSITORY TAG IMAGE ID CREATED SIZE some-redis-save latest 69ee84b5567b 9 seconds ago 95MB vagrant@ubuntu-xenial:~$ docker save -o some-redis-save.tar some-redis-save  docker load ubuntu@utuntu:~$ docker load -i ./some-redis-save.tar 5dacd731af1b: Loading layer [==================================================\u0026gt;] 58.45MB/58.45MB b52995330c04: Loading layer [==================================================\u0026gt;] 338.4kB/338.4kB 1540700d9a4f: Loading layer [==================================================\u0026gt;] 3.034MB/3.034MB f3918e45d85b: Loading layer [==================================================\u0026gt;] 36.43MB/36.43MB 290c0f1ac500: Loading layer [==================================================\u0026gt;] 1.536kB/1.536kB f02e80b7746e: Loading layer [==================================================\u0026gt;] 3.584kB/3.584kB Loaded image: some-redis-save:latest ubuntu@utuntu:~$ ls some-redis-save.tar ubuntu@utuntu:~$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE some-redis-save latest 69ee84b5567b 3 minutes ago 95MB hello-world latest fce289e99eb9 4 months ago 1.84kB  但是这里的镜像，没有把层拿过来，导致，我pull redis:5.0.4依然要去 hub.docker.com 中拉取\nubuntu@utuntu:~$ docker pull redis:5.0.4 5.0.4: Pulling from library/redis 743f2d6c1f65: Pull complete 171658c5966d: Pull complete fbef10bd7a65: Pull complete 98afd60e45e4: Pull complete 495c87fda859: Pull complete ed6767858416: Pull complete Digest: sha256:2dfa6432744659268d001d16c39f7be52ee73ef7e1001ff80643f0f7bdee117e Status: Downloaded newer image for redis:5.0.4  start ubuntu@utuntu:~$ docker run --name some-redis -p 6379:6379 -v /home/ubuntu/docker/data/some-redis:/data -d some-redis-save redis-server --appendonly yes d08919c3edeb529c8dc2f424ccba548652fcd84afa6422ff7fe3c505f60c5f0f ubuntu@utuntu:~$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d08919c3edeb some-redis-save \u0026quot;docker-entrypoint.s…\u0026quot; 3 seconds ago Up 1 second 0.0.0.0:6379-\u0026gt;6379/tcp some-redis ubuntu@utuntu:~$ docker exec -it some-redis bash root@d08919c3edeb:/data# ls -a . .. appendonly.aof root@d08919c3edeb:/data# redis-cli 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; exit root@d08919c3edeb:/data# exit exit ubuntu@utuntu:~$ ubuntu@utuntu:~$ ls ~/docker/data/some-redis/ -a . .. appendonly.aof docker some-redis-save.tar ubuntu@utuntu:~$ telnet 127.0.0.1 6379 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is '^]'. ^] telnet\u0026gt; quit Connection closed. ubuntu@utuntu:~$  mysql 之 docker save, docker load mysql 之 docker save, docker load。 发现 mysql 本身的数据，没有随 docker save image 迁移\n那么这时，要完成mysql数据的迁移，就要完成下面几步：\n docker 中的数据，则只能 mysqldump 成 sql文件, docker exec -it mysql03 mysqldump -uroot -p123456 lcnx_20190512 \u0026gt; /home/vagrant/mysql03-lcnx_20190512.sql 然后，scp到新机器，scp mysql03-lcnx_20190512.sql ubuntu@lanServer:/home/ubuntu/docker/container/mysql03/ 然后，新机器, create database, CREATE DATABASE IF NOT EXISTS lcnx_20190512 CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; 然后，进入 docker container, docker exec -it mysql03-20190525 bash 进入 mysql, mysql -uroot -p 然后source *.sql文件. source /root/mysql03-lcnx_20190512.sql; 如果报错，看下面的内容。  https://gist.github.com/spalladino/6d981f7b33f6e0afe6bb https://blog.csdn.net/qq_37674858/article/details/80082903\n# Backup docker exec CONTAINER /usr/bin/mysqldump -u root --password=root DATABASE \u0026gt; backup.sql # Restore cat backup.sql | docker exec -i CONTAINER /usr/bin/mysql -u root --password=root DATABASE  试问，有没有更好的在docker间迁移mysql的方式？\nmysql 之 docker volume https://www.cnblogs.com/JacZhu/p/7835237.html\n利用 Docker 备份、迁移数据库 最近在把腾讯云的国内主机迁移到香港主机，因为之前使用的 MySql 跟 MongoDb 都是基于 Docker 部署的，所以迁移起来还算比较方便，主要思路就是把数据库容器的数据卷单独做成一个数据镜像，然后把这个镜像提交到香港主机上面的私有仓库，最后用这个镜像生成一个数据容器挂载到应用容器上就好了。 1. 备份数据卷 docker run --rm --volumes-from data-container-backup --name tmp-backup -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /folderToBackup #Example: Backup mysql database docker run --rm --volumes-from blog-mysql --name tmp-backup -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /var/lib/mysql --rm 用来创建一个“用完即销”的容器，--volumes-from 用来把一个已有容器上挂载的卷挂载到新创建的容器上 2. 创建数据容器 docker run -d -v $(pwd):/backup --name data-backup alpine /bin/sh -c \u0026quot;cd / \u0026amp;\u0026amp; tar xvf /backup/backup.tar\u0026quot; 3. 推送数据容器到私有仓库 docker commit data-backup registry-host:port/data-backup:$VERSION docker push registry-host:port/data-backup:$VERSION 4. 在另一台主机下载数据容器 docker run -v /folderToBackup --entrypoint \u0026quot;bin/sh\u0026quot; --name data-container registry-host:port/data-backup:${VERSION} 5. 将数据容器里面的数据卷挂载到应用容器上 docker run --volumes-from=data-container registry-host:port/data-backup:${VERSION} # Example docker run --name new-mysql -d -p 3306:3306 --volumes-from=data-container registry-host:port/data-backup:${VERSION} 就这样 5 步操作，就可以很方便的备份、迁移数据库了。所以买主机也一定要买支持 Docker 的 KVM 虚拟机啊。  这种方式，还没有尝试，等会要试一下。\nmysql error MySQL ERROR 1231 (42000):Variable \u0026lsquo;character_set_client\u0026rsquo; can\u0026rsquo;t be set to the value of \u0026lsquo;NULL\u0026rsquo; mysql 导入数据 source x.sql 时，报这个错误。\nhttps://stackoverflow.com/questions/29112716/mysql-error-1231-42000variable-character-set-client-cant-be-set-to-the-val\nAdded the following text at the beginning of the mysqldump file and the restore was successful.\n/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */; /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; /*!40101 SET NAMES utf8 */; /*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */; /*!40103 SET TIME_ZONE='+00:00' */; /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */; /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */; /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;  还有一种 次优解\nhttps://blog.csdn.net/lipeigang1109/article/details/78810679 https://dba.stackexchange.com/questions/153510/error-on-re-import-1231-variable-character-set-client-cant-be-set-to-the\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/docker/docker-use-faq.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "ubuntu@VM-0-12-ubuntu:~$ sudo docker pull tomtsang:ubuntu-desktop-ide Error response from daemon: pull access denied for tomtsang, repository does not exist or may require 'docker login' ubuntu@VM-0-12-ubuntu:~$  表示要登录\nubuntu@VM-0-12-ubuntu:~$ sudo docker login Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one. Username: tomtsang Password: Login Succeeded ubuntu@VM-0-12-ubuntu:~$  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/emacs/emacs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "emacs\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/enterprise/enterprise.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "enterprise\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/git.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "git\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/git/github.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "github\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitbook/gitbook-bookjson.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "https://www.cnblogs.com/zhangjk1993/p/5066771.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitbook/gitbook.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "gitbook\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab-gitbook.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Gitlab 之 Gitbook 自动集成\nhttps://www.loveli.site/2016/07/24/Gitlab%20%E4%B9%8B%20Gitbook%20%E8%87%AA%E5%8A%A8%E9%9B%86%E6%88%90/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/gitlab/gitlab.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "gitlab\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/golang/golang.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "golang\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hexo/hexo.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "hexo\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo-build-hugobook-with-theme-hugo-material-docs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 使用hugo的hugo-material-docs主题模板来构建书籍\n下载仓库 git clone https://github.com/skyao/learning-istio  创建文件夹 mkdir themes public node_modules _book  下载themes 这里应当使用skyao的修改后的themes\n# cd themes \u0026amp;\u0026amp; git clone https://github.com/digitalcraftsman/hugo-material-docs git clone https://github.com/skyao/hugo-material-docs themes/hugo-material-docs  增加内容  删除原content下内容 增加 _index.md, index.md 等内容   .gitignore hugo serve git 修改 rm -rf .git/ git init git remote add origin XXXXXXXXXXXXX git add -A git commit -m \u0026quot;init\u0026quot; git push origin master  .travis.yml 利用Travis CI和Hugo將Blog自動部署到Github Pages\n思路 https://zyfdegh.github.io/post/201705-how-i-setup-hugo/ https://blog.yuantops.com/tech/hugo-travis-ci-auto-deploy-to-gh-pages/ https://axdlog.com/zh/2018/using-hugo-and-travis-ci-to-deploy-blog-to-github-pages-automatically/\n成功travis.yml文件 https://travis-ci.com/EmielH/tale-hugo/jobs/158730898/config\nhugo的重点部分是\ninstall: - wget https://github.com/gohugoio/hugo/releases/download/v0.51/hugo_0.51_Linux-64bit.tar.gz - tar -xzvf hugo_0.51_Linux-64bit.tar.gz - chmod +x hugo - export PATH=$PATH:$PWD - hugo version  最终 .travis.yml 文件是\nlanguage: go go: - \u0026quot;1.8\u0026quot; # 指定Golang 1.8 # Specify which branches to build using a safelist # 分支白名单限制: 只有hugo分支的提交才会触发构建 branches: only: - master install: # 安装最新的hugo # - go get github.com/spf13/hugo - wget https://github.com/gohugoio/hugo/releases/download/v0.51/hugo_0.51_Linux-64bit.tar.gz - tar -xzvf hugo_0.51_Linux-64bit.tar.gz - chmod +x hugo - export PATH=$PATH:$PWD - hugo version script: # 运行hugo命令 - mkdir -p themes - git clone https://github.com/skyao/hugo-material-docs themes/hugo-material-docs - hugo deploy: provider: pages # 重要，指定这是一份github pages的部署配置 skip-cleanup: true # 重要，不能省略 local-dir: public # 静态站点文件所在目录 target-branch: gh-pages # 要将静态站点文件发布到哪个分支 github-token: $GITHUB_TOKEN # 重要，$GITHUB_TOKEN是变量，需要在GitHub上申请、再到配置到Travis # fqdn: eiu.app # 如果是自定义域名，此处要填 keep-history: true # 是否保持target-branch分支的提交记录 on: branch: master # 博客源码的分支  (可跳过).travis.yml文件过程 go # https://docs.travis-ci.com/user/deployment/pages/ # https://docs.travis-ci.com/user/reference/xenial/ # https://docs.travis-ci.com/user/languages/go/ # https://docs.travis-ci.com/user/customizing-the-build/ dist: xenial language: go go: - master # before_install # install - install any dependencies required install: - go get github.com/gohugoio/hugo # consume time 70.85s before_script: - rm -rf public 2\u0026gt; /dev/null # script - run the build script script: - hugo 2\u0026gt; /dev/null # - echo \u0026quot;$CNAME_URL\u0026quot; \u0026gt; public/CNAME deploy: provider: pages skip-cleanup: true github-token: $GITHUB_TOKEN # Set in travis-ci.org dashboard, marked secure # email: $GITHUB_EMAIL name: eiuapp # $GITHUB_USERNAME verbose: true keep-history: true local-dir: public target_branch: gh-pages # branch contains blog content on: branch: master # branch contains Hugo generator code  确实会提示\nThe command \u0026quot;go get github.com/gohugoio/hugo\u0026quot; failed and exited with 1 during .  更新成\nlanguage: go go: - \u0026quot;1.8\u0026quot; # 指定Golang 1.8 # Specify which branches to build using a safelist # 分支白名单限制: 只有hugo分支的提交才会触发构建 branches: only: - hugo install: # 安装最新的hugo - go get github.com/spf13/hugo script: # 运行hugo命令 - hugo deploy: provider: pages # 重要，指定这是一份github pages的部署配置 skip-cleanup: true # 重要，不能省略 local-dir: public # 静态站点文件所在目录 target-branch: gh-pages # 要将静态站点文件发布到哪个分支 github-token: $GITHUB_TOKEN # 重要，$GITHUB_TOKEN是变量，需要在GitHub上申请、再到配置到Travis # fqdn: blog.yuantops.com # 如果是自定义域名，此处要填 keep-history: true # 是否保持target-branch分支的提交记录 on: branch: master # 博客源码的分支  python 会出现curl 没有下载成功hugo\nhttps://discourse.gohugo.io/t/hugo-basic-using-theme-with-hugo-pipes-works-on-local-machine-but-fails-on-travis-ci/15312/3\n找到\nhttps://travis-ci.com/EmielH/tale-hugo/jobs/158730898/config\n这样是\ninstall: - wget https://github.com/gohugoio/hugo/releases/download/v0.51/hugo_0.51_Linux-64bit.tar.gz - tar -xzvf hugo_0.51_Linux-64bit.tar.gz - chmod +x hugo - export PATH=$PATH:$PWD - hugo version  hugo 可执行文件 还有一种方式，是把 hugo 可执行文件，直接放在repo中\nhttps://www.metachris.com/2017/04/continuous-deployment-hugo---travis-ci--github-pages/ https://github.com/Ghoust-game/website/blob/master/.travis.yml\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/hugo/hugo.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "hugo\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/java/ubuntu-install-java-jdk-tomcat.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Ubuntu18.04配置Java环境和安装Tomcat的方法（详细） https://blog.csdn.net/qq_31954797/article/details/80149504\nenv  os: ubuntu 18.04 jdk: jdk1.8.0_72 tomcat: apache-tomcat-9.0.20  两个安装包：JavaJDK，Tomcat 如果说真的是去下载，需要帐户，有了帐户，不一定登录得上。尴尬。\n 搜索 oracle 帐户  https://blog.csdn.net/CSDNno/article/details/79397566\n下载去吧\n 搜索 jdk  https://wiki.jikexueyuan.com/project/linux-in-eye-of-java/JDK-Install.html 提供了一个百度云下载地址\ntomcat 地址，wget http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.7/bin/apache-tomcat-9.0.7.tar.gz ，\n也是已经失效了，但是，思路是在的。打开 http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/ ，有 v9.0.19 那就直接把上面的地址改成：\nhttp://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.19/bin/apache-tomcat-9.0.19.tar.gz 就可以了。或者按这个地址，找一下，就行了。\n配置Javajdk ubuntu@utuntu:~/lcnx/aliyun/env$ cd /home/ubuntu/lcnx/aliyun/env/ ubuntu@utuntu:~/lcnx/aliyun/env$ tar -zxvf ./jdk-8u72-linux-x64.tar.gz ubuntu@utuntu:~/lcnx/aliyun/env$ ln -s ./jdk1.8.0_72/ java ubuntu@utuntu:~/lcnx/aliyun/env$ ls /home/ubuntu/lcnx/aliyun/env/java bin COPYRIGHT db include javafx-src.zip jre lib LICENSE man README.html release src.zip THIRDPARTYLICENSEREADME-JAVAFX.txt THIRDPARTYLICENSEREADME.txt ubuntu@utuntu:~/lcnx/aliyun/env$ sudo vi /etc/profile ubuntu@utuntu:~/lcnx/aliyun/env$ tail -10 /etc/profile LCNX_HOME=/home/ubuntu/lcnx/aliyun/env/ JAVA_HOME=$LCNX_HOME/java JRE_HOME=$JAVA_HOME/jre PATH=$PATH:$JAVA_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export JRE_HOME export PATH export CLASSPATH ubuntu@utuntu:~/lcnx/aliyun/env$ source /etc/profile ubuntu@utuntu:~/lcnx/aliyun/env$ echo $JAVA_HOME /home/ubuntu/lcnx/aliyun/env/java ubuntu@utuntu:~/lcnx/aliyun/env$ java -version java version \u0026quot;1.8.0_72\u0026quot; Java(TM) SE Runtime Environment (build 1.8.0_72-b15) Java HotSpot(TM) 64-Bit Server VM (build 25.72-b15, mixed mode) ubuntu@utuntu:~/lcnx/aliyun/env$  配置Tomcat ln -s ./tomcat ubuntu@utuntu:~/lcnx/aliyun/env$ vi tomcat/ bin/ BUILDING.txt conf/ CONTRIBUTING.md lib/ LICENSE logs/ NOTICE README.md RELEASE-NOTES RUNNING.txt temp/ webapps/ work/ ubuntu@utuntu:~/lcnx/aliyun/env$ vi tomcat/bin/startup.sh ubuntu@utuntu:~/lcnx/aliyun/env$ tail -14 tomcat/bin/startup.sh # set java environment LCNX_HOME=/home/ubuntu/lcnx/aliyun/env JAVA_HOME=$LCNX_HOME/java JRE_HOME=$JAVA_HOME/jre PATH=$PATH:$JAVA_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export JRE_HOME export PATH export CLASSPATH # tomcat export TOMCAT_HOME=$LCNX_HOME/tomcat ubuntu@utuntu:~/lcnx/aliyun/env$  启动Tomcat ubuntu@utuntu:~/lcnx/aliyun/env$ ln -s ./apache-tomcat-9.0.20/ tomcat ubuntu@utuntu:~/lcnx/aliyun/env$ cd tomcat/bin/ ubuntu@utuntu:~/lcnx/aliyun/env/tomcat/bin$ ./startup.sh Using CATALINA_BASE: /home/ubuntu/lcnx/aliyun/env/tomcat Using CATALINA_HOME: /home/ubuntu/lcnx/aliyun/env/tomcat Using CATALINA_TMPDIR: /home/ubuntu/lcnx/aliyun/env/tomcat/temp Using JRE_HOME: /home/ubuntu/lcnx/aliyun/env/java/jre Using CLASSPATH: /home/ubuntu/lcnx/aliyun/env/tomcat/bin/bootstrap.jar:/home/ubuntu/lcnx/aliyun/env/tomcat/bin/tomcat-juli.jar Tomcat started. ubuntu@utuntu:~/lcnx/aliyun/env/tomcat/bin$ netstat -tnlp | grep 8080 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp6 0 0 :::8080 :::* LISTEN 21554/java ubuntu@utuntu:~/lcnx/aliyun/env/tomcat/bin$  通过chrome也是可以访问的。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/k8s.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " kubernetes kubernetes对象 pod kubernetes的最小单位，共享网络和存储\npod中多个container通过localhost进行通信\n通常情况下pod不会运行一个应用的多个实例\nprevileged：特权模式，容器内可以获得等同容器外进程的权限\npod状态  pending：pod已在kube API中创建，但还在准备阶段（拉取镜像、启动） running：pod已正产运行 successed：pod已运行结束并成功推出，不再重启 failed：pod中有容器异常终止 unknown：因为一些原因无法获知pod状态  init容器 pod启动过程中， init容器会按顺序依次启动，并且只有在一个init容器启动并成功退出后，才会启动下一个容器；如果启动失败，则按照restartPolicy规则重启\n只有在所有init容器正常退出后，pod才会变成ready\napiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! \u0026amp;\u0026amp; sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;']  pause容器  在pod中担任命名空间共享的基础 启用pid命名空间，开启init进程  pause容器启动后，创建一个命名空间，pod中其他应用通过加入相同的命名空间获得共享的网络和存储\n# 启动一个pause容器 docker run -d --name pause -p 8880:80 jimmysong/pause-amd64:3.0 # 启动一个nginx，加入到pause容器的命名空间中 docker run -d --name nginx -v `pwd`/nginx.conf:/etc/nginx/nginx.conf --net=container:pause --ipc=container:pause --pid=container:pause nginx # 启动一个博客系统，加入到pause容器的命名空间中 docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause ghost  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/kubernetes%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " kubernetes核心原理 kubernetes API 提供各种资源对象（Pod、RC、Service、deployment、HPA、PV等等的）增删改查及watch等REST接口，成为集群内各个功能模块之间的数据交互和通信的中心枢纽，是整个系统的数据总线和数据中心。\n 集群管理的API入口 是资源配额控制的入口 提供了完备的集群安全机制  集群功能模块之间的通信 集群所有模块都只和kubeAPI通信，不直接操作etcd数据库\n如kubelet：kubelet每个一个周期就与api通信报告自身状态，api收到信息后，将节点状态存入etcd中；kubelet通过watch api监听pod信息，如果坚挺到新的pod副本被调度到本节点，则执行pod相应的创建和启动逻辑。删除亦如此\n一个完整的pod创建过程\n kubectl创建一个pod，将pod信息传递给api api将pod信息写入etcd kube-controller-maneger通过api watch接口实时监控pod变化信息，做相关操作 kube-schduler与api交互，监控到pod新建信息，检索符合pod要求的node列表，开始执行pod调度逻辑，将pod绑定到目标节点 kubelet与API交互，检测到pod创建信息，开始创建pod  Controller Manager 负责集群内node、pod、endpoint、namespace、serviceaccount、资源配额等管理，当某个node宕机时，controller manager会及时发现故障并执行自动化修复流程\n ReplicationController  控制pod副本数量符合预期 通过调整spec.replicas来实现系统扩容和缩容 实现滚动升级  NodeController  设置CIDR，防止节点间CIDR冲突 逐个读取节点信息，实时修改nodeStatusMap，状态没变化则修改nodestatusmap的时间，否则修改nodestatusmap的信息  ResourceQuotaController NamespaceController ServiceAccountController TokenController ServiceController EndpointController  controller通过api实施监控整个集群里的每个资源对象的当前状态，当发生故障时会尝试将系统修复至期望状态\nScheduler 将待调度的pod按照特定的调度算法和调度策略绑定到集群中的某个特定的node，并将绑定信息写入etcd。\n默认调度流程分如下两步：\n 预选调度过程，便利所有目标node，筛选出符合要求的候选节点 确定最优节点，在第一步的基础上，采用优选策略计算出每一个候选节点的积分，积分最高者胜出  预选调度策略 NoDiskConflict 读取备选pod的所有volume信息（Pod.Spec.Volumes），如果volume是GCE或者AWS，且所要调度的节点上存在已挂载相同volume的pod，则存在磁盘冲突，不适合备选pod\nPodFitsResources 检测备选pod和备选node是否存在资源需求冲突\nPodSelectorMatches 判断备选node是否包含备选pod的标签指定的标签（spec.nodeSelector）\nPodFitsHost 判断Pod的spec.nodeName所指定的节点名称是否和备选节点的名称是否一致\nCheckNodeLablePresence scheduler会通过RegisterCustomfitPredicate注册该策略，判定判断策略列出的标签存在时是否选择该备选节点\n如果presence为false，存在标签时为false\n如果presence为true，存在标签使为true\nCheckServiceAffinity PodFitsPorts 判断备选pod所用的端口列表是否在备选节点被占用\n优选调度策略 LeastRequestedPriority 该优选策略用于从备选node列表中选出资源消耗最小的node\n 计算备选node上的totalMillionCPU 计算备选node上的totalMemory 计算得分  CalculateNodeLabelPriority label优先级，\npresence值为true，label匹配，score为10\npresence值为false，label不匹配，score为10\n#### BalanceResourceAllocation\n从备选节点中选则各项资源使用率最均衡的节点，计算方式与LeastRequestedPriority略微不同\nkubelet ### 节点管理\n向apiserver注册自己，并定时向apiserver发送node的新消息，默认10秒一次，可以通过node-status-update-frequency设置时间间隔\nPod管理  定期检查配置文件/etc/kubernetes/manifests/\n apiserver：kubelet通过apiserver监听etcd，同步pod列表，对pod做相应处理\n  关于staticpod，不受apiserver监管，apiserver会创建一个mirror pod与其相匹配，mirrorpod会真实反映staticpod的状态，当staticpod被删除，mirrorpod也会被删除\npod创建过程 kubelet监听到创建信息后，做如下操作\n 为pod创建一个数据目录 从apiserver读取pod清单 为pod挂载外部卷 下载pod用到的secret 检查pod容器是否正常启动，检查pause容器，如果pause容器没有启动，则停止pod里所有的容器进程，如果在pod中有需要删除的容器，则点出这些容器 用kubernetes/pause镜像为每个pod创建pause容器，用于接管pod中其他容器的网络   为容器计算hash值，然后根据容器名查询对应docker容器的hash，若不匹配，则停止docker容器中的进程，并停止pause容器 若容器终止，且没有restartPolicy，则不做任何处理 调用dockerclient下载镜像，调用dockerclient运行容器   容器健康检查 cAdvisor资源监控 cAdvisor是一个开源的分析容器资源使用率和性能特性的代理工具，自动查找所在节点上的容器，采集CPU，内存，文件系统和网络使用的统计信息\n通过所在节点的4194端口暴露一个简单的UI，暴露node信息，docker信息，pod信息等等\nkube-proxy service实现的基础，将对service的访问转发到后端的多个pod实例上\n转发实现原理，IPtables，kube-proxy动态创建于service相关的iptables规则，实现了将clusterIP即nodeport的请求流量重定向到kube-proxy进程是对应服务的代理端口的功能\n无论是clusterIP+targetport还是nodeIP+nodeport，都重定向到kube-proxy坚挺的service服务代理端口\nkube-proxy默认roundrobin轮询，但也可以做session保持。若session没有超时，则保存在affinitystate中的IP后来的访问都会转发到同一个pod\nkube-proxy通过查询和监听apiserver中service与endpoint的变化，为每个service都建立了一个服务代理对象，并自动同步。包含了一个用于监听此服务请求的socketserver，socketserver的端口是随机选择的一个本地空闲端口。同时，kube-proxy创建一个loadbalance，保存了service到对应的后端endpoint列表的动态转发路由表。\n集群安全机制 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/notes.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " kubernetes权威指南读书笔记 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/pod%E8%AF%A6%E8%A7%A3.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " pod详解 pod配置文件示例 # API版本 apiVersion: v1 # 控制器类型 kind: pod # 元数据 metadata: # pod名 name: string # pod所属的命名空间 namespace: string # pod的label键值对，列表 labels: - name: string # 自定义注解键值对，列表 annotations: - name: string # pod详细定义 spec: # 容器列表 containers: # 第1个容器名称 - name: string # 容器镜像 image: string # 镜像拉取的策略，always每次都重新下载镜像；IfNotPresent如果本地有就用本地，没有时下载镜像；never只使用本地镜像 imagePullPolicy: [ Always | Never | IfNotPresent ] # 容器启动命令，不指定则使用镜像打包是使用的启动命令 command: [string] # 启动参数 args: [string] # 容器工作目录 workingDir: string # 容器存储卷配置列表 volumeMounts: # 卷1 - name: string # 挂载的容器目录 mountPath: string # 是否只读，默认为读写 readonly: boolean # 容器需要暴露的端口列表 ports: # 第一个端口配置 - name: string # 容器监听的端口 containerPort: int # 容器所在node需要监听的端口，默认与containerPort相同，设置后，同一node不可以存在多副本 hostPort: int # 端口协议，TCP/UDP protocol: string # 容器的环境变量，列表 env: # 第一个环境变量，变量名和值 - name: string value: string # 容器资源配置 resources: # 资源限制 limits: cpu: string memory: string # 资源请求 requests: cpu: string memory: string # 容器存活探针 livenessProbe: # 执行命令检测是否存活 exec: command: [string] # 发起HTTP请求检测是否存活 httpGet: path: string port: number host: string scheme: string httpHeaders: - name: string value: string # 检测端口监听 tcpSocket: port: number initialDelaySeconds: 0 timeoutSeconds: 0 periodSeconds: 0 successThreshould: 0 failureThreshould: 0 securityContext: privileged: false # 重启策略 restartPolicy: [ Always | Never | Onfailure ] # 选择启动pod的node标签 nodeSelector: object # imagePullsecrets: - name: string # hostNetwork: false # pod共享存储配置，列表 volumes: - name: string # emptyDir模式，占用内存，跟随pod生命周期 emptyDir: {} # node本地路径 hostPath: path: string # 类型为secret的存储卷，表示挂载集群预定义的secret对象到容器内部 secret: secretName: string items: - key: string path: string # configMap configMap: name: string items: - key: string path: string  pod基本用法  与docker一样，前台执行（后台nohup执行后，pod认为nohup执行结束，会关闭pod，若定义了rc则无限重启）,无法前台的应用可以使用supervisor 紧耦合的应用建议放置在同一个pod 同一pod的容器可以通过localhost通信  静态pod 由kubelet运行在特定node上的pod，不受API管理，无法与RC、deployment、daemonset关联\n创建静态pod有两种方式，配置文件和HTTP\n 配置文件  将yaml配置文件防止在kubelet配置文件目录中，然后启动kubelet\nkubelet \u0026ndash;config=/etc/kubelet.d/\npod共享volume APIVersion: v1 kind: Pod metadata: name: volume-pod spec: containers: - name: tomcat image: tomcat ports: tomcat - containerPort: 8080 volumeMounts: - name: app-logs mountPath: /usr/local/tomcat/logs - name: busybox image: busybox command: [\u0026quot;sh\u0026quot;,\u0026quot;-c\u0026quot;.\u0026quot;tail -f /logs/catalina*.log\u0026quot;] volumeMounts: - name: app-logs mountPath: /logs volumes: - name: app-logs emptyDir: {}  pod中配置一个共享存储卷app-logs\nTomcat挂载在/usr/local/tomcat/logs写日志\nbusybox挂载在/logs读取日志\nconfigMap 创建方法  yaml配置文件 kubectl create configamp $NAME \u0026ndash;from-file=[key1=]source1 \u0026ndash;from-file=[key2=]source2 kubectl create configmap $NAME \u0026ndash;from-literal=key1-value1 \u0026ndash;from-literal=key2-value2  使用方法 生成容器内的环境变量 apiVersion: v1 kind: ConfigMap metadata: name: cm-appvars data: apploglevel: info appdatadir: /var/data  设置容器启动命令的启动参数 以volume形式挂载为容器内部的文件或目录 写了一个挂载configMap的pod，tail配置文件保持前台，查看pod日志即可看到configmap映射是否成功\napiVersion: v1 kind: ConfigMap metadata: name: configmap-for-yaml data: application.yaml.key: |- apiVersion: v1 kind: ConfigMap metadata: name: cm-appvars data: apploglevel: info appdatadir: /var/data --- apiVersion: v1 kind: Pod metadata: name: configmap-pod spec: containers: - name: configmap-pod image: busybox volumeMounts: - name: application-yml mountPath: /config command: ['sh','-c','tail -f /config/application.yaml'] volumes: - name: application-yml configMap: name: configmap-for-yaml items: - key: application.yaml.key path: application.yaml  查看pod的tail后的log\n[k8s@kube-node1 ~]$ kubectl logs configmap-pod apiVersion: v1 kind: ConfigMap metadata: name: cm-appvars data: apploglevel: info  pod生命周期和重启策略 pod状态    状态值 描述     pending APIserver已创建pod，但pod内还有容器的镜像没有创建   running pod内所有容器都已创建，切至少一个容器处于运行状态、正在启动状态和正在重启状态   succeeded pod内所有容器均执行成功并退出，且不再重启   failed pod内所有容器已退出，但至少还有一个容器退出为失败状态   unknown 无法获取pod状态，可能由于网络通信不畅导致    pod重启策略  Always 容器失效时自动重启 OnFailure 容器中支运行且退出码部位0时，有kubelet自动重启该容器 Never 不论容器运行状态如何，kubelet都不会重启该容器  重启的时间间隔以sync-frequency乘2计算，1、2、4、8等，最长延时5分钟，并在成功重启后10分钟后重置该时间\n不同的控制器对pod的充气策略要求如下：\n RC和DaemonSet：Always Job： OnFailure或Never kubelet：pod失效时自动重启  pod健康检查 LivenessProbe 用于判定容器是否存活，如果探测到容器不健康，则kubelet杀掉改容器，并根据容器的重启策略做相应的处理；如果不配置LivenessProbe，则认为容器返回值永远是success\nExecAction 通过执行命令的返回值判定容器健康状态\napiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-exec spec: containers: - name: liveness image: busybox args: - /bin/sh - -c - echo ok \u0026gt; /tmp/health;sleep 10;rm -rf /tmp/health;sleep 60 livenessProbe: exec: command: - cat - /tmp/health initialDelaySeconds: 30 timeoutSeconds: 1  describe这个pod会发现在不断的重启\nTCPsocketProbe 通过容器的IP和端口检查，能简历TCP链接，则表明容器健康\nlivenessProbe: tcpSocket: port: 80  HTTPGetAction 通过get方法，如果相应的状态码大于等于200且小于等于400，则认为容器状态健康\nlivenessProbe： httpGet: path: /_status/healthz port: 80 initialDelaySeconds: 30 timeoutSeconds: 1  ReadinessProbe node定向调度  nodeSelector 通过label键值对选择node  selector: name: frontend   nodeAffinity  selector升级版，添加了in，noting，exists，doesnotexist，gt，lt等操作符\n RequiredDuringSchedulingRequiredExection：类似于nodeselector，node不满足条件时，系统将从该node上移除之前调度的pod RequiredDuringSchedulingIgnoredDuringExection，类似RequiredDuringSchedulingRequiredExection，区别在于node不满足条件时，系统不一定从该node上移除之前调动的pod PreferredDuringSchdulingIgnoredDuringExection：满足条件的node优先调度，不满足的node不一定移除  在当前版本中，需要在pod的metadata中设置nodeaffinity\napiVersion: v1 kind: Pod metadata: name: with-lables nanotations: scheduler.alpha.kubernetes.io/affinity .......  DaemonSet 每个node上只运行一个的特殊pod\napiVersions/v1beta1 kind: DaemonSet metadata: name: fluentd-cloud-logging namespace: kube-system labels: k8s-app: fluentd-cloud-logging spec: template: metadata: namespace: kube-system labels: k8s-app: fluentd-cloud-logging spec: container: - name: fluentd-cloud-logging image: fluentd-elasticsearch:1.17 resource: limits: cpu: 100m memory: 200Mi env: - name: FLURNTD_ARGS value: -q volumeMounts: - name: varlog mountPath: /var/logging readOnly: false - name: varlog mountPath: /var/log readOnly: false Volumes: - name: containers hostpath: path: /var/lib/docker/containers - name: varlog hostpath: path: /var/log  job  job Template Expansion: 一个job对应一个待处理的workitem，有几个workitem就产生几个独立的job，通常适合workitem数量较少、每个workitem需要处理大量的数据 queue with pod per work item，采用一个任务队列存放workitem，一个job对象作为消费者去完成，在这种模式下，job会启动N个pod，每个pod对应一个workitem queue with variable pod count：采用一个任务队列存放workitem，一个job对象作为消费者去完成这些workitem，但job启动的pod数是可变的  滚动升级 kubectl rolling-update redis-master -f redis-master-controller-v2.yaml  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/service%E8%AF%A6%E8%A7%A3.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " service详解 service 配置文件详解 # 版本 apiVersion: v1 # 类型service kind: Service # 元数据 metadata: # service name name: string # 所属namespace namespace: string # 标签键值对，列表 labels: - name: string # 注解 annotations: - name: string # 详解 spec: # pod选择的标签列表 selector: [] # service类型，指定service访问类型，默认clusterIP，还有NodePort(直接采用宿主机IP+端口)，LoadBalance（指定外部负载器的IP地址，并同时定义nodePort和clusterIP） type: string # service的cluster IP clusterIP: string sessionsAffinity: 是否支持session # 端口配置 ports: - name: string protocol: string port: int # pod端口 targetPort: int # 宿主机端口 nodePort: int # 当spec.type=NodePort时，指定的外部负载均衡地址 status: # 外部负载均衡器配置 loadBalancer: ingress: ip: string hostname: string  负载模式  roundrobin 轮询 sessionaffinity IP哈希  默认情况下采用roundrobin，但可以通过service.spec.sessionAffinity设置为clientIP启用sessionAffinity\n某些情况下，也可以不使用service负载均衡，通过labelselector将后端的pod列表返回给调用的客户端\nclusterIP: None selector: api: nginx  集群外部服务的连接方式 当集群内部需要与外部通信时，可以将外部服务创建为一个没有selector的service，手动添加endpoint，endpoint和service同名\nkind: Service apiVersion: v1 metadata: name: my-service spec: ports: - protocol: TCP port: 80 targetPort: 80 --- kind: Endpoints apiVersion: v1 metadata: name: my-service subsets: - addresses: - IP: 1.2.3.4 ports: - port: 80  集群外部访问pod和service 将container端口映射给node hostPort 通过设置hostport将containerport的内容通过自定义的hostport映射到node\napiVersion: v1 kind: Pod metadata: name: webapp labels: - app: webapp spec: containers: - name: webapp image: tomcat ports: - containerPort: 8080 hostPort: 8081  hostNetwork=true 如果设置hostport=true，则pod中容器端口号会被直接映射到node\n若指定hostPort，则hostPort必须等于containerPort\n若未指定hostPort，则hostPort默认等于containerport\napiVersion: v1 kind: Pod metadata: webapp name: webapp labels: app: webapp spec: hostNetwork: true containers: - name: webapp image: tomcat imagePullPolocy: Never ports: - containerPort: 8080  将service端口映射给node 通过设置nodePort映射给端口 apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 nodePort: 30061  loadbalance apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 nodePort: 30061 clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 type: LoadBalancer status: loadBalancer： ingress: - ip: 146.148.47.155  DNS原理 ingress 普通的service只能实现loadbalance，Ingress可以将不同的URL请求转发到不同的service，实现http层的业务路由机制\n类似nginx的location+proxypass\n http://mywebsite.com/api 路由到api service http://mywebsite.com/web 路由到web service  创建ingress控制器 apiversion: extensions/v1beta1 kind: Deployment metadata: name: nginx-ingress labels: app: nginx-ingress spec: replicas: 1 selector: matchLabels: app: nginx-ingress template: metadata: labels: app: nginx-ingress spec: containers: - name: nginx-ingress image: nginx-ingress imagePullPolicy: IfNotPresent ports: - containerPort: 80 hostPort: 80  创建ingress规则 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: mywebsite-ingrss spec: rules: - host: mywebsite.com http: paths: - path: /web backend: serviceName: webapp servicePort: 80 - path: /api backend: serviceName: api servicePort: 80  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/%E4%BC%81%E4%B8%9A%E5%AE%9E%E8%B7%B5%E6%95%B4%E7%90%86.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 企业实践整理 资源管理 计算资源管理 多集群管理 ##### federation\n资源分区管理 ##### namespace\n实现逻辑隔离，默认权限下不可跨namespace访问资源\nnamespace可以看做一级域名，不同的namespace下解析各自的service（search domain）\n/ # cat /etc/resolv.conf nameserver 10.254.0.2 search default.svc.cluster.local. svc.cluster.local. cluster.local. options ndots:5  ##### node调度\n#### 资源配额和资源限制\n pod：limit，request，limitrange namespace：ResourceQuota  #### service端口管理\n   namespace service name service IP NodePort     default webservice1 10.1.1.1 8089   partition1 webservice1 10.1.1.2 8090    外部服务可以作为虚拟service纳入kubernetes集群，不设置selector，统一管理\n网络资源管理 flannel  VxLAN 对数据进行二次封装\n DUP\n host-gw\n  calico  通过bgp动态路由协议  #### macVLAN\n每个pod一个主机地址\nlinen 基于open vswith的overlay方案\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/%E5%9F%BA%E4%BA%8ERBAC%E5%AE%9E%E7%8E%B0dashboard%E5%8F%AA%E8%AF%BB-view%E6%9D%83%E9%99%90.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 基于RBAC实现dashboard只读——view权限 只是简单利用默认的clusterrole - view实现了只读所有namespace下的对象(除去secret、role、rolebinding)，不支持读取集群信息，后期深入了解resource后再重新梳理role和rule\nkind: ServiceAccount apiVersion: v1 metadata: name: view namespace: kube-system --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: dashboard-dev-rolebinding subjects: - kind: ServiceAccount name: view namespace: kube-system roleRef: kind: ClusterRole name: view apiGroup: rbac.authorization.k8s.io  使用默认的clusterrole：view(Allows read-only access to see most objects in a namespace. It does not allow viewing roles or rolebindings. It does not allow viewing secrets, since those are escalating. )\nhttps://kubernetes.io/docs/reference/access-authn-authz/rbac/\n拿token\nkubectl describe secret -n kube-system `kubectl describe sa view -n kube-system | grep \u0026quot;Mountable secrets\u0026quot; | awk '{print $3}'` | grep -E ^token | awk '{print $2}'  登录dashboard即可\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 基础概念 基本组件 master  kubernetes API server：集群的控制入口，提供rest接口，对集群进行增删查改 kubernetes Controller Manager：管理集群资源对象，rc，service，deployment等等对象 kubernetes Scheduler：集群资源调度（Pod），建立相应任务，比如讲某个pod通过算法指定到某个node etcd：存储集群信息，与kubenetes API server进行交互  node  kubelet：负责启停pod，并与API server通信 kube-proxy：实现service通信和负载 docker engine：docker引擎，负责容器创建（也可以是其他的容器引擎）  ## 基本术语\npod pod是kubernetes的最小单元\n每个pod都有pause容器，用来解决pod网络、存储资源共享问题，\npod内部通过localhost通信，pod与pod通过pause的IP通信\n两种类型\n 普通pod，etcd中存储相关信息，受API server管理，可以运行在集群中任意node\n 静态pod（static pod），etcd中不存在pod的任何信息，不受API server管理，只运行在特定的node上\n  label key:value格式，对不同的资源对象，根据不同的场景打上相应的label，可以打任意个label\nRC（replicas controller） 实现pod多副本，高可用\nAPI接收到RC创建请求后，controller manager就会定期检查pod副本数是否匹配RC，发现pod数据异常就会通知scheduler，scheduler通知kubelet，增删pod\napiVersion: v1 #api版本 kind: ReplicationController # 类型 rc metadata: # 元数据 name: nginx # RC名称 nginx spec: # 详细信息 replicas: 3 # 期望的副本数，3个 selector: # 选择pod的label，app=nginx app: nginx template: # pod模板 metadata: # 元数据 name: nginx # pod名称 nginx labels: # pod标签 app=nginx app: nginx spec: # 详细信息 containers: - name: nginx # 容器1 image: nginx # docker镜像 ports: # 容器端口 80 - containerPort: 80  命令行修改RC副本数量\nkubectl scale rc RC_NAME --replicas=10  删除RC 直接删除RC不会删除通过RC创建的pod，如果需要删除pod需要将replicas置为0，再删除RC\nRC set replicas controller升级版，RC set支持基于集合的selector\n 通过RC实现pod的创建过程及副本数量的自动控制 RC里包含完整的pod定义模板 RC通过label selector实现对pod副本的自动控制 通过改变RC里pod模板镜像版本，可以实现pod的滚动升级  deployment RS的升级，内置replicas，更好的解决容器编排问题，应用场景如下：\n 创建一个deployment对象生成对应的RS并完成pod副本的创建过程 检查deployment的状态查看部署是否完成 更新deployment以创建新的pod 回滚到上一个deployment  kind: Deployment metadata: name: tomcat labels: server_type: tomcat spec: replicas: 2 selector: matchLabels: server_type: tomcat template: metadata: labels: server_type: tomcat spec: containers: - name: tomcat image: tomcat imagePullPolicy: IfNotPresent ports: - containerPort: 8080  查看deployment\n[k8s@kube-node1 ~]$ kubectl get deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx01 1 1 1 1 13d tomcat 2 2 2 2 22h   desired：期望的pod副本数 current：当前的副本数 up-to-date：最新版本的pod副本数，用于在滚动升级中指示有多少个pod成功升级 available：可用的pod副本数 age：deployment的存活时间  #### deployment、replicas set、pod命名\n[k8s@kube-node1 ~]$ kubectl get deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx01 1 1 1 1 13d tomcat 2 2 2 2 22h [k8s@kube-node1 ~]$ kubectl get replicaset NAME DESIRED CURRENT READY AGE nginx01-6c8b6cb47d 1 1 1 13d tomcat-f95576647 2 2 2 22h [k8s@kube-node1 ~]$ kubectl get pod NAME READY STATUS RESTARTS AGE busybox 1/1 Running 95 4d mysql-mvfmh 1/1 Running 0 10d nginx01-6c8b6cb47d-8d7mz 1/1 Running 0 13d tomcat-f95576647-29qk2 1/1 Running 0 22h tomcat-f95576647-5rwpd 1/1 Running 0 22h  replicaset在deployment的基础上加了一个字段，pod在replicaset的基础上加了一个字段\n### HPA\nhorizontal pod autosacler，动态pod横向扩展。通过追踪pod负载情况实现pod自动扩展\n负载度量指标：\n CPU utilization Percentage，通过heapster查询CPU使用量，计算1分钟的平均值，此外，pod必须定义request CPU  apiVersion: autoscaling/v1 kind: HorizontalPodAutosacler metadata: namespace: default spec: maxReplicas: 10 minReplicas: 1 scaleTargetRef: kind: Deployment name: php-apache targetCPUUtilizationPercentage: 90  也可以通过命令行\nkubectl autoscale deployment php-apache --cpu-percent=90 --min=1 --max=10   应用程序自定义的度量指标（访问频率等等）  service  每个pod都有独立的IP，都有一个独立的endpoint（podIP + containerPort） 一个deployment中有多个相同的pod副本 service分配一个全局唯一的虚拟IP，kube-proxy负责将对service的访问负载分发到pod副本  apiVersion: v1 kind: Service metadata: name: mysql spec: type: NodePort ports: - port: 3306 nodePort: 8500 selector: app: mysql  volume enptyDir template: metadata: labels: app: app-damo tier: frontend spec: volume: - name: datavol emptyDir containers: - name: tomcat-damo image: tomcat volumeMounts: - mountPath: /mydata-data name: datavol imagePullPolicy: IfNotPresent  hostPath pod挂载宿主机文件系统\n 不同的node上运行的不同pod挂载的本地路径不同，因此看到的内容也不一样 资源配额管理无法管理hostpath在宿主机上的资源占用  volumes: - name: \u0026quot;persistent-storage\u0026quot; hostPath: path: \u0026quot;/data\u0026quot;  gcePersistendDisk google cloud的永久磁盘，与emptyDir不同，pod删除后只是被卸载，不会被删除\n未了解\nawsELasticBlockStore 类似gce，aws的云服务，未了解\nNFS volumes: - name: nfs-custom nfs: server: nfs-serverIP path: \u0026quot;/\u0026quot;  Persistent Volume PV PV可以理解为kubernetes集群中某一个网络存储中对应的一块存储，与volume类似，但存在一些区别：\n PV只能是网络存储，不属于node，但可以在node上 PV并不定义在pod，有单独的controller manager，可以被pod调用 PV类型：NFS、GFS、RBD、iSCSI、aswElasticBlockStore、GCE等等  apiVersion: v1 kind: PersistentVolume metadata: name: pv0003 spec: capacity: storage: 5Gi accessModes: - ReadWriteOnce nfs: path: /somepath server: 172.17.0.2  其中AccessModes有以下几种：\n ReadWriteOnce 读写权限，仅限单个node挂载 ReadOnlyMany 只读权限，可以多node ReadWriteMany 读写权限，允许多node  PV的状态\n Available：空闲状态 Bound： 已经绑定到某个PVC上 Released： 对应的PVC已经删除，但资源未被集群回收 Failed： PV自动回收失败  PVC persistent volume claim，pod发起的持久化存储申请，从相应条件的PV中分割申请的存储（类似虚拟机磁盘与存储的关系）\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: myclaim spec: accessModes: - ReadWriteOnce resources: requests: storags: 8Gi  然后，在pod的volume中引用上述PVC\nvolumes: - name: mypd persistentVolumeClaim: claimNameL myclaim  #### namespace\napiVersion: v1 kind: Namespace metadata: name: development  Annotation 类似label，一般记录注解信息，作者、联系方式、镜像信息等等\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 日志收集 翻译自k8s官方文档：https://kubernetes.io/docs/concepts/cluster-administration/logging/\n应用和系统日志可以帮助我们理解我们的集群发生了什么。对于排插问题和监控集群活动也非常有用。大多数应用都有某种日志机制；同样的，大部分容器引擎设计时也支持多种日志记录。对于容器应用，最容易并且最受欢迎的记录方式是写标准输出和标准错误输出。\n然而，容器引擎原生的方法通常不足以完全的解决日志记录问题。比如，如果container故障，或者pod移除，或者node不可用，你仍然希望接收应用的日志。因此，日志应该有不依赖与node、pod、或者container的生命周期和独立存储。这个概念被称之为*cluster-level-logging* *cluster-level-logging* 要求一个独立的后台去存储，分析并且查询日志。k8s提供非远程的存储解决方案给日志数据，你可以集群很多已经存在的日志记录方案在k8s集群\n## Basic logging in Kubernetes\n在这个部分，你可以看到一些*Basic logging in Kubernetes*的例子：输出数据到stdout，这个实力用一个pod指定一个container每秒一次输出一些文本到stdout。\napiVersion: v1 kind: Pod metadata: name: counter spec: containers: - name: count image: busybox args: [/bin/sh, -c, 'i=0; while true; do echo \u0026quot;$i: $(date)\u0026quot;; i=$((i+1)); sleep 1; done']  启动pod后，通过kubectl logs获取日志信息\n$ kubectl logs counter 0: Mon Jan 1 00:00:00 UTC 2001 1: Mon Jan 1 00:00:01 UTC 2001 2: Mon Jan 1 00:00:02 UTC 2001 ...  你可以使用kubectl logs从以前的带有 \u0026ndash;previous标签的实例中获取日志，加入container已经被破坏。如果你的pod中有多个容器，你必须指定你想要获取的容器的日志。从kubectl logs中获取更多细节\nlogging at the node level 容器应用的stdout和stderr都由容器引擎处理和重定向。比如，docker容器引擎重定向这两个数据流到logging driver，可以在k8s中配置写到一个json格式的文件中\n注意：docker json logging driver以行分离信息，不支持多行的信息。你必须在logging agent层次或者更高层次处理多行日志\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/kubernetes/%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 集群安全机制  挨批server的认证授权 保证容器与其所在的宿主机的隔离 限制容器给基础设施及其他容器带来消极影响的能力 最小权限原则——合理限制所有组件的权限 划分普通用户和管理员的角色 明确组件间边界的划分 在必要的时候云讯将管理员权限付给普通用户 允许拥有secret数据的应用在集群中运行  APIserver认证 所有资源的访问都是通过APIserver的REST API实现的，所以集群安全的关键点在于如何识别并认证客户端身份，以及访问权限控制\n三种级别的客户端身份认证方式\n HTTPS证书双向认证  通过CA根证书签发服务器证书，客户端证书，客户端请求服务器时互相验证对方的证书\n HTTP token认证  私钥签发一个很长的特殊编码方式且难以模仿的字符串，HTTP访问时在header里携带token\n HTTPbase认证  HTTP基础认证，将用户名明码放在request中的header authorization域里发送给服务器\nAPIserver授权  AlwaysDeny 默认拒绝所有\n AlwaysAllow 默认允许所有且不需要授权\n ABAC attribute-base access control 基于属性的访问控制\n 用户名 是否是只读请求 被访问的是哪一类资源 被访问对象所属的namespace   使用abac需要在授权文件中写入json格式的访问策略对象\n{\u0026quot;user\u0026quot;:\u0026quot;alice\u0026quot;} # 允许Alice做所有事情 {\u0026quot;user\u0026quot;:\u0026quot;kubelet\u0026quot;,\u0026quot;resource\u0026quot;:\u0026quot;pods\u0026quot;,\u0026quot;readonly\u0026quot;:\u0026quot;true\u0026quot;} # 允许kubelet只读pod {\u0026quot;user\u0026quot;:\u0026quot;bob\u0026quot;,\u0026quot;resource\u0026quot;:\u0026quot;pods\u0026quot;,\u0026quot;readonly\u0026quot;:\u0026quot;true\u0026quot;,\u0026quot;ns\u0026quot;:\u0026quot;myNamespace\u0026quot;} # 允许Bob只读myNamespace的pod  客户端发起APIserver调用，先进行用户认证，再执行鉴权\nadmission control准入控制？？ ServiceAccount 用于pod访问APIserver时的身份认证\n客户端访问APIserver时需要对客户端进行身份认证\npod中的客户端访问apiserver时是以service方式访问kubernetes这个service\nservice account就是pod访问kubernetesAPI时的认证机制，访问的时候，在header中传递一个token\n token是controller用APIserver的私钥动态生成的JWTSecret，存放在pod的/run/secrets/kubernetes.io/serviceaccount/token HTTPS双向认证  逻辑 每个serviceaccount都有一个mountable secrets挂载了一个token，token中包含了ca.crt信息，namespace，以及token\n[k8s@kube-node1 kubernetes]$ kubectl describe serviceaccounts filebeat -n kube-system Name: filebeat Namespace: kube-system Labels: k8s-app=filebeat Annotations: \u0026lt;none\u0026gt; Image pull secrets: \u0026lt;none\u0026gt; Mountable secrets: filebeat-token-dk2hv Tokens: filebeat-token-dk2hv Events: \u0026lt;none\u0026gt; [k8s@kube-node1 kubernetes]$ kubectl describe secrets filebeat-token-dk2hv -n kube-system Name: filebeat-token-dk2hv Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name=filebeat kubernetes.io/service-account.uid=c02fc8f1-9b77-11e8-9f55-005056beaf48 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1367 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJmaWxlYmVhdC10b2tlbi1kazJodiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJmaWxlYmVhdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImMwMmZjOGYxLTliNzctMTFlOC05ZjU1LTAwNTA1NmJlYWY0OCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpmaWxlYmVhdCJ9.p6faW7gqCajPTJgUcbVNthadFxwx9Gcs0zs7aRdsmVmvQkij4IDEWQ7BYs8fieLQHsTKeEQbRP42BSZfp07jBKn2Y_EW5MIVlnzhiCrkrS1GsqJuHncGtcqzlZKf0crWcBK-ppvm55HDMvS18TUAFjzTYCtuaxuwEWR17Aoxai8EDyZdzCyR61x0U1_hnejqV3Rvme0tkTWcznEHhocL67YNUpy4LWdP3ops0DTo9RZDf-s3roSDqzBHfhWzFtnUw_oHGksAYcpzDrtotFers3o5I1tq7lkyQtvcu5LJBU3cI6dxz8FWYphgRlEbjd0fRE9jh9aonb4jF3AEnDuP4A  我们再查看对应的pod\n[root@filebeat-chsvj filebeat]# ll /run/secrets/kubernetes.io/serviceaccount/ total 0 lrwxrwxrwx 1 root root 13 Aug 9 01:58 ca.crt -\u0026gt; ..data/ca.crt lrwxrwxrwx 1 root root 16 Aug 9 01:58 namespace -\u0026gt; ..data/namespace lrwxrwxrwx 1 root root 12 Aug 9 01:58 token -\u0026gt; ..data/token  可以看到，pod中的secret文件与serviceaccount中的信息是一一对应的\n每个namespace下都有一个default serviceaccount\n[k8s@kube-node1 kubernetes]$ kubectl get serviceaccount --all-namespaces | grep default default default 1 23d kube-public default 1 23d kube-system default 1 23d  如果pod没有定义spec.serviceAccountName，则系统直接尾气复制default，如果需要给default的serviceaccount，则需要指定：\napiVersion: v1 kind: Pod metadata: name: mypod spec: containers: - image: mycontainer image: nginx:v1 serviceAccountName: myserviceaccount  一个serviceaccount可以包含多个secret对象\n tokens用于访问APIserver，也被成为serviceaccountsecret imagepullsecret用于下载容器竟像是的认证过程，通常镜像库都为insecure模式，所以这个secure为空 用户自定义的其他secret，用于用户进程  ## RBAC\nrole-base access control\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/delete-end-of-line-when-unix-format.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Linux下删除^M文件的方法 Unix系统里，每行结尾只有“\u0026lt;换行\u0026gt;”，即“\\n”；Windows系统里面，每行结尾是“\u0026lt;换行\u0026gt;\u0026lt;回车\u0026gt;”，即“\\n\\r”；Mac系统里，每行结尾是“\u0026lt;回车\u0026gt;”。\n1. 问题描述： 在windows下写的文件上传到Linux服务器之后,文件中多出了很多^M符号\n2. 原因分析： Linux和windows的文本中，对换行方式处理不同：\n'\\n' 10 换行（newline） '\\r' 13 回车（return）  | 系统 | 换行方式 | |\u0026mdash;\u0026mdash;\u0026mdash;-|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-:| | Windows | 结尾是\u0026lt;换行\u0026gt;\u0026lt;回车\u0026gt;,即“\\n\\r”| |linux/unix | 结尾是\u0026lt;换行\u0026gt;,即 “\\n” | | Mac | 结尾是\u0026lt;回车\u0026gt;,即“\\r” |\n所以windows下的文件，在Linux中会有^M，即回车符号\n参考：回车符和换行符的区别\n3.解决办法： 解决办法主要以下几个方案：\n注意： ^M要用Ctrl+v，\u0026lt;回车\u0026gt;代替\n| 命令 |\n|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| |1. vim 中使用替换命令：:%s/^M//g | |2. 使用sed:sed 's/^M//' filename \u0026gt; newfile | |3. 使用tr删除“\\r”：tr -d \u0026quot;\\r\u0026quot; filename | |4. 使用dos2unix命令：dos2unix filename | |5. 在vim下：:set ff = unix（把dos文件类型变为unix）|\n此外，也可以使用sed把win文档转化为Linux下文档:\nfind . -type f print0 | xargs -0 sed -i 's/^M$//'\n其中实践中试验了第一种方法，举例说明该命令的含义：\n将文件中的 a 全部替换为b,可以使用:%s/a/b/g\n有时候，你会发现，当文件已经是 unix 格式时，依然会在行尾有 ^M，这时，通过 以上几种方式依然不能删除这个^M，那么请使用：\nsed -i 's#^M##g' filename\nDELL@DESKTOP-MQ9CENU MINGW64 /f/org-notes (master) $ sed -i 's#^M##g' ./gtd.org DELL@DESKTOP-MQ9CENU MINGW64 /f/org-notes (master) $ vi gtd.org  参考  去掉Linux中删除^M符号的方法\n vim如何去掉^M字符 https://www.zhihu.com/question/22130727  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/https%E8%AE%A4%E8%AF%81%E9%80%BB%E8%BE%91.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " https认证逻辑 https://blog.csdn.net/duanbokan/article/details/50847612 写的很好\nHTTP：明文传输所有数据，数据容易被篡改（运营商流量劫持）\nHTTPS单向认证：最常见的HTTP认证方式，客户端只需要验证服务器传输的证书是否为CA认证中心签发的有效证书，通过后开始传输对等秘钥并使用对等秘钥加密数据\nHTTPS双向认证：客户端验证服务器的证书后发送自己的证书给服务器验证，两次验证通过后才传输对等秘钥，一般用于安全性要求较高的场景（银行、金融）\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux-cp-exclude-dir-or-exclude-file.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 在linux中，如果你想cp一个文件夹，但是，又不想cp此文件夹下的某些文件或某些文件夹，则请往下看。\nstep 方法一：cp \u0026amp; ls \u0026amp; grep 此方法，最好，简单直接。主要就是依赖grep去除\ncd spacemacs-private/ \u0026amp;\u0026amp; cp -rf `ls -a . | grep -E -v \u0026quot;^(.|..|.git|.gitignore)$\u0026quot;` ../../../submodule/test/  方法二：cp \u0026amp; find 说明：/home目录里面有data目录，data目录里面有a、b、c、d、e五个目录，现在要把data目录里面除过e目录之外的所有目录拷贝到/bak目录中\n终端命令行下执行以下命令\ncp -R `find /home/data -type d -path /home/data/e -prune -o -print | sed 1d ` /bak  脚本实现 脚本存放路径/home/osyunwei.sh\n$ cat /home/osyunwei.sh #编辑脚本，添加下面的代码 #!/bin/sh cp -R `find /home/data -type d -path /home/data/e -prune -o -print | sed 1d ` /bak $ chmod +x /home/osyunwei.sh #添加脚本执行权限 $ cd /home #进入脚本存放目录 $ ./osyunwei.sh #执行脚本  方法三：rsync 使用cp命令复制的时候，只能排除一个目录不被复制，如果想排除两个或者多个目录的话，就需要使用rsync命令来实现了，看下面的例子 如果要排除/home/data目录下面的a、b、c、三个目录，同时拷贝其它所有目录，执行以下命令。\nyum install rsync #安装rsync rsync -av --exclude data/a --exclude data/b --exclude data/c data /bak  注意：\u0026ndash;exclude后面的路径不能为绝对路径，必须为相对路径才可以，否则出错。\n实际操作中，很容易发现问题，此方法，有副作用，不是函数式的（多次执行，无效果）\n➜ latest git:(master) ✗ rsync -av --exclude spacemacs-private/.git --exclude spacemacs-private/.gitignore ../../submodule/test/ sending incremental file list drwxrwxr-x 4,096 2019/01/23 20:23:34 . -rw-rw-r-- 1,430 2019/01/15 22:22:59 README.org sent 85 bytes received 125 bytes 420.00 bytes/sec total size is 1,430 speedup is 6.81 ➜ latest git:(master) ✗ ls spacemacs-private ➜ latest git:(master) ✗ rsync -av --exclude spacemacs-private/.git --exclude spacemacs-private/.gitignore ../../submodule/test/ sending incremental file list drwxrwxr-x 4,096 2019/01/23 20:24:15 . sent 56 bytes received 64 bytes 240.00 bytes/sec total size is 0 speedup is 0.00 ➜ latest git:(master) ✗ rsync -av --exclude spacemacs-private/.git --exclude spacemacs-private/.gitignore ../../submodule/test/ sending incremental file list drwxrwxr-x 4,096 2019/01/23 20:24:15 . sent 56 bytes received 64 bytes 240.00 bytes/sec total size is 0 speedup is 0.00 ➜ latest git:(master) ✗  ref  https://yq.aliyun.com/ziliao/54339 https://www.osyunwei.com/archives/2626.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/linux.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Linux "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/ssh/ssh-login-specify-idrsa.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 今天在服务器上配置了自己电脑的public key，但是还是不能直接免密码登录，\n原因是\nssh 对目录的权限有要求，代码中要设置下新生成的config文件权限才行。\n~目录权限是750， ~/.ssh 的是700， ~/.ssh/* 的是600， ~/.ssh/config 是700\n-rw-rw-r-- 1 webuser webuser 396 Feb 19 04:20 authorized_keys $chmod 600 .ssh/authorized_keys -rw------- 1 webuser webuser 396 Feb 19 04:20 authorized_keys  还有一次是，我死活登录不上 ubuntu@tencent-cloud 。 最后通过web连接登录，然后，机器上用ubuntu用户ssh localhost都登录不了，那就说明一定是权限问题了。 一看，原来，整个文件夹/home/ubuntu/ 的权限被更改成 tom:tom 了。那当然进不来了。所以这时：\nsudo chown ubuntu:ubuntu /home/ubuntu/  这样，才能ssh 登录正常。\nref:  https://blog.csdn.net/shiralwz/article/details/50697207\n  假如在生成密钥对的时候指定了其他文件名（或者需要控制N台机器，此时你会生成多对密钥），则需要使用参数-i指定私钥文件\n$ ssh ubuntu@192.68.0.11 -i ./id_rsa Welcome to Ubuntu 16.04.1 LTS (GNU/Linux 4.4.0-91-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage New release '18.04.1 LTS' available. Run 'do-release-upgrade' to upgrade to it. Last login: Thu Jan 17 09:42:08 2019 from 113.91.43.118 ubuntu@VM-0-12-ubuntu:~$  放在前面也是可以的\n$ ssh -i ./id_rsa ubuntu@111.230.153.251 Welcome to Ubuntu 16.04.1 LTS (GNU/Linux 4.4.0-91-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage New release '18.04.1 LTS' available. Run 'do-release-upgrade' to upgrade to it. Last login: Thu Jan 17 09:52:45 2019 from 113.91.43.118 ubuntu@VM-0-12-ubuntu:~$  ref  http://www.cnblogs.com/ma6174/archive/2012/05/26/2519458.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/linux/tar.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-navicat-mysql-61-error-code.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " mac 本机安装 mysql8.0 后，navicat 连接 mysql 后报 61 错误码。怎么办？\nenv mac下mysql无法开启或者关闭\nstep 在terminal中查看mysql的所有进程：ps aux |grep mysq*\n查找到进程编号，使用kill ****关闭进程，如果没有权限在前面添加sudo，完成！\n第一步：\n点击系统偏好设置-\u0026gt;最下边点MySQL，在弹出页面中，关闭服务\n第二步：\n进入终端输入：cd /usr/local/mysql/bin/ 回车后 登录管理员权限 sudo su 回车后输入以下命令来禁止mysql验证功能 ./mysqld_safe \u0026ndash;skip-grant-tables \u0026amp; 回车后mysql会自动重启（偏好设置中mysql的状态会变成running）\n第三步：\n输入命令 ./mysql 回车后，输入命令 FLUSH PRIVILEGES; 回车后，输入命令 SET PASSWORD FOR \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; = PASSWORD(\u0026lsquo;你的新密码\u0026rsquo;);\nref  https://blog.csdn.net/a787188834/article/details/76152735 https://blog.csdn.net/wujunwen/article/details/52039697  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/macos/mac-tools.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "dash\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mariadb/mariadb.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "mariadb\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown/convert-html-to-markdown.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Convert HTML to Markdown\nstep method 1, online  http://domchristie.github.io/turndown/ https://tool.lu/markdown/  nodejs turndown Convert HTML to Markdown with Node.js Start by installing Turndown:\n https://davidwalsh.name/convert-html-markdown  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/markdown/convert-markdown-to-org-with-pandoc.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " convert-markdown-to-org-with-pandoc\npandoc 检查是否有 pandoc 命令\ninstall docker pull dalibo/pandocker alias pandoc=\u0026quot;docker run --rm -u `id -u`:`id -g` -v `pwd`:/pandoc dalibo/pandocker\u0026quot;  CRLF or LF 查看文件类型 使用vim打开文件，输入:set ff?。根据返回结果可以文件类型\n https://www.cnblogs.com/jiangz/p/4231279.html  LR 把文档全转成 unix end-of-line\ndos2unix ./*/*.md   https://github.com/greenrobot/greenDAO/issues/71  to org docker run --rm -u `id -u`:`id -g` -v `pwd`:/pandoc dalibo/pandocker README.md -o README.org  或者\npandoc README.md -o README.org  ref  https://pandoc.org/demos.html https://hub.docker.com/r/dalibo/pandocker  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mongodb/mongodb.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "mongodb\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/elk/elk.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " ELK "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/monitor.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 监控系统 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/prometheus/functions.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " function函数 [TOC]\nabs 求绝对值\nabsent 检测是否为空\nceil 四舍五入\nchanges 一定时间范围内改变的次数\nclamp_max 设置上限，最大值不大于设置的上限\nclamp_max(v instant-vector,max scalar)  clamp_min 设置下限，最小值不小于设置的下限\nclamp_min(v instant-vector,min scalar)  day_of_month day_of_week days_in_month 每个月的天数 28-31\ndelta 计算区间开始时与当前值的差值\ndelta(cpu_temp_celsius{host=\u0026quot;zeus\u0026quot;}[2h])  deriv deriv（v range-vector）使用简单线性回归计算范围向量v中时间序列的每秒导数。\n仅限于gauge数据\nexp floor 取整\n0.6 \u0026ndash;\u0026gt; 0\nhistogram_quantile holt_winters hour 返回小时数，0-23\nidelta increase 一定时间内的增长量，比如CPU时间，访问量(counter数据类型)\nirate 一定时间区间内，两个相邻的值之间的变化率（对应整体的变化量）\nlabel_join 添加标签\nlabel——replace 替换标签\nln 自然对数\nlog10 十进制对数\nminute 返回分钟（0-59）\nmouth 返回月份（1-12）\npredict_linear 简单线性回归\nrate 计算一段时间内美妙的平均增长率（与irate类似但又不同）\nresets 返回一定范围内呗reset的次数，仅适用count\nresets(up[1y]) 查看一年内exporter重启次数\nround scalar 向量转换为标量 vector -\u0026gt; scalar\nsort 按照升序返回向量元素\nsort_desc 降序返回向量元素\nsqrt 计算向量的平方根\ntime 返回Unix时间\ntimestamp 返回时间戳\nvector 讲标量座位没有标签的向量返回\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/prometheus/prometheus.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " prometheus "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/prometheus/storage.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " storage 本地存储 每两个小时的数据存储在一个目录中，包含一个或者多个块文件，里面也有这个时间区间的所有时间序列样本，以及元数据文件和索引文件（通过metric name和label索引时间序列）。当前时间段的数据并没有直接持久化到本地，而是存放在内存中。有一个WAL（write-ahead-log）预写日志机制，当Prometheus服务从崩溃中重启时可以重放WAL日志。当时间序列数据通过API被删除时，只是把删除记录保存在单独的逻辑删除文件中，而不是立即从块文件中删除数据\n最初的两小时一个的时间序列会在后期被不断压缩并整合成一个长时间序列（类似zabbix保留趋势数据的方式？减小时间精度之类）\n参数  --storage.tsdb.path: 数据存储目录，默认为data/ --storage.tsdb.retention：数据保留时间，默认为15d  远程存储 本地存储不支持多节点\nhttp2\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/zabbix/python%E5%AE%9E%E7%8E%B0zabbix%E5%91%8A%E8%AD%A6%E6%8E%A8%E9%80%81%E9%92%89%E9%92%89.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " python实现zabbix告警推送钉钉 写了一个简单的python脚本，用来推送zabbix告警到钉钉机器人，推送格式为markdown，有需要的可以自己修改markdown的格式及推送的值（zabbix宏）\n环境如下，理论上zabbix版本不影响，可以看看官方宏定义是否有区别\n python 3 zabbix 3.4.2  zabbix宏官方文档：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location\n配置 配置钉钉自定义机器人  官方文档：https://open-doc.dingtalk.com/docs/doc.htm?treeId=257\u0026amp;articleId=105735\u0026amp;docType=1  编写zabbix告警脚本并置于alertscripts路径下 [itservice@zabbix alertscripts]$ cat /usr/lib/zabbix/alertscripts/alert_for_zabbix_by_dingding.py #!/usr/bin/env python3 # encoding: utf-8 # author: huangwj # mail: huangwjwork@gmail.com # bolg: huangwj.app # csdn: http://blog.csdn.net/u010871982 # github: https://github.com/huangwjwork # file: alert_for_zabbix_by_dingding.py # time: 2018/5/11 14:31 ''' 本程序由huangwjwork开发,一切最终解释权归于huangwjwork. 本程序为开源,只用于技术交流,只供开发者参考与学习. 不得用于违反法律以及未经许可不得用于商业.保留其追责权利. 本程序不涉及任何违法敏感因素,如有人拿程序改造成违法工具,将与本程序开发者无关. 勇于开源,请勿滥用.内部学习交流,请勿传播.违反者造成相关法律事故,自行承担刑事责任. ''' import sys import getopt import requests import json import traceback try: opts,args = getopt.getopt(sys.argv[1:],shortopts='',longopts=['webhook_url=','webhook_title=','alert_message=']) for opt,value in opts: if opt == '--webhook_url': webhook_url = value elif opt == '--webhook_title': webhook_title = value elif opt == '--alert_message': alert_message = value webhook_header = { \u0026quot;Content-Type\u0026quot;: \u0026quot;application/json\u0026quot;, \u0026quot;charset\u0026quot;: \u0026quot;utf-8\u0026quot; } webhook_message = { \u0026quot;msgtype\u0026quot;: \u0026quot;markdown\u0026quot;, \u0026quot;markdown\u0026quot;: { \u0026quot;title\u0026quot;: webhook_title, \u0026quot;text\u0026quot;: alert_message } } sendData = json.dumps(webhook_message,indent=1) requests.post(url=webhook_url,headers=webhook_header,data=sendData) except: traceback.print_exc(file=open('/tmp/alert_zabbix_dingding.log','w+'))  配置zabbix mediatype webhook_url替换成钉钉机器人webhook URL\n配置user 配置action 附上message\n 告警   ## 故障 **主机名称：** {HOSTNAME1} **告警名称：** {TRIGGER.NAME} **告警级别：** {TRIGGER.SEVERITY} **告警时间：** {EVENT.DATE} {EVENT.TIME} **检查项：** {TRIGGER.KEY1} **当前值：** {ITEM.LASTVALUE} **IP地址：** {HOST.IP} **事件ID：** {EVENT.ID}   恢复   ## 恢复 **主机名称：** {HOSTNAME1} **告警名称：** {TRIGGER.NAME} **告警级别：** {TRIGGER.SEVERITY} **告警时间：** {EVENT.DATE} {EVENT.TIME} **恢复时间：** {EVENT.RECOVERY.DATE} {EVENT.RECOVERY.TIME} **故障时长：** {EVENT.AGE} **检查项：** {TRIGGER.KEY1} **当前值：** {EVENT.RECOVERY.VALUE} **IP地址：** {HOST.IP} **事件ID：** {EVENT.ID}  ​\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/monitor/zabbix/zabbix.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " zabbix "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/mysql/mysql.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "mysql\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/expressvpn-open-app-not-use-proxy.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 如何在打开VPN时正常访问国内网站 如何在打开VPN时正常访问国内网站\n把 firefox 加入，让其不再使用 expressvpn . 想听歌时，用firefox打开 https://y.qq.com/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/network.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "network\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/network/privoxy-socks-to-https.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " linux下使用privoxy将socks转为http代理\nhttps://www.cnblogs.com/liuxuzzz/p/5324749.html\nprivoxy有将socks代理转为http代理的功能。\n1.开启shadowsocks，socks代理地址为127.0.0.1:1080。\n2.安装privoxy。\n$ sudo apt-get install privoxy\n3.更改provoxy配置，位置在“/etc/privoxy/config”。\n$ sudo vim /etc/privoxy/config\n在里面添加一条：\n在 froward-socks4下面添加一条socks5的，因为shadowsocks为socks5， 地址是127.0.0.1:1080。注意他们最后有一个“.” forward-socks4 / socks-gw.example.com:1080 . forward-socks5 / 127.0.0.1:1080 .\n下面还存在以下一条配置，表示privoxy监听本机8118端口， 把它作为http代理，代理地址为 http://localhost.8118/ 。 可以把地址改为 0.0.0.0:8118，表示外网也可以通过本机IP作http代理。 这样，你的外网IP为1.2.3.4，别人就可以设置 http://1.2.3.4:8118/ 为http代理。 listen-address localhost:8118\n4.然后重启privoxy。\n$ sudo systemctl restart privoxy\n5.现在你就可以使用http代理了，如果你要给系统设置http代理，就在~/.bashrc里添加一条http_proxy配置。\n$ vim ~/.bashrc\n添加：\nexport http_proxy=http://127.0.0.1:8118/\n然后使用source是它立刻生效。\n$ source ~/.bashrc\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-bug-fix.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 记一次nginx的漏洞补救\nenv 安全报告中提示 nginx 安全漏洞（CVE-2018-16843） ,百度，nginx CVE-2018-16843\n nginx:  version: 1.13.0 directory:  源码： /usr/svc/nginx-1.13.0 编译后：/opt/local/nginx   os: solaris10  step 找版本 https://cloud.tencent.com/info/71abe1e1ae97740ce376d8b46f894dbd.html\n提示，要升级到 1.14.1 。去 github.com 查一下 nginx的releases.\nhttps://github.com/nginx/nginx/releases\n果然，\non 6 Nov 2018 release-1.14.1  那我们快速安装 1.14.1 或以上版本吧。\n不编译 试图躲过编译安装\n因为是 solaris10, 机器上，没有 c 编译器，所以，看能不能躲过编译安装\nhttps://www.opencsw.org/packages/CSWnginx/\npkgadd -d http://get.opencsw.org/now /opt/csw/bin/pkgutil -U /opt/csw/bin/pkgutil -i nginx /opt/csw/bin/pkgutil -y -i nginx /usr/sbin/pkgchk -L CSWnginx # list files  /opt/csw/bin/pkgutil -i nginx 是为了查看版本号，看是不是我们想要的版本，如果不是，则不安装。\n查了一下，版本是 1.13.8 不行呀。躲不过去了。老老实实去编译吧。（一般不编译的最新版本一般都会滞后,其实，心里也有预料）\n编译 https://www.nginx.com/resources/wiki/start/topics/tutorials/solaris_10_u5/\nhttps://www.nginx.com/resources/wiki/start/topics/tutorials/solaris_11/\n找源码 查找一下 在 1.14.1后的 releases\nhttps://github.com/nginx/nginx/releases?after=release-1.14.1\n找到感觉合适的版本号\nhttp://nginx.org/en/download.html\n比如 http://nginx.org/download/nginx-1.14.2.tar.gz\n下载吧。\ngunzip nginx-1.14.2.tar.gz tar -xvf nginx-1.14.2.tar.gz  configure（第一次） 拿 configure 参数 先要去原来的nginx 编译后文件夹找到 nginx 启动文件，输入 nginx -V 拿到 configure 的参数。\n-bash-3.2# cd /opt/local/nginx/ -bash-3.2# ./sbin/nginx -V nginx version: nginx/1.13.0 built by Sun C 5.14 SunOS_sparc 2016/05/31 built with OpenSSL 1.1.0e 16 Feb 2017 TLS SNI support enabled configure arguments: --prefix=/opt/local/nginx --with-cpu-opt=sparc64 --with-http_ssl_module --with-cc-opt='-I /opt/local/include' --with-ld-opt='-L /opt/local/lib -R /lib -R /usr/lib -R /opt/local/lib' -bash-3.2#  把configure 参数 里的目录，修改成我们的新nginx安装的对应目录\n./configure --prefix=/opt/local2/nginx --with-cpu-opt=sparc64 --with-http_ssl_module --with-cc-opt=\u0026quot;-I /opt/local2/include\u0026quot; --with-ld-opt=\u0026quot;-L /opt/local2/lib -R /lib -R /usr/lib -R /opt/local2/lib\u0026quot;\n尝试 configure -bash-3.2# ./configure --prefix=/opt/local2/nginx --with-cpu-opt=sparc64 --with-http_ssl_module --with-cc-opt=\u0026quot;-I /opt/local2/include\u0026quot; --with-ld-opt=\u0026quot;-L /opt/local2/lib -R /lib -R /usr/lib -R /opt/local2/lib\u0026quot; checking for OS + SunOS 5.10 sun4v checking for C compiler ... not found ./configure: error: C compiler cc is not found -bash-3.2#  需要 cc\nsolaris 找 gcc -bash-3.2# pkginfo | grep -i gcc application CSWgcc4core gcc4core - GNU C compiler application CSWgcc4g++ gcc4g++ - GNU C++ Compiler application CSWlibgcc-s1 libgcc_s1 - The GNU Compiler Collection, libgcc_s.so.1 application SPRO-studio-gccrt gcc 5.1.0 libstdc++ and libgcc_s headers and libraries system SUNWgcc gcc - The GNU C compiler system SUNWgccruntime GCC Runtime libraries -bash-3.2# which SUNWgcc no SUNWgcc in /usr/sbin /usr/bin /opt/SUNWSpro/bin /usr/ccs/bin /usr/sfw/bin /opt/local/bin /usr/ucb  https://www.unix.com/solaris/165222-there-gcc-but-doesnt-work.html\n-bash-3.2# which gcc /usr/sfw/bin/gcc -bash-3.2# /usr/sfw/bin/gcc --version gcc (GCC) 3.4.3 (csl-sol210-3_4-branch+sol_rpath) Copyright (C) 2004 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. -bash-3.2#  configure（第二次） -bash-3.2# CC=\u0026quot;/usr/sfw/bin/gcc\u0026quot; ./configure --prefix=/opt/local2/nginx --with-cpu-opt=sparc64 --with-http_ssl_module --with-cc-opt=\u0026quot;-I /opt/local2/include\u0026quot; --with-ld-opt=\u0026quot;-L /opt/local2/lib -R /lib -R /usr/lib -R /opt/local2/lib\u0026quot;  ./configure 示例 -bash-3.2# CC=\u0026quot;/opt/SUNWspro/bin/cc\u0026quot; ./configure --prefix=/opt/local2/nginx --with-cpu-opt=sparc64 --with-http_ssl_module --with-cc-opt=\u0026quot;-I /opt/local2/include\u0026quot; --with-ld-opt=\u0026quot;-L /opt/local2/lib -R /lib -R /usr/lib -R /opt/local2/lib\u0026quot; checking for OS + SunOS 5.10 sun4v checking for C compiler ... found + using Sun C compiler + Sun C version: 5.14 SunOS_sparc 2016/05/31 checking for --with-ld-opt=\u0026quot;-L /opt/local2/lib -R /lib -R /usr/lib -R /opt/local2/lib\u0026quot; ... found checking for -Wl,-E switch ... not found checking for gcc builtin atomic operations ... disabled checking for C99 variadic macros ... found checking for gcc variadic macros ... found checking for gcc builtin 64 bit byteswap ... not found checking for unistd.h ... found checking for inttypes.h ... found checking for limits.h ... found checking for sys/filio.h ... found checking for sys/param.h ... found checking for sys/mount.h ... found checking for sys/statvfs.h ... found checking for crypt.h ... found checking for SunOS specific features checking for sendfilev() ... found checking for event ports ... found checking for nobody group ... found checking for poll() ... found checking for /dev/poll ... found checking for kqueue ... not found checking for crypt() ... found checking for F_READAHEAD ... not found checking for posix_fadvise() ... not found checking for O_DIRECT ... not found checking for F_NOCACHE ... not found checking for directio() ... found checking for statfs() ... not found checking for statvfs() ... found checking for dlopen() ... found checking for sched_yield() ... not found checking for sched_yield() in librt ... found checking for sched_setaffinity() ... not found checking for SO_SETFIB ... not found checking for SO_REUSEPORT ... not found checking for SO_ACCEPTFILTER ... not found checking for SO_BINDANY ... not found checking for IP_TRANSPARENT ... not found checking for IP_BINDANY ... not found checking for IP_BIND_ADDRESS_NO_PORT ... not found checking for IP_RECVDSTADDR ... found checking for IP_SENDSRCADDR ... not found checking for IP_PKTINFO ... found checking for IPV6_RECVPKTINFO ... found checking for TCP_DEFER_ACCEPT ... not found checking for TCP_KEEPIDLE ... not found checking for TCP_FASTOPEN ... not found checking for TCP_INFO ... not found checking for accept4() ... not found checking for eventfd() ... not found checking for eventfd() (SYS_eventfd) ... not found checking for int size ... 4 bytes checking for long size ... 8 bytes checking for long long size ... 8 bytes checking for void * size ... 8 bytes checking for uint32_t ... found checking for uint64_t ... found checking for sig_atomic_t ... found checking for sig_atomic_t size ... 4 bytes checking for socklen_t ... found checking for in_addr_t ... found checking for in_port_t ... found checking for rlim_t ... found checking for uintptr_t ... uintptr_t found checking for system byte ordering ... big endian checking for size_t size ... 8 bytes checking for off_t size ... 8 bytes checking for time_t size ... 8 bytes checking for AF_INET6 ... found checking for setproctitle() ... not found checking for pread() ... found checking for pwrite() ... found checking for pwritev() ... not found checking for sys_nerr ... not found checking for _sys_nerr ... not found checking for maximum errno ... found checking for localtime_r() ... found checking for clock_gettime(CLOCK_MONOTONIC) ... not found checking for clock_gettime(CLOCK_MONOTONIC) in librt ... found checking for posix_memalign() ... not found checking for memalign() ... found checking for mmap(MAP_ANON|MAP_SHARED) ... found checking for mmap(\u0026quot;/dev/zero\u0026quot;, MAP_SHARED) ... found checking for System V shared memory ... found checking for POSIX semaphores ... not found checking for POSIX semaphores in libpthread ... not found checking for POSIX semaphores in librt ... found checking for struct msghdr.msg_control ... not found checking for ioctl(FIONBIO) ... found checking for struct tm.tm_gmtoff ... not found checking for struct dirent.d_namlen ... not found checking for struct dirent.d_type ... not found checking for sysconf(_SC_NPROCESSORS_ONLN) ... found checking for sysconf(_SC_LEVEL1_DCACHE_LINESIZE) ... not found checking for openat(), fstatat() ... found checking for getaddrinfo() ... found checking for PCRE library ... not found checking for PCRE library in /usr/local/ ... not found checking for PCRE library in /usr/include/pcre/ ... not found checking for PCRE library in /usr/pkg/ ... not found checking for PCRE library in /opt/local/ ... found checking for PCRE JIT support ... found checking for OpenSSL library ... not found checking for OpenSSL library in /usr/local/ ... not found checking for OpenSSL library in /usr/pkg/ ... not found checking for OpenSSL library in /opt/local/ ... found checking for zlib library ... found creating objs/Makefile Configuration summary + using system PCRE library + using system OpenSSL library + using system zlib library nginx path prefix: \u0026quot;/opt/local2/nginx\u0026quot; nginx binary file: \u0026quot;/opt/local2/nginx/sbin/nginx\u0026quot; nginx modules path: \u0026quot;/opt/local2/nginx/modules\u0026quot; nginx configuration prefix: \u0026quot;/opt/local2/nginx/conf\u0026quot; nginx configuration file: \u0026quot;/opt/local2/nginx/conf/nginx.conf\u0026quot; nginx pid file: \u0026quot;/opt/local2/nginx/logs/nginx.pid\u0026quot; nginx error log file: \u0026quot;/opt/local2/nginx/logs/error.log\u0026quot; nginx http access log file: \u0026quot;/opt/local2/nginx/logs/access.log\u0026quot; nginx http client request body temporary files: \u0026quot;client_body_temp\u0026quot; nginx http proxy temporary files: \u0026quot;proxy_temp\u0026quot; nginx http fastcgi temporary files: \u0026quot;fastcgi_temp\u0026quot; nginx http uwsgi temporary files: \u0026quot;uwsgi_temp\u0026quot; nginx http scgi temporary files: \u0026quot;scgi_temp\u0026quot; -bash-3.2# cd /opt/local2/ -bash-3.2# ls -a include/ lib/ nginx/ -bash-3.2# ls -a nginx/ . .. -bash-3.2# ls -a lib/ . .. -bash-3.2# ls -a include/ . .. -bash-3.2#  找到一大把地 not found, 很多 not found 不影响，不需要找到相应的软件, 并不意味 configure 失败，且，虽然文件夹中文件全无.\nmake 文件夹中文件, 由 make 生成.\n-bash-3.2# make \u0026amp;\u0026amp; make install  检验 -bash-3.2# cd /opt/local2/nginx/ -bash-3.2# ls conf html logs sbin nginx version: nginx/1.15.12 built by gcc 3.4.3 (csl-sol210-3_4-branch+sol_rpath) built with OpenSSL 1.1.0e 16 Feb 2017 TLS SNI support enabled configure arguments: --prefix=/opt/local2/nginx --with-cpu-opt=sparc64 --with-http_ssl_module --with-cc-opt='-I /opt/local2/include' --with-ld-opt='-L /opt/local2/lib -R /lib -R /usr/lib -R /opt/local2/lib' -bash-3.2#  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx-fix-diff-path-diff-cookie-path.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 解决同域名不同路径下形成不同session cookie, 从而使得不同的帐户密码登录\ntargit 我的最终目的是要让\n http://192.168.168.137:8081/ 使用 一个帐号密码(admin:adminsz189)登录 http://192.168.168.137:8081/admin/ 使用 另一个帐号密码(admin:admin)登录  env 参考 解决nginx proxy_pass反向代理cookie,session丢失的问题\n为什么cookie 会丢失？ 比如说一个没有经过代理的地址 ： http://127.0.0.1/project cookie_path：/project\n如果按照第二种方式代理 那么地址就是 ： http://127.0.0.1/proxy_path cookie_path: /proxy_path\n如果cookie_path与地址栏上的path不相符游览器就不会接受这个cookie，自然session就失效了\nproxy_cookie_path 的用法 proxy_cookie_path 的作用是用来改变cookie的路径\n语法： proxy_cookie_path path replacement; path就是你要替换的路径 replacement 就是要替换的值\n详情可以去nginx 官网看看 传送门\n下面是可能的三种情况\n host、端口转换，cookie不会丢失   location /project { proxy_pass http://127.0.0.1:8080/project; }   路径也变化，则需要设置cookie的路径转换   location /proxy_path { proxy_pass http://127.0.0.1:8080/project; proxy_cookie_path /project /proxy_path; }   直接代理本地端口   location /proxy_path { proxy_pass http://127.0.0.1:8080/; proxy_cookie_path /project /proxy_path; # project 为你的项目名 也可用变量代替 }  实践 到这里，我们知道，我的实战环境是第2种，设置cookie的路径转换\n修改 /admin/ 的 cookie path\n location /admin/{ proxy_pass http://127.0.0.1:3021/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_cookie_path / /admin; }  最后效果如下：\n（可跳过）弯路 因为这里是使用的是 express-session 所以，到\nhttps://github.com/expressjs/session\n然后，设置 cookie.path 如下：\napp.use(session({ store: new RedisStore({ prefix: \u0026quot;admin:\u0026quot;, host: process.env.REDIS_URL, db: process.env.REDIS_DB }), secret: pkgInfo.description, resave: false, saveUninitialized: true, cookie: { maxAge: 3600 * 1000 * 1000, httpOnly: true, path: \u0026quot;/admin/\u0026quot; } }))  发现服务会报错。找原因。\n找到 /node_modules/_express-session@1.16.1@express-session/index.js 下的\n // pathname mismatch var originalPath = parseUrl.original(req).pathname || '/' if (originalPath.indexOf(cookieOptions.path || '/') !== 0) return next();  这个地方，我们console.log 一下。\n-----》 originalPath /GET_LIST/device_rent_manage -----\u0026gt; cookieOptions.path undefined  发现，originalPath 是 \u0026ldquo;/GET_LIST/device_rent_manage\u0026rdquo;, 而不是我们以为的 \u0026ldquo;/admin/GET_LIST/device_rent_manage\u0026rdquo;\n所以，这样来说，我们的 cookie path 不是 \u0026ldquo;/admin\u0026rdquo; 而是 \u0026ldquo;/\u0026rdquo; .\n回想一下，这个是合理的，因为nginx通过 \u0026ldquo;/admin\u0026rdquo; 把端口转发至其它端口了，所以，实际处理进程，是不知道 \u0026ldquo;/admin\u0026rdquo; 的存在的。\n那么，也就意味着，程序修改不了 cookie 的path.\n思路  修改 cookie 的 path 修改 cookie 的 Domain  修改 cookie 的 Domain 要把 /admin 放在二级域名下. 成本比较高。\n修改 cookie 的 path 程序修改不了 cookie.path ，但是其它应用可以（比如nginx）\ngoogle: nginx proxy_cookie_path\n找到 - 解决nginx proxy_pass反向代理cookie,session丢失的问题 - 解决nginx使用proxy_pass反向代理时,session丢失的问题\n如上配置就解决了。\n关于 cookie, session 的其它参考  node.js操作Cookie Cookie和Session详解 express-session session_set_cookie_params  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/nginx.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "nginx\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/Rewrite.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Rewrite [TOC]\nUpstream命令-负载 upstream upstream name {...} ;  name为服务器组的组名（别名），花括号中可以列出后端服务器组中包含的服务器\n默认轮询（Round-Robin），轮流处理请求，如果某个服务器处理时出现错误，则切换下一个服务器，直到所有服务器报错，返回报错内容\nserver server address [patameters];   address，服务器地址，可以是IP地址，主机名，域名，或者unix Domain Socket  parameters  weight=number，服务器权重，权重值高的优先处理请求 max_fails=number，设置请求失败次数，一定时间范围，服务器请求失败的次数搞过限定值，认为服务器down，默认值为1，设置为0则失效 fail_timeout，设置尝试请求某服务器的时间，即max_fails的事件范围。也用于检查服务器时候有效，如果一台服务器down，则该时间段内不会再次检查服务器状态；默认10Ss backup,标记某个服务器为备用服务器，只有其他服务器down或者busy时才处理客户端请求 down，永久标记服务器为无效，通常与ip_hash配合使用   配置示例：\nupstream backend { server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; }  ip_hash 基于IP地址将客户端的请求定向到同一台服务器，保证客户端与服务器间会话稳定\n局限：\n 不能用server中的weight变量一起使用 nginx服务器必须是最前端的服务器，才能获取到客户端真实IP 客户端IP地址必须是C类地址  upstream backend { ip_hash; server myback1.proxy.com; server myback2.proxy.com; }  keepalive keepalive connections;  connections为nginx服务器每个worker process允许该服务器组保持的空闲网络连接数上线，超过后哦，将采用最近最少使用的策略关闭网络连接\nleast_conn 配置nginx服务器使用负载均衡策，选择最少连接负载的服务器分配连接，如果有多台符合的服务器，则采用加权轮询选择这几台服务器\nRewrite指令 rewrite依赖PCRE（peal compatible regular expressions）\n地址重写 \u0026amp; 地址转发  地址重写：实现地址标准化，如google.com，www,google.com，google.cn，都跳向google首页 地址转发：将一个域名知道另一个以后站点的过程  区别：\n 地址转发后客户端地址显示不变，地址红鞋后客户端浏览器地址栏中的地址改变为服务器选择确定的地址 地址转发过程只产生一次网络请求；地址重写一般会产生两次请求 地址转发一般发生在同一站点项目内，地址重写没有该限制 地址转发的页面可以不用全路径表示，但地址重写到的页面必须使用完整的路径名表示 地址转发过程中，可以将客户端请求的request传递给新的页面，地址重写不可以 地址转发的速度较地址重定向快  if 根据条件判断结果选择不同的nginx配置，可以在server块或者location块中配置该指令\nif （condition） {...}   变量名条件，不为空为true，空或0false  if （$slow） { ... #nginx配置 }   变量判断  if ( $request_method = POST ){ return 405; }   正则判断，匹配则true  if ( $http_user_agent ~ MSIE ) { ... } IF ( $HTTP_COOKIE ~* \u0026quot;ID=([^;]+)(?:;|$)\u0026quot;){ 匹配正则表达式，成功则true }   判断文件是否存在 -f 是否不存在 !-f  if ( -f $request_filename ) { ... } if ( !-f $request_filename ) { ... }   判断目录是否存在 -d 是否不存在 !-d\n 判断目录或者文件是否存在 -e  判断请求的事件是否可执行 -x\n  注意：字符串不需要加引号\nbreak  跳出当前作用域\nlocation / { if ($slow){ set #id $1 break; limit_rate 10k;\t# break跳出当前作用域，不执行 } if (condition A ){\t# break上级其他作用域，顺序执行 ... } }  return  用于完成对请求的处理，直接返回响应状态代码，return后的配置均无效\nreturn [text] return code URL; # code为301,302,303,307 return URL;\t# code为302,307  rewrite rewrite regex replacement [flag];   rewrite接收到的URI不包含host，也不包含请求指令?arg1=value1 replacement为替换URI中被截取内容的字符串 flag  last，一条URI匹配规则后，被重新为一条新的URI，重新再所有location中进行匹配，提供了URI转入其他location的机会 break，一条URI匹配后，重写为新的URI，在本location中继续进行处理，不会转入其他的location redirect，将重写后的URI返回给客户端，状态码302，临时重定向 permanent，重写后的URI返回给客户端，状态码301，永久重定向   rewrite_log rewrite_log on | off  默认off，配置为on后，URL重写的日志会以notice级别输出到error_log里\nset 设置一个新的变量\nset variable value   variable为变量名，要用符号$标记，且不能与nginx服务器预设的全局变量同名 value，变量的值  uninitialized_variable_warn 用于配置使用未初始化的变量时，是偶记录警告日志：\nuninitialized_variable_warn on | off  默认on\nrewrite的使用 域名跳转 sever { listen 80; server_name jump.myweb.name; rewrite ^/ http://www/myweb.info/;\t# 域名跳转，针对jump.myweb.name的所有请求跳转到www.myweb.info }  server{ listen 80； server_name jump.mywebname jump.myweb.info； if ( $host ~ myweb\\.info )\t# 如果主机名正则匹配myweb.info { rewrite ^(.*) http://jump.myweb.name$1 permanent；\t# 重写URI到http://jump.myweb.name/URL } }  域名镜像？？ 没懂和普通rewrite的区别，根据资源做分流？\n独立域名 将一个站点根据资源分割为多个域名\nserver { listen 80; server_name bbs.myweb.name; rewrite ^(.*) http://www.myweb.name/bbs$1 last;\t# 将bbs模块重写为域名bbs.myweb.name } server { listen 80; server_name home.myweb.name; rewrite ^(.*) http://www.myweb.name/home$1 last;\t# 将home模块重写为域名home.myweb.name }  目录自动添加\u0026rsquo;/\u0026rsquo; 配置index参数后\nhttp://www.myweb.name/bbs/ 带/的可以直接查找index文件\nhttp://ww.myweb.name/bbs 不带/不能被识别为目录，不能自动寻找index\nlocation ^~ /bbs\t# 依据匹配程度标准匹配 { if ( -d $request_filename ) {\t# 检测请求的目录是否存在 rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent;\t# 匹配结尾没有/的目录，在结尾加上/ } }  目录合并 目录结构复杂不利于搜索，可以通过rewrite简化路径，比如root/server/12/34/56/78/9.html\nserver { listen 80; server_name www.myweb.name; location ^~ /server { rewrite ^/server-(\\d+)-(\\d+)-(\\d+)-(\\d+)\\.html$ /server/$1/$2/$3/$4/html last ; } }  防盗链 请求网页时，A网页中存在B站点的资源时，就存在A对B的盗链行为，B站点为了防止这种行为，就需要检测http协议中header中referer头域检测访问目标资源的源地址，当检测到referer头域中的值不是自己的站点的URL，就阻止访问\nnginx中valid_referers用来获取referer头域中的值，并将结果赋值给全局变量$invalid_referer,如果referer头域中没有符合valid_referers指令配置的值，$invalid_referer会被赋值为1\nvalid_referers none | blocked | server_names | string ...;   none，referer头域不存在 blocked，检测referer头域的值被伪装或者被删除的情况 server_names，设置一个或多个URL，检测referer头域的值是否是这些URL中的某个  server { listen 80; server_name www.myweb.name; location ~* ^.+(gif|jpg|png|swf|flv|rar|zip)$ { valid_referers none blocked server_names *.myweb.name; if ($invalid_referer){ rewrite ^/ htttp://www.myweb.com/images/forbidden.png; } ) }  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/gzip%E5%8E%8B%E7%BC%A9.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " gzip压缩 gzip压缩页面需要浏览器和服务器双方支持，即服务器端压缩，浏览器端解压并解析。压缩页面后，传输流量小，传输速度更快\n我的配置如下，压缩效果很明显：\ngzip on; gzip_comp_level 9; gzip_min_length 1024; gzip_types text/plain application/javascript text/css application/xml application/json;  查看header信息中Content-Encoding: gzip\n$ curl -I -H \u0026quot;Accept-Encoding: gzip, deflate\u0026quot; https://huangwj.app/search_index.json % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0HTTP/1.1 200 OK Server: nginx/1.12.2 Date: Tue, 12 Jun 2018 06:28:11 GMT Content-Type: application/json Last-Modified: Mon, 11 Jun 2018 09:24:44 GMT Connection: keep-alive ETag: W/\u0026quot;5b1e3fdc-a2cf6\u0026quot; Content-Encoding: gzip  压缩效果很nice，压缩前search_index.json660K左右，压缩后80K\nngx_http_gzip_module模块处理的9个指令 gzip 用于启用或关闭gzip功能，默认off\ngzip on | off;  gzip_buffers 设置gzip压缩文件使用的缓存空间大小\n number，指定nginx服务器需要向系统申请缓存空间的个数，默认number*size=128 size，指定每个缓存空间的大小，一般取内存页一页的大小，4KB或8KB  gzip_buffers number size;\t# 32 4K | 16 8K  gzip_comp_level 指定压缩级别，1-9从低到高，压缩程度从低到高，压缩效率从高到底（时间、计算效率）\ngzip_comp_level level;  gzip_disable 针对不同种类客户端发起的请求，选择性开启或关闭gzip功能\ngzip_disable regex ...;  gzip_http_version 针对不同HTTP协议版本，选择性开启gzip功能，用于设置开启gzip功能的最低http协议版本\ngzip_http_version 1.1;  默认1.1版本\ngzip_min_length 启用压缩的下限，过小的页面压缩没有意义，单位字节\ngzip_min_length 1024;  默认20，设置为0是表示不管响应页面大小如何通通进行压缩，建议1KB以上\ngzip_proxied 反向代理时后效，用于设置是否对后端服务器返回的结果进行gzip压缩\ngzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...;   off ，关闭nginx对后端服务器返回结果的gzip压缩，默认关闭 expired，后端服务器响应头部包含用于只是响应数据过期时间的expired头域时，启用gzip no-cache，后端服务器响应页头部包含用于通知所有缓存机制是否缓存cache-control头域，且指令值为no-cache时，启用gzip no-store，后端服务器响应页头部包含用于通知所有缓存机制是否缓存cache-control头域，且指令值为no-store时，启用gzip private，后端服务器响应页头部包含用于通知所有缓存机制是否缓存cache-control头域，且指令值为private时，启用gzip no_last_modified，后端服务器响应页头部不包含用于指明需要获取数据最后秀爱时间的last-modified头域时，启用gzip no-etag，当后端服务器响应页头部不包含用于标示被请求变量的实体值etag头域时，启用对响应数据的gzip压缩 auth，后端服务器响应页头部包含用于标示HTTP授权证书的authorizationl头域，且指令值为private时，启用gzip any，无条件对后端服务器响应数据的gzip  gzip_types 根据MIME类型选择性开启gzip\ngzip_types mime-type ...;  gzip开启时，默认对text/html进行gzip压缩，可以按照需求添加压缩类型，也可以压缩所有“*”\ngzip_types text/plain application/javascript text/css text/html application/xml; gzip_types * ;  gzip_vary 用于设置是否在响应头部添加\u0026rdquo;Vary: Accept-Encoding\u0026rdquo;，告诉接收方接收到的数据是否为压缩数据。对于不慎不支持gzip压缩的客户端浏览器很有用\ngzip_vary on | off ;  也可以用add_header得到相同效果\nadd_header Vary Accept-Encoding gzip ;  注意：该指令存在bug，会导致IE4级以上浏览器的数据缓存功能失效\nngx_http_gzip_static_module模块处理的指令 可选模块，使用前需要\u0026ndash;with-http_gunzip_module\nngx_http_zip_static_module模块主要负责搜索和发送经过gzip压缩过的数据，这些数据以”GZ“作为后缀名存储在服务器。如果请求的数据被压缩过，且客户端支持gzip，直接返回压缩后数据\n ngx_http_gzip_static_module，使用静态压缩，在HTTP响应头部包含Content-Length指明报文长度，服务器可确定相应数据长度 ngx_http_gzip_module，使用chunked编码的动态压缩，主要适用于服务器无法确定响应数据长度的情况，比如大文件下载，需要实时生成数据长度  相关指令  gzip_static on | off | always;  on，开启模块功能 off，关闭模块功能 always，一直发送gzip预压缩文件，不检查客户端是否支持gzip  gzip_proxied expired | no-cache | no-store | private auth ;  注意：该模块下的gzip_vary，只给未压缩的内容添加\u0026rsquo;Vary:Accept-Encoding\u0026rsquo;，如果要给所有响应头添加头域，可以通过nginx配置add_header指令实现\nngx_http_gunzip_module模块处理的2个指令 可选模块，使用前需要\u0026ndash;with-http_gunzip_module\n默认关闭，开启式如果客户端不支持gzip，则返回解压后的数据，如果支持gzip，则仍然返回压缩数据\ngunzip_static实际测试中没有该指令，官方文档也查不到！！！！\nhttp://nginx.org/en/docs/http/ngx_http_gunzip_module.html\ngunzip gunzip_static gunzip_static on | off ;  gunzip_buffer 类似ngx_http_gzip_module中的gzip_buffers\ngunzip_buffers number size ;  默认number*size=128\ngzip配置实例 gzip on ;\t#开启gzip功能 gzip_min_length ;\t#开启gzip的文件大小 gzip_buffers 4 16K；\t#申请4个缓存空间，每个16K gzip_comp_level 2；\t#压缩级别2 gzip_types text/plain applicatio/json text/css application/xml application/javascript; gzip_vary on; gunzip_static on ;  建议配置在HTTP块，全局开启压缩，不压缩的server可以单独gzip off\nserver { listen 8082 ; server_name 192.168.1.1 ; gzip off ; }  nginx与其他web服务器协作gzip nginx作为反向代理时建议关闭后端服务器gzip，开启nginx gzip，否则可能出现页面异常\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/nginx%E5%9F%BA%E7%A1%80.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " nginx基础 nginx官网：http://www.nginx.org\nnginx wiki：https://www.nginx.com/resources/wiki/\nnginx配置文件 nginx.conf示例 # 全局块：默认配置文件到event块之间的内容，主要设置一些影响nginx服务器整体运行的配置命令，包括nginx的用户，用户组，允许生成的worker process数，nginx进程PID存放路径，日志存放路径和类型、配置文件引入 user nobody;\t# 用户nobody worker_processes 1;\t# error_log logs/error.log; error_log logs/error.log notice; error_log logs/error.log info; pid logs/nginx.pid; # events块：events块涉及的指令主要影响nginx服务器与用户的网络连接，常用到的设置包括是否开启对多worker process下的网络连接进行序列化，是否允许同事接受多个网络连接，怄那种时间驱动模型处理连接请求，每个worker process可以同事支持的最大连接数等 events { worker_connections 1024; } # http块是nginx服务器配置中的重要部分，代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这个模块中。 # http块中可以包含自己的全局快，也可以包含server块，server块中又可以金亦波包含location块，在本书中我们使用\u0026quot;http全局块\u0026quot;来表示http中自己的全局块，即http块中不包含在server块中的部分 # http全局块中可以包含文件引入、MIME-Type定义、日志自定义、是否使用sendfile传输文件、连接超时时间、单连接请求数上限等 http { include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log logs/access.log main; sendfile on; tcp_nopush on; keepalive_timeout 0; keepalive_timeout 65; gzip on; # server块与虚拟主机的概念有密切联系。 # 虚拟主机，又称虚拟服务器、主机空间或者网页空间，他是一种技术，为了节互联网服务器硬件成本而出现。将服务内容逻辑划分为多个服务单位，对外表现为多个服务器，充分利用服务器硬件资源 # server块可以包含多个server块，而每个server块就相当于一台虚拟主机，他内部可有多台主机联合提供服务 server { listen 80; server_name localhost; charset koi8-r; access_log logs/host.access.log main; # 每个server块可以包含多个location块，主要作用于给予nginx服务器接收到的请求字符串对除虚拟主机名称之外的字符串进行匹配，对特定的请求进行处理，地址定向、数据缓存和应答控制等功能都是在这部分实现，许多第三方模块的配置也是在location块中提供功能 location / { root html; index index.html index.htm; } error_page 404 /404.html; redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } proxy the PHP scripts to Apache listening on 127.0.0.1:80 location ~ \\.php$ { proxy_pass http://127.0.0.1; } pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 location ~ \\.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi_params; } deny access to .htaccess files, if Apache's document root concurs with nginx's one location ~ /\\.ht { deny all; } } another virtual host using mix of IP-, name-, and port-based configuration server { listen 8000; listen somename:8080; server_name somename alias another.alias; location / { root html; index index.html index.htm; } } HTTPS server server { listen 443 ssl; server_name localhost; ssl_certificate cert.pem; ssl_certificate_key cert.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root html; index index.html index.htm; } } }  user 启动用户 user user [group];   user：制定运行nginx服务器的用户 group：可选项制定可以运行nginx服务器的用户组  如果想要所有用户都可以启动nginx，则把user注释掉，或者设置为\nuser nobody nobody;  worker process 进程数 nginx服务器实现并发处理服务的关键所在，理论上worker process越大支持的并发越大，但实际受限于服务器本身资源\nworker process number|auto;   number：制定nginx进程最多可以产生多少个worker process auto：nginx自动检测生成相应的worker process（一般等同于CPU线程数量）  pid 进程ID 主进程号，编译安装默认在logs目录下\n尽量写绝对路径，如：/opt/nginx/logs/nginx.pid\nerror_log 错误日志 全局块、HTTP块和server块都可以对你滚下服务器的日志进行相关配置，语法结构如下：\nerror_log file | stderr [debug | info | notice | warn | error | crit | alert |emerg];  从语法结构上看，nginx服务器错误日志支持输出到固定文件file或者输出到标准错误输出stderr；日志的错误级别可选，（debug、info、notice、warn、error、crit、alert、emerg）。需要注意：设置某一级别后，比这一级别高的日志也会被记录下来\nreeor_log logs/error.log error;  日志等级高于error的日志会被记录在logs/error.log下\ninclude 包含配置文件 用于将其他的nginx配置或者第三方模块的配置引用到当前的主配置文件中。语法为：\ninclude file;  注意： 新引用进来的文件同样要求运行nginx进程的用户对其具有写权限，并且符合nginx配置文件规定的相关语法和结构\n该配置命令可以放在配置文件的任意地方\naccept_mutex 网络连接序列化 惊群问题：当某一时刻只有一个网络连接到来时，多个睡眠进程会被同时叫醒，但只有一个进程可获得连接，如果每次还行的进程数目太多，会影响一部分系统性能。\n为了解决这样的问题，nginx配置中包含了accept_mutex，当accept_mutex开启时，将对多个nginx进程接收连接进行序列化，防止多个进程对连接的争抢，其语法结构为：\naccept_mutex on | off ;  该指令默认开启，只能在events块中进行配置\nmulti_accept 多网络连接 nginx服务器的worker process是否同时接收多个新到达的网络连接，由multi_accept控制：\nmulti_accept on | off ;  use 事件驱动模型 nginx服务器提供多宗事件驱动模型来处理网络消息，指令use:\nuse method;  其中，method可选择的内容：select、poll、kqueue、epoll、rtsig、/dev/poll以及eventport\n注意： 可以在编译是使用--with-select_module和--without-select_module设置是否强制编译select模块到nginx内核；使用--with-poll_module和--without-poll_module设置是否强制编译poll模块到nginx内核。\n此指令只能在events块中进行配置。\nwork_connections 最大连接数 每一个worker process同时开启的最大连接数\nworker_connections number;  默认值512\n注意：这里的number不仅仅包括和前端用户简历的连接数，而是包括所有可能的连接数。另外，number值不能大于操作系统支持打开的最大我呢见句柄数量\n只能在events块中进行配置\nMIME-Type 文件类型 MIME-Type是网络子u按的媒体类型，包括HTML，XML，GIF，及Flash等文本、媒体资源\ninclude mine.types; default_type application/octet-stram;  [root@test nginx]# cat conf/mime.types types { text/html html htm shtml; ... text/mathml mml; ... image/png png; ... image/x-ms-bmp bmp; application/font-woff woff; application/java-archive jar war ear; ... application/vnd.openxmlformats-officedocument.presentationml.presentation pptx; application/vnd.openxmlformats-officedocument.spreadsheetml.sheet xlsx; application/vnd.openxmlformats-officedocument.wordprocessingml.document docx; ... application/octet-stream bin exe dll; application/octet-stream deb; ... audio/midi mid midi kar; audio/mpeg mp3; ... video/3gpp 3gpp 3gp; video/mp2t ts; video/mp4 mp4; ... }  type中包含了浏览器能够识别的MIME类型以及对应相应类型的文件啊后缀名，由于mime——types文件是猪配置文件应用的第三方文件\ndefault——type mime-type;  access_log 服务日志 access_log path [format [buffer=size]]   path: 日志存放的路径和名称 format： 可选项，自定义服务日志的格式字符串 size： 配置临时存放日志的内存缓存区大小  access_log可以在HTTP、server、或者location块进行设置，默认的配置为：\naccess_log logs/access.log combined;  combined 为log_format指令默认定义的日志格式字符串的名称\n取消日志 access_log off;\t log_format 服务日志格式 只能在HTTP块中进行配置\n name 格式民称，默认为combined string 服务日志的格式字符串，可以使用nginx预设的变量获取相关内容，变量的名称使用双引号，string整体使用单引号括起来。  log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;';  sendfile 文件传输模式 sendfile可以放nginx在传输文件是直接在磁盘和TCP socket之间传输数据，如果这个参数不开启，会先在用户空间(nginx进程空间)申请一个buffer，用read函数把数据从磁盘读到cache，再从cache读取到用户空间的buffer，再用writer函数把数据从用户空间的buffer写入到内核的buffer，最后到TCP socket，开启这个参数可以让数据不用经过用户buffer。\nsendfile on | off ; sendfile_max_chunk size;   sendfile默认为off，可以在HTTP、server、location中进行配置\n sendfile_max_chunk默认值为0，可以在HTTP、server、location中配置\n  size值如果大于0，则nginx每个worker process每次调用sendfile传输的数据量最大不能超过这个值；size值设置为0，则无限制。\nkeepalive_timeout 连接超时时间 与用户简历会话连接后，nginx服务器可以保持的会话时长，可以配置在server和location中\nkeepalive_timeout timeout [header_timeout];   timeout 服务器端对连接的保持时间，默认75S header_timeout，可选项，在应答报文头部的keep-alive域设置超时时间：“Keep-Alive：timeout=header_timeout”，保温中的指令可以被Mozilla或者konqueror识别  # 在服务端保持连接的时间设置为120s，发送给用户端的应答报文头部中Keep-Alive域的超时时间设置为100s keepalive_timeout 120s 100s;  keepalive_requests 单连接请求数上限 nginx服务端与用户建立会话连接后，用户端通过此连接发送请求。keepalive用于限制用户通过一个连接向nginx服务器发送请求的次数，默认为100\nkeepalive_requests number;  listen 网络监听 三种监听模式 监听地址 listen address [:port] [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [deferred] [accepy_filter=filter] [bind] [ssl];  监听端口 listen port [default_server] [setfib=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [ssl];  Unix domain socket listen unix:path [default_server] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ssl];  参数  setfib=number，监听socket关联路由表，目前只对FreeBSD起作用 backlog=number，设置监听函数listen()最多允许多少网络连接同时处于挂起状态，在FreeBSD中默认为-1，其他平台默认511（比默认的512work_connections少1个） rcvbuf=size，设置监听socket接收缓存区大小 sndbuf=size，设置监听socket发送缓存区大小 deferred，标识符，将accept()设置为deferred模式 accept_filter=filter，设置accept()设置为deferred模式 bind，标识符，使用独立的bind()处理address:port；一般情况下，对于端口相同而IP地址不同的多个连接，nginx服务器将只使用一个监听命令，并使用bind()处理端口相同的所有链接。 ssl，标识符，设置会话连接使用ssl模式进行，此标识符与nginx服务器提供的HTTPS  server_name 基于名称的虚拟主机 server_name name ,,,;  name可以是一个名称，也可以由多个名称并列，用空格隔开。第一个名称作为虚拟主机的主要名称\nserver_name myserver.com www.myserver.com ;  server_name支持通配符'*'以及正则表达式，'~':\n# 通配符 server_name *.myserver.com www.myserver.*; # 正则表达式 server_name ~^www\\d+\\.myserver\\.com$;  nginx0.7.40开始，正则表达式支持字符串捕获功能，既可以将正则表达式匹配成功的名称中的一部分字符串拾取出来，作为变量使用。对内容嵌套小括号，内容从左到右依次存放在变量$1，$2，$3，变量有效区域不超过本server块（局部变量）\nserver_name ~^www\\.(.+)\\.com$;  匹配主机名www.myserver.com，则$1为myserver\nserver_name匹配优先级 当一个主机名满足多条server_name匹配规则时，按下列顺序进行匹配\n 精确匹配 通配符在开始位置 通配符在结束位置 正则表达式匹配  基于IP的虚拟主机 针对多IP的情况，设置nginx监听多个IP\nhttp { server { listen 80； server_name 192.168.1.31; } server { listen 80； server_name 192.168.1.32; } }  location location [ = | ~ | ~* | ^~ ] URI { . . . }  URI：待匹配的请求字符串，如/myserver.php，或者/.php$\n标准URI：不包含正则表达式的URI\n正则URI：包含正则表达式的URI\n =，用于标准URI，精确匹配 ^~，用于标准URI前，要求nginx服务器找到表示URI和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则URI和请求字符串做匹配 ~，表示URI包含正则表达式，并且区分大小写 ~*，表示URI包含正则表达式，并且不区分大小写  root root path;  path为nginx服务器接收到请求以后查找资源的根目录路径。path变量中可以包含nginx服务器预设的大多数变量，只有$document_root和$realpath_root\nalias alias可以改变location接收到的URI请求\nlocation ~ ^/data/(.+\\.(htm|html))$ { alias /locationtest1/other/$1 }  index location ~/data/(.+)/web/ { index index.$1.html index.myl.html index.html; }  当接收到/data/locationtest/web/，匹配成功，$1=locationtest，依次在/data/locationtest/web/查找index.locationtest.html，index.myl.html，index.html\nerror_page 用户尝试查看网页时遇到问题，服务器会将HTTP错误从服务端发送到web客户端。\nerror_page 404 /404.html; error_page 403 /403.html; location /404.html { root /myserver/errorpages; }  基于IP的访问权限 allow 允许 支持IPv4，IPv6\nallow address | CIDR | all ;   address，允许访问的客户端的IP，不支持同事设置多个，多个IP需要设置时需要重复使用allow命令 CIDR(无类域间路由，即可变长掩码)，允许访问的客户端CIDR地址，例如202.80.18.23\u0026frasl;25 ALL，荀彧所有客户端访问  deny 拒绝 deny address | CIDR | all ;  用法同上\n匹配规则 location / { deny 192.168.1.1; allow 192.168.1.0/24; deny all; }  匹配自上而下，匹配到规则即不再继续匹配\n例如：\n 192.168.1.1自上而下匹配第一条规则，deny，不再继续匹配 192.168.1.2自上而下匹配第二条规则，allow，不再继续匹配  基于密码的访问权限 NGINX支持基于HTTP basic authentication协议的认证。该功能由HTTP标准模块ngx_http_auth_basic_module支持\nauth_basic strng | off ;   string：开启认证功能，并配置验证时的只是信息 off：关闭认证功能  auth_basic_user_file指令，用于设置包含用户名和密码信息的文件路径\nauth_basic_user_file file;   file为密码文件的绝对路径  cat /etc/nginx/password name1:password1 name2:password2  加密密码可以使用crypt()函数进行密码加密的方式，在Linux平台可以使用htpasswd命令生成，运行后输入密码即可\nhtpasswd -c -d /nginx/conf/pass_file username  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84%E5%88%9D%E6%8E%A2.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " nginx服务器架构初探 模块化结构  核心模块：进程管理、权限控制、错误日志记录 标准HTTP模块：支持NGINX服务器标准HTTP功能 可选HTTP模块：扩展标准的HTTP功能，使其能够处理一些特殊的HTTP请求 邮件服务模块：支持NGINX的邮件服务 第三方模块：扩展NGINX服务器应用  核心模块和标准HTTP模块在NGINX快速编译后就包含在NGINX中\n查看NGINX源码包\n[root@test nginx-1.14.0]# ll objs/ total 3724 -rw-r--r-- 1 root root 19575 May 22 11:41 autoconf.err -rw-r--r-- 1 root root 39268 May 22 11:41 Makefile -rwxr-xr-x 1 root root 3679067 May 22 11:41 nginx -rw-r--r-- 1 root root 5321 May 22 11:41 nginx.8 -rw-r--r-- 1 root root 6598 May 22 11:41 ngx_auto_config.h -rw-r--r-- 1 root root 657 May 22 11:41 ngx_auto_headers.h -rw-r--r-- 1 root root 5725 May 22 11:41 ngx_modules.c -rw-r--r-- 1 root root 35840 May 22 11:41 ngx_modules.o drwxr-xr-x 9 root root 4096 May 22 11:41 src  查看NGINX变异后包含的的所有固有模块，这些模块声明以extern关键字修饰\n[root@test nginx-1.14.0]# cat objs/ngx_modules.c | grep extern extern ngx_module_t ngx_core_module; extern ngx_module_t ngx_errlog_module; extern ngx_module_t ngx_conf_module; extern ngx_module_t ngx_regex_module; extern ngx_module_t ngx_events_module; extern ngx_module_t ngx_event_core_module; extern ngx_module_t ngx_epoll_module; extern ngx_module_t ngx_http_module; extern ngx_module_t ngx_http_core_module; extern ngx_module_t ngx_http_log_module; extern ngx_module_t ngx_http_upstream_module; extern ngx_module_t ngx_http_static_module; extern ngx_module_t ngx_http_autoindex_module; extern ngx_module_t ngx_http_index_module; extern ngx_module_t ngx_http_mirror_module; extern ngx_module_t ngx_http_try_files_module; extern ngx_module_t ngx_http_auth_basic_module; extern ngx_module_t ngx_http_access_module; extern ngx_module_t ngx_http_limit_conn_module; extern ngx_module_t ngx_http_limit_req_module; extern ngx_module_t ngx_http_geo_module; extern ngx_module_t ngx_http_map_module; extern ngx_module_t ngx_http_split_clients_module; extern ngx_module_t ngx_http_referer_module; extern ngx_module_t ngx_http_rewrite_module; extern ngx_module_t ngx_http_proxy_module; extern ngx_module_t ngx_http_fastcgi_module; extern ngx_module_t ngx_http_uwsgi_module; extern ngx_module_t ngx_http_scgi_module; extern ngx_module_t ngx_http_memcached_module; extern ngx_module_t ngx_http_empty_gif_module; extern ngx_module_t ngx_http_browser_module; extern ngx_module_t ngx_http_upstream_hash_module; extern ngx_module_t ngx_http_upstream_ip_hash_module; extern ngx_module_t ngx_http_upstream_least_conn_module; extern ngx_module_t ngx_http_upstream_keepalive_module; extern ngx_module_t ngx_http_upstream_zone_module; extern ngx_module_t ngx_http_write_filter_module; extern ngx_module_t ngx_http_header_filter_module; extern ngx_module_t ngx_http_chunked_filter_module; extern ngx_module_t ngx_http_range_header_filter_module; extern ngx_module_t ngx_http_gzip_filter_module; extern ngx_module_t ngx_http_postpone_filter_module; extern ngx_module_t ngx_http_ssi_filter_module; extern ngx_module_t ngx_http_charset_filter_module; extern ngx_module_t ngx_http_userid_filter_module; extern ngx_module_t ngx_http_headers_filter_module; extern ngx_module_t ngx_http_copy_filter_module; extern ngx_module_t ngx_http_range_body_filter_module; extern ngx_module_t ngx_http_not_modified_filter_module;  NGINX模块命名习惯：ngx_前缀，_module后缀，中间使用一个或者多个英文单词描述模块的功能。比如ngx_core_module，中间的core表明是NGINX的核心模块\n核心模块 [root@test nginx-1.14.0]# cat objs/ngx_modules.c | grep extern extern ngx_module_t ngx_core_module; extern ngx_module_t ngx_errlog_module; extern ngx_module_t ngx_conf_module; extern ngx_module_t ngx_regex_module; extern ngx_module_t ngx_events_module; extern ngx_module_t ngx_event_core_module; extern ngx_module_t ngx_epoll_module;  核心模块分两类\n 主体功能：包括进程管理、权限控制、错误日志、配置解析 相应请求事件：事件驱动机制、正则表达式解析  标准HTTP模块    模块 功能     ngx_http_core 配置端口、URI分析、服务器相应错误处理、别名控制以及其他HTTP核心事务   ngx_http_access_module 基于IP地址的访问控制   ngx_http_auth_basic_module 基于HTTP的身份认证   ngx_http_autoindex_module 处理以“/”结尾的请求并自动生成目录列表   ngx_http_browser_module 解析HTTP请求头中的user-agent域的值   ngx_http_charset_module 指定网页编码   ngx_http_empty_gif_module 从内存创建一个1*1的透明GIF，可以快速调用   ngx_http_fastcgi_module 对fastCGI的支持   ngx_http_geo_module 将客户端请求中的参数转化为键值对变量   ngx_http_gzip_module 压缩请求响应，可以减少数据传输   ngx_http_index_filter_module 设置HTTP响应头   ngx_http_index_module 处理以\u0026rdquo;/\u0026ldquo;结尾的请求，如果没有找到该目录下的index页，就将请求转给ngx_http_autoindex_module模块处理；如果nginx服务器开启了ngx_http_random_index_module模块，则随机选择index页   ngx_http_limit_req_module 限制来自客户端的请求的相应和处理速率   ngx_http_limit_conn_module 限制来自客户端的链接的相应和处理速度   ngx_http_map_module 创建任意键值对变量   ngx_http_log_module 自定义access日志   ngx_http_memcached_module 对memcached的支持   ngx_http_proxy_module 支持代理服务   ngx_htttp_referer_module 过滤HTTP头中referer域值为空的HTTP请求   ngx_http_rewrite_module 通过正则表达式重新定向请求   ngx_http_scgi_module 对scgi的支持   ngx_http_ssl_module 对HTTPS的支持   ngx_http_upstream_module 定义一组服务器，可以接受来自代理、fastcgi、memcached的重定向、主要用于负载均衡    可选HTTP模块 可选HTTP模块在目前的nginx发行版本中只提供远吗，默认不编译。想要使用需编译时添加--with-XXX\n   模块 功能     ngx_http_addition_module 在响应请求的页面开始或者结尾添加文本信息   ngx_http_degradation_module 在低内存的情况下允许nginx服务器范围444或者204错误   ngx_http_perl_module 在nginx配置文件中可以使用Perl脚本   ngx_http_flv_module 支持将flash多媒体信息按照刘文建传输，可以根据客户端指定的开始位置返回flash   ngx_http_geoip_module 支持解析基于GeoIP数据库的客户端请求   ngx_http_perftools_module 支持google performance tools   ngx_http_gzip_module 支持在线实施压缩响应客户端的输出数据流   ngx_http_gzip_static_module 搜索并使用与压缩的以.gz为后缀名的文件代替一般文件响应客户端请求   ngx_http_image_filter_module 支持改变JPEG、GIF、PNG图片的尺寸和旋转方向   ngx_http_mp4_module 支持H.264/AAC编码的多媒体信息（MP4、M4V、M4A）   ngx_random_index_module nginx接收到以\u0026quot;/\u0026quot;结尾的请求时，对响应目录下随机选择一个文件作为index文件   ngx_http_secure_link_module 支持对请求链接的有效性检查   ngx_http_ssl_module 支持HTTPS/SSL   ngx_http_stub_status_module 支持返回nginx服务器的统计信息，包括处理链接的数量，链接成功的数量，处理的请求书，读取和返回的header信息数等信息   ngx_http_sub_module 使用指定的字符串替换响应信息中的信息   ngx_http_dav_module 支持HTTP协议和webDAV协议中的PUT、DELETE、NKCOL、COPY和MOVE方法   ngx_http_xslt_module 将XML响应信息使用XSLT（扩展样式表转换语言）进行转换    邮件服务模块 默认编译时不编译邮件服务模块\n ngx_mail_core_module ngx_mail_pop3_module ngx_mail_imap_module ngx_mail_smtp_module ngx_mail_auth_http_module ngx_mail_proxy_module ngx_mail_ssl_module  第三方模块 wiki站点\nnginx服务器的web请求处理机制 web服务器和客户端是一对多的关系，要实现并行处理请求，有三种方式可选：多进程、多线程、异步\n多进程方式 是指服务器没收到一个客户端请求，就由服务器主进程生成一个子进程与客户端建立连接进行交互，知道连接端口子进程结束\n 优点  实现简单，各子进程相互独立，处理过程不受干扰，稳定性好；处理结束后占用资源会被操作系统回收\n 缺点  操作系统建立子进程需要进行内存复制等操作，资源和时间上产生一定的额外开销，当处理大量并发请求时，系统资源压力大\n初期的Apache采用这种多进程方式，为应对大量并发请求，它采用预生成进程，即在客户端请求未到来前生成好子进程，处理结束后也不释放进程，等待下一个请求\n多线程方式 多线程与多进程类似，当服务器收到一个客户端请求时，由服务器主进程派生出一个县城出来和改客户端进行交互。\n 优点  由于操作系统产生一个县城的开销远远小于产生一个进程的开销，所以多线程减轻了web服务器对系统资源的要求。\n 缺点  多个线程处于同一进程，可以访问同样的内存空间，彼此相互影响；开发者需要对内存进行管理，增加出错风向；服务器需要长时间连续不停运转，错误的逐渐累积会对服务器产生重大影响\nIIS服务器使用多线程方式，稳定性良好，但经验丰富的web服务器管理员还是会定期检查和重启服务器\n异步方式 先从网络通信层面分析同步、异步、阻塞、非阻塞：\n 同步机制  是指发送请求后，收到接收方返回的相应后，继续发送下一个请求\n 异步机制  发送方发出一个请求，不等待接收方相应请求，就继续发送下一个请求\n同步机制中，所有的请求在服务器端得到同步，发送方和接收方对请求的处理步调是一直的；异步机制中，所有来自发送方得请求形成一个队列，接收方处理完成后通知发送方\n 阻塞  socket本质是IO操作。socket阻塞调用方式为：调用结果返回前，当前线程从运行状态变成挂起，一直等到调用结果返回之后，才进入就绪状态，获取CPU后继续执行\n 非阻塞  如果调用结果不能发上返回，当前线程也不会被挂起，而是立即返回执行下一个调用\n 同步阻塞方式  发送方想接收方发送请求后，一直等待相应，接收方处理请求时进行的IO操作如果不能马上得到结果，就一直等到返回结果后，才响应发送方，期间不能进行其他工作。\n 同步非阻塞方式  发送方想接收方发送请求后，一直等待相应；接收方处理请求时进行的IO操作如果不能马上得到结果，就立即返回，去做其他事情，但与有没有得到请求处理结果，不相应发送方，发送方一直等待；一直到IO操作完成后，接收方活得结果相应发送方后，接收方才进入下一次请求过程，在实际中不适用这种方式。\n 异步阻塞方式  发送方方向接收方发送请求后，不用等待相应，可以接着进行其他工作；接收方处理请求时进行的IO操作如果不能马上得到结果，就一直等到返回结果后，才相应发送方，期间不能进行其他工作，实际中不使用\n 异步非阻塞方式  发送方向接收方发送请求后，不用等待响应，可以继续其他工作；接收方处理请求时进行的IO操作如果不能马上得到结果，也不等待，而是马上返回去做其他事情。当IO操作完成以后，将完成状态和结果通知接收方，接收方再相应发送方。\n异步非阻塞是通信效率最高的一种\nnginx如何处理请求 nginx结合多进程机制和异步非阻塞机制对外提供服务。启动nginx后，会产生一个主进程（master process nginx）和多个工作进程（worker process），可以在配置文件中指定worker process数量。只有工作进程才用于处理客户端请求。\n[root@test ~]# ps -ef |grep -i nginx root 1425 1 0 May22 ? 00:00:00 nginx: master process nginx elk 1426 1425 0 May22 ? 00:00:00 nginx: worker process  nginx服务器进程模型有两种\n single模型  单进程，性能差，一般不使用\n master-worker模型  即master-slave模型，常用，工作进程即slave\n每个worker process都是用异步非阻塞方式，客户端请求数量增长，万国府在繁重时，nginx服务器使用多进程机制能够保证不增长系统资源的压力；同事异步非阻塞方式减少了工作进程在IO调用上的阻塞延迟，保证了不降低对请求的处理能力\nnginx的事件处理机制 nginx采用异步非阻塞方式处理请求，当IO调用完成后，需要通知工作进程。有两种方案：\n worker process每隔一段事件去检查IO的运行状态，这样会增大资源开销 IO处理完毕后主动通知worker process，nginx使用这种事件处理机制  select / poll / epoll / kqueue等事件驱动模型都用来支持第二种解决方案，可以让进程同时处理多个并发请求，不用关心IO调用的具体状态，事件准备好后就通知工作进程事件已经就绪。\nnginx服务器的事件驱动模型 事件驱动模型概述 事件驱动就是在持续事物管理过程中，有当前时间点上出现的事件引发的调用可用应用资源执行相关人物，解决不断出现的问题，防止事物堆积的一种策略。\n事件驱动模型组成：\n 事件收集器  收集所有事件，来自用户的（鼠标键盘输入等），来自硬件的（时钟事件）、来自软件（操作系统、应用程序）\n 事件发送器  事件发送器负责将收集器收集到的事件分发到目标对象中，即发送给事件处理器\n 事件处理器  主要负责具体时间的响应\n事件发送器每传递过来一个请求，目标对象就将其放入一个待处理时间列表，使用非阻塞IO的方式调用事件处理器来处理请求\n事件驱动处理库又被称作多路IO服用方式发，常见的有select模型、poll模型、epoll模型，nginx还支持rtsig模型、kqueue模型、dev/poll模型和eventport模型。\n事件驱动模型 后期补充\nselect库 poll库 epoll库 rtsig库 其他事件驱动模型 设计架构概览 服务器架构 服务进程  master process（主进程）  外界通信、内部管理\n 读取nginx配置文件并验证其有效性和正确性 建立、绑定和关闭socket 按照配置生成、管理和结束工作进程 接收外界指令，比如中期、升级即退出服务器等指令 不中断服务、实现平滑升级，升级失败进行回滚处理 开启日志文件、获取文件描述符 编译和处理Perl脚本\n worker process（工作进程）\n  处理用户请求\n 接收客户端请求 将请求一次送入各个功能模块进行过滤处理 IO调用，获取响应数据 与后端服务器通信，接受后端服务器处理结果 数据缓存，访问缓存索引、查询和调用缓存数据 发送请求结果、响应客户端请求 接收主程序指令、比如重启、升级和退出等指令\n cache loader \u0026amp; cache manager（缓存索引重建及管理进程）\n cache loader（缓存索引重建）  每1分钟1次，由master process生成，在缓存元数据重建完成后就自动退出\n根据本地此案的缓存文件在内存中建立索引元数据库\n cache loader（缓存索引管理）  主进程整个生命周期，对缓存索引进行管理\n判定索引元数据是否过期\n  进程交互  master-worker交互\n主进程指向工作进程的单向管道\n worker-worker交互\n通过master进程交互\n  run loops 事件处理循环模型 非自动，需要在设计代码过程中，在适当的时候启动run-loop机制对输入的事件作出响应。\n该模型师一个集合，每个元素就是一个run-lopp。一个run-loop可运行在不同模式下， 其中可以包含他所坚挺的输入事件源、定时器以及在事件发生时需要通知的run-loop监听器，当被监听的事件发生时，run-loop会产生一个消息，被run-loop监听器补货，从而执行预定的动作。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " nginx服务器的高级配置 /etc/sysctl.conf  针对IPv4的内核优化 net.core.netdev_max_backlog 队列数据包最大数目，表示每个网络接口接收数据报的速率比内核处理这些包的速率快时，允许发送到队列的数据包的最大数目\n系统默认值128，NGINX服务器中定义的NGX_LISTEN_BACKLOG默认为511，需要调整参数\nnet.core.netdev_max_backlog = 262144  net.core.somaxconn 系统同时发起的TCP连接数，默认值128，可能导致链接超时或者重传问题，可以根据实际需要结合并发请求书来调节\nnet.core.somaxconn = 262144  net.ipv4.tcp_max_orphans 设置系统中最多允许存在多少TCP套接字不被关联到任何一个用户文件句柄，超过这个数字，米有与用户文件句柄关联的TCP套接字将被立即复位，同时给出警告信息\nnet.ipv4.tcp_max_orphans = 262144  net.ipv4.tcp_max_syn_backlog 未收到客户端确认信息的连接请求的最大值。大于128MB内存的系统默认值为1024，小内存则是128。可以增大该参数：\nnet.ipv4.tcp_max_syn_backlog = 262144  net.ipv4.tcp_timestamps 用于设置时间戳，避免序列号的卷绕。赋值为0时表示禁止TCP时间戳的支持。\nnet.ipv4.tcp_timestamps = 0  net.ipv4.tcp_synack_retries 用于内核放弃TCP连接之前向客户端发送SYN+ACK包的数量。服务器与客户端要通过三次握手建立连接，在第二次握手期间，内核需要发送SYN并附带一个回应前一个SYN的ACK，主要影响这里，建议赋值为1，即内核放弃连接之前发送一次SYN+ACK包：\nnet.ipv4.tcp_synack_retries = 1  net.ipv4.tcp_syn_retries 与net.ipv4.tcp_synack_retries类似，设置内核放弃建立连接之前发送SYN包的数量，建议1\nnet.ipv4.tcp_syn_retries = 1  针对CPU的配置优化 worker proceses  用来设置nginx服务的进程数，一般设置为CPU的倍数，我这里配置worker process auto，一个4个CPU线程，会起4个nginx进程\n[root@test nginx]# ps -ef | grep nginx | grep -v grep root 1425 1 0 May22 ? 00:00:00 nginx: master process nginx elk 3495 1425 0 11:33 ? 00:00:00 nginx: worker process elk 3496 1425 0 11:33 ? 00:00:00 nginx: worker process elk 3497 1425 0 11:33 ? 00:00:00 nginx: worker process elk 3498 1425 0 11:33 ? 00:00:00 nginx: worker process [root@test nginx]# cat /proc/cpuinfo | grep processor processor : 0 processor : 1 processor : 2 processor : 3  worker_cpu_affinity  指定每一个线程的启动在哪个CPU核心，用二进制的每一位表示每个CPU核心，如果线程使用某个CPU核心，则对应核心的位置会置为1，不使用则置为0\n比如四CPU，起了4个nginx进程，那么需要4位而至今来表示CPU（4321，自右向左）\n 线程1使用第1个CPU核心：0001 线程2使用第2个CPU核心：0010 线程3使用第3个CPU核心：0100 线程4使用第4个CPU核心：1000  如果线程1使用4个核心，那么表示为1111\nworker_cpu_affinity 0001 0010 0100 1000;  如果8核心，则需要8位二进制表示CPU 00000001 00000010 10000000\n与网络连接相关的配置 基础：长连接和短连接 http建立tcp连接\n短连接：每一个请求都需要建立一次连接\n长链接：一段时间内同一客户端只需要监理一次连接\nkeepalive_timeout 设置nginx服务器与客户端保持连接的超时时间，可以设置两个时间：第一个时间字段为服务器断开连接的时间，第二个时间字段可选，为客户端主动断开连接的时间，keepalive消息头会发送给客户端）\nkeepalive_timeout 60 50;  上面的表示60S后服务器与客户端断开连接，客户端在50S后会主动断开与服务器的连接（不会等待服务器的60S）\nsend_timeout 建立连接后，会话活动中服务器等待客户端的响应时间。\nsend_timeout 10s;  代表在连接建立后，如果10秒内nginx服务器没有收到客户端新的响应，服务器会自动关闭连接\nclient_header_buffer_size 设置nginx服务器允许的客户端请求头的缓冲区大小，默认1KB，可以根据分系统分页大小来设置。\n获取系统分页大小：\n[huangwj@instance-1 ~]$ getconf PAGESIZE 4096  nginx服务器返回400错误时大概率是由于请求头过大造成，根据系统分页大小，可以设置client_header_buffer_size为4096\nclient_header_buffer_size 4k;  multi_accept 配置nginx服务器是否可以尽可能多的接收客户端的网络连接请求，默认off。\n与事件驱动模型相关的配置 use 指定nginx服务器使用的事件驱动模型\nwork_connections 设置nginx服务每个工作进程允许同时连接客户端的最大数量\nworker_connections 65535；  worker_connections受限于内核参数open_file_resource_limit（进程可以打开文件句柄的数量）\n查看file-max\n[huangwj@instance-1 ~]$ cat /proc/sys/fs/file-max 2000000  修改file-max\n[huangwj@instance-1 ~]$ cat /etc/sysctl.conf fs.file-max = 2000000 [huangwj@instance-1 ~]$ sudo sysctl -p fs.file-max = 2000000  worker_rlimit_sigpending 设置linux平台时间信号队列的长度上限\n主要影响rtsig事件驱动模型可以保存的最大信号数。nginx每个worker process有自己的时间信号队列用于暂存客户端请求发生信号，超过长度上限后悔自动专用poll模型处理为处理的客户端请求，根据实际的客户端并发请求数量和服务器运行环境的处理能力自行设定：\nworker_rlimit_sigpending 1024;  devpoll_changes和devpoll_enents 用于设置在/dev/poll事件驱动模式下nginx服务器可以与内核之间传递事件的数量\n# 传递给内核的事件数量 devpoll_changes number # 从内核获取的事件数量 devpoll_events  kqueue_changes和kqueue_events 用于设置在kqueue事件驱动模式下nginx服务器可以与内核之间传递事件的数量\n# 传递给内核的事件数量 kqueue_changes number # 从内核获取的事件数量 kqueue_events number  epoll_events 设置在epoll事件驱动模式下nginx服务器可以与内核之间传递事件的数量\nepoll_changes number  RTSIG_SIGNO 用于设置rtsig模式使用得当两个信号中的第一个，第二个信号实在第一个信号的编号上+1\nrtsig_signo signo  默认的第一个信号设置为SIGRTMIN+10\n查看系统支持的SIGRTMIN\n[huangwj@instance-1 ~]$ kill -l | grep SIGRTMIN 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12  rtsig_overflow_events 、rrtsig_overflow_test、rtsig_overflow_threshold 控制rtsig模式中信号队列溢出时nginx服务器的处理方式\nrtsig_overflow_events指令指定队列一出事使用poll库处理的事件数，默认16\nrtsig_overflow_test指定poll库处理完第几间时间后将清空rtsig模型是用的信号队列，默认32\nrtsig_overfolw_threshold指定rtsig模式使用的信号队列中的事件超过多少事就需要清空队列\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/nginx%E7%BC%93%E5%AD%98.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " nginx缓存 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/notes.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " nginx学习笔记 参考苗泽nginx高性能web服务器详解，记录学习过程\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/notes/proxy.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " proxy 反向代理常用命令 proxy_pass  server { location / { proxy_pass http://1.1.1.1:8080; } }  upstream时关于http协议的写法 proxy_pass带协议，则upstream不带协议\nupstream api { server 1.1.1.1:8080； server 2.2.2.2:8080; } server { location / { proxy_pass http://api; } }  upstream带协议，则proxy_pass不带协议\nupstream api { server http://1.1.1.1:8080； server http://2.2.2.2:8080; } server { location / { proxy_pass api; } }  proxy传递URI注意事项 想要改变URI，则在proxy中配置URI\n不想改变URI，则不再proxy中配置URI\nserver { server_name server location / { proxy_pass http://proxy; # proxy_pass不带URI，则传递原本请求的URI,即访问server/aaa代理为proxy/aaa } location /aaa { proxy_pass http://proxy; # proxy_pass不带URI，则传递URI，即访问server/aaa代理为proxy/aaa } location /aaa { proxy_pass http://proxy/bbb; # proxy_pass带URI，则替换原有URI，访问server/*全部代理为proxy/bbb } location /ccc { proxy_pass http://proxy/; # proxu_pass带URL，则替换原有URI，访问server/*全部代理为proxy/; } }  proxy_hide_header 隐藏头域信息\nproxy_hide_header field;  proxy_pass_header 发送部分头域信息，默认情况下nginx服务器头部不包含date，server，x-accel等来自被代理服务器的头域信息\nproxy_pass_header field ;  proxy_pass_request_body 用于配置是否将客户端的请求体（请求的参数）发送给代理服务器，默认开启\nproxy_pass_request_body on | off ;  proxy_pass_request_headers 是否将客户端请求头发送给代理服务器，默认on\nproxy_pass_request_headers on | off ;  proxy_set_header  更改客户端的请求头，将新的请求头发送给被代理的服务器\nproxy_set_header field value ;  proxy_set_header Host $proxy_host ; proxy_set_header Connection close ; proxy_set_header Host $http_host ; proxy_set_header Host $host:$proxy_port ;  proxy_set_body 修改客户端的请求体，并发送给代理服务器\nproxy_set_body value ;  proxy_bind  在配置了多个被代理服务器时，指定某一台服务器处理请求\nproxy_bind address ;  proxy_connect_timeout  nginx与被代理服务器尝试建立连接的超时时间，默认60s\nproxy_connect_timeout time ;  proxy_read_timeout nginx向后端服务器发送read请求后等待响应的事件，默认60s\nproxy_read_timeout time ;  proxy_send_timeout nginx向后端服务器发送write请求后等待响应的超时时间\nproxy_send_timeout time ;  proxy_http_version  指定nginx服务器提供代理服务的http协议版本，默认1.0，1.1版本支持upstream服务器组设置中的Keepalive指令\nproxy_http_version 1.0 | 1.1 ;  proxy_method  用于设置nginx服务器请求被代理服务器时的请求方法，一般为POST或者GET，设置了该命令后，客户端的请求方法就被忽略了\nproxy_method method ；  proxy_ignore_client_abort 忽略客户端中断，用于设置在客户端中断网络请求时，nginx服务器是否中断对后端服务器的请求，默认off\nproxy_ignore_client_abort on | off ;  proxy_ignore_headers 是否忽略头域信息，field为忽略的头域字段 proxy_ignore_headers field ...;  proxy_redirect 用于修改被代理服务器返回的响应头中的location和refresh\nproxy_redirect redirect replacement; # 将后端头域（redirect）替换为修改后的头域（replacement） proxy_redirect default; # 将后端头域替换为location块匹配的URL proxy_redirect off ; # 关闭proxy_redirect，则直接返回后端服务器的location和refresh  location /server/ { proxy_pass http://proxyserver/source/; proxy_redirect default ; } # default等同于如下 location /server/{ proxy_pass http://proxyserver/source/; proxy_redirect http://proxyserver/source/ /server/; }  proxy_intercept_errors 开启时，如果后端你服务器状态码≥400，则nginx返回自己定义错误页\n关闭时，nginx服务器直接返回后端服务器状态\nproxy_intercept——error on | off ;  proxy_headers_hash_max_size 配置存放在报文头的哈希表的容量，上限512字符\nproxy_headers_hash_max_size 512 ;  proxy_headers_hash_bucjet_size 设置nginx服务器生情存放http报文头的哈希表容量的单位大小，默认64字符\nproxy_headers_hash_bucket_size 64;  proxy_next_upstream 默认情况下，服务器组遵循upstream的轮询规则；使用该指令可以在出现某些错误时将请求交由组内其他服务器处理\nproxy_next_upstream status ...;   status为服务器返回状态，可以多个  error，与后端服务器发生连接错误 timeout，与后端服务器连接超时 invalid_header，后端服务器返回的请求头为空或者无效 http_400 | http_502 | http_503 等错误状态码 off，无法将请求发送给被代理的服务器   proxy_ssl_session_reuse 默认启用基于SSL的https，如果错误日志中出现SSL3_GET_FINISHED:digest check failed，可以关闭该配置\nproxy_ssl_session_reuse on | off ;  proxy buffer的常用配置 proxy_buffer_size、proxy_buffers、proxy_busy_buffers_size都是针对每一条请求\n每一次请求，nginx服务器尽可能多的从后端服务器接收响应数据，若响应数据超过buffer，则写入部分临时文件，一次响应数据接收完成或者buffer装满后，才向客户端传输数据\n每一个proxy buffer装满数据后，向客户端发送数据直至全部发送完成，过程中都处于busy状态，期间对他进行的其他操作都会失败\n当proxy buffer关闭时，nginx只要接收到后端服务器响应数据就会同步传递给客户端，本身不再读取完成的响应数据\nproxy_buffering 是否开启proxy buffer，也可以通过在HTTP响应头鱼x-accel-buffering头域设置yes或者no\nproxy_buffering on | off ;  proxy_buffers 用于配置接收一次后端服务器响应数据的proxy buffer个数和每个buffer的大小\nproxy_buffers number size ;  size一般为内存分页大小\n一次后端服务器相应数据的proxy buffer的总大小为number*size\nproxy_buffer_size 用于配置从后端服务器获取的第一部分响应数据的大小，一般包含HTTP响应头\nproxy_buffer_size size ;  一般与proxy_buffers设置保持一致或者更小\nproxy_busy_buffers_size size 用于限制同事处于busy的Proxy buffer的大小\nproxy_temp_path 配置用于临时存放后端服务器大体积响应数据的本地磁盘路径\nproxy_temp_path path [level 1 [ level 2 [ level 3 ] ] ] ;  level N：设置在path下第几级hash目录下存放临时文件 1 2 3 为嵌套关系\nproxy_temp_path /nginx/proxy_web/spool/proxy_temp 1 2 ;  配置为level2 二级目录，则目录如下\n/nginx/proxy_web/spool/proxy_temp/1/10/10101010101  proxy_max_temp_file_size  用于限制所有临时文件的总大小\nproxy_temp_file_write_size size；  proxy_temp_file_write_size 用于配置同时写入临时文件的数据量的总大小\nproxy_temp_file_write_size size ;  proxy_cache的常用配置 buffer与cache的区别  buffer，缓冲，主要用于传输速率不同步或者优先级不相同的设备之间传递数据，一般通过对一方数据进行临时存放，再同一发送给另一方 cache，缓存，将已有的数据在内存中建立缓存数据，提高数据的访问效率，对于过期不用的缓存可以随时销毁，但不会销毁硬盘上的数据  proxy_buffer与proxy_cache  proxy_buffer实现后端服务器与客户端的异步传输 proxy_cache实现nginx服务器对客户端的快速响应；将后端服务器回复到nginx的数据缓存在nginx本地，当客户端请求想用数据时，nginx服务器可以直接从本地检索数据返回给用户，减少与后端服务器交互的时间，提高响应速度  proxy_cache需要在proxy_buffer开启的情况下才能发挥作用\nproxy_cache常用命令 proxy_cache 用于配置一块公用的内存区域，用于存放缓存的索引数据\nproxy_cache zone | off ;   zone，设置用于存放缓存索引的内存区域的名称 off，关闭proxy_cache功能  proxy cache会检测候选服务器响应数据的HTTP头中的cache-control，expires。当cache-control值为no-cache，no-store，private，max-age=0时，expires头域包含一个过期时间时，数据不会被nginx服务器缓存，这是为了避免私有数据被其他客户端得到\nproxy_cache_bypass 当写在proxy_cache_bypass中的任意一个变量不为空且不为0，响应数据不从缓存中获取\nproxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment $http_pragma $http_authorization ;  proxy_cache_key 用于设置nginx服务器在内存中为缓存数据建立索引时的关键字，通常配置如下字段\nproxy_cache_key \u0026quot;$scheme$proxy_host$uri$is_args$args\u0026quot;  proxy_cache_lock "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nginx/ubuntu-install-nginx.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " ubuntu 安装 nginx\nenv aliyun 上面的 nginx配置，放到本地\nlan server\n os: ubuntu18.04 ip: 192.168.168.137  aliyun lcnx@iZwz95dxhc92qtibd4f399Z:/alidata/server/nginx/sbin$ ./nginx -V nginx version: nginx/1.6.0 built by gcc 4.6.3 (Ubuntu/Linaro 4.6.3-1ubuntu5) TLS SNI support enabled configure arguments: --user=www --group=www --prefix=/alidata/server/nginx --with-http_stub_status_module --without-http-cache --with-http_ssl_module --with-http_gzip_static_module lcnx@iZwz95dxhc92qtibd4f399Z:/alidata/server/nginx/sbin$  lan server 所以，我的编译参数是\nubuntu@utuntu:~/lcnx/aliyun/env/nginx-1.16.0$ --prefix=/home/ubuntu/lcnx/aliyun/env/nginx-1.16.0 --with-http_stub_status_module --without-http-cache --with-http_ssl_module --with-http_gzip_static_module checking for OS + Linux 4.15.0-50-generic x86_64 checking for C compiler ... not found ./configure: error: C compiler cc is not found  所以要安装一下 gcc . https://blog.csdn.net/AnneQiQi/article/details/51725658\nubuntu@utuntu:~/lcnx/aliyun/env/nginx-1.16.0$ sudo apt-get install build-essential  然后如果有报错，参考一下 cheatsheets\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/install-nodejs-with-nvm-ubuntu12.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 使用nvm安装nodejs 在 ubuntu12 下\nlcnx@iZwz95dxhc92qtibd4f399Z:~/src/nginx-1.15.12$ nvm install stable v12.0.0 is already installed. node: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by node) node: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.17' not found (required by node) node: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.16' not found (required by node) nvm is not compatible with the npm config \u0026quot;prefix\u0026quot; option: currently set to \u0026quot;\u0026quot; Run `nvm use --delete-prefix v12.0.0` to unset it. Creating default alias: default -\u0026gt; stable (-\u0026gt; v12.0.0) lcnx@iZwz95dxhc92qtibd4f399Z:~/src/nginx-1.15.12$ nvm use stable node: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by node) node: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.17' not found (required by node) node: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.16' not found (required by node) nvm is not compatible with the npm config \u0026quot;prefix\u0026quot; option: currently set to \u0026quot;\u0026quot; Run `nvm use --delete-prefix v12.0.0` to unset it. lcnx@iZwz95dxhc92qtibd4f399Z:~/src/nginx-1.15.12$ ls auto CHANGES CHANGES.ru conf configure contrib html LICENSE Makefile man objs README src lcnx@iZwz95dxhc92qtibd4f399Z:~/src/nginx-1.15.12$  安装gcc https://blog.csdn.net/jom_ch/article/details/78738824\nwget ftp://ftp.mirrorservice.org/sites/sourceware.org/pub/gcc/releases/gcc-5.5.0/gcc-5.5.0.tar.gz tar -zxvf gcc-5.5.0.tar.gz cd gcc-5.5.0 sudo ./configure --enable-checking=release --enable-languages=c,c++ --disable-multilib  报错\nconfigure: error: Building GCC requires GMP 4.2+, MPFR 2.4.0+ and MPC 0.8.0+.\n说明, 这个方式, 还是有问题呀.\n升级gcc https://itbilu.com/linux/management/NymXRUieg.html\n找到\nhttps://itbilu.com/linux/management/V1vdnt9ll.html\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/nodejs/nodejs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "nodejs\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-cmder.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " cmder change default shell https://gist.github.com/nickautomatic/02ccb76292f7f8d9767e\n如果输入\n\u0026quot;\u0026quot;D:\\Program Files\\Git\\bin\\bash.exe\u0026quot; -l -new_console:d:%CMDER_START%\u0026quot;  会每次都提示，好烦。。。\n最后的输入是：\n\u0026quot;D:\\Program Files\\Git\\bin\\bash.exe\u0026quot; -l  基本配置 https://www.jianshu.com/p/979db1a96f6d\ncmder快捷键记录 keyboard shortcuts https://www.jianshu.com/p/58a2dbc6aac4\nGlobal Keyboard shortcuts\n| 快捷键 | 描述 |\n|:\u0026mdash;\u0026mdash;\u0026mdash;-|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| | Ctrl + ` | Global Summon from taskbar |\n| Win + Alt + p | Preferences (Or right click on title bar) |\n| Alt + Enter | Fullscreen |\n| Ctrl + t | New tab dialog (maybe you want to open cmd as admin?) |\n| Ctrl + w | close tab |\n| Shift + alt + number | Fast new tab:1. CMD 2.Powershell 具体看Startup/Tasks 中的 number |\n| Ctrl+Tab或Ctrl+1,2\u0026hellip; | 切换Tab |\nshell 中的 Keyboard shortcuts\n| 快捷键 | 描述 |\n|:\u0026mdash;\u0026mdash;\u0026mdash;-|:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| | Ctrl + r | History search | | Shift + mouse | Select and copy text from buffer | | Right click / Ctrl + Shift + v | Paste text | | Ctrl + Alt + u | Traverse up in directory structure (lovely feature!) (没有测试出来) | | End，Home，Ctrl | Traverse text as usual on Windows (没有测试出来) |\nref  https://www.jianshu.com/p/979db1a96f6d https://www.jianshu.com/p/58a2dbc6aac4  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-gvm.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " gvm 安装 go1.5+ 必先 gvm install go1.4 -B ➜ ~ git:(master) ✗ gvm install go1.11.5 Downloading Go source... Installing go1.11.5... * Compiling... /root/.gvm/scripts/install: 行 84: go: 未找到命令 ERROR: Failed to compile. Check the logs at /root/.gvm/logs/go-go1.11.5-compile.log ERROR: Failed to use installed version ➜ ~ git:(master) ✗  参考 https://github.com/moovweb/gvm/issues/302 到 https://github.com/moovweb/gvm#a-note-on-compiling-go-15\ngvm install go1.4 -B gvm use go1.4 export GOROOT_BOOTSTRAP=$GOROOT gvm install go1.5  ref  https://github.com/moovweb/gvm#a-note-on-compiling-go-15  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/note/note-about-windows.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " env  os: win10  windows startup folder Your personal startup folder should be C:\\Users\u0026lt;user name\u0026gt;\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup. The All Users startup folder should be C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup. You can create the folders if they aren\u0026rsquo;t there. Enable viewing of hidden folders to see them.\nC:\\Users\\$username\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup  在windows中获取某个进程的具体执行路径 在windows下要获取具体的路径可以使用powershell ，例如我们要查看chrome的执行路径，可以：\n 在cmd中这样写：  \u0026gt; powershell \u0026quot;get-process chrome | select-object path\u0026quot;   在powershell中这样写：  \u0026gt; get-process chrome | select-object path  这里展示一个 bash 的执行路径：\nC:\\Users\\DELL [master ≡ +1 ~4 -0 !] λ get-process bash | select-object path Path ---- C:\\Windows\\system32\\bash.exe D:\\Program Files\\Git\\usr\\bin\\bash.exe C:\\Users\\DELL [master ≡ +1 ~4 -0 !]  ref  https://answers.microsoft.com/en-us/windows/forum/all/how-to-get-startup-folder-in-start-all-programs/d3f5486a-16c0-4e69-8446-c50dd35163f1 https://chainhou.iteye.com/blog/1872294  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/org/org.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "org\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/pip-install-memcache.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " python2 通过 pip 安装 memcache\nenv os: ubuntu server 16.04 python: 2.7.12\nstep pip install python-memcached 而不是 pip install memcache\nroot@ubuntu:~# pip install memcache /usr/local/lib/python2.7/dist-packages/pip/_vendor/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown. warnings.warn(warning, RequestsDependencyWarning) DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. Collecting memcache Could not find a version that satisfies the requirement memcache (from versions: ) No matching distribution found for memcache root@ubuntu:~# pip install python-memcached /usr/local/lib/python2.7/dist-packages/pip/_vendor/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown. warnings.warn(warning, RequestsDependencyWarning) DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. Collecting python-memcached Downloading https://files.pythonhosted.org/packages/f5/90/19d3908048f70c120ec66a39e61b92c253e834e6e895cd104ce5e46cbe53/python_memcached-1.59-py2.py3-none-any.whl Requirement already satisfied: six\u0026gt;=1.4.0 in /usr/lib/python2.7/dist-packages (from python-memcached) (1.10.0) Installing collected packages: python-memcached Successfully installed python-memcached-1.59 root@ubuntu:~#  check root@ubuntu:/etc/swift# python -c \u0026quot;import memcache; print(1+1);\u0026quot; 2 root@ubuntu:/etc/swift#  ref  https://blog.csdn.net/zhaoyangjian724/article/details/69817640  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-error-m-bad-interpreter-duplicate.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " /usr/bin/python^M: bad interpreter [duplicate] If you are using Vim, just enter the following command:\n:set fileformat=unix  ref  https://stackoverflow.com/questions/9975011/pycharm-usr-bin-pythonm-bad-interpreter  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python-struct-module.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " python：struct模块的pack、unpack\nPython是一门非常简洁的语言，对于数据类型的表示，不像其他语言预定义了许多类型（如：在C#中，光整型就定义了8种）\n它只定义了六种基本类型：字符串，整数，浮点数，元组（set），列表（array），字典（key/value）\n通过这六种数据类型，我们可以完成大部分工作。但当Python需要通过网络与其他的平台进行交互的时候，必须考虑到将这些数据类型与其他平台或语言之间的类型进行互相转换问题。打个比方：C++写的客户端发送一个int型(4字节)变量的数据到Python写的服务器，Python接收到表示这个整数的4个字节数据，怎么解析成Python认识的整数呢？ Python的标准模块struct就用来解决这个问题。\n官网地址： https://docs.python.org/2/library/struct.html\n示例 # ref: http://blog.csdn\u0026lt;a href=\u0026quot;http://lib.csdn.net/base/dotnet\u0026quot; class='replace_word' title=\u0026quot;.NET知识库\u0026quot; target='_blank' style='color:#df3434; font-weight:bold;'\u0026gt;.NET\u0026lt;/a\u0026gt;/JGood/archive/2009/06/22/4290158.aspx import struct #pack - unpack print print '===== pack - unpack =====' str = struct.pack(\u0026quot;ii\u0026quot;, 20, 400) print 'str:', str print 'len(str):', len(str) # len(str): 8 a1, a2 = struct.unpack(\u0026quot;ii\u0026quot;, str) print \u0026quot;a1:\u0026quot;, a1 # a1: 20 print \u0026quot;a2:\u0026quot;, a2 # a2: 400 print 'struct.calcsize:', struct.calcsize(\u0026quot;ii\u0026quot;) # struct.calcsize: 8 #unpack print print '===== unpack =====' string = 'test astring' format = '5s 4x 3s' print struct.unpack(format, string) # ('test ', 'ing') string = 'he is not very happy' format = '2s 1x 2s 5x 4s 1x 5s' print struct.unpack(format, string) # ('he', 'is', 'very', 'happy') #pack print print '===== pack =====' a = 20 b = 400 str = struct.pack(\u0026quot;ii\u0026quot;, a, b) print 'length:', len(str) #length: 8 print str print repr(str) # '/x14/x00/x00/x00/x90/x01/x00/x00' #pack_into - unpack_from print print '===== pack_into - unpack_from =====' from ctypes import create_string_buffer buf = create_string_buffer(12) print repr(buf.raw) struct.pack_into(\u0026quot;iii\u0026quot;, buf, 0, 1, 2, -1) print repr(buf.raw) print struct.unpack_from(\u0026quot;iii\u0026quot;, buf, 0)  运行结果：\n[work@db-testing-com06-vm3.db01.baidu.com Python]$ python struct_pack.py ===== pack - unpack ===== str: \u0014? len(str): 8 a1: 20 a2: 400 struct.calcsize: 8 ===== unpack ===== ('test ', 'ing') ('he', 'is', 'very', 'happy') ===== pack ===== length: 8 \u0014? '/x14/x00/x00/x00/x90/x01/x00/x00' ===== pack_into - unpack_from ===== '/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00' '/x01/x00/x00/x00/x02/x00/x00/x00/xff/xff/xff/xff' (1, 2, -1)  常用的方法 struct模块的内容不多，也不是太难，下面对其中最常用的方法进行介绍：\nstruct.pack struct.pack用于将Python的值根据格式符，转换为字符串（因为Python中没有字节(Byte)类型，可以把这里的字符串理解为字节流，或字节数组）。其函数原型为：struct.pack(fmt, v1, v2, \u0026hellip;)，参数fmt是格式字符串，关于格式字符串的相关信息在下面有所介绍。v1, v2, \u0026hellip;表示要转换的python值。\nstruct.unpack struct.unpack做的工作刚好与struct.pack相反，用于将字节流转换成python数据类型。它的函数原型为：struct.unpack(fmt, string)，该函数返回一个元组。\n下面的例子将两个整数转换为字符串（字节流）:\nimport struct a = 20 b = 400 s = struct.pack('ii', a, b) print(s, type(s)) #输出：b'\\x14\\x00\\x00\\x00\\x90\\x01\\x00\\x00' \u0026lt;class 'bytes'\u0026gt; print('length: ', len(s)) #输出：length: 8 s2 = struct.unpack('ii', s) print(s2) #输出：(20, 400) s2 = struct.unpack('ii', s) #报错：unpack requires a buffer of 4 bytes #==\u0026gt;解压需要一个4字节的缓冲区，也就是说'ii'表示8个字节的缓冲 #格式符\u0026quot;i\u0026quot;表示转换为int，'ii'表示有两个int变量。 #进行转换后的结果长度为8个字节（int类型占用4个字节，两个int为8个字节）  可以使用python的内置函数repr来获取可识别的字符串，其中十六进制的0x00000014, 0x00001009分别表示20和400。\nstruct.calcsize struct.calcsize用于计算格式字符串所对应的结果的长度，如：struct.calcsize(\u0026lsquo;ii\u0026rsquo;)，返回8。因为两个int类型所占用的长度是8个字节。\nimport struct print \u0026quot;len: \u0026quot;, struct.calcsize('i') # len: 4 print \u0026quot;len: \u0026quot;, struct.calcsize('ii') # len: 8 print \u0026quot;len: \u0026quot;, struct.calcsize('f') # len: 4 print \u0026quot;len: \u0026quot;, struct.calcsize('ff') # len: 8 print \u0026quot;len: \u0026quot;, struct.calcsize('s') # len: 1 print \u0026quot;len: \u0026quot;, struct.calcsize('ss') # len: 2 print \u0026quot;len: \u0026quot;, struct.calcsize('d') # len: 8 print \u0026quot;len: \u0026quot;, struct.calcsize('dd') # len: 16  struct.pack_into、 struct.unpack_from 这两个函数在Python手册中有所介绍，但没有给出如何使用的例子。其实它们在实际应用中用的并不多。Google了很久，才找到一个例子，贴出来共享一下：\n#!/usr/bin/env python #encoding: utf8 import sys reload(sys) sys.setdefaultencoding(\u0026quot;utf-8\u0026quot;) import struct from ctypes import create_string_buffer buf = create_string_buffer(12) print repr(buf.raw) # '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' struct.pack_into(\u0026quot;iii\u0026quot;, buf, 0, 1, 2, -1) print repr(buf.raw) # '\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\xff\\xff\\xff\\xff' print struct.unpack_from(\u0026quot;iii\u0026quot;, buf, 0) # (1, 2, -1)  struct 类型表 https://docs.python.org/2/library/struct.html#format-characters\nref  https://www.cnblogs.com/volcao/p/8807507.html https://docs.python.org/2/library/struct.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/python.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "python\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/python/ubuntu-install-pip.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " ubuntu 安装 pip\nenv os: ubuntu server 16.04\nstep root@ubuntu:~# sudo apt-get install python-pip python-dev build-essential Reading package lists... Done Building dependency tree Reading state information... Done build-essential is already the newest version (12.1ubuntu2). python-dev is already the newest version (2.7.12-1~16.04). The following NEW packages will be installed: python-pip 0 upgraded, 1 newly installed, 0 to remove and 98 not upgraded. Need to get 0 B/144 kB of archives. After this operation, 635 kB of additional disk space will be used. Do you want to continue? [Y/n] y Selecting previously unselected package python-pip. (Reading database ... 70623 files and directories currently installed.) Preparing to unpack .../python-pip_8.1.1-2ubuntu0.4_all.deb ... Unpacking python-pip (8.1.1-2ubuntu0.4) ... Processing triggers for man-db (2.7.5-1) ... Setting up python-pip (8.1.1-2ubuntu0.4) ... root@ubuntu:~# which pip /usr/local/bin/pip root@ubuntu:~# pip -V Traceback (most recent call last): File \u0026quot;/usr/bin/pip\u0026quot;, line 9, in \u0026lt;module\u0026gt; from pip import main ImportError: cannot import name main root@ubuntu:~# sudo ln -s /usr/local/bin/pip /usr/bin/pip ln: failed to create symbolic link '/usr/bin/pip': File exists root@ubuntu:~# which pip /usr/local/bin/pip root@ubuntu:~#  出现的问题，真的是搞不懂了，python2到 2020过期，难道连 pip 也一并都没有人维护了。真的是。\n把这个 /usr/bin/pip 删除掉\nroot@ubuntu:~# rm /usr/bin/pip root@ubuntu:~# sudo ln -s /usr/local/bin/pip /usr/bin/pip root@ubuntu:~# pip -V /usr/local/lib/python2.7/dist-packages/pip/_vendor/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown. warnings.warn(warning, RequestsDependencyWarning) pip 19.0 from /usr/local/lib/python2.7/dist-packages/pip (python 2.7) root@ubuntu:~#  pip search 一下。\nroot@ubuntu:~# pip search pysftp /usr/local/lib/python2.7/dist-packages/pip/_vendor/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown. warnings.warn(warning, RequestsDependencyWarning) DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. pysftp (0.2.9) - A friendly face on SFTP cheesefactory-sftp (0.13) - Wrapper for Pysftp. root@ubuntu:~#  安装成功\nref  http://makaidong.com/hellojesson/127680_20223560.html  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/qor/qor.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "qor\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/rancher/rancher.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "rancher\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/redis/redis.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "redis\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ruby/install-rvm-with-ubuntu.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "install rvm with ubuntu\n去 https://github.com/rvm/rvm#installing-rvm\nvagrant@ubuntu-xenial:~$ curl -L https://get.rvm.io | bash -s stable % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 194 100 194 0 0 29 0 0:00:06 0:00:06 --:--:-- 48 100 24168 100 24168 0 0 1908 0 0:00:12 0:00:12 --:--:-- 6628 Downloading https://github.com/rvm/rvm/archive/1.29.7.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc gpg: directory `/home/vagrant/.gnupg' created gpg: new configuration file `/home/vagrant/.gnupg/gpg.conf' created gpg: WARNING: options in `/home/vagrant/.gnupg/gpg.conf' are not yet active during this run gpg: keyring `/home/vagrant/.gnupg/pubring.gpg' created gpg: Signature made Thu 03 Jan 2019 10:01:48 PM UTC using RSA key ID 39499BDB gpg: Can't check signature: public key not found GPG signature verification failed for '/home/vagrant/.rvm/archives/rvm-1.29.7.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg --import - command curl -sSL https://rvm.io/pkuczynski.asc | gpg --import - In case of further problems with validation please refer to https://rvm.io/rvm/security vagrant@ubuntu-xenial:~$ source ~/.rvm/scripts/rvm -bash: /home/vagrant/.rvm/scripts/rvm: No such file or directory vagrant@ubuntu-xenial:~$ ls ~/.rvm/ archives src vagrant@ubuntu-xenial:~$ which rvm  说明rvm 没有安装成功。为什么？\n去 http://rvm.io/\n说明了先运行 gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB\nvagrant@ubuntu-xenial:~$ gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB The program 'gpg2' is currently not installed. To run 'gpg2' please ask your administrator to install the package 'gnupg2' vagrant@ubuntu-xenial:~$  要先安装 gpg2\nhttps://blog.programster.org/ubuntu-install-gpg-2\nvagrant@ubuntu-xenial:~$ sudo apt-get install gnupg2 -y  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/saleor/saleor.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "saleor\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/scoop/scoop.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "https://scoop.sh/\nscoop master = $ scoop list Installed apps: 7zip 19.00 concfg 0.2019.02.21 curl 7.64.0 figlet 1.0-go grep 2.5.4 openssh 7.6p1 pshazz 0.2019.02.04 touch 0.2018.08.04 scoop master = $  command\nscoop help scoop install 7zip scoop list scoop search scoop reset ruby  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs-faq-is-the-package-name-misspelled.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " spacemacs\n安装 Package 失败： Package is unavailable. Is the package name misspelled ? https://emacs-china.org/t/topic/2662/13\n我昨天遇到同样问题，参照 这个 issue 24 解决了。方法是打开配置文件（SPC f e d）找到 dotspacemacs-elpa-timeout 5 这一行改成 dotspacemacs-elpa-timeout 300 （或任何比较大的数），重启。不知道能不能帮到你。\nnyan-mode Invalid image type \u0026lsquo;xpm\u0026rsquo; "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/spacemacs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "spacemacs\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/ubuntu-spacemacs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " spacemacs 在ubuntu下的配置思考\n私人配置 环境1 os: wsl-ubuntu16 emacs: 26.2 spacemacs:\n环境2 操作系统: Ubuntu 16.04 TLS * Emacs版本: Emacs24.5.1\nEmacs版本: Emacs25.2.2\n问题  启动后，j,k 上下移动行的时候，行会移动   emacs 高手配置\n spacemacs 高手配置\n spacemacs ubuntu 配置 https://github.com/lsytj0413/spacemacs-private\n spacemacs 与 docker https://github.com/JAremko/spacemacs\n  sudo docker run -it \u0026ndash;rm -v $(\u0026lsquo;pwd\u0026rsquo;):/mnt/workspace -v /etc/localtime:/etc/localtime:ro -v ~/.ssh/id_rsa:${UHOME}/.ssh/id_rsa:ro -v ~/.gnupg:${UHOME}/.gnupg -v /var/run/dbus/system_bus_socket:/var/run/dbus/system_bus_socket -v /tmp/.X11-unix:/tmp/.X11-unix -v /etc/machine-id:/etc/machine-id:ro -e DISPLAY=$DISPLAY -e TZ=UA \u0026ndash;name spacemacs jare/spacemacs\n spacemacs 与 box  https://github.com/abellmann/spacemacs-devbox\n spacemacs 与 dotfiles https://github.com/mazinbokhari/dotfiles  配置中遇到的几个问题\ngoogle-c-style 与 c-c++ 相关\nhttps://github.com/syl20bnr/spacemacs/pull/10190\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/win10-MobaXterm-wsl-ubuntu-spacemacs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 借助 MobaXterm 使得 wsl-ubuntu 在 win10 下可使用 spacemaces\nenv  host:  os: win10 MobaXterm: MobaXterm_Portable_v11.1  wsl:  os: ubuntu16 spacemaces: 26.2.0   step DESKTOP-APB1HCJ% emacs --insecure process 4212: D-Bus library appears to be incorrectly set up; failed to read machine uuid: UUID file '/etc/machine-id' should contain a hex string of length 32, not length 0, with no other text See the manual page for dbus-uuidgen to correct this issue. ^C% DESKTOP-APB1HCJ%  sudo apt-get install dbus-x11\n没效果\nhttps://token2shell.com/howto/x410/setting-up-wsl-for-linux-gui-apps/\nsudo dbus-uuidgen --ensure\nemacs\n错误提示消失了。\n发现不能正常加载 spacemaces 的配置，只有emacs的配置\n然后，看到了\nhttps://zhuanlan.zhihu.com/p/36784160\n这里面确实有一些很好的东西.\n是.\n最后发现,刚刚只有悬emacs而没有加载spaceamcs的原因,是没有重新安装26.2的包.\n 转移 ~/.spacemacs.d/ 修改 ~/.emacs.d/core/templates/.spacemacs.template 中的 下载源(来自一个网站) emacs \u0026ndash;debug-init \u0026ndash;insecure 会安装一些包 把 ~/.spacemacs.env 和 ~/.spacemacs 文件转移 然后把原来的 ~/.spacemacs.d/ 还原回来 把 刚刚的 ~/.spacemacs.env 放到 ~/.spacemacs.d 中 emacs \u0026ndash;debug-init \u0026ndash;insecure 会安装一些包  这样,就可以开心使用 spacemacs 了.\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/spacemacs/win10-vcxsrv-wsl-ubuntu-xfce4-spacemacs.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 借助 vcxsrv 使得 wsl-ubuntu 在 win10 下可使用 spacemaces\nenv  host:  os: win10 vcxsrv: vcxsrv-64.1.20.1.4.installer.exe  wsl:  os: ubuntu16 spacemaces: 26.2.0 xfce4   https://www.emacswiki.org/emacs/CategoryWSL https://solarianprogrammer.com/2017/04/16/windows-susbsystem-for-linux-xfce-4/ https://emacs-china.org/t/topic/4332/1\nsudo apt install xfce4\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/stock/stock.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "stock\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/svn/svn.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "svn\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tmux/tmux.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "tmux\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tmux/tmuxinator-install-with-babun.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " babun 安装 tmuxinator\n安装 gem { ~ } master » which gem ~ 1 gem not found { ~ } master » pact install rvm ~ 1 Working directory is /setup Mirror is http://mirrors.kernel.org/sourceware/cygwin/ setup.ini taken from the cache Installing rvm Package rvm not found or ambiguous name, exiting { ~ } master » which scoop ~ /cygdrive/c/Users/DELL/scoop/shims/scoop { ~ } master » scoop install rvm ~ 1 Couldn't find manifest for 'rvm'. { ~ } master » pact install rvm ~ Working directory is /setup Mirror is http://mirrors.kernel.org/sourceware/cygwin/ setup.ini taken from the cache Installing rvm Package rvm not found or ambiguous name, exiting { ~ } master » pact install ruby  直接安装 rvm 是没有希望了。\n安装 ruby { ~ } master » pact install ruby { ~ } master » curl -sSL https://get.rvm.io | bash -s stable ~ 127 Downloading https://github.com/rvm/rvm/archive/1.29.7.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc GPG signature verification failed for '/cygdrive/c/Users/DELL/.rvm/archives/rvm-1.29.7.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg --import - command curl -sSL https://rvm.io/pkuczynski.asc | gpg --import - In case of further problems with validation please refer to https://rvm.io/rvm/security { ~ } master » gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB { ~ } master » curl -sSL https://get.rvm.io | bash -s stable ~ 127 Downloading https://github.com/rvm/rvm/archive/1.29.7.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc GPG signature verification failed for '/cygdrive/c/Users/DELL/.rvm/archives/rvm-1.29.7.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg --import - command curl -sSL https://rvm.io/pkuczynski.asc | gpg --import - In case of further problems with validation please refer to https://rvm.io/rvm/security { ~ } master » { ~ } master » command curl -sSL https://rvm.io/mpapis.asc | gpg --import - ~ 127 (23) Failed writing body { ~ } master » ~ 127 { ~ } master » command curl -sSL https://rvm.io/pkuczynski.asc | gpg --import - ~ 127 (23) Failed writing body { ~ } master »  到官网找找看\nhttps://github.com/rvm/rvm/issues/3623 中说用下面\ncurl -sSL https://get.rvm.io | bash -s branch /bugfix/issue-3623-cygwin-gnupg  替代\ncurl -sSL https://get.rvm.io | bash -s stable  还是不行。\n后来发现\ngpg --version 都没有输出。说明我们的之前 pact install gunpg 并没有成功。\n安装 gpg 那问题： - pact 安装软件后的 目录在哪里呢？\nhttps://www.zhihu.com/question/265291192\n\u0026gt;\u0026gt; cd \\your_path_to\\.babun #进入你win系统中安装babun的目录 \u0026gt;\u0026gt; .\\update.bat #执行更新批处理文件，更新cygwin，然后问题解决  之后，果然可以了！~\n这时，再安装 pact install gnupg2\nhttps://github.com/rvm/rvm 安装\n{ ~ } master » curl -sSL https://get.rvm.io | bash -s stable ~ Downloading https://github.com/rvm/rvm/archive/1.29.7.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc gpg: WARNING: unsafe permissions on homedir '/cygdrive/c/Users/DELL/.gnupg' gpg: keybox '/cygdrive/c/Users/DELL/.gnupg/pubring.kbx' created gpg: Signature made Fri, Jan 4, 2019 6:01:48 AM CST gpg: using RSA key 7D2BAF1CF37B13E2069D6956105BD0E739499BDB gpg: Can't check signature: No public key GPG signature verification failed for '/cygdrive/c/Users/DELL/.rvm/archives/rvm-1.29.7.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg2 --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import - command curl -sSL https://rvm.io/pkuczynski.asc | gpg2 --import - In case of further problems with validation please refer to https://rvm.io/rvm/security { ~ } master » gpg2 --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB gpg: WARNING: unsafe permissions on homedir '/cygdrive/c/Users/DELL/.gnupg' gpg: keyserver receive failed: No such file or directory { ~ } master » command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import - ~ 2 gpg: WARNING: unsafe permissions on homedir '/cygdrive/c/Users/DELL/.gnupg' gpg: key 3804BB82D39DC0E3: 47 signatures not checked due to missing keys gpg: /cygdrive/c/Users/DELL/.gnupg/trustdb.gpg: trustdb created gpg: key 3804BB82D39DC0E3: public key \u0026quot;Michal Papis (RVM signing) \u0026lt;mpapis@gmail.com\u0026gt;\u0026quot; imported gpg: Total number processed: 1 gpg: imported: 1 gpg: no ultimately trusted keys found { ~ } master »  还是报错了\u0026hellip;\u0026hellip;\u0026hellip;\n{ ~ } master » command curl -sSL https://rvm.io/pkuczynski.asc | gpg2 --import - ~ 2 gpg: WARNING: unsafe permissions on homedir '/cygdrive/c/Users/DELL/.gnupg' gpg: key 105BD0E739499BDB: public key \u0026quot;Piotr Kuczynski \u0026lt;piotr.kuczynski@gmail.com\u0026gt;\u0026quot; imported gpg: Total number processed: 1 gpg: imported: 1 { ~ } master »  command curl -sSL https://rvm.io/pkuczynski.asc | gpg2 --import - 这个没有报错了，看来这个提示有用了！~\nrvm 安装 { ~ } master » curl -sSL https://get.rvm.io | bash -s stable ~ 130 Downloading https://github.com/rvm/rvm/archive/1.29.7.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.7/1.29.7.tar.gz.asc gpg: WARNING: unsafe permissions on homedir '/cygdrive/c/Users/DELL/.gnupg' gpg: Signature made Fri, Jan 4, 2019 6:01:48 AM CST gpg: using RSA key 7D2BAF1CF37B13E2069D6956105BD0E739499BDB gpg: Good signature from \u0026quot;Piotr Kuczynski \u0026lt;piotr.kuczynski@gmail.com\u0026gt;\u0026quot; [unknown] gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 7D2B AF1C F37B 13E2 069D 6956 105B D0E7 3949 9BDB GPG verified '/cygdrive/c/Users/DELL/.rvm/archives/rvm-1.29.7.tgz' Installing RVM to /cygdrive/c/Users/DELL/.rvm/ Adding rvm PATH line to /cygdrive/c/Users/DELL/.profile /cygdrive/c/Users/DELL/.mkshrc /cygdrive/c/Users/DELL/.bashrc /cygdrive/c/Users/DELL/.zshrc. Adding rvm loading line to /cygdrive/c/Users/DELL/.profile /cygdrive/c/Users/DELL/.bash_profile /cygdrive/c/Users/DELL/.zlogin. Installation of RVM in /cygdrive/c/Users/DELL/.rvm/ is almost complete: * To start using RVM you need to run `source /cygdrive/c/Users/DELL/.rvm/scripts/rvm` in all your open shell windows, in rare cases you need to reopen all shell windows. { ~ } master »  启用并检查 rvm version { ~ } master » source /cygdrive/c/Users/DELL/.rvm/scripts/rvm ~ 130 { ~ } master » { ~ } master » rvm version ~ rvm 1.29.7 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io] { ~ } master »  rvm 安装 ruby { ~ } master » rvm install 2.3.1 ~ 130 Searching for binary rubies, this might take some time. No binary rubies available for: cygwin/unknown/i386/ruby-2.3.1. Continuing with compilation. Please read 'rvm help mount' to get more information on binary rubies. Checking requirements for cygwin. Installing requirements for cygwin. Updating system - please wait Installing required packages: libcrypt-devel, libffi-devel - please wait Error running 'requirements_cygwin_libs_install libcrypt-devel libffi-devel', please read /cygdrive/c/Users/DELL/.rvm/log/1551261019_ruby-2.3.1/package_install_libcrypt-devel_libffi-devel.log Requirements installation failed with status: 127. { ~ } master »  根据提示：\npact install libcrypt-devel libffi-devel rvm install 2.3.1  还是报错了，如下：\n{ ~ } master » rvm install 2.3.1 ~ 130 ruby-2.3.1 - #removing src/ruby-2.3.1 - please wait Searching for binary rubies, this might take some time. No binary rubies available for: cygwin/unknown/i386/ruby-2.3.1. Continuing with compilation. Please read 'rvm help mount' to get more information on binary rubies. Checking requirements for cygwin. Requirements installation successful. __rvm_install_source:source:2: no such file or directory: /cygdrive/c/Users/DELL/.rvm/scripts/functions/manage/install/cygwin Installing Ruby from source to: /cygdrive/c/Users/DELL/.rvm/rubies/ruby-2.3.1, this may take a while depending on your cpu(s)... ruby-2.3.1 - #downloading ruby-2.3.1, this may take a while depending on your connection... ruby-2.3.1 - #extracting ruby-2.3.1 to /cygdrive/c/Users/DELL/.rvm/src/ruby-2.3.1 - please wait ruby-2.3.1 - #applying patch /cygdrive/c/Users/DELL/.rvm/patches/ruby/ruby_2_3_gcc7.patch - please wait ruby-2.3.1 - #applying patch /cygdrive/c/Users/DELL/.rvm/patches/ruby/2.3.1/random_c_using_NR_prefix.patch - please wait ruby-2.3.1 - #applying patch /cygdrive/c/Users/DELL/.rvm/patches/ruby/2.3.1/fix_resolv_kernel32_dll.patch - please wait ruby-2.3.1 - #configuring - please wait ruby-2.3.1 - #post-configuration - please wait ruby-2.3.1 - #compiling - please wait Error running '__rvm_make -j6', please read /cygdrive/c/Users/DELL/.rvm/log/1551316037_ruby-2.3.1/make.log There has been an error while running make. Halting the installation. { ~ } master » cat /cygdrive/c/Users/DELL/.rvm/log/1551316037_ruby-2.3.1/make.log ~ 127 +__rvm_make:0\u0026gt; make -j6 C:/Users/DELL/.babun/cygwin/bin/make.exe: error while loading shared libraries: ?: cannot open shared object file: No such file or directory +__rvm_make:0\u0026gt; return 127 { ~ } master »  说明安装不了 2.3.1 ，文章说得没错。\n之后分别尝试 ruby 1.7.0, 1.9.3, 2.5.0 都失败了，且报类似错误。\n通过原生安装 既然babun 中的 rvm 安装 ruby 失败，那就通过原生安装\n参考这里\n去 https://rubyinstaller.org/downloads/ 下载了 Ruby+Devkit 2.6.1-1 (x64) 版本，安装 到 D:\\Ruby26-x64\n添加环境变量D:\\Ruby26-x64\\bin\n在 cmd 中\nC:\\Users\\DELL\u0026gt;ruby -v ruby 2.6.1p33 (2019-01-30 revision 66950) [x64-mingw32] C:\\Users\\DELL\u0026gt;gem -v 3.0.1  但是这时，在 git-bash, babun/zsh 中还是没有找到 ruby 命令。\n添加环境变量至 babun/zsh 环境 修改 .zshrc 文件  添加 export PATH=$PATH:/d/Ruby26-x64/bin 添加 alias gem='D:/\\Ruby26-x64/\\bin/\\gem'  参考这里 如果不做第2步，就会报(LoadError),如下：\n{ ~ } master » ruby -v ~ ruby 2.6.1p33 (2019-01-30 revision 66950) [x64-mingw32] { tmp } master » which gem ~/Desktop/tmp /d/Ruby26-x64/bin//gem { tmp } master » gem -v ~/Desktop/tmp D:\\Ruby26-x64\\bin\\ruby.exe: No such file or directory -- /d/Ruby26-x64/bin//gem (LoadError) { ~ } master » alias gem='D:/\\Ruby26-x64/\\bin/\\gem' ~ 1 { ~ } master » gem -v ~ 3.0.1 { ~ } master »  安装 tmuxinator 依赖 （可忽略）安装 弯路 参考 http://wiki.k-zone.cn/post/wiki/tmux-pei-zhi\n{ tmp } master » curl -O https://rubygems.org/downloads/erubis-2.7.0.gem ~/Desktop/tmp { tmp } master » curl -O https://rubygems.org/downloads/tmuxinator-0.6.10.gem ~/Desktop/tmp { tmp } master » curl -O https://rubygems.org/downloads/teamocil-1.2.gem ~/Desktop/tmp { tmp } master » gem install --local ./erubis-2.7.0.gem ~/Desktop/tmp  在继续前，想安装 tmuxinator 的最新版本。\n所以 根据上面这个链接，打开 https://rubygems.org/ ,输入 tmuxinator ,发现最新版是 0.15.0 , 下载了\n{ tmp } master » curl -O https://rubygems.org/downloads/tmuxinator-0.15.0.gem ~/Desktop/tmp { tmp } master » gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp ERROR: While executing gem ... (Errno::EACCES) Permission denied @ rb_file_s_symlink - (completion/tmuxinator.fish, D:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion/mux.fish)  报错，那就sudo 执行。\n{ tmp } master » sudo gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp 1 D:\\Ruby26-x64\\bin\\ruby.exe: No such file or directory -- /d/Ruby26-x64/bin/gem (LoadError) { tmp } master » sudo D:/\\Ruby26-x64/\\bin/\\gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp 1 ERROR: While executing gem ... (Errno::EACCES) Permission denied @ rb_file_s_symlink - (completion/tmuxinator.fish, D:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion/mux.fish) { tmp } master » gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp 1 ERROR: While executing gem ... (Errno::EACCES) Permission denied @ rb_file_s_symlink - (completion/tmuxinator.fish, D:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion/mux.fish) { tmp } master »  然后就想，是不是因为文件没有下载，那手工传一下文件试试\n{ tmp } master » ruby -v ~/Desktop/tmp 1 ruby 2.6.1p33 (2019-01-30 revision 66950) [x64-mingw32] { tmp } master » ls /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp { tmp } master » ls /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion ~/Desktop/tmp 127 mux.fish tmuxinator.bash tmuxinator.fish tmuxinator.zsh { tmp } master » ls /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/*sh ~/Desktop/tmp /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/mux.fish /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/tmuxinator.fish /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/tmuxinator.bash /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/tmuxinator.zsh { tmp } master » cp /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/*sh /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp { tmp } master » ls /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp mux.fish tmuxinator.bash tmuxinator.fish tmuxinator.zsh { tmp } master » gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp ERROR: While executing gem ... (Errno::EACCES) Permission denied @ rb_file_s_symlink - (completion/tmuxinator.fish, D:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion/mux.fish) { tmp } master » ls /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp { tmp } master » cp /f/tom/dotfiles-windows/.dotfiles-private-windows-jinweilai/.tmuxinator/completion/*sh /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp { tmp } master » ls /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp mux.fish tmuxinator.bash tmuxinator.fish tmuxinator.zsh { tmp } master » sudo gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp D:\\Ruby26-x64\\bin\\ruby.exe: No such file or directory -- /d/Ruby26-x64/bin/gem (LoadError) { tmp } master » ls /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp 1 mux.fish tmuxinator.bash tmuxinator.fish tmuxinator.zsh { tmp } master » sudo D:/\\Ruby26-x64/\\bin/\\gem install --local ./tmuxinator-0.15.0.gem ~/Desktop/tmp ERROR: While executing gem ... (Errno::EACCES) Permission denied @ rb_file_s_symlink - (completion/tmuxinator.fish, D:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion/mux.fish) { tmp } master » ls /d/Ruby26-x64/lib/ruby/gems/2.6.0/gems/tmuxinator-0.15.0/completion ~/Desktop/tmp 1 { tmp } master » which gem ~/Desktop/tmp gem: aliased to D:/\\Ruby26-x64/\\bin/\\gem { tmp } master »  通过上面看，应该就不是这个 mux.fish 文件的问题。那就再 google Permission denied @ rb_file_s_symlink, 找到\nhttps://stackoverflow.com/questions/45070484/error-installing-gem-thinreports-rails-on-windows-10\n要用 管理员权限 打开 命令行。\n管理员权限 命令行安装 那就试一下，直接安装，而不是下载*.gem文件安装。\n{ ~ } master » gem install tmuxinator ~ __________________________________________________________ .......................................................... Thank you for installing tmuxinator. Make sure that you've set these variables in your ENV: $EDITOR, $SHELL You can run `tmuxinator doctor` to make sure everything is set. Happy tmuxing with tmuxinator! .......................................................... __________________________________________________________ Successfully installed tmuxinator-0.15.0 Parsing documentation for tmuxinator-0.15.0 Installing ri documentation for tmuxinator-0.15.0 Done installing documentation for tmuxinator after 0 seconds 1 gem installed { ~ } master » ~  哈哈，成功了！~\n安装检查 { ~ } master » which tmuxinator ~ 1 /cygdrive/d/Ruby26-x64/bin/tmuxinator { ~ } master » tmuxinator ls ~ D:\\Ruby26-x64\\bin\\ruby.exe: No such file or directory -- /cygdrive/d/Ruby26-x64/bin/tmuxinator (LoadError) { ~ } master » which gem ~ gem: aliased to D:/\\Ruby26-x64/\\bin/\\gem { ~ } master » alias ruby='D:/\\Ruby26-x64/\\bin/\\ruby.exe' ~ { ~ } master » which ruby ~ ruby: aliased to D:/\\Ruby26-x64/\\bin/\\ruby.exe { ~ } master » ruby -v ~ 1 ruby 2.6.1p33 (2019-01-30 revision 66950) [x64-mingw32] { ~ } master » tmuxinator --version ~ D:\\Ruby26-x64\\bin\\ruby.exe: No such file or directory -- /cygdrive/d/Ruby26-x64/bin/tmuxinator (LoadError) { ~ } master » { ~ } master » D:/\\Ruby26-x64/\\bin/\\tmuxinator ls ~ 1 tmuxinator projects: { ~ } master »  这样的话，只能往 .zshrc.local 文件添加了\n{ ~ } master » cat .zshrc.local ~ ## ruby and gem export PATH=$PATH:/d/Ruby26-x64/bin alias ruby='D:/\\Ruby26-x64/\\bin/\\ruby.exe' alias gem='D:/\\Ruby26-x64/\\bin/\\gem' alias tmuxinator='D:/\\Ruby26-x64/\\bin/\\tmuxinator' ## tmuxinator source $HOME/.tmuxinator/completion/tmuxinator.zsh export EDITOR='vi' { ~ } master »  是不是意味着，每一个 gem 安装的包，想要正常执行，都需要在 .zshrc.local 中添加呢？还有没有更好的解决方案呢？目前不知道。\n至此，我们的tmuxinator 环境安装完毕了。\n使用中报错 C:\\Users\\DELL\u0026gt;tmuxinator edit ceph-pai Checking if tmux is installed ==\u0026gt; 系统找不到指定的路径。 No Checking if $EDITOR is set ==\u0026gt; No Checking if $SHELL is set ==\u0026gt; No C:\\Users\\DELL\u0026gt;tmux version 'tmux' 不是内部或外部命令，也不是可运行的程序 或批处理文件。 C:\\Users\\DELL\u0026gt;  也就是说，使用中，tmuxinator 要去找 tmux ，找不到。\n为什么呢？因为 tmux 是由 pact install tmux 安装的。pact 安装后的软件包，没有被 tmuxinator 识别。\n那现在就尴尬了。\n pact 安装了 tmux , 安装不了tmuxinator pact 安装了 gem ，gem 安装不了 ./tmuxinator-0.15.0.gem 文件 原生安装了ruby,gem, 安装了 tmuxinator 但是，又识别不到 tmux  基于目前这个情况，暂时放弃了。准备在windows10中使用 WSL 然后在 WSL中的ubuntu安装tmuxinator并使用。 如果您有更好的在 win10 下使用tmuxinator的方式，请让我受教吧！~\n(可忽略) 为了安装 可用的 gem .rbenv/bin/rbenv install 2.6.1， 失败 { ~ } master » .rbenv/bin/rbenv install 2.6.1 ~ C:/Users/DELL/.babun/cygwin/bin/perl.exe: error while loading shared libraries: ?: cannot open shared object file: No such file or directory Downloading ruby-2.6.1.tar.bz2... -\u0026gt; https://cache.ruby-lang.org/pub/ruby/2.6/ruby-2.6.1.tar.bz2 Installing ruby-2.6.1... BUILD FAILED (CYGWIN_NT-10.0-WOW 3.0.1(0.338/5/3) using ruby-build 20190130-4-g0e33b11) Inspect or clean up the working tree at /tmp/ruby-build.20190301170457.21293 Results logged to /tmp/ruby-build.20190301170457.21293.log Last 10 log lines: -Wno-tautological-compare -Wno-unused-parameter \\ -Wno-unused-value -Wsuggest-attribute=format \\ -Wsuggest-attribute=noreturn -Wunused-variable * strip command: strip * install doc: yes * JIT support: yes * man page type: doc --- C:/Users/DELL/.babun/cygwin/bin/make.exe: error while loading shared libraries: ?: cannot open shared object file: No such file or directory { ~ } master »  源码编译安装，失败 { ruby-2.5.3 } master » ./configure { ruby-2.5.3 } master » make ~/.rvm/src/ruby-2.5.3 127 C:/Users/DELL/.babun/cygwin/bin/make.exe: error while loading shared libraries: ?: cannot open shared object file: No such file or directory { ruby-2.5.3 } master »  https://raw.githubusercontent.com/wzhishen/dotfiles/master/tools/install.sh\n通过 apt-cyg 来安装 ruby 和 gem， 失败 还是失败了。。。\nref  http://gvlnetworks.com/Babun-Tmux/ http://www.elonwoo.com/2016/08/17/babun-ruby-gem-tmuxinator/ http://wiki.k-zone.cn/post/wiki/babun-pei-zhi https://www.question-defense.com/2009/03/27/rubyexe-no-such-file-or-directory-cygdrivecrubybingem-loaderror https://numediaweb.com/ruby-and-rubygems-in-windows-vs-babun/1288 https://stackoverflow.com/questions/45070484/error-installing-gem-thinreports-rails-on-windows-10  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/travis/travis-build-using-a-safelist.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "travis分支白名单导致无法构建\n手动触发\n报出错误alert如下：\nOh no! You tried to trigger a build for eiuapp/linux-hugo but the request was rejected.  且 提示信息中的\nBranch \u0026quot;master\u0026quot; not included per configuration.  则是 分支白名单的问题\n检看.travis.yml 文件，是否对 branches.only 中设置正确\n# Specify which branches to build using a safelist # 分支白名单限制: 只有hugo分支的提交才会触发构建 branches: only: - master  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-docker-change-ufw-rules.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "见 https://eiuapp.github.io/linux-handbook/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-reboot-cannot-ping-qq.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "虚拟机网络在vmware中配置正确，但是，重新启动后，又连接不上外网了。 这个时候，查一下\n➜ ~ cat /etc/network/interfaces # interfaces(5) file used by ifup(8) and ifdown(8) auto lo iface lo inet loopback auto ens33 iface ens33 inet static address 192.168.0.103 netmask 255.255.255.0 gateway 192.168.0.1 auto ens38 iface ens38 inet dhcp #iface ens38 inet static #address 192.168.100.50 #netmask 255.255.255.0 #up ip link set dev $IFACE up #down ip link set dev $IFACE down #auto ens39 #iface ens39 inet dhcp ➜ ~ cat /etc/resolv.conf # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 192.168.0.1 search localdomain ➜ ~  再试\n➜ ~ traceroute qq.com traceroute to qq.com (58.60.9.21), 30 hops max, 60 byte packets 1 192.168.0.1 (192.168.0.1) 36.834 ms 69.393 ms 36.537 ms 2 100.64.0.1 (100.64.0.1) 94.342 ms 94.228 ms 94.120 ms 3 202.105.154.97 (202.105.154.97) 68.876 ms 202.105.159.25 (202.105.159.25) 69.634 ms 113.106.40.81 (113.106.40.81) 93.921 ms 4 119.147.223.178 (119.147.223.178) 93.872 ms 119.147.223.250 (119.147.223.250) 93.807 ms 119.147.223.166 (119.147.223.166) 93.761 ms^C ➜ ~  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/ubuntu/ubuntu-ssh-login-error-system-is-booting-up-see-pam-nologin-8.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " ssh无法远程连接ubuntu系统，提示System is booting up. See pam_nologin(8)\nenv 本机也无法登陆, 如 ssh ubuntu@127.0.0.1\nos: ubuntu16\nstep The only way to get out of there is by pressing CTRL+ALT+F1 and then CTRL+ALT+DELETE.\n先按 CTRL+ALT+F1 ，再按 CTRL+ALT+DELETE 令系统重启，就可以了。\nref  https://ubuntuforums.org/showthread.php?t=2327330  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/virtualbox/virtualbox.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "virtualbox\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vm/vm.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 虚拟化 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vscode/vscode-git-integrated-terminal.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " vscode integrated terminal and git\nenv  os: win10 vscode: 1.30.2  step 我的git安装在 “D:\\Program Files\\Git\\” 下， 最后的配置结果如下：\n{ \u0026quot;git.autofetch\u0026quot;: true, \u0026quot;git.confirmSync\u0026quot;: false, \u0026quot;terminal.external.windowsExec\u0026quot;: \u0026quot;D:\\\\Program Files\\\\Git\\\\git-bash.exe\u0026quot;, \u0026quot;terminal.integrated.shell.windows\u0026quot;: \u0026quot;D:\\\\Program Files\\\\Git\\\\bin\\\\bash.exe\u0026quot;, \u0026quot;git.path\u0026quot;: \u0026quot;D:\\\\Program Files\\\\Git\\\\bin\\\\git.exe\u0026quot;, \u0026quot;files.eol\u0026quot;: \u0026quot;\\n\u0026quot; }  如果报错 “no source control providers registered” 如果报错 “no source control providers registered”，则是 \u0026ldquo;git.path\u0026rdquo;: \u0026ldquo;D:\\Program Files\\Git\\bin\\git.exe\u0026rdquo;, 这个位置没有配置正确。\nref  https://code.visualstudio.com/docs/editor/integrated-terminal https://github.com/Microsoft/vscode/issues/61522 https://stackoverflow.com/questions/44450218/how-do-i-use-bash-on-ubuntu-on-windows-wsl-for-my-vs-code-terminal https://blog.csdn.net/weixin_40965293/article/details/80319982 https://www.jianshu.com/p/c803d5729f29  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/vscode/vscode.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "vscode\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/web/web.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " web服务器 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/weight.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "weight key-value\nopen the lines with csv\nai,210, blockchain,310, cloudnative,410, kubernetes,420, docker,430, rancher,440, cloud,450, aws,460, bigdata,510, databases,520, mariadb,530, mysql,540, postgresql,550, mongodb,560, redis,570, swift,580, ceph,590, rust,610, golang,620, javascript,630, nodejs,640, npm,650, python,660, django,670, java,680, ruby,690, rails,700, rvm,710, r,720, php,730, emacs,810, spacemacs,820, vscode,830, ide,840, cli,850, yasnippet,860, babun,870, scoop,880, wechat,890, linux,910, ubuntu,920, centos,930, windows,940, macos,950, solaris,960, vagrant,970, virtualbox,980, vmware,990, vm,1000, shell,1010, bash,1020, zsh,1030, vim,1040, tmux,1050, monitor,1060, zabbix,1070, git,1110, github,1120, gitlab,1130, devops,1140, dev,1150, bitbucket,1160, cheatsheets,1170, svn,1180, travis,1190, ansible,1200, blog,1410, hugo,1420, gitbook,1430, jupyter,1440, markdown,1450, org,1460, learn,1470, resource,1480, note,1490, post,1500, hexo,1510, jekyll,1520, network,1610, nginx,1620, ngrok,1630, security,1640, chrome,1710, web,1720, vue,1730, yapi,1740, html,1750, eslint,1760, cookie,1770, yarn,1780, taro,1790, react,1800, css,1810, apps,1820, baidu,1830, analytics,1910, elixir,1920, enterprise,1930, fitness,1940, google,1950, ledger,1960, markup,1970, keyboard,2010, apple,2020, stock,3010, qor,3020, saleor,3030, learn-hugo,8010, others,9010, tools,9020, about,9030,  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/ide-windows.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 本文主要参考： 如何搭建优雅的windows开发环境 。有修改。\n如何搭建优雅的windows开发环境 [2016-12-17]()\n之前写过 \u0026lt;如何搭建优雅的开发环境\u0026gt; 系列(未完结)， 分章节的介绍了开发过程中使用的工具和技巧。里面也提及了 Windows 下的工具，但是不够系统，我还是很想整理一篇讲解 windows 下具体设置的文章。\n[](#命令行 \u0026ldquo;命令行\u0026rdquo;)命令行 [](#PowerShell \u0026ldquo;PowerShell\u0026rdquo;)PowerShell 微软以后肯定是要用 PowerShell 替代 cmd.exe 的，所以早晚我们都会用到，就别停留在 cmd 下了，那个难易操作的终端环境，反正我是打开一次就不想再看到。如果你觉得 cmd.exe 也无所谓，那起码安装一个 clink 提升一些编辑操作。喜欢 linux 命令的朋友，还可以安装下 gow 体验 linux 命令。\n但是我还是建议大家使用 PowerShell, 特别是配合 cmder(下面会提到)。可以安装一些插件来提升使用的体验。\n因为 PowerShell 也更新了好几个版本，我们可以先看下如何安装or更新 PowerShell:\n How to Install How to Install Windows PowerShell 4.0  安装完成，我们使用 $PSVersionTable.PSVersion 查看下安装的版本。\n关于教程，可以看看:\n Learning-powershell MSDN: PowerShell  官方的教程，但是我也没看过，有问题就上 MSDN 或 Google 上搜一下吧。\n[](#插件安装 \u0026ldquo;插件安装\u0026rdquo;)插件安装 我不确定是否内置了命令 Install-Module, 因为我看到了一个模块： PsGet, 也是提供install-module 命令的, 估计是对原生的扩展吧。反正有了这个命令，我们就可以来安装模块了.\n查找模块，对于的命令为 Find-Module。\n模块安装完成后，一般会自动载入，如果有些没有自动载入，可能需要自己修改配置文件， 手动 Import-Module。对于安装过的模块和路径，我们可以通过 get-Module, Get-Module --listAvailable 和 $env:PSModulePath 查看。\n[](#推荐模块 \u0026ldquo;推荐模块\u0026rdquo;)推荐模块 模块可以在 PsGet: Directory Index 中找到，我推荐几个我安装过的:\n Jump-Location: 必装，提供 autojump 的实现，方便通过 j xx 进行目录跳转，配置 open （alias explorer.exe）, 方便打开目录 Posh-git: 必装， 提升 git 命令行操作体验。 PSColor: 提供输入高亮 PSColors: 提供色彩高亮提示与输出，和上面那个可能是2选一关系吧, 这个感觉高端一些 TabExpansionPlusPlus: 提升 命令后下 tab 扩展功能。 PowerLS: 提供 powerls 命令，可以配置 Set-Alias -Name ls -Value PowerLS -Option AllScope 针对目录展示色彩高亮（其实也没太多用处） Find-String: 提供类似 grep 命令 Posh-svn: 提升 svn 命令行操作，但是一般 svn 都用 GUI 操作了。  [](#cmder \u0026ldquo;cmder\u0026rdquo;)cmder cmder: 是 windows 下的一个终端模拟器，它只是一个壳子，结合了 ConEum, clink, git-for-windows(可选)。提供可方便的快捷操作以及舒适的UI界面。\n我一般是选择 mini 版本安装，解压缩后，打开 cmder.exe, 运行 cmder /register all 即可给右键菜单，添加上 open cmder here 功能。\n然后再从 Settings 中设置默认的终端，选择 PowerShell, 这样配合起来就更加完美了。基于 cmder 的配置文件，我们放置在 cmder/config 中， 如果是 PowerShell 的，就添加 user_profile.ps1 即可。启动 cmder 会自动加载这个目录下的配置。\n配置cmder到右键菜单报错  打开安装文件夹，我的是F:\\software\\cmder (这步可不执行)这个地址加到系统的path环境变量里面， 然后右键Cmder.exe属性-兼容性-以管理员身份运行此程序， 再重新打开Cmder.exe（最上面边框，New console dialog... 选择 {cmd::Cmder as Admin}） 输入Cmder.exe /REGISTER ALL，不报错，就行了~  这时，在文件夹的任何位置，右键菜单都有Cmder here选项。\n这么做的好处，你可以在任何文件夹下，快速得用上cmder。\n[](#babun \u0026ldquo;babun\u0026rdquo;)babun 如果你比较 Geek 或者需要在 windows 下进行 linux 开发，那么 babun: 一个整合 Cygwin, oh-my-zsh 等许多特性的终端环境，十分值得推荐。\n安装过程异常简单，解压缩执行 install.bat 即可，都不需要管理员权限。但是需要注意的是，如果你安装过 Emacs, 一般都会设置 HOME 环境变量，这时 babun 会提示你不建议这么做，不用管它，直接继续安装。安装完成，你的 ~ 目录就是 HOME 配置的目录，一般是 C:/User/uesr_name。官方FAQ也给出过指导: How to use the Windows’ user profile directory as my home directory in babun ?\n安装完成后，桌面会有一个 babun 快捷方式， 进入后可以运行 babun shell 查看当前的 shell, 正常应该为 zsh，如果不是, 可执行 babun shell zsh 进行配置。\n我们还会通过 babun check 检查下环境是否安装正常，可能网络是有问题的，就需要我们去配置 ~/.babunrc 文件，设置对应的代理。\n如果有更新，执行 babun update 即可。\n[](#oh-my-zsh \u0026ldquo;oh-my-zsh\u0026rdquo;)oh-my-zsh 当我设置了 HOME 后，进入 babun 执行 upgrade_oh_my_zsh 会报错，提示我有没提交的内容，但是我如果没设置 HOME 进行安装后，是可以正常更新的。。。\n算了，谁叫我用了 Emacs 了，只能再搜搜解决方案，终于找到了一个issue: Cannot update oh-my-zsh on start ， 里面给了解决方案为:\n git config core.filemode false 在 .oh-my-zsh 目录中，执行 git rebase --skip 运行 upgrade_oh_my_zsh 即可更新  [](#oh-my-zsh-插件 \u0026ldquo;oh-my-zsh 插件\u0026rdquo;)oh-my-zsh 插件 当我们可以运行 zsh 后，那么我们体验的东西又被大大的扩展了，者就是一个 linux 小世界，比如 tumx （我还没有尝试），我使用的一些插件，可以推荐一下:\n autojump zsh-syntax-highlighting proxychains: 貌似不是 zsh 插件  还有 autojump colored-man zsh_reload zsh-syntax-highlighting git git-flow ruby gem python pip node npm bower\n这些插件，我们都在 ~/.oh-my-zsh/custom/plugins 目录下进行 git clone， 然后配置 ~/.zshrc， 最后 souce ~/.zshrc 完成配置。\n具体的操作，可以看 Babun 配置 .\n[](#包管理 \u0026ldquo;包管理\u0026rdquo;)包管理 [](#chocolye \u0026ldquo;chocolye\u0026rdquo;)chocolye  chocolatey: The Package manager for Windows  windows 下一直缺少一个好用的包管理工具，这个就是解决这个问题的，且支持代理配置，网络也不是太大的问题了。比如我们可以通过 choco 安装一些软件以及开发工具:\n Yarn： 可以不选择安装依赖的 node, 如果你单独安装过 node 的话 CClearn  由于我也是刚刚切换到 choco，所以之前的一些软件和工具，还不是用 choco 安装，但是后面我会一直用下去，因为包管理工具，配合命令行以及脚本，真是能够让你快速恢复开发环境。\n[](#开发环境 \u0026ldquo;开发环境\u0026rdquo;)开发环境 作为一个开发者，开发环境也是需要好好配置一些的，基础的 python, node, java 都需要安装。推荐大家看下微软的一篇文章： Configuring your Windows development environment\n[](#node \u0026ldquo;node\u0026rdquo;)node  nvm-windows npm-windows-upgrade: 打算逐步用 Yarn 替代 npm 了。  [](#c \u0026ldquo;c++\u0026rdquo;)c++  windows-build-tools  如果开发 node add-on 的话，c++ 环境就是必须的，即使不开发，我们使用 node-gyp 的时候，也需要安装。\n[](#java \u0026ldquo;java\u0026rdquo;)java 未完待续…\nref  https://segmentfault.com/q/1010000009976575 如何搭建优雅的windows开发环境 Windows 系统下的开发环境搭建 Babun 配置  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/package-manager-for-windows.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " https://www.slant.co/topics/1843/~best-windows-package-managers\n本文主要介绍以下工具\npackage manager for Windows: * Chocolatey * Scoop * ninite * pact(in babun)  结论  请注意：win10或以上有一个 WSL。如果你支持 WSL 请使用 WSL。能在WSL完成的事情，就请不要用以下 package manager。 如果是babun用户，请直接使用 pack 。pack不能完成的任务，再考虑scoop，再考虑chocolatey scoop 和 chocolatey 将是你目前比较好的包管理工具。可以都使用 能用 scoop 安装的，就不要 chocolatey 安装。不能 scoop 安装的，都用 chocolatey 安装 两者都不能的，请安 scoop 方式定制 私人内容，用 scoop 定制 scoop 安装、卸载、更新、清理 时，清保证软件未正在被使用（这一点，是致命的缺点呀，具体原因见 h404bi 的博文）  Scoop https://www.h404bi.com/blog/2018/05/12/talk-about-scoop-the-package-manager-for-windows-again.html\nhttps://davidsheh.github.io/2017/09/09/windows-chocolatey-scoop/\nscoop 个人库 https://github.com/h404bi/dorado\nchocolatey https://chocolatey.org/\nvs chocolatey vs scoop https://github.com/lukesampson/scoop/wiki/Chocolatey-Comparison https://www.reddit.com/r/devops/comments/9o4si5/installing_dependencies_on_windows_do_you_use/ https://www.slant.co/versus/6470/6471/~chocolatey_vs_scoop\nwindows vs mac https://davidsheh.github.io/2017/09/09/windows-chocolatey-scoop/ 认为是：\n对应于 Mac 下的 Homebrew) + iTerm 2 + Fish shell ， Windows 下是 Chocolatey( + Scoop) + ConEmu + PowerShell。\n但是，经过时间选择：\n ConEmu 已经被 cmder 封装 powershell 明显，不是最佳的shell工具，因为，与linux 下的shell 不是一个套路。可以试着使用 babun, fish 代替着（我正在尝试的路上）。  为了更快切换工程，请记得使用 tmux 哟！~\n因为 tmux 的原因。scoop 不支持安装 tmux，而pact 可以安装，说明 babun 这个工具，还是有优势。\nbabun/pact( + scoop) + cmder + babun/zsh( + fish) + tmux + tmuxinator 这个组合，可能是非 WSL 用户的最佳选择。\n如果你支持 WSL 请使用 WSL，下面组合，可能是linux重度用户的最佳选择：\nbabun/pact( + scoop) + cmder + babun/zsh( + fish) + tmux 这个组合，嘿嘿，是我非 WSL 功能的组合。\nWSL/ubuntu/apt + cmder + WSL/ubuntu/zsh( + fish) + tmux + tmuxinator 这个组合，嘿嘿，是我 WSL 功能的组合。\n新势力 https://appget.net/\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/windows-link.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Windows的四种链接方式\n如果要看明白，请参考这里 https://binarythink.net/2013/06/windows-link/\nenv  os: win10 cmder: 180626 preview  step 创建硬链接 并 查询 C:\\Users\\DELL (master -\u0026gt; origin) λ mklink /H C:\\Users\\DELL\\Desktop\\ahk.ahk C:\\Users\\DELL\\autohotkey.ahk 为 C:\\Users\\DELL\\Desktop\\ahk.ahk \u0026lt;\u0026lt;===\u0026gt;\u0026gt; C:\\Users\\DELL\\autohotkey.ahk 创建了硬链接 C:\\Users\\DELL (master -\u0026gt; origin) λ fsutil.exe hardlink list autohotkey.ahk \\Users\\DELL\\autohotkey.ahk \\Users\\DELL\\Desktop\\ahk.ahk  如果移动了这个硬链接，系统依然可以找到的，所以不用担心。\nC:\\Users\\DELL (master -\u0026gt; origin) λ fsutil.exe hardlink list autohotkey.ahk \\Users\\DELL\\autohotkey.ahk \\Users\\DELL\\Desktop\\ahk.ahk C:\\Users\\DELL (master -\u0026gt; origin) λ fsutil.exe hardlink list autohotkey.ahk \\Users\\DELL\\autohotkey.ahk \\Users\\DELL\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\ahk.ahk  ref  https://binarythink.net/2013/06/windows-link/ https://www.konekomoe.com/command-windows-mklink/  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/windows-wsl.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " windows wsl 子系统 https://www.jianshu.com/p/bc38ed12da1d 此文中的环境与我的大体一致。\nenv win10 版本： 1703 (查看版本可 cmd 下输入winver)\n找到 子系统 目录 在 文件夹下 输入 %localappdata%, 然后搜索框输入： rootfs , 则会出现结果。\n我的是在 %localappdata%\\lxss\\rootfs 。那么说明 wsl 子系统 目录 是 %localappdata%\\lxss\n子系统环境(lxss目录) 备份 那最终powershell 中 运行命令如下（运行过程中视情况：1.D选择复制目录;2.选择A全选择）：\nxcopy .\\lxss .\\lxss.20190306.bak /E/C  毕竟爱折腾，难免会把子系统环境(lxss目录)玩坏掉，因此干正事前最好先备份下以便快速还原。注意，不要直接右键复制或者打包，可能会导致文件权限丢失的。\npowershell 中 运行：\n\u0026gt; xcopy .\\lxss .\\lxss.bak /E  但是，因为某些文件，会导致文件创建错误 - 系统找不到指定的文件。 这样的错误：\nLocal master + = $ xcopy .\\lxss\\root\\.nvm\\test .\\lxsstest /E 目标 .\\lxsstest 是文件名 还是目录名 (F = 文件，D = 目录)? d .\\lxss\\root\\.nvm\\test\\common.sh .\\lxss\\root\\.nvm\\test\\fast\\nvm should remove the last trailing slash in $NVM_DIR .\\lxss\\root\\.nvm\\test\\fast\\Running #0022nvm alias#0022 should create a file in the alias directory. 文件创建错误 - 系统找不到指定的文件。 Local master + = $ ls /E  查看 xcopy 参数，https://blog.csdn.net/zhihui1017/article/details/50621747 ，可能 /C 即使有错误，也继续复制。 能帮助我们\nLocal master + = $ xcopy .\\lxss\\root\\.nvm\\test .\\lxsstest3 /E/C 目标 .\\lxsstest3 是文件名 还是目录名 (F = 文件，D = 目录)? d .\\lxss\\root\\.nvm\\test\\common.sh .\\lxss\\root\\.nvm\\test\\fast\\nvm should remove the last trailing slash in $NVM_DIR .\\lxss\\root\\.nvm\\test\\fast\\Running #0022nvm alias#0022 should create a file in the alias directory. 文件创建错误 - 系统找不到指定的文件。 .\\lxss\\root\\.nvm\\test\\fast\\Running #0022nvm current#0022 should display current nvm environment. 文件创建错误 - 系统找不到指定的文件。 .\\lxss\\root\\.nvm\\test\\fast\\Running #0022nvm deactivate#0022 should unset the nvm environment variables. 文件创建错误 - 系统找不到指定的文件。 ... ... ...  那最终命令如下：\nxcopy .\\lxss .\\lxss.20190306.bak /E/C  Error 0x80070005 on startup https://github.com/Microsoft/WSL/issues/651\nAlso had this issue after running Oracle instant client. Just like others above, restarting into safe mode (hold shift and choose restart on the login screen or start menu) and deleting %LOCALAPPDATA%\\lxss\\temp fixed the problem.\n也就是删除 %LOCALAPPDATA%\\lxss\\temp 就可以了\nref  https://www.jianshu.com/p/bc38ed12da1d  "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/windows/windows.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "windows\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yapi/api-format.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " YAPI 使用\n接口集合 接口定义 接口定义与使用，要近可能符合 Restful API 风格\n方法 - 中文 - 英文  Get - 查询 - Get ; Post - 提交（新增） - Add, Set, Post Post, Put - 修改 - Set, Post, Put, Update Delete - 删除 - Delete  示例 （优先）\n Get - 查询用户帐户 - GetUserAccout Post - 新增用户帐户 - AddUserAccout Post, Put - 修改用户帐户 - SetUserAccount 或者 UpdateUserAccout Delete - 删除用户帐户 - DeleteUserAccout  或者\n（其次）\n Get - 查询用户帐户 - UserAccout/Get Post - 新增用户帐户 - UserAccout/Add Post, Put - 修改用户帐户 - UserAccout/Update Delete - 删除用户帐户 - UserAccout/Delete  注意  不要 List, List是名词 , 如果要查询用户帐户列表， Get - 查询用户帐户列表 - GetUserAccoutList  测试集合 配置 "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yapi/install-yapi-with-docker.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " yapi通过docker安装\nhttps://github.com/Ryan-Miao/docker-yapi 学习笔记\nenv  os: ubuntu docker: 18.09.5  step 直接运行 index.sh vagrant@ubuntu-xenial:~/yapi$ cat index.sh #!/bin/bash git clone https://github.com/Ryan-Miao/docker-yapi.git cd docker-yapi bash build.sh 1.5.10 bash start.sh init-network bash start.sh start-mongo bash start.sh init-mongo bash start.sh init-yapi bash start.sh logs-yapi vagrant@ubuntu-xenial:~/yapi$ bash index.sh ... ... init mongodb account admin and yapi MongoDB shell version v4.0.9 connecting to: mongodb://127.0.0.1:27017/admin?gssapiServiceName=mongodb 2019-04-24T03:22:21.172+0000 E QUERY [js] Error: couldn't connect to server 127.0.0.1:27017, connection attempt failed: SocketException: Error connecting to 127.0.0.1:27017 :: caused by :: Connection refused : connect@src/mongo/shell/mongo.js:343:13 @(connect):2:6 exception: connect failed inti mongodb done init yapi db and start yapi server 5eaca2adb290fb948f7c2c1536cf1d209f92076376359221c555d39b5d6a7f6f init yapi done vagrant@ubuntu-xenial:~/yapi$  出错了。\n此时 curl http://localhost:3001 会出现 curl: (56) Recv failure: Connection reset by peer 这样的错误。\n(可跳过)bash index.sh 日志 vagrant@ubuntu-xenial:~/yapi$ ./index.sh Cloning into 'docker-yapi'... remote: Enumerating objects: 43, done. remote: Counting objects: 100% (43/43), done. remote: Compressing objects: 100% (30/30), done. remote: Total 43 (delta 20), reused 35 (delta 12), pack-reused 0 Unpacking objects: 100% (43/43), done. Checking connectivity... done. usage: sh build.sh \u0026lt;version\u0026gt; yapi的版本： https://github.com/YMFE/yapi/releases 我们将从这里下载： http://registry.npm.taobao.org/yapi-vendor/download/yapi-vendor-$1.tgz 将下载版本1.5.10 download new package (version 1.5.10) --2019-04-24 03:20:11-- http://registry.npm.taobao.org/yapi-vendor/download/yapi-vendor-1.5.10.tgz Resolving registry.npm.taobao.org (registry.npm.taobao.org)... 114.55.80.225 Connecting to registry.npm.taobao.org (registry.npm.taobao.org)|114.55.80.225|:80... connected. HTTP request sent, awaiting response... 302 Found Location: https://cdn.npm.taobao.org/yapi-vendor/-/yapi-vendor-1.5.10.tgz [following] --2019-04-24 03:20:11-- https://cdn.npm.taobao.org/yapi-vendor/-/yapi-vendor-1.5.10.tgz Resolving cdn.npm.taobao.org (cdn.npm.taobao.org)... 183.60.159.232, 183.60.159.230, 183.60.159.228, ... Connecting to cdn.npm.taobao.org (cdn.npm.taobao.org)|183.60.159.232|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 8395015 (8.0M) [application/octet-stream] Saving to: ‘yapi.tgz’ yapi.tgz 100%[=========================================================================================================================================\u0026gt;] 8.01M 1.82MB/s in 4.4s 2019-04-24 03:20:18 (1.82 MB/s) - ‘yapi.tgz’ saved [8395015/8395015] build new image Sending build context to Docker daemon 8.525MB Step 1/16 : FROM node:11-alpine as builder 11-alpine: Pulling from library/node bdf0201b3a05: Pull complete f82315922d4f: Pull complete e70c14082adc: Pull complete Digest: sha256:2278992c11ebfba68ca40a56ac77de59f5669b9ce1bb479f89840c95ac1adae7 Status: Downloaded newer image for node:11-alpine ---\u0026gt; cd4fae427afc Step 2/16 : COPY repositories /etc/apk/repositories ---\u0026gt; 53171340fe01 Step 3/16 : RUN apk update \u0026amp;\u0026amp; apk add --no-cache git python make openssl tar gcc ---\u0026gt; Running in 0cf1f76bfcda fetch https://mirrors.aliyun.com/alpine/v3.6/main/x86_64/APKINDEX.tar.gz fetch https://mirrors.aliyun.com/alpine/v3.6/community/x86_64/APKINDEX.tar.gz v3.6.5-23-g47b45e6408 [https://mirrors.aliyun.com/alpine/v3.6/main/] v3.6.5-18-gfdfe1f6192 [https://mirrors.aliyun.com/alpine/v3.6/community/] OK: 8455 distinct packages available fetch https://mirrors.aliyun.com/alpine/v3.6/main/x86_64/APKINDEX.tar.gz fetch https://mirrors.aliyun.com/alpine/v3.6/community/x86_64/APKINDEX.tar.gz (1/32) Installing binutils-libs (2.30-r1) (2/32) Installing binutils (2.30-r1) (3/32) Installing gmp (6.1.2-r0) (4/32) Installing isl (0.17.1-r0) (5/32) Installing libgomp (6.3.0-r4) (6/32) Installing libatomic (6.3.0-r4) (7/32) Installing pkgconf (1.3.7-r0) (8/32) Installing mpfr3 (3.1.5-r0) (9/32) Installing mpc1 (1.0.3-r0) (10/32) Installing gcc (6.3.0-r4) (11/32) Installing libressl2.5-libcrypto (2.5.5-r2) (12/32) Installing ca-certificates (20161130-r2) (13/32) Installing libssh2 (1.8.2-r0) (14/32) Installing libressl2.5-libssl (2.5.5-r2) (15/32) Installing libcurl (7.61.1-r2) (16/32) Installing expat (2.2.0-r1) (17/32) Installing pcre (8.41-r0) (18/32) Installing git (2.13.7-r2) (19/32) Installing make (4.2.1-r0) (20/32) Installing libcrypto1.0 (1.0.2r-r0) (21/32) Installing libssl1.0 (1.0.2r-r0) (22/32) Installing openssl (1.0.2r-r0) (23/32) Installing libbz2 (1.0.6-r5) (24/32) Installing libffi (3.2.1-r3) (25/32) Installing gdbm (1.12-r0) (26/32) Installing ncurses-terminfo-base (6.0_p20171125-r1) (27/32) Installing ncurses-terminfo (6.0_p20171125-r1) (28/32) Installing ncurses-libs (6.0_p20171125-r1) (29/32) Installing readline (6.3.008-r5) (30/32) Installing sqlite-libs (3.25.3-r0) (31/32) Installing python2 (2.7.15-r0) (32/32) Installing tar (1.32-r0) Executing busybox-1.29.3-r10.trigger Executing ca-certificates-20161130-r2.trigger OK: 164 MiB in 48 packages Removing intermediate container 0cf1f76bfcda ---\u0026gt; d0aaaf657609 Step 4/16 : ADD yapi.tgz /home/ ---\u0026gt; e90dafc00a41 Step 5/16 : RUN mkdir /api \u0026amp;\u0026amp; mv /home/package /api/vendors ---\u0026gt; Running in 666e0e900ac9 Removing intermediate container 666e0e900ac9 ---\u0026gt; c77ac514594b Step 6/16 : RUN cd /api/vendors \u0026amp;\u0026amp; npm install --production --registry https://registry.npm.taobao.org ---\u0026gt; Running in 470f82e165c5 Step 6/16 : RUN cd /api/vendors \u0026amp;\u0026amp; npm install --production --registry https://registry.npm.taobao.org ---\u0026gt; Running in 470f82e165c5 npm WARN deprecated babel@6.23.0: In 6.x, the babel package has been deprecated in favor of babel-cli. Check https://opencollective.com/babel to support the Babel maintainers npm WARN deprecated babel-preset-es2015@6.24.1: ???? Thanks for using Babel: we recommend using babel-preset-env now: please read babeljs.io/env to update! npm WARN deprecated validate-commit-msg@2.14.0: Check out CommitLint which provides the same functionality with a more user-focused experience. npm WARN deprecated core-js@2.5.7: core-js@\u0026lt;2.6.5 is no longer maintained. Please, upgrade to core-js@3 or at least to actual version of core-js@2. npm WARN deprecated fsevents@1.1.2: Way too old npm WARN deprecated babel-preset-es2017@6.24.1: ???? Thanks for using Babel: we recommend using babel-preset-env now: please read babeljs.io/env to update! npm WARN deprecated joi@6.10.1: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial). npm WARN deprecated hawk@3.1.3: This version has been deprecated. Please upgrade to the latest version to get the best features, bug fixes, and security patches. npm WARN deprecated browserslist@2.11.3: Browserslist 2 could fail on reading Browserslist \u0026gt;3.0 config used in other tools. npm WARN deprecated sw-precache@5.2.1: Please migrate to Workbox: https://developers.google.com/web/tools/workbox/guides/migrations/migrate-from-sw npm WARN deprecated ejs@2.3.4: Critical security bugs fixed in 2.5.5 npm WARN deprecated topo@1.1.0: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial). npm WARN deprecated hoek@2.16.3: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial). npm WARN deprecated boom@2.10.1: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial). npm WARN deprecated sntp@1.0.9: This module moved to @hapi/sntp. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues. npm WARN deprecated cryptiles@2.0.5: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial). npm WARN deprecated core-js@1.2.7: core-js@\u0026lt;2.6.5 is no longer maintained. Please, upgrade to core-js@3 or at least to actual version of core-js@2. npm WARN deprecated browserslist@1.7.7: Browserslist 2 could fail on reading Browserslist \u0026gt;3.0 config used in other tools. npm WARN deprecated circular-json@0.3.3: CircularJSON is in maintenance only, flatted is its successor. npm WARN deprecated sw-toolbox@3.6.0: Please migrate to Workbox: https://developers.google.com/web/tools/workbox/guides/migrations/migrate-from-sw npm WARN deprecated nomnom@1.5.2: Package no longer supported. Contact support@npmjs.com for more info. \u0026gt; dtrace-provider@0.8.7 install /api/vendors/node_modules/dtrace-provider \u0026gt; node-gyp rebuild || node suppress-error.js make: Entering directory '/api/vendors/node_modules/dtrace-provider/build' TOUCH Release/obj.target/DTraceProviderStub.stamp make: Leaving directory '/api/vendors/node_modules/dtrace-provider/build' \u0026gt; jsonpath@1.0.1 postinstall /api/vendors/node_modules/jsonpath \u0026gt; node lib/aesprim.js \u0026gt; generated/aesprim-browser.js npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN mongoose-auto-increment@5.0.1 requires a peer of mongoose@^4.1.12 but none is installed. You must install peer dependencies yourself. npm WARN sass-loader@7.1.0 requires a peer of webpack@^3.0.0 || ^4.0.0 but none is installed. You must install peer dependencies yourself. npm WARN react-slick@0.15.4 requires a peer of react@^0.14.0 || ^15.0.1 but none is installed. You must install peer dependencies yourself. npm WARN react-slick@0.15.4 requires a peer of react-dom@^0.14.0 || ^15.0.1 but none is installed. You must install peer dependencies yourself. npm WARN slick-carousel@1.8.1 requires a peer of jquery@\u0026gt;=1.8.0 but none is installed. You must install peer dependencies yourself. added 353 packages from 343 contributors and audited 41745 packages in 38.91s found 117 vulnerabilities (59 low, 34 moderate, 24 high) run `npm audit fix` to fix them, or `npm audit` for details Removing intermediate container 470f82e165c5 ---\u0026gt; e1de184ab7a0 Step 7/16 : FROM node:11-alpine ---\u0026gt; cd4fae427afc Step 8/16 : MAINTAINER Ryan Miao ---\u0026gt; Running in b304c7d45f2c Removing intermediate container b304c7d45f2c ---\u0026gt; bd75d12b26ee Step 9/16 : ENV TZ=\u0026quot;Asia/Shanghai\u0026quot; HOME=\u0026quot;/\u0026quot; ---\u0026gt; Running in e504582ebe19 Removing intermediate container e504582ebe19 ---\u0026gt; 583777d1bcd7 Step 10/16 : WORKDIR ${HOME} ---\u0026gt; Running in f9212737f022 Removing intermediate container f9212737f022 ---\u0026gt; 16a0a4f59e15 Step 11/16 : COPY --from=builder /api/vendors /api/vendors ---\u0026gt; 3da85b57c8e0 Step 12/16 : COPY config.json /api/ ---\u0026gt; b71ac66ce6f9 Step 13/16 : EXPOSE 3001 ---\u0026gt; Running in 21dabe247a61 Removing intermediate container 21dabe247a61 ---\u0026gt; aa4a013e4b26 Step 14/16 : COPY docker-entrypoint.sh /api/ ---\u0026gt; 73654cc8b435 Step 15/16 : RUN chmod 755 /api/docker-entrypoint.sh ---\u0026gt; Running in d0a2f8e50ca9 Removing intermediate container d0a2f8e50ca9 ---\u0026gt; 92da279fbb41 ---\u0026gt; 92da279fbb41 Step 16/16 : ENTRYPOINT [\u0026quot;/api/docker-entrypoint.sh\u0026quot;] ---\u0026gt; Running in 82902ed862cf Removing intermediate container 82902ed862cf ---\u0026gt; 48a4e40ff4bb Successfully built 48a4e40ff4bb Successfully tagged yapi:latest Error: No such network: tools-net c417c9379d767c4e8c03c5fc48aae07724f9c2dbf94867bb47ed09c6ffd2d7ff Error response from daemon: Cannot kill container: mongod: No such container: mongod Error: No such container: mongod Unable to find image 'mongo:4' locally 4: Pulling from library/mongo 34667c7e4631: Pull complete d18d76a881a4: Pull complete 119c7358fbfc: Pull complete 2aaf13f3eff0: Pull complete f7833eaffdda: Pull complete 8287cb5b9daf: Pull complete 3f92d9c8d3be: Pull complete c8a99ed04127: Pull complete 7c26ac89d736: Pull complete f6f01a3e0a56: Pull complete ff5825a76fb6: Pull complete 0af8892a044b: Pull complete 33eada78dbf2: Pull complete Digest: sha256:68209a50d83c8e37f3f2dca6d2a69b1c84c57dbae7d74a47640434f2678ae13a Status: Downloaded newer image for mongo:4 4e2e51837df8ed226dd607f47f7923fc27800ea3b1095b8a4fd16f66fe8d8e97 init mongodb account admin and yapi MongoDB shell version v4.0.9 connecting to: mongodb://127.0.0.1:27017/admin?gssapiServiceName=mongodb 2019-04-24T03:22:21.172+0000 E QUERY [js] Error: couldn't connect to server 127.0.0.1:27017, connection attempt failed: SocketException: Error connecting to 127.0.0.1:27017 :: caused by :: Connection refused : connect@src/mongo/shell/mongo.js:343:13 @(connect):2:6 exception: connect failed inti mongodb done init yapi db and start yapi server 5eaca2adb290fb948f7c2c1536cf1d209f92076376359221c555d39b5d6a7f6f init yapi done vagrant@ubuntu-xenial:~/yapi$  init-mongodb 报错 但是，这个时候，看到上面有错误提示了。\n这时，sudo docker logs --tail 10 yapi 报错，说mongodb 认证错误。\n这里 index.sh 中有 bash start.sh init-mongo 这一步，出错了。 也就是说，在 bash start.sh init-mongo 这一步的时候，出错了，没有成功。 决定手工执行一下吧。\n打开 start.sh 看一下，init-mongo 函数的具体内容。执行一下。\ncd docker-yapi sudo docker ps cat init-mongo.js cat ../index.sh sudo docker cp init-mongo.js mongod:/data sudo docker exec -it mongod bash # 在容器中执行 `mongo admin /data/init-mongo.js`  检查 mongodb 用户，确认 init-mongo 成功\n$ mongo -u \u0026quot;admin\u0026quot; -p \u0026quot;admin123456\u0026quot; \u0026gt; use admin \u0026gt; show users  如果说有 yapi 用户，就表示，init-mongo 成功了。\n启动 yapi vagrant@ubuntu-xenial:~/yapi/docker-yapi$ docker kill yapi \u0026amp;\u0026amp; docker rm yapi vagrant@ubuntu-xenial:~/yapi/docker-yapi$ sudo docker run -d -p 3001:3001 --name yapi --net tools-net --ip 172.18.0.3 yapi b3611d11096e84324bdb31690878031607db1cfd52ab9758ce9bdd03df45c344 vagrant@ubuntu-xenial:~/yapi/docker-yapi$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b3611d11096e yapi \u0026quot;/api/docker-entrypo…\u0026quot; 3 seconds ago Up 3 seconds 0.0.0.0:3001-\u0026gt;3001/tcp yapi 4e2e51837df8 mongo:4 \u0026quot;docker-entrypoint.s…\u0026quot; 2 hours ago Up 2 hours 0.0.0.0:27017-\u0026gt;27017/tcp mongod vagrant@ubuntu-xenial:~/yapi/docker-yapi$ sudo docker logs --tail 10 yapi log: 服务已启动，请打开下面链接访问: http://127.0.0.1:3001/ log: mongodb load success... vagrant@ubuntu-xenial:~/yapi/docker-yapi$  说明启动成功\nvagrant@ubuntu-xenial:~/yapi/docker-yapi$ curl http://localhost:3001/ \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta id=\u0026quot;cross-request-sign\u0026quot; charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;keywords\u0026quot; content=\u0026quot;yapi接口管理,api管理,接口管理,api,接口,接口文档,api文档,接口管理系统\u0026quot; /\u0026gt; \u0026lt;meta name=\u0026quot;description\u0026quot; content=\u0026quot;YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。可以帮助开发者轻松创建、发布、维护 API，YApi 还为用户提供了优秀的交互体验，开发人员只需利用平台提供的接口数 据写入工具以及简单的点击操作就可以实现接口的管理。\u0026quot; /\u0026gt; \u0026lt;title\u0026gt;YApi-高效、易用、功能强大的可视化接口管理平台\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;icon\u0026quot; type=\u0026quot;image/png\u0026quot; sizes=\u0026quot;192x192\u0026quot; href=\u0026quot;/image/favicon.png\u0026quot;\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;script src=\u0026quot;/prd/assets.js?v=' + Math.random() + '\u0026quot;\u0026gt;\u0026lt;\\/script\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;/prd/' + window.WEBPACK_ASSETS['index.js'].css + '\u0026quot; /\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026quot;yapi\u0026quot; style=\u0026quot;height: 100%;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;script src=\u0026quot;/prd/' + window.WEBPACK_ASSETS['manifest'].js + '\u0026quot;\u0026gt;\u0026lt;\\/script\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;script src=\u0026quot;/prd/' + window.WEBPACK_ASSETS['lib3'].js + '\u0026quot;\u0026gt;\u0026lt;\\/script\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;script src=\u0026quot;/prd/' + window.WEBPACK_ASSETS['lib2'].js + '\u0026quot;\u0026gt;\u0026lt;\\/script\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;script src=\u0026quot;/prd/' + window.WEBPACK_ASSETS['lib'].js + '\u0026quot;\u0026gt;\u0026lt;\\/script\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.write('\u0026lt;script src=\u0026quot;/prd/' + window.WEBPACK_ASSETS['index.js'].js + '\u0026quot;\u0026gt;\u0026lt;\\/script\u0026gt;'); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; vagrant@ubuntu-xenial:~/yapi/docker-yapi$  初始化 yapi接口管理 vagrant@ubuntu-xenial:~/yapi/docker-yapi$ sudo docker exec -it yapi sh / # which node /usr/local/bin/node / # node /api/vendors/server/install.js log: mongodb load success... 初始化管理员账号成功,账号名：\u0026quot;ryan.miao@demo.com\u0026quot;，密码：\u0026quot;ymfe.org\u0026quot; / # exit  chrome: http://192.168.168.162:3001 管理员登录,账号名：\u0026rdquo;ryan.miao@demo.com\u0026rdquo;，密码：\u0026rdquo;ymfe.org\u0026rdquo; 成功。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/yapi/yapi-practices.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " 实践 原则  前端是接口的主要发起者, 维护者 后端, 测试与前端交互, 只认YAPI中的接口与测试用例 接口, 有重大修改, 请及时通知相关人 单个接口只完成单个功能 尽可能不要在一个接口中, 返回不同的数据结构, 接口列表与测试集合要配合编写 请先经过相关人员讨论后再编写情况  返回不同的数据结构 参数表达困难 接口功能不清楚   接口列表 下面只说一些注意点, 其它不明的問同事\n编辑接口 基本设置  请使用英文而不是拼音 使用 JSON 交互 当编辑完 测试集合 后, 回到接口列表打 tag  请求函数  中文名称: 操作 - 模块 - 子模块 - 功能名 英文名称: AddUserAccout 大驼峰法: 大写字母开头的驼峰  请求参数  小驼峰法: 小写字母开头的驼峰, 而不是下划线 单参数多值: ,号分隔. 如: users=a,b,c,d 如果是 不同参数值返回不同数据结构,请在 mock和测试集合 中分别加示例,并在备注中指出. 非 Get 请求均要使用 json 格式 Post 请求, 编写时,请导入 JSON 是否为必需,写准确.  如: 当传入 year 时, 与传入 stage , 返回不同结果时, 说明,\n year 且 stage 不是必须的 year 或 stage 是必须的  不合理的做法之一: 此时应该编写为, year 和 stage 都不是必须的, 同时, 在备注头部写上上面2句话, 以让他人理解清楚.\n合理做法: 这种情况, 应当写成2个独立的接口 分别代表:\n 按年获取XXX 按考核阶段获取XXX  备注  写业务或业务逻辑相关的内容. 特殊交待的部分.  如: 当一个 ADD 功能需要 影响其它 Get 功能时, 要明确指出.\n高级MOCK  POST请求 要导入 JSON 每一条 mock要在 测试集合 中分别加示例  测试集合 写完接口列表后,请一定要写上对应位置的测试集合.\n导入接口 把测试集合从接口列表中导入.\n如果之前的接口列表中 接口名称 有修改, 等同于新增一个接口, 则测试集合要重新添加或导入, 同时, 测试集合中原测试用例, 请同时删除.\n选择测试用例环境 请 正确使用 通用规则配置, 如\n 有时, 返回的 code = 0 才是前端想要的结果 有时, 返回 httpCode = 200 才是前端想要的结果  具体测试用例  记得点击 更新 接口列表中的 高级 MOCK 中的每一个MOCK , 都要对应有一个 测试用例, 且要在MOCK环境中, 返回正确结果. 此时, 点击对应接口按键, 返回至接口列表中, 明示, 前端人员确认接口, 后端人员可开始开发.  接口确认 tag tag 全使用 A.B 模式\nA :\n 0 前端编写版本 1 后端开发版本 2 线上版本  B :\n 0 编写出现问题, 需要修复 或 未编写 1 版本号1 11 版本号11     Tags 人员 含义     0.0 后端 前端编写有问题, 一般是后端发现问题, 需要接口修复   0.1 前端 首次编写完成1版本   0.1, 1.1 前后 前端完成1版本, 后端开发环境完成1版本   0.2, 1.1 前后 前端完成2版本, 后端开发环境完成1版本   0.0, 1.1 前后 后端开发环境完成1版本, 发现 前端2版本编写有问题   0.2, 1.2 前后 前端完成2版本, 后端开发环境完成2版本   0.2, 1.2, 2.2 前后 前端完成2版本, 后端开发环境完成2版本, 线上环境完成2版本   0.2, 1.2, 2.1 前后 前端完成2版本, 后端开发环境完成2版本, 线上环境完成1版本    状态 状态:\n 未完成 已完成     状态 人员 含义     未完成 前后 前端编写有问题   已完成 后端 线上完成, 且tag中A.B的所有数字B一致    "
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/zabbix/zabbix.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "zabbix\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/zsh/use-HOME-not-use-bolanghao-in-zshrc.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": "在 编写 ~/.zshrc 的过程中，请不要使用 ~而改为使用 $HOME。\n请直接看下面示例：\n➜ ~ git:(master) ✗ tail -25 ~/.zshrc if [ -f \u0026quot;$HOME/.zshrc.local\u0026quot; ]; then echo \u0026quot;hello\u0026quot; else echo \u0026quot;no .zshrc.local\u0026quot; fi if [ -f \u0026quot;~/.zshrc.local\u0026quot; ]; then echo \u0026quot;hello \u0026quot; else echo \u0026quot;no .zshrc.local\u0026quot; fi echo `pwd` ➜ ~ git:(master) ✗ source ~/.zshrc hello no .zshrc.local /home/ubuntu ➜ ~ git:(master) ✗  使用 $HOME，正确。使用 ~，出错。\n"
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/CA.html",
	"title": "CA",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/CA.html",
	"title": "CA",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/DNS.html",
	"title": "DNS",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ERP.html",
	"title": "ERP",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ERP.html",
	"title": "ERP",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/R.html",
	"title": "R",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/R.html",
	"title": "R",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/Rstudio.html",
	"title": "Rstudio",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/TortoiseSVN.html",
	"title": "TortoiseSVN",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ab.html",
	"title": "ab",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/apple.html",
	"title": "apple",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/apple.html",
	"title": "apple",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/apt.html",
	"title": "apt",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/architect.html",
	"title": "architect",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/architect.html",
	"title": "architect",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/auth.html",
	"title": "auth",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/autohotkey.html",
	"title": "autohotkey",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/autohotkey.html",
	"title": "autohotkey",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/aws.html",
	"title": "aws",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/aws.html",
	"title": "aws",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/babun.html",
	"title": "babun",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/baidu.html",
	"title": "baidu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/before.html",
	"title": "before",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/benchmarks.html",
	"title": "benchmarks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/bitbucket.html",
	"title": "bitbucket",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/bitbucket.html",
	"title": "bitbucket",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/blockchain.html",
	"title": "blockchain",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/blockchain.html",
	"title": "blockchain",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/blog.html",
	"title": "blog",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/blog.html",
	"title": "blog",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/build.html",
	"title": "build",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/bundle.html",
	"title": "bundle",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/bundle.html",
	"title": "bundle",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/categories.html",
	"title": "categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/centos.html",
	"title": "centos",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/centos.html",
	"title": "centos",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ceph.html",
	"title": "ceph",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ceph.html",
	"title": "ceph",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/cephfs.html",
	"title": "cephfs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/certificates.html",
	"title": "certificates",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/channel.html",
	"title": "channel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/charts.html",
	"title": "charts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/charts.html",
	"title": "charts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/cheatsheet.html",
	"title": "cheatsheet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/cheatsheet.html",
	"title": "cheatsheet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/check.html",
	"title": "check",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/chrome.html",
	"title": "chrome",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/chrome.html",
	"title": "chrome",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/cloud-native.html",
	"title": "cloud-native",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/cluster.html",
	"title": "cluster",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/cni.html",
	"title": "cni",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/code.html",
	"title": "code",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/code.html",
	"title": "code",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/command.html",
	"title": "command",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/conf.html",
	"title": "conf",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/config.html",
	"title": "config",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/coreos.html",
	"title": "coreos",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/crawler.html",
	"title": "crawler",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/curl.html",
	"title": "curl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/curl.html",
	"title": "curl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ddos.html",
	"title": "ddos",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ddos.html",
	"title": "ddos",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/decoder.html",
	"title": "decoder",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/delete.html",
	"title": "delete",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/desktop.html",
	"title": "desktop",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/devops.html",
	"title": "devops",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/devops.html",
	"title": "devops",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/discipline.html",
	"title": "discipline",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/distinct.html",
	"title": "distinct",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/django.html",
	"title": "django",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/django.html",
	"title": "django",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/docker.html",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/docker.html",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/docker-compose.html",
	"title": "docker-compose",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/download.html",
	"title": "download",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/easy-hugo.html",
	"title": "easy-hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/emacs.html",
	"title": "emacs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/emacs.html",
	"title": "emacs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/enterprise.html",
	"title": "enterprise",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/enterprise.html",
	"title": "enterprise",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/env.html",
	"title": "env",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/env.html",
	"title": "env",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/erp.html",
	"title": "erp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/erp.html",
	"title": "erp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/eshell.html",
	"title": "eshell",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/eslint.html",
	"title": "eslint",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/eslint.html",
	"title": "eslint",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/export.html",
	"title": "export",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/extensions.html",
	"title": "extensions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/faq.html",
	"title": "faq",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/fdisk.html",
	"title": "fdisk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/file.html",
	"title": "file",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/file-name.html",
	"title": "file-name",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/film.html",
	"title": "film",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/flannel.html",
	"title": "flannel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/flycheck.html",
	"title": "flycheck",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/framework.html",
	"title": "framework",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/framework.html",
	"title": "framework",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ftp.html",
	"title": "ftp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ftp.html",
	"title": "ftp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/galera.html",
	"title": "galera",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gcc.html",
	"title": "gcc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/gem.html",
	"title": "gem",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gem.html",
	"title": "gem",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gfm.html",
	"title": "gfm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/git.html",
	"title": "git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/git.html",
	"title": "git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/gitbook.html",
	"title": "gitbook",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gitbook.html",
	"title": "gitbook",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/github.html",
	"title": "github",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/github.html",
	"title": "github",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/gitlab.html",
	"title": "gitlab",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gitlab.html",
	"title": "gitlab",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/godaddy.html",
	"title": "godaddy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gogland.html",
	"title": "gogland",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/golang.html",
	"title": "golang",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/golang.html",
	"title": "golang",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/golangs.html",
	"title": "golangs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/google.html",
	"title": "google",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/grep.html",
	"title": "grep",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/grep.html",
	"title": "grep",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/gvm.html",
	"title": "gvm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/health.html",
	"title": "health",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/health.html",
	"title": "health",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/healthy.html",
	"title": "healthy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/heapster.html",
	"title": "heapster",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/hedge-fund.html",
	"title": "hedge-fund",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/hedge-fund.html",
	"title": "hedge-fund",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/hello-world.html",
	"title": "hello-world",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/hexo.html",
	"title": "hexo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/hexo.html",
	"title": "hexo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/hotkey.html",
	"title": "hotkey",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/html.html",
	"title": "html",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/html.html",
	"title": "html",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/httpd-tools.html",
	"title": "httpd-tools",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/hugo.html",
	"title": "hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/hugo.html",
	"title": "hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/icard.html",
	"title": "icard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ide.html",
	"title": "ide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/idea.html",
	"title": "idea",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ideas.html",
	"title": "ideas",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/image.html",
	"title": "image",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/images.html",
	"title": "images",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/import.html",
	"title": "import",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/infile.html",
	"title": "infile",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/install.html",
	"title": "install",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/install.html",
	"title": "install",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/interview.html",
	"title": "interview",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/interview.html",
	"title": "interview",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/intro.html",
	"title": "intro",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ip.html",
	"title": "ip",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ip.html",
	"title": "ip",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/iphone.html",
	"title": "iphone",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/iptables.html",
	"title": "iptables",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/iterm2.html",
	"title": "iterm2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/iterm2.html",
	"title": "iterm2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/iwencai.html",
	"title": "iwencai",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/jane.html",
	"title": "jane",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/jaqs.html",
	"title": "jaqs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/javascript.html",
	"title": "javascript",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/javascript.html",
	"title": "javascript",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/jlch.html",
	"title": "jlch",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/kernel.html",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/keybinding.html",
	"title": "keybinding",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/keyboard.html",
	"title": "keyboard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/keyboard.html",
	"title": "keyboard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/kubeadm.html",
	"title": "kubeadm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/kubernetes.html",
	"title": "kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/kubernetes.html",
	"title": "kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/learn.html",
	"title": "learn",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/learn.html",
	"title": "learn",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/life.html",
	"title": "life",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/life.html",
	"title": "life",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/links.html",
	"title": "links",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/linux.html",
	"title": "linux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/linux.html",
	"title": "linux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/login.html",
	"title": "login",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mac.html",
	"title": "mac",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mac.html",
	"title": "mac",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/magit.html",
	"title": "magit",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mail.html",
	"title": "mail",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mail.html",
	"title": "mail",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/make.html",
	"title": "make",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mariadb.html",
	"title": "mariadb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mariadb.html",
	"title": "mariadb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/markdown.html",
	"title": "markdown",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/markdown.html",
	"title": "markdown",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mastercard.html",
	"title": "mastercard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mastercard.html",
	"title": "mastercard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/me.html",
	"title": "me",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/microservices.html",
	"title": "microservices",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/microservices.html",
	"title": "microservices",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mirrors.html",
	"title": "mirrors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mkfs.html",
	"title": "mkfs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mongodb.html",
	"title": "mongodb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mongodb.html",
	"title": "mongodb",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mount.html",
	"title": "mount",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mount.html",
	"title": "mount",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/mysql.html",
	"title": "mysql",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mysql.html",
	"title": "mysql",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mysqldump.html",
	"title": "mysqldump",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/mysqlslap.html",
	"title": "mysqlslap",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/navicat.html",
	"title": "navicat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/network.html",
	"title": "network",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/nfs.html",
	"title": "nfs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/nginx.html",
	"title": "nginx",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/nginx.html",
	"title": "nginx",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ngrok.html",
	"title": "ngrok",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ngrok.html",
	"title": "ngrok",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/nodejs.html",
	"title": "nodejs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/nodejs.html",
	"title": "nodejs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/note.html",
	"title": "note",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/notebook.html",
	"title": "notebook",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/npm.html",
	"title": "npm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/nvm.html",
	"title": "nvm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/openssl.html",
	"title": "openssl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/openstack.html",
	"title": "openstack",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/org.html",
	"title": "org",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/org.html",
	"title": "org",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/oscar.html",
	"title": "oscar",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/oscar.html",
	"title": "oscar",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ox-hugo.html",
	"title": "ox-hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/pandoc.html",
	"title": "pandoc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/panubo.html",
	"title": "panubo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/parted.html",
	"title": "parted",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/passwd.html",
	"title": "passwd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/perl.html",
	"title": "perl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/perl.html",
	"title": "perl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/php.html",
	"title": "php",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/php.html",
	"title": "php",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/pip.html",
	"title": "pip",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/pipenv.html",
	"title": "pipenv",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/port.html",
	"title": "port",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/preview.html",
	"title": "preview",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/privoxy.html",
	"title": "privoxy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/privoxy.html",
	"title": "privoxy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/project.html",
	"title": "project",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/project.html",
	"title": "project",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/protection.html",
	"title": "protection",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/protection.html",
	"title": "protection",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/proxy.html",
	"title": "proxy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/proxy.html",
	"title": "proxy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/pyenv.html",
	"title": "pyenv",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/python.html",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/python.html",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/qor.html",
	"title": "qor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/qor.html",
	"title": "qor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/rancher.html",
	"title": "rancher",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/rancher.html",
	"title": "rancher",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/rar.html",
	"title": "rar",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/react.html",
	"title": "react",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/react.html",
	"title": "react",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/readme.html",
	"title": "readme",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/realtek.html",
	"title": "realtek",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/realtek.html",
	"title": "realtek",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/redis.html",
	"title": "redis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/redis.html",
	"title": "redis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/registry.html",
	"title": "registry",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/registry-ui.html",
	"title": "registry-ui",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/replace.html",
	"title": "replace",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/resource.html",
	"title": "resource",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/resource.html",
	"title": "resource",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/route.html",
	"title": "route",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/rpm.html",
	"title": "rpm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/rst.html",
	"title": "rst",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ruby.html",
	"title": "ruby",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ruby.html",
	"title": "ruby",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/saleor.html",
	"title": "saleor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/saleor.html",
	"title": "saleor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/sapcemacs.html",
	"title": "sapcemacs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/scp.html",
	"title": "scp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/search.html",
	"title": "search",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/sed.html",
	"title": "sed",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/sed.html",
	"title": "sed",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/seo.html",
	"title": "seo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/setup.html",
	"title": "setup",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/shadowsocks.html",
	"title": "shadowsocks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/shadowssocks.html",
	"title": "shadowssocks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/shell.html",
	"title": "shell",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/shell.html",
	"title": "shell",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/shop.html",
	"title": "shop",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/shop.html",
	"title": "shop",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/software.html",
	"title": "software",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/source.html",
	"title": "source",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/spacemacs.html",
	"title": "spacemacs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/spacemacs.html",
	"title": "spacemacs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/sqlalchemy.html",
	"title": "sqlalchemy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ssh.html",
	"title": "ssh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ssh.html",
	"title": "ssh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/sshpass.html",
	"title": "sshpass",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/statefulset.html",
	"title": "statefulset",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/stock.html",
	"title": "stock",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/stock.html",
	"title": "stock",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/storage.html",
	"title": "storage",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/submodules.html",
	"title": "submodules",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/svn.html",
	"title": "svn",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/svn.html",
	"title": "svn",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/taro.html",
	"title": "taro",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/teamviewer.html",
	"title": "teamviewer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/teamviewer.html",
	"title": "teamviewer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/telnet.html",
	"title": "telnet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/telnet.html",
	"title": "telnet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tips.html",
	"title": "tips",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/tmux.html",
	"title": "tmux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tmux.html",
	"title": "tmux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/today.html",
	"title": "today",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/tom.html",
	"title": "tom",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tom.html",
	"title": "tom",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/tomcat.html",
	"title": "tomcat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tomcat.html",
	"title": "tomcat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/tools.html",
	"title": "tools",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tools.html",
	"title": "tools",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tour.html",
	"title": "tour",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/trade.html",
	"title": "trade",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/trade.html",
	"title": "trade",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/travis.html",
	"title": "travis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/travis.html",
	"title": "travis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tty.html",
	"title": "tty",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/tutor.html",
	"title": "tutor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/ubuntu.html",
	"title": "ubuntu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ubuntu.html",
	"title": "ubuntu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/ubunut.html",
	"title": "ubunut",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/undo.html",
	"title": "undo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/update.html",
	"title": "update",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/update-kernel.html",
	"title": "update-kernel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/upgrade.html",
	"title": "upgrade",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/user.html",
	"title": "user",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/version.html",
	"title": "version",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/vi.html",
	"title": "vi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/vi.html",
	"title": "vi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/virtualbox.html",
	"title": "virtualbox",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/virtualbox.html",
	"title": "virtualbox",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/vmware.html",
	"title": "vmware",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/vmware.html",
	"title": "vmware",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/vscode.html",
	"title": "vscode",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/vscode.html",
	"title": "vscode",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/vsftp.html",
	"title": "vsftp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/wechat.html",
	"title": "wechat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/wechat.html",
	"title": "wechat",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/wemux.html",
	"title": "wemux",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/wget.html",
	"title": "wget",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/win10.html",
	"title": "win10",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/win10.html",
	"title": "win10",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/win7.html",
	"title": "win7",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/windows.html",
	"title": "windows",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/windows.html",
	"title": "windows",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/workflow.html",
	"title": "workflow",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/works.html",
	"title": "works",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/works.html",
	"title": "works",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/wubipinyin.html",
	"title": "wubipinyin",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/xmodmap.html",
	"title": "xmodmap",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/xshell.html",
	"title": "xshell",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/yaml.html",
	"title": "yaml",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/yapi.html",
	"title": "yapi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/yapi.html",
	"title": "yapi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/categories/yarn.html",
	"title": "yarn",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/yarn.html",
	"title": "yarn",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/yasnippet.html",
	"title": "yasnippet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/yum.html",
	"title": "yum",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/tags/zsh.html",
	"title": "zsh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://eiuapp.github.io/eiuapp-learn/about/friend.html",
	"title": "友情链接",
	"tags": [],
	"description": "",
	"content": ".tg {border-collapse:collapse;border-spacing:0;border-color:#aabcfe;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#669;background-color:#e8edff;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#aabcfe;color:#039;background-color:#b9c9fe;} .tg .tg-xldj{border-color:inherit;text-align:left} .tg .tg-0lax{text-align:left;vertical-align:top}   宋净超的博客 阳明的博客 漠然 柳清风的专栏 伪架构师   ybyang2 Feisky Cizixs 李佶澳 Reliable Insights  \n"
}]